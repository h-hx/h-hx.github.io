<!-- build time:Mon Nov 01 2021 12:22:10 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-big-counter.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|DejaVu Sans Mono for Powerline:300,300italic,400,400italic,700,700italic|Fira Code:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-flower.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-flower.png?v=5.1.4"><meta name="keywords" content="深度学习,"><meta name="description" content="深度卷积网络：实例探究（Deep convolutional models: case studies）2.1 为什么要进行实例探究？（Why look at case studies?）2.2 经典网络（Classic networks）几个经典的神经网络结构，分别是LeNet-5、AlexNet和VGGNet。LeNet-5LeNet-5是针对灰度图片训练的，所以图片的大小只有32×32×1。"><meta name="keywords" content="深度学习"><meta property="og:type" content="article"><meta property="og:title" content="deeplearning-ai笔记（4-2）"><meta property="og:url" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/index.html"><meta property="og:site_name"><meta property="og:description" content="深度卷积网络：实例探究（Deep convolutional models: case studies）2.1 为什么要进行实例探究？（Why look at case studies?）2.2 经典网络（Classic networks）几个经典的神经网络结构，分别是LeNet-5、AlexNet和VGGNet。LeNet-5LeNet-5是针对灰度图片训练的，所以图片的大小只有32×32×1。"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578138488300.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578138845010.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578138939395.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578138987081.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578139140658.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578139773509.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578139802632.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578139975931.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140035087.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140293483.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140644373.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140679713.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140704131.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578140964494.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578141143371.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578141226588.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578141271135.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578143212903.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578143401827.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578143483443.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578143743255.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578143891216.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578144112173.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578144310002.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578144322983.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578144516090.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578144548581.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578204955725.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578206825367.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578206879425.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578207639812.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578207716978.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578208974931.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578209307727.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578209482900.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578209502543.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578210627409.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578211294007.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578211881806.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578212422490.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578212456366.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578212503005.png"><meta property="og:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578212564151.png"><meta property="og:updated_time" content="2020-01-06T00:39:29.374Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="deeplearning-ai笔记（4-2）"><meta name="twitter:description" content="深度卷积网络：实例探究（Deep convolutional models: case studies）2.1 为什么要进行实例探究？（Why look at case studies?）2.2 经典网络（Classic networks）几个经典的神经网络结构，分别是LeNet-5、AlexNet和VGGNet。LeNet-5LeNet-5是针对灰度图片训练的，所以图片的大小只有32×32×1。"><meta name="twitter:image" content="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/1578138488300.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"5.1.4",sidebar:{position:"right",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/"><title>deeplearning-ai笔记（4-2） |</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-right page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title"></span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/04/deeplearning-ai笔记（4-2）/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="Kikyō"><meta itemprop="description" content><meta itemprop="image" content="/images/kikyo.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content></span><header class="post-header"><h1 class="post-title" itemprop="name headline">deeplearning-ai笔记（4-2）</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-04T19:35:54+08:00">2020-01-04 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于&#58;</span> <time title="更新于" itemprop="dateModified" datetime="2020-01-06T08:39:29+08:00">2020-01-06 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/deeplearning-ai笔记/" itemprop="url" rel="index"><span itemprop="name">deeplearning.ai笔记</span></a></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">10.6k </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">60</span></div></div></header><div class="post-body" itemprop="articleBody"><h2 id="深度卷积网络：实例探究（Deep-convolutional-models-case-studies）"><a href="#深度卷积网络：实例探究（Deep-convolutional-models-case-studies）" class="headerlink" title="深度卷积网络：实例探究（Deep convolutional models: case studies）"></a>深度卷积网络：实例探究（Deep convolutional models: case studies）</h2><h3 id="2-1-为什么要进行实例探究？（Why-look-at-case-studies-）"><a href="#2-1-为什么要进行实例探究？（Why-look-at-case-studies-）" class="headerlink" title="2.1 为什么要进行实例探究？（Why look at case studies?）"></a>2.1 为什么要进行实例探究？（Why look at case studies?）</h3><h3 id="2-2-经典网络（Classic-networks）"><a href="#2-2-经典网络（Classic-networks）" class="headerlink" title="2.2 经典网络（Classic networks）"></a>2.2 经典网络（Classic networks）</h3><p>几个经典的神经网络结构，分别是<strong>LeNet-5</strong>、<strong>AlexNet</strong>和<strong>VGGNet</strong>。</p><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h4><p><strong>LeNet-5</strong>是针对灰度图片训练的，所以图片的大小只有32×32×1。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578138488300.png" alt="1578138488300"></p><p>在LetNet中，存在的经典模式：</p><ul><li>随着网络的深度增加，图像的大小在缩小，与此同时，通道的数量却在增加；</li><li>每个卷积层后面接一个池化层。</li></ul><h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a><strong>AlexNet</strong></h4><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578138845010.png" alt="1578138845010"></p><p>在写这篇论文的时候，<strong>GPU</strong>的处理速度还比较慢，所以<strong>AlexNet</strong>采用了非常复杂的方法在两个<strong>GPU</strong>上进行训练。大致原理是，这些层分别拆分到两个不同的<strong>GPU</strong>上，同时还专门有一个方法用于两个<strong>GPU</strong>进行交流。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578138939395.png" alt="1578138939395"></p><p>经典的<strong>AlexNet</strong>结构还有另一种类型的层，叫作“局部响应归一化层”（<strong>Local Response Normalization</strong>），即<strong>LRN</strong>层。</p><h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578138987081.png" alt="1578138987081"></p><p><strong>VGG-16</strong>的这个数字16，就是指在这个网络中包含16个卷积层和全连接层。确实是个很大的网络，总共包含约1.38亿个参数。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578139140658.png" alt="1578139140658"></p><h3 id="2-3-残差网络-ResNets-（Residual-Networks-ResNets-）"><a href="#2-3-残差网络-ResNets-（Residual-Networks-ResNets-）" class="headerlink" title="2.3 残差网络(ResNets)（Residual Networks (ResNets)）"></a>2.3 残差网络(ResNets)（Residual Networks (ResNets)）</h3><p>非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。跳跃连接（<strong>Skip connection</strong>），它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578139773509.png" alt="1578139773509"></p><p>信息流从$a^{\left\lbrack l \right\rbrack}$到$a^{\left\lbrack l + 2 \right\rbrack}$需要经过以上所有步骤，即这组网络层的主路径。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578139802632.png" alt="1578139802632"></p><p>在残差网络中有一点变化，我们将$a^{[l]}$直接向后，拷贝到神经网络的深层，在<strong>ReLU</strong>非线性激活函数前加上$a^{[l]}$，这是一条捷径。$a^{[l]}$的信息直接到达神经网络的深层，不再沿着主路径传递，这就意味着最后这个等式($a^{\left\lbrack l + 2 \right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack})$)去掉了，取而代之的是另一个<strong>ReLU</strong>非线性函数，仍然对$z^{\left\lbrack l + 2 \right\rbrack}$进行$g$函数处理，但这次要加上$a^{[l]}$，即：$\ a^{\left\lbrack l + 2 \right\rbrack} = g\left(z^{\left\lbrack l + 2 \right\rbrack} + a^{[l]}\right)$，也就是加上的这个$a^{[l]}$产生了一个残差块。</p><p><strong>普通网络（Plain network）</strong></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578139975931.png" alt="1578139975931"></p><p><strong>ResNet</strong></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140035087.png" alt="1578140035087"></p><ul><li>在没有残差的普通神经网络中，训练的误差实际上是随着网络层数的加深，先减小再增加；</li><li><p>在有残差的ResNet中，即使网络再深，训练误差都会随着网络层数的加深逐渐减小。</p><p>ResNet对于中间的激活函数来说，有助于能够达到更深的网络，解决梯度消失和梯度爆炸的问题。</p></li></ul><h3 id="2-4-残差网络为什么有用？（Why-ResNets-work-）"><a href="#2-4-残差网络为什么有用？（Why-ResNets-work-）" class="headerlink" title="2.4 残差网络为什么有用？（Why ResNets work?）"></a>2.4 残差网络为什么有用？（Why ResNets work?）</h3><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140293483.png" alt="1578140293483"></p><p>假设有一个大型神经网络，其输入为$X$，输出激活值$a^{[l]}$。假如你想增加这个神经网络的深度，那么用<strong>Big NN</strong>表示，输出为$ a^{\left\lbrack l\right\rbrack}$。再给这个网络额外添加两层，依次添加两层，最后输出为$a^{\left\lbrack l + 2 \right\rbrack}$，可以把这两层看作一个<strong>ResNets</strong>块，即具有捷径连接的残差块。假设在整个网络中使用<strong>ReLU</strong>激活函数，所以激活值都大于等于0，包括输入$X$的非零异常值。因为<strong>ReLU</strong>激活函数输出的数字要么是0，要么是正数。</p><p>则有$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$。展开这个表达式$a^{\left\lbrack l + 2 \right\rbrack} = g(W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$，其中$z^{\left\lbrack l + 2 \right\rbrack} = W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2\right\rbrack}$。</p><p>如果使用<strong>L2</strong>正则化或权重衰减，它会压缩$W^{\left\lbrack l + 2\right\rbrack}$的值，如果对$b$应用权重衰减也可达到同样的效果。</p><p>假设$W^{\left\lbrack l + 2 \right\rbrack} = 0$，$b^{\left\lbrack l + 2 \right\rbrack} = 0$，这几项就没有了，最后$ a^{\left\lbrack l + 2 \right\rbrack} = \ g\left( a^{[l]} \right) = a^{\left\lbrack l\right\rbrack}$</p><p>结果表明，残差块学习这个恒等式函数并不难，跳跃连接使我们很容易得出$ a^{\left\lbrack l + 2 \right\rbrack} = a^{\left\lbrack l\right\rbrack}$。这意味着，即使给神经网络增加了这两层，它的效率也并不逊色于更简单的神经网络，因为学习恒等函数对它来说很简单。尽管它多了两层，也只把$a^{[l]}$的值赋值给$a^{\left\lbrack l + 2 \right\rbrack}$。所以给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现。</p><p>另外，之所以能实现跳跃连接是因为<strong>same</strong>卷积保留了维度，所以很容易得出这个捷径连接，并输出这两个相同维度的向量。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140644373.png" alt="1578140644373"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140679713.png" alt="1578140679713"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140704131.png" alt="1578140704131"></p><p><strong>ResNets</strong>类似于其它很多网络，也会有很多卷积层，其中偶尔会有池化层或类池化层的层。普通网络和<strong>ResNets</strong>网络常用的结构是：卷积层-卷积层-卷积层-池化层-卷积层-卷积层-卷积层-池化层……依此重复。直到最后，有一个通过<strong>softmax</strong>进行预测的全连接层。</p><h3 id="2-5-网络中的网络以及-1×1-卷积（Network-in-Network-and-1×1-convolutions）"><a href="#2-5-网络中的网络以及-1×1-卷积（Network-in-Network-and-1×1-convolutions）" class="headerlink" title="2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）"></a>2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）</h3><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578140964494.png" alt="1578140964494"></p><p>对于二维，用1×1的过滤器进行卷积，似乎用处不大，只是对输入矩阵乘以某个数字。</p><p>对于三维，1×1×32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字（输入图片中左下角位置32个通道中的数字），即相同高度和宽度上某一切片上的32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用<strong>ReLU</strong>非线性函数，在这里输出相应的结果。</p><p>所以1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为$n_{C}^{\left\lbrack l + 1\right\rbrack}$，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（<strong>non-trivial</strong>）计算。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578141143371.png" alt="1578141143371"></p><p><strong>1x1卷积应用：</strong></p><ul><li>维度压缩：使用目标维度的1×1的卷积核个数。</li><li>增加非线性：保持与原维度相同的1×1的卷积核个数。</li></ul><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578141226588.png" alt="1578141226588"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578141271135.png" alt="1578141271135"></p><h3 id="2-6-谷歌-Inception-网络简介（Inception-network-motivation）"><a href="#2-6-谷歌-Inception-网络简介（Inception-network-motivation）" class="headerlink" title="2.6 谷歌 Inception 网络简介（Inception network motivation）"></a>2.6 谷歌 Inception 网络简介（Inception network motivation）</h3><p>构建卷积层时，<strong>Inception</strong>网络的作用就是代替你来决定过滤器类型，或者确定是否需要创建卷积层或池化层。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578143212903.png" alt="1578143212903"></p><p>在上面的Inception结构中，应用了不同的卷积核，以及带padding的池化层。在保持输入图片大小不变的情况下，通过不同运算结果的叠加，增加了通道的数量。</p><h4 id="计算成本"><a href="#计算成本" class="headerlink" title="计算成本"></a>计算成本</h4><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578143401827.png" alt="1578143401827"></p><p>对于1×1大小卷积核用作过渡的计算成本，也将下面的中间的层叫做“bottleneck layer”：</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578143483443.png" alt="1578143483443"></p><p>所以1×1卷积核作为“bottleneck layer”的过渡层能够有效减小卷积神经网的计算成本。事实证明，只要合理地设置“bottleneck layer”，既可以显著减小上层的规模，同时又能降低计算成本，从而不会影响网络的性能。</p><h3 id="2-7-Inception-网络（Inception-network）"><a href="#2-7-Inception-网络（Inception-network）" class="headerlink" title="2.7 Inception 网络（Inception network）"></a>2.7 Inception 网络（Inception network）</h3><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578143743255.png" alt="1578143743255"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578143891216.png" alt="1578143891216"></p><h3 id="2-8-使用开源的实现方案（Using-open-source-implementations）"><a href="#2-8-使用开源的实现方案（Using-open-source-implementations）" class="headerlink" title="2.8 使用开源的实现方案（Using open-source implementations）"></a>2.8 使用开源的实现方案（Using open-source implementations）</h3><p><strong>ResNets</strong>实现的<strong>GitHub</strong>地址<a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener">https://github.com/KaimingHe/deep-residual-networks</a></p><h3 id="2-9-迁移学习（Transfer-Learning）"><a href="#2-9-迁移学习（Transfer-Learning）" class="headerlink" title="2.9 迁移学习（Transfer Learning）"></a>2.9 迁移学习（Transfer Learning）</h3><p>假如说你要建立一个猫咪检测器，然而你的训练集很小。此时从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。例如<strong>ImageNet</strong>数据集，它有1000个不同的类别，因此这个网络会有一个<strong>Softmax</strong>单元，它可以输出1000个可能类别之一。可以去掉这个<strong>Softmax</strong>层，创建你自己的<strong>Softmax</strong>单元。</p><p>对于使用的框架，它也许会有<code>trainableParameter=0</code>这样的参数，对于这些前面的层，你可能会设置这个参数。为了不训练这些权重，有时也会有<code>freeze=1</code>这样的参数。不同的深度学习编程框架有不同的方式，允许你指定是否训练特定层的权重。在这个例子中，你只需要训练<strong>softmax</strong>层的权重，把前面这些层的权重都冻结。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578144112173.png" alt="1578144112173"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578144310002.png" alt="1578144310002"></p><p>如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这所有的权重当作初始化，然后训练整个网络。如果这是一个1000节点的<strong>softmax</strong>，而你只有三个输出，你需要你自己的<strong>softmax</strong>输出层来输出你要的标签。</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578144322983.png" alt="1578144322983"></p><h3 id="2-10-数据增强（Data-augmentation）"><a href="#2-10-数据增强（Data-augmentation）" class="headerlink" title="2.10 数据增强（Data augmentation）"></a>2.10 数据增强（Data augmentation）</h3><ul><li>镜像翻转（Mirroring）</li><li>随机剪裁（Random Cropping）</li><li>色彩转换（Color shifting）：<br>为图片的RGB三个色彩通道进行增减值，如（R：+20，G：-20，B：+20）；PCA颜色增强：对图片的主色的变化较大，图片的次色变化较小，使总体的颜色保持一致。</li></ul><h3 id="2-11-计算机视觉现状（The-state-of-computer-vision）"><a href="#2-11-计算机视觉现状（The-state-of-computer-vision）" class="headerlink" title="2.11 计算机视觉现状（The state of computer vision）"></a>2.11 计算机视觉现状（The state of computer vision）</h3><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578144516090.png" alt="1578144516090"></p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578144548581.png" alt="1578144548581"></p><h2 id="Keras-tutorial-Emotion-Detection-in-Images-of-Faces"><a href="#Keras-tutorial-Emotion-Detection-in-Images-of-Faces" class="headerlink" title="Keras tutorial - Emotion Detection in Images of Faces"></a>Keras tutorial - Emotion Detection in Images of Faces</h2><p>Welcome to the first assignment of week 2. In this assignment, you will:</p><ol><li>Learn to use Keras, a high-level neural networks API (programming framework), written in Python and capable of running on top of several lower-level frameworks including TensorFlow and CNTK.</li><li>See how you can in a couple of hours build a deep learning algorithm.</li></ol><h3 id="Why-are-we-using-Keras"><a href="#Why-are-we-using-Keras" class="headerlink" title="Why are we using Keras?"></a>Why are we using Keras?</h3><ul><li>Keras was developed to enable deep learning engineers to build and experiment with different models very quickly.</li><li>Just as TensorFlow is a higher-level framework than Python, Keras is an even higher-level framework and provides additional abstractions.</li><li>Being able to go from idea to result with the least possible delay is key to finding good models.</li><li>However, Keras is more restrictive than the lower-level frameworks, so there are some very complex models that you would still implement in TensorFlow rather than in Keras.</li><li>That being said, Keras will work fine for many common models.</li></ul><h3 id="Updates"><a href="#Updates" class="headerlink" title="Updates"></a>Updates</h3><h4 id="If-you-were-working-on-the-notebook-before-this-update…"><a href="#If-you-were-working-on-the-notebook-before-this-update…" class="headerlink" title="If you were working on the notebook before this update…"></a>If you were working on the notebook before this update…</h4><ul><li>The current notebook is version “v2a”.</li><li>You can find your original work saved in the notebook with the previous version name (“v2”).</li><li>To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.</li></ul><h4 id="List-of-updates"><a href="#List-of-updates" class="headerlink" title="List of updates"></a>List of updates</h4><ul><li>Changed back-story of model to “emotion detection” from “happy house.”</li><li>Cleaned/organized wording of instructions and commentary.</li><li>Added instructions on how to set <code>input_shape</code></li><li>Added explanation of “objects as functions” syntax.</li><li>Clarified explanation of variable naming convention.</li><li>Added hints for steps 1,2,3,4</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> layer_utils</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> kt_utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">'channels_last'</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p><strong>Note</strong>: As you can see, we’ve imported a lot of functions from Keras. You can use them by calling them directly in your code. Ex: <code>X = Input(...)</code> or <code>X = ZeroPadding2D(...)</code>.</p><p>In other words, unlike TensorFlow, you don’t have to create the graph and then make a separate <code>sess.run()</code> call to evaluate those variables.</p><h3 id="1-Emotion-Tracking"><a href="#1-Emotion-Tracking" class="headerlink" title="1 - Emotion Tracking"></a>1 - Emotion Tracking</h3><ul><li>A nearby community health clinic is helping the local residents monitor their mental health.</li><li>As part of their study, they are asking volunteers to record their emotions throughout the day.</li><li>To help the participants more easily track their emotions, you are asked to create an app that will classify their emotions based on some pictures that the volunteers will take of their facial expressions.</li><li><p>As a proof-of-concept, you first train your model to detect if someone’s emotion is classified as “happy” or “not happy.”</p><p>To build and train this model, you have gathered pictures of some volunteers in a nearby neighborhood. The dataset is labeled.</p></li></ul><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578204955725.png" alt="1578204955725"></p><p>Run the following code to normalize the dataset and learn about its shapes.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape</span></span><br><span class="line">Y_train = Y_train_orig.T</span><br><span class="line">Y_test = Y_test_orig.T</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of training examples = "</span> + str(X_train.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of test examples = "</span> + str(X_test.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_train shape: "</span> + str(X_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_train shape: "</span> + str(Y_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_test shape: "</span> + str(X_test.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_test shape: "</span> + str(Y_test.shape))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">number of training examples = <span class="number">600</span></span><br><span class="line">number of test examples = <span class="number">150</span></span><br><span class="line">X_train shape: (<span class="number">600</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">Y_train shape: (<span class="number">600</span>, <span class="number">1</span>)</span><br><span class="line">X_test shape: (<span class="number">150</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">Y_test shape: (<span class="number">150</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="2-Building-a-model-in-Keras"><a href="#2-Building-a-model-in-Keras" class="headerlink" title="2 - Building a model in Keras"></a>2 - Building a model in Keras</h3><p>Keras is very good for rapid prototyping. In just a short time you will be able to build a model that achieves outstanding results.</p><p>Here is an example of a model in Keras:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    input_shape: The height, width and channels as a tuple.  </span></span><br><span class="line"><span class="string">        Note that this does not include the 'batch' as a dimension.</span></span><br><span class="line"><span class="string">        If you have a batch like 'X_train', </span></span><br><span class="line"><span class="string">        then you can provide the input_shape using</span></span><br><span class="line"><span class="string">        X_train.shape[1:]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero-Padding: pads the border of X_input with zeroes</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># CONV -&gt; BN -&gt; RELU Block applied to X</span></span><br><span class="line">    X = Conv2D(<span class="number">32</span>, (<span class="number">7</span>, <span class="number">7</span>), strides = (<span class="number">1</span>, <span class="number">1</span>), name = <span class="string">'conv0'</span>)(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">'bn0'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># MAXPOOL</span></span><br><span class="line">    X = MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'max_pool'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># FLATTEN X (means convert it to a vector) + FULLYCONNECTED</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'fc'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create model. This creates your Keras model instance, you'll use this instance to train/test the model.</span></span><br><span class="line">    model = Model(inputs = X_input, outputs = X, name=<span class="string">'HappyModel'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h4 id="Variable-naming-convention"><a href="#Variable-naming-convention" class="headerlink" title="Variable naming convention"></a>Variable naming convention</h4><ul><li>Note that Keras uses a different convention with variable names than we’ve previously used with numpy and TensorFlow.</li><li><p>Instead of creating unique variable names for each step and each layer, such as</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = ...</span><br><span class="line">Z1 = ...</span><br><span class="line">A1 = ...</span><br></pre></td></tr></table></figure></li><li><p>Keras re-uses and overwrites the same variable at each step:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = ...</span><br><span class="line">X = ...</span><br><span class="line">X = ...</span><br></pre></td></tr></table></figure></li><li><p>The exception is <code>X_input</code>, which we kept separate since it’s needed later.</p></li></ul><h4 id="Objects-as-functions"><a href="#Objects-as-functions" class="headerlink" title="Objects as functions"></a>Objects as functions</h4><ul><li><p>Notice how there are two pairs of parentheses in each statement. For example:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = ZeroPadding2D((3, 3))(X_input)</span><br></pre></td></tr></table></figure></li><li><p>The first is a constructor call which creates an object (ZeroPadding2D).</p></li><li>In Python, objects can be called as functions. Search for ‘python object as function and you can read this blog post <a href="https://medium.com/python-pandemonium/function-as-objects-in-python-d5215e6d1b0d" target="_blank" rel="noopener">Python Pandemonium</a>. See the section titled “Objects as functions.”</li><li>The single line is equivalent to this:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ZP = ZeroPadding2D((3, 3)) # ZP is an object that can be called as a function</span><br><span class="line">X = ZP(X_input)</span><br></pre></td></tr></table></figure></li></ul><p><strong>Exercise</strong>: Implement a <code>HappyModel()</code>.</p><ul><li>This assignment is more open-ended than most.</li><li>Start by implementing a model using the architecture we suggest, and run through the rest of this assignment using that as your initial model. * Later, come back and try out other model architectures.</li><li>For example, you might take inspiration from the model above, but then vary the network architecture and hyperparameters however you wish.</li><li>You can also use other functions such as <code>AveragePooling2D()</code>, <code>GlobalMaxPooling2D()</code>, <code>Dropout()</code>.</li></ul><p><strong>Note</strong>: Be careful with your data’s shapes. Use what you’ve learned in the videos to make sure your convolutional, pooling and fully-connected layers are adapted to the volumes you’re applying it to.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: HappyModel</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">HappyModel</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of the HappyModel.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    input_shape -- shape of the images of the dataset</span></span><br><span class="line"><span class="string">        (height, width, channels) as a tuple.  </span></span><br><span class="line"><span class="string">        Note that this does not include the 'batch' as a dimension.</span></span><br><span class="line"><span class="string">        If you have a batch like 'X_train', </span></span><br><span class="line"><span class="string">        then you can provide the input_shape using</span></span><br><span class="line"><span class="string">        X_train.shape[1:]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a Model() instance in Keras</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Feel free to use the suggested outline in the text above to get started, and run through the whole</span></span><br><span class="line">    <span class="comment"># exercise (including the later portions of this notebook) once. The come back also try out other</span></span><br><span class="line">    <span class="comment"># network architectures as well. </span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero-Padding: pads the border of X_input with zeroes</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)  <span class="comment">#(?, 70, 70, 3)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># CONV -&gt; BN -&gt; RELU Block applied to X</span></span><br><span class="line">    X = Conv2D(<span class="number">32</span>, (<span class="number">7</span>, <span class="number">7</span>), strides = (<span class="number">1</span>, <span class="number">1</span>), name = <span class="string">'conv0'</span>)(X) <span class="comment">#(?, 64, 64, 32)</span></span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">'bn0'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># MAXPOOL</span></span><br><span class="line">    X = MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'max_pool'</span>)(X)  <span class="comment">#(?, 32, 32, 32)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># FLATTEN X (means convert it to a vector) + FULLYCONNECTED</span></span><br><span class="line">    X = Flatten()(X)</span><br><span class="line">    X = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'fc'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create model. This creates your Keras model instance, you'll use this instance to train/test the model.</span></span><br><span class="line">    model = Model(inputs = X_input, outputs = X, name=<span class="string">'HappyModel'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>You have now built a function to describe your model. To train and test this model, there are four steps in Keras:</p><ol><li><p>Create the model by calling the function above</p></li><li><p>Compile the model by calling <code>model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;])</code></p></li><li><p>Train the model on train data by calling <code>model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)</code></p></li><li><p>Test the model on test data by calling <code>model.evaluate(x = ..., y = ...)</code></p></li></ol><p>If you want to know more about <code>model.compile()</code>, <code>model.fit()</code>, <code>model.evaluate()</code> and their arguments, refer to the official <a href="https://keras.io/models/model/" target="_blank" rel="noopener">Keras documentation</a>.</p><h4 id="Step-1-create-the-model"><a href="#Step-1-create-the-model" class="headerlink" title="Step 1: create the model."></a>Step 1: create the model.</h4><p><strong>Hint</strong>:<br>The <code>input_shape</code> parameter is a tuple (height, width, channels). It excludes the batch number.<br>Try <code>X_train.shape[1:]</code> as the <code>input_shape</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">happyModel = HappyModel(X_train.shape[<span class="number">1</span>:])</span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br></pre></td></tr></table></figure><h4 id="Step-2-compile-the-model"><a href="#Step-2-compile-the-model" class="headerlink" title="Step 2: compile the model"></a>Step 2: compile the model</h4><p><strong>Hint</strong>:<br>Optimizers you can try include <code>&#39;adam&#39;</code>, <code>&#39;sgd&#39;</code> or others. See the documentation for <a href="https://keras.io/optimizers/" target="_blank" rel="noopener">optimizers</a><br>The “happiness detection” is a binary classification problem. The loss function that you can use is <code>&#39;binary_cross_entropy&#39;</code>. Note that <code>&#39;categorical_cross_entropy&#39;</code> won’t work with your data set as its formatted, because the data is an array of 0 or 1 rather than two arrays (one for each category). Documentation for <a href="https://keras.io/losses/" target="_blank" rel="noopener">losses</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">happyModel.compile(optimizer = <span class="string">"Adam"</span>, loss = <span class="string">"binary_crossentropy"</span>, metrics = [<span class="string">"accuracy"</span>])</span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br></pre></td></tr></table></figure><h4 id="Step-3-train-the-model"><a href="#Step-3-train-the-model" class="headerlink" title="Step 3: train the model"></a>Step 3: train the model</h4><p><strong>Hint</strong>:<br>Use the <code>&#39;X_train&#39;</code>, <code>&#39;Y_train&#39;</code> variables. Use integers for the epochs and batch_size</p><p><strong>Note</strong>: If you run <code>fit()</code> again, the <code>model</code> will continue to train with the parameters it has already learned instead of reinitializing them.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">happyModel.fit(x = X_train, y = Y_train, epochs = <span class="number">10</span>, batch_size = <span class="number">32</span>)</span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578206825367.png" alt="1578206825367"></p><h4 id="Step-4-evaluate-model"><a href="#Step-4-evaluate-model" class="headerlink" title="Step 4: evaluate model"></a>Step 4: evaluate model</h4><p><strong>Hint</strong>:<br>Use the <code>&#39;X_test&#39;</code> and <code>&#39;Y_test&#39;</code> variables to evaluate the model’s performance.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (1 line)</span></span><br><span class="line">preds = happyModel.evaluate(X_test, Y_test)</span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br><span class="line">print()</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Loss = "</span> + str(preds[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Test Accuracy = "</span> + str(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578206879425.png" alt="1578206879425"></p><h4 id="Expected-performance"><a href="#Expected-performance" class="headerlink" title="Expected performance"></a>Expected performance</h4><p>If your <code>happyModel()</code> function worked, its accuracy should be better than random guessing (50% accuracy).</p><p>To give you a point of comparison, our model gets around <strong>95% test accuracy in 40 epochs</strong> (and 99% train accuracy) with a mini batch size of 16 and “adam” optimizer.</p><h4 id="Tips-for-improving-your-model"><a href="#Tips-for-improving-your-model" class="headerlink" title="Tips for improving your model"></a>Tips for improving your model</h4><p>If you have not yet achieved a very good accuracy (&gt;= 80%), here are some things tips:</p><ul><li>Use blocks of CONV-&gt;BATCHNORM-&gt;RELU such as:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), strides = (<span class="number">1</span>, <span class="number">1</span>), name = <span class="string">'conv0'</span>)(X)</span><br><span class="line">X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">'bn0'</span>)(X)</span><br><span class="line">X = Activation(<span class="string">'relu'</span>)(X)</span><br></pre></td></tr></table></figure></li></ul><p>until your height and width dimensions are quite low and your number of channels quite large (≈32 for example).<br>You can then flatten the volume and use a fully-connected layer.</p><ul><li>Use MAXPOOL after such blocks. It will help you lower the dimension in height and width.</li><li>Change your optimizer. We find ‘adam’ works well.</li><li>If you get memory issues, lower your batch_size (e.g. 12 )</li><li>Run more epochs until you see the train accuracy no longer improves.</li></ul><p><strong>Note</strong>: If you perform hyperparameter tuning on your model, the test set actually becomes a dev set, and your model might end up overfitting to the test (dev) set. Normally, you’ll want separate dev and test sets. The dev set is used for parameter tuning, and the test set is used once to estimate the model’s performance in production.</p><h3 id="3-Conclusion"><a href="#3-Conclusion" class="headerlink" title="3 - Conclusion"></a>3 - Conclusion</h3><p>Congratulations, you have created a proof of concept for “happiness detection”!</p><h4 id="Key-Points-to-remember"><a href="#Key-Points-to-remember" class="headerlink" title="Key Points to remember"></a>Key Points to remember</h4><ul><li>Keras is a tool we recommend for rapid prototyping. It allows you to quickly try out different model architectures.</li><li>Remember The four steps in Keras:</li></ul><ol><li>Create</li><li>Compile</li><li>Fit/Train</li><li>Evaluate/Test</li></ol><h3 id="4-Test-with-your-own-image-Optional"><a href="#4-Test-with-your-own-image-Optional" class="headerlink" title="4 - Test with your own image (Optional)"></a>4 - Test with your own image (Optional)</h3><p>Congratulations on finishing this assignment. You can now take a picture of your face and see if it can classify whether your expression is “happy” or “not happy”. To do that:</p><ol><li>Click on “File” in the upper bar of this notebook, then click “Open” to go on your Coursera Hub.</li><li>Add your image to this Jupyter Notebook’s directory, in the “images” folder</li><li>Write your image’s name in the following code</li><li>Run the code and check if the algorithm is right (0 is not happy, 1 is happy)!</li></ol><p>The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try!</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ###</span></span><br><span class="line">img_path = <span class="string">'images/my_image.jpg'</span></span><br><span class="line"><span class="comment">### END CODE HERE ###</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">64</span>, <span class="number">64</span>))</span><br><span class="line">imshow(img)</span><br><span class="line"></span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">print(happyModel.predict(x))</span><br></pre></td></tr></table></figure><h3 id="5-Other-useful-functions-in-Keras-Optional"><a href="#5-Other-useful-functions-in-Keras-Optional" class="headerlink" title="5 - Other useful functions in Keras (Optional)"></a>5 - Other useful functions in Keras (Optional)</h3><p>Two other basic features of Keras that you’ll find useful are:</p><ul><li><code>model.summary()</code>: prints the details of your layers in a table with the sizes of its inputs/outputs</li><li><code>plot_model()</code>: plots your graph in a nice layout. You can even save it as “.png” using SVG() if you’d like to share it on social media ;). It is saved in “File” then “Open…” in the upper bar of the notebook.</li></ul><p>Run the following code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">happyModel.summary()</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578207639812.png" alt="1578207639812"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_model(happyModel, to_file=<span class="string">'HappyModel.png'</span>)</span><br><span class="line">SVG(model_to_dot(happyModel).create(prog=<span class="string">'dot'</span>, format=<span class="string">'svg'</span>))</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578207716978.png" alt="1578207716978"></p><h2 id="Residual-Networks"><a href="#Residual-Networks" class="headerlink" title="Residual Networks"></a>Residual Networks</h2><p>Welcome to the second assignment of this week! You will learn how to build very deep convolutional networks, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by <a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">He et al.</a>, allow you to train much deeper networks than were previously practically feasible.</p><p><strong>In this assignment, you will:</strong></p><ul><li>Implement the basic building blocks of ResNets.</li><li>Put together these building blocks to implement and train a state-of-the-art neural network for image classification.</li></ul><h3 id="Updates-1"><a href="#Updates-1" class="headerlink" title="Updates"></a>Updates</h3><h4 id="If-you-were-working-on-the-notebook-before-this-update…-1"><a href="#If-you-were-working-on-the-notebook-before-this-update…-1" class="headerlink" title="If you were working on the notebook before this update…"></a>If you were working on the notebook before this update…</h4><ul><li>The current notebook is version “2a”.</li><li>You can find your original work saved in the notebook with the previous version name (“v2”)</li><li>To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.</li></ul><h4 id="List-of-updates-1"><a href="#List-of-updates-1" class="headerlink" title="List of updates"></a>List of updates</h4><ul><li>For testing on an image, replaced <code>preprocess_input(x)</code> with <code>x=x/255.0</code> to normalize the input image in the same way that the model’s training data was normalized.</li><li>Refers to “shallower” layers as those layers closer to the input, and “deeper” layers as those closer to the output (Using “shallower” layers instead of “lower” or “earlier”).</li><li>Added/updated instructions.</li></ul><p>This assignment will be done in Keras.</p><p>Before jumping into the problem, let’s run the cell below to load the required packages.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, load_model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> layer_utils</span><br><span class="line"><span class="keyword">from</span> keras.utils.data_utils <span class="keyword">import</span> get_file</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">import</span> pydot</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> SVG</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> model_to_dot</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> resnets_utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br><span class="line"><span class="keyword">import</span> scipy.misc</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> imshow</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line">K.set_image_data_format(<span class="string">'channels_last'</span>)</span><br><span class="line">K.set_learning_phase(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="1-The-problem-of-very-deep-neural-networks"><a href="#1-The-problem-of-very-deep-neural-networks" class="headerlink" title="1 - The problem of very deep neural networks"></a>1 - The problem of very deep neural networks</h3><p>Last week, you built your first convolutional neural network. In recent years, neural networks have become deeper, with state-of-the-art networks going from just a few layers (e.g., AlexNet) to over a hundred layers.</p><ul><li>The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output).</li><li>However, using a deeper network doesn’t always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.</li><li>More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and “explode” to take very large values).</li><li>During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds:</li></ul><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578208974931.png" alt="1578208974931"></p><p>You are now going to solve this problem by building a Residual Network!</p><h3 id="2-Building-a-Residual-Network"><a href="#2-Building-a-Residual-Network" class="headerlink" title="2 - Building a Residual Network"></a>2 - Building a Residual Network</h3><p>In ResNets, a “shortcut” or a “skip connection” allows the model to skip layers:</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578209307727.png" alt="1578209307727"></p><p>The image on the left shows the “main path” through the network. The image on the right adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, you can form a very deep network.</p><p>We also saw in lecture that having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance.</p><p>(There is also some evidence that the ease of learning an identity function accounts for ResNets’ remarkable performance even more so than skip connections helping with vanishing gradients).</p><p>Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are same or different. You are going to implement both of them: the “identity block” and the “convolutional block.”</p><h4 id="2-1-The-identity-block"><a href="#2-1-The-identity-block" class="headerlink" title="2.1 - The identity block"></a>2.1 - The identity block</h4><p>The identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). To flesh out the different steps of what happens in a ResNet’s identity block, here is an alternative diagram showing the individual steps:</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578209482900.png" alt="1578209482900"></p><p>The upper path is the “shortcut path.” The lower path is the “main path.” In this diagram, we have also made explicit the CONV2D and ReLU steps in each layer. To speed up training we have also added a BatchNorm step. Don’t worry about this being complicated to implement—you’ll see that BatchNorm is just one line of code in Keras!</p><p>In this exercise, you’ll actually implement a slightly more powerful version of this identity block, in which the skip connection “skips over” 3 hidden layers rather than 2 layers. It looks like this:</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578209502543.png" alt="1578209502543"></p><p>Here are the individual steps.</p><p>First component of main path:</p><ul><li>The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and its name should be <code>conv_name_base + &#39;2a&#39;</code>. Use 0 as the seed for the random initialization.</li><li>The first BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2a&#39;</code>.</li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p>Second component of main path:</p><ul><li>The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is “same” and its name should be <code>conv_name_base + &#39;2b&#39;</code>. Use 0 as the seed for the random initialization.</li><li>The second BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2b&#39;</code>.</li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p>Third component of main path:</p><ul><li>The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and its name should be <code>conv_name_base + &#39;2c&#39;</code>. Use 0 as the seed for the random initialization.</li><li>The third BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2c&#39;</code>.</li><li>Note that there is <strong>no</strong> ReLU activation function in this component.</li></ul><p>Final step:</p><ul><li>The <code>X_shortcut</code> and the output from the 3rd layer <code>X</code> are added together.</li><li><strong>Hint</strong>: The syntax will look something like <code>Add()([var1,var2])</code></li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p><strong>Exercise</strong>: Implement the ResNet identity block. We have implemented the first component of the main path. Please read this carefully to make sure you understand what it is doing. You should implement the rest.</p><ul><li>To implement the Conv2D step: <a href="https://keras.io/layers/convolutional/#conv2d" target="_blank" rel="noopener">Conv2D</a></li><li>To implement BatchNorm: <a href="https://faroit.github.io/keras-docs/1.2.2/layers/normalization/" target="_blank" rel="noopener">BatchNormalization</a> (axis: Integer, the axis that should be normalized (typically the ‘channels’ axis))</li><li>For the activation, use: <code>Activation(&#39;relu&#39;)(X)</code></li><li>To add the value passed forward by the shortcut: <a href="https://keras.io/layers/merge/#add" target="_blank" rel="noopener">Add</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: identity_block</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block</span><span class="params">(X, f, filters, stage, block)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of the identity block as defined in Figure 4</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    f -- integer, specifying the shape of the middle CONV's window for the main path</span></span><br><span class="line"><span class="string">    filters -- python list of integers, defining the number of filters in the CONV layers of the main path</span></span><br><span class="line"><span class="string">    stage -- integer, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    block -- string/character, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save the input value. You'll need this later to add back to the main path. </span></span><br><span class="line">    X_shortcut = X</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># First component of main path</span></span><br><span class="line">    X = Conv2D(filters = F1, kernel_size = (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">'valid'</span>, name = conv_name_base + <span class="string">'2a'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">'same'</span>, name = conv_name_base + <span class="string">'2b'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2b'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(filters = F3, kernel_size = (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), padding = <span class="string">'valid'</span>, name = conv_name_base + <span class="string">'2c'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> test:</span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    A_prev = tf.placeholder(<span class="string">"float"</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">    X = np.random.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br><span class="line">    A = identity_block(A_prev, f = <span class="number">2</span>, filters = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>], stage = <span class="number">1</span>, block = <span class="string">'a'</span>)</span><br><span class="line">    test.run(tf.global_variables_initializer())</span><br><span class="line">    out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line">    print(<span class="string">"out = "</span> + str(out[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>][<span class="number">0</span>]))</span><br><span class="line"><span class="comment"># out = [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]</span></span><br></pre></td></tr></table></figure><h4 id="2-2-The-convolutional-block"><a href="#2-2-The-convolutional-block" class="headerlink" title="2.2 - The convolutional block"></a>2.2 - The convolutional block</h4><p>The ResNet “convolutional block” is the second block type. You can use this type of block when the input and output dimensions don’t match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path:</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578210627409.png" alt="1578210627409"></p><ul><li>The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.)</li><li>For example, to reduce the activation dimensions’s height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2.</li><li>The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step.</li></ul><p>The details of the convolutional block are as follows.</p><p>First component of main path:</p><ul><li>The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is “valid” and its name should be <code>conv_name_base + &#39;2a&#39;</code>. Use 0 as the <code>glorot_uniform</code> seed.</li><li>The first BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2a&#39;</code>.</li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p>Second component of main path:</p><ul><li>The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is “same” and it’s name should be <code>conv_name_base + &#39;2b&#39;</code>. Use 0 as the <code>glorot_uniform</code> seed.</li><li>The second BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2b&#39;</code>.</li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p>Third component of main path:</p><ul><li>The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and it’s name should be <code>conv_name_base + &#39;2c&#39;</code>. Use 0 as the <code>glorot_uniform</code> seed.</li><li>The third BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;2c&#39;</code>. Note that there is no ReLU activation function in this component.</li></ul><p>Shortcut path:</p><ul><li>The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is “valid” and its name should be <code>conv_name_base + &#39;1&#39;</code>. Use 0 as the <code>glorot_uniform</code> seed.</li><li>The BatchNorm is normalizing the ‘channels’ axis. Its name should be <code>bn_name_base + &#39;1&#39;</code>.</li></ul><p>Final step:</p><ul><li>The shortcut and the main path values are added together.</li><li>Then apply the ReLU activation function. This has no name and no hyperparameters.</li></ul><p><strong>Exercise</strong>: Implement the convolutional block. We have implemented the first component of the main path; you should implement the rest. As before, always use 0 as the seed for the random initialization, to ensure consistency with our grader.</p><ul><li><a href="https://keras.io/layers/convolutional/#conv2d" target="_blank" rel="noopener">Conv2D</a></li><li><a href="https://keras.io/layers/normalization/#batchnormalization" target="_blank" rel="noopener">BatchNormalization</a> (axis: Integer, the axis that should be normalized (typically the features axis))</li><li>For the activation, use: <code>Activation(&#39;relu&#39;)(X)</code></li><li><a href="https://keras.io/layers/merge/#add" target="_blank" rel="noopener">Add</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: convolutional_block</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolutional_block</span><span class="params">(X, f, filters, stage, block, s = <span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of the convolutional block as defined in Figure 4</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)</span></span><br><span class="line"><span class="string">    f -- integer, specifying the shape of the middle CONV's window for the main path</span></span><br><span class="line"><span class="string">    filters -- python list of integers, defining the number of filters in the CONV layers of the main path</span></span><br><span class="line"><span class="string">    stage -- integer, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    block -- string/character, used to name the layers, depending on their position in the network</span></span><br><span class="line"><span class="string">    s -- Integer, specifying the stride to be used</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># defining name basis</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Retrieve Filters</span></span><br><span class="line">    F1, F2, F3 = filters</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Save the input value</span></span><br><span class="line">    X_shortcut = X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">##### MAIN PATH #####</span></span><br><span class="line">    <span class="comment"># First component of main path </span></span><br><span class="line">    X = Conv2D(F1, (<span class="number">1</span>, <span class="number">1</span>), strides = (s,s), name = conv_name_base + <span class="string">'2a'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2a'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Second component of main path (≈3 lines)</span></span><br><span class="line">    X = Conv2D(F2, (f, f), strides = (<span class="number">1</span>,<span class="number">1</span>), name = conv_name_base + <span class="string">'2b'</span>, padding = <span class="string">'same'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X) </span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2b'</span>)(X) </span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Third component of main path (≈2 lines)</span></span><br><span class="line">    X = Conv2D(F3, (<span class="number">1</span>, <span class="number">1</span>), strides = (<span class="number">1</span>,<span class="number">1</span>), name = conv_name_base + <span class="string">'2c'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'2c'</span>)(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment">##### SHORTCUT PATH #### (≈2 lines)</span></span><br><span class="line">    X_shortcut = Conv2D(F3, (<span class="number">1</span>, <span class="number">1</span>), strides = (s,s), name = conv_name_base + <span class="string">'1'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X_shortcut)</span><br><span class="line">    X_shortcut = BatchNormalization(axis = <span class="number">3</span>, name = bn_name_base + <span class="string">'1'</span>)(X_shortcut)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)</span></span><br><span class="line">    X = Add()([X, X_shortcut])</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> test:</span><br><span class="line">    np.random.seed(<span class="number">1</span>)</span><br><span class="line">    A_prev = tf.placeholder(<span class="string">"float"</span>, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">    X = np.random.randn(<span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">6</span>)</span><br><span class="line">    A = convolutional_block(A_prev, f = <span class="number">2</span>, filters = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>], stage = <span class="number">1</span>, block = <span class="string">'a'</span>)</span><br><span class="line">    test.run(tf.global_variables_initializer())</span><br><span class="line">    out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): <span class="number">0</span>&#125;)</span><br><span class="line">    print(<span class="string">"out = "</span> + str(out[<span class="number">0</span>][<span class="number">1</span>][<span class="number">1</span>][<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><h3 id="3-Building-your-first-ResNet-model-50-layers"><a href="#3-Building-your-first-ResNet-model-50-layers" class="headerlink" title="3 - Building your first ResNet model (50 layers)"></a>3 - Building your first ResNet model (50 layers)</h3><p>You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. “ID BLOCK” in the diagram stands for “Identity block,” and “ID BLOCK x3” means you should stack 3 identity blocks together.</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578211294007.png" alt="1578211294007"></p><p>The details of this ResNet-50 model are:</p><ul><li>Zero-padding pads the input with a pad of (3,3)</li><li>Stage 1:<ul><li>The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is “conv1”.</li><li>BatchNorm is applied to the ‘channels’ axis of the input.</li><li>MaxPooling uses a (3,3) window and a (2,2) stride.</li></ul></li><li>Stage 2:<ul><li>The convolutional block uses three sets of filters of size [64,64,256], “f” is 3, “s” is 1 and the block is “a”.</li><li>The 2 identity blocks use three sets of filters of size [64,64,256], “f” is 3 and the blocks are “b” and “c”.</li></ul></li><li>Stage 3:<ul><li>The convolutional block uses three sets of filters of size [128,128,512], “f” is 3, “s” is 2 and the block is “a”.</li><li>The 3 identity blocks use three sets of filters of size [128,128,512], “f” is 3 and the blocks are “b”, “c” and “d”.</li></ul></li><li>Stage 4:<ul><li>The convolutional block uses three sets of filters of size [256, 256, 1024], “f” is 3, “s” is 2 and the block is “a”.</li><li>The 5 identity blocks use three sets of filters of size [256, 256, 1024], “f” is 3 and the blocks are “b”, “c”, “d”, “e” and “f”.</li></ul></li><li>Stage 5:<ul><li>The convolutional block uses three sets of filters of size [512, 512, 2048], “f” is 3, “s” is 2 and the block is “a”.</li><li>The 2 identity blocks use three sets of filters of size [512, 512, 2048], “f” is 3 and the blocks are “b” and “c”.</li></ul></li><li>The 2D Average Pooling uses a window of shape (2,2) and its name is “avg_pool”.</li><li>The ‘flatten’ layer doesn’t have any hyperparameters or name.</li><li>The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be <code>&#39;fc&#39; + str(classes)</code>.</li></ul><p><strong>Exercise</strong>: Implement the ResNet with 50 layers described in the figure above. We have implemented Stages 1 and 2. Please implement the rest. (The syntax for implementing Stages 3-5 should be quite similar to that of Stage 2.) Make sure you follow the naming convention in the text above.</p><p>You’ll need to use this function:</p><ul><li>Average pooling <a href="https://keras.io/layers/pooling/#averagepooling2d" target="_blank" rel="noopener">see reference</a></li></ul><p>Here are some other functions we used in the code below:</p><ul><li>Conv2D: <a href="https://keras.io/layers/convolutional/#conv2d" target="_blank" rel="noopener">See reference</a></li><li>BatchNorm: <a href="https://keras.io/layers/normalization/#batchnormalization" target="_blank" rel="noopener">See reference</a> (axis: Integer, the axis that should be normalized (typically the features axis))</li><li>Zero padding: <a href="https://keras.io/layers/convolutional/#zeropadding2d" target="_blank" rel="noopener">See reference</a></li><li>Max pooling: <a href="https://keras.io/layers/pooling/#maxpooling2d" target="_blank" rel="noopener">See reference</a></li><li>Fully connected layer: <a href="https://keras.io/layers/core/#dense" target="_blank" rel="noopener">See reference</a></li><li>Addition: <a href="https://keras.io/layers/merge/#add" target="_blank" rel="noopener">See reference</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: ResNet50</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ResNet50</span><span class="params">(input_shape = <span class="params">(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span>, classes = <span class="number">6</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implementation of the popular ResNet50 the following architecture:</span></span><br><span class="line"><span class="string">    CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3</span></span><br><span class="line"><span class="string">    -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    input_shape -- shape of the images of the dataset</span></span><br><span class="line"><span class="string">    classes -- integer, number of classes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    model -- a Model() instance in Keras</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Define the input as a tensor with shape input_shape</span></span><br><span class="line">    X_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Zero-Padding</span></span><br><span class="line">    X = ZeroPadding2D((<span class="number">3</span>, <span class="number">3</span>))(X_input)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 1</span></span><br><span class="line">    X = Conv2D(<span class="number">64</span>, (<span class="number">7</span>, <span class="number">7</span>), strides = (<span class="number">2</span>, <span class="number">2</span>), name = <span class="string">'conv1'</span>, kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X)</span><br><span class="line">    X = BatchNormalization(axis = <span class="number">3</span>, name = <span class="string">'bn_conv1'</span>)(X)</span><br><span class="line">    X = Activation(<span class="string">'relu'</span>)(X)</span><br><span class="line">    X = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 2</span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage = <span class="number">2</span>, block=<span class="string">'a'</span>, s = <span class="number">1</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'b'</span>)</span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], stage=<span class="number">2</span>, block=<span class="string">'c'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Stage 3 (≈4 lines) </span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage = <span class="number">3</span>, block=<span class="string">'a'</span>, s = <span class="number">2</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'b'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'c'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], stage=<span class="number">3</span>, block=<span class="string">'d'</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 4 (≈6 lines) </span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage = <span class="number">4</span>, block=<span class="string">'a'</span>, s = <span class="number">2</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'b'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'c'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'d'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'e'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], stage=<span class="number">4</span>, block=<span class="string">'f'</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Stage 5 (≈3 lines) </span></span><br><span class="line">    X = convolutional_block(X, f = <span class="number">3</span>, filters = [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage = <span class="number">5</span>, block=<span class="string">'a'</span>, s = <span class="number">2</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'b'</span>) </span><br><span class="line">    X = identity_block(X, <span class="number">3</span>, [<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], stage=<span class="number">5</span>, block=<span class="string">'c'</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)" </span></span><br><span class="line">    X = AveragePooling2D((<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'avg_pool'</span>)(X) </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output layer </span></span><br><span class="line">    X = Flatten()(X) </span><br><span class="line">    X = Dense(classes, activation=<span class="string">'softmax'</span>, name=<span class="string">'fc'</span> + str(classes), kernel_initializer = glorot_uniform(seed=<span class="number">0</span>))(X) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Create model </span></span><br><span class="line">    model = Model(inputs = X_input, outputs = X, name=<span class="string">'ResNet50'</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>Run the following code to build the model’s graph. If your implementation is not correct you will know it by checking your accuracy when running <code>model.fit(...)</code> below.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet50(input_shape = (<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>), classes = <span class="number">6</span>)</span><br></pre></td></tr></table></figure><p>As seen in the Keras Tutorial Notebook, prior training a model, you need to configure the learning process by compiling the model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure><p>The model is now ready to be trained. The only thing you need is a dataset.</p><p>Let’s load the SIGNS Dataset.</p><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578211881806.png" alt="1578211881806"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize image vectors</span></span><br><span class="line">X_train = X_train_orig/<span class="number">255.</span></span><br><span class="line">X_test = X_test_orig/<span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert training and test labels to one hot matrices</span></span><br><span class="line">Y_train = convert_to_one_hot(Y_train_orig, <span class="number">6</span>).T</span><br><span class="line">Y_test = convert_to_one_hot(Y_test_orig, <span class="number">6</span>).T</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of training examples = "</span> + str(X_train.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"number of test examples = "</span> + str(X_test.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_train shape: "</span> + str(X_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_train shape: "</span> + str(Y_train.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"X_test shape: "</span> + str(X_test.shape))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Y_test shape: "</span> + str(Y_test.shape))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">number of training examples = 1080</span><br><span class="line">number of test examples = 120</span><br><span class="line">X_train shape: (1080, 64, 64, 3)</span><br><span class="line">Y_train shape: (1080, 6)</span><br><span class="line">X_test shape: (120, 64, 64, 3)</span><br><span class="line">Y_test shape: (120, 6)</span><br></pre></td></tr></table></figure><p>Run the following cell to train your model on 2 epochs with a batch size of 32. On a CPU it should take you around 5min per epoch.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, Y_train, epochs = <span class="number">2</span>, batch_size = <span class="number">32</span>)</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578212422490.png" alt="1578212422490"></p><p>Let’s see how this model (trained on only two epochs) performs on the test set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">preds = model.evaluate(X_test, Y_test)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Loss = "</span> + str(preds[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Test Accuracy = "</span> + str(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578212456366.png" alt="1578212456366"></p><p>For the purpose of this assignment, we’ve asked you to train the model for just two epochs. You can see that it achieves poor performances. Please go ahead and submit your assignment; to check correctness, the online grader will run your code only for a small number of epochs as well.</p><p>After you have finished this official (graded) part of this assignment, you can also optionally train the ResNet for more iterations, if you want. We get a lot better performance when we train for ~20 epochs, but this will take more than an hour when training on a CPU.</p><p>Using a GPU, we’ve trained our own ResNet50 model’s weights on the SIGNS dataset. You can load and run our trained model on the test set in the cells below. It may take ≈1min to load the model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = load_model(<span class="string">'ResNet50.h5'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">preds = model.evaluate(X_test, Y_test)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Loss = "</span> + str(preds[<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">"Test Accuracy = "</span> + str(preds[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578212503005.png" alt="1578212503005"></p><p>ResNet50 is a powerful model for image classification when it is trained for an adequate number of iterations. We hope you can use what you’ve learnt and apply it to your own classification problem to perform state-of-the-art accuracy.</p><p>Congratulations on finishing this assignment! You’ve now implemented a state-of-the-art image classification system!</p><h3 id="4-Test-on-your-own-image-Optional-Ungraded"><a href="#4-Test-on-your-own-image-Optional-Ungraded" class="headerlink" title="4 - Test on your own image (Optional/Ungraded)"></a>4 - Test on your own image (Optional/Ungraded)</h3><p>If you wish, you can also take a picture of your own hand and see the output of the model. To do this:</p><pre><code>1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub.
2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder
3. Write your image&#39;s name in the following code
4. Run the code and check if the algorithm is right! 
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">img_path = <span class="string">'images/my_image.jpg'</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">64</span>, <span class="number">64</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">x = x/<span class="number">255.0</span></span><br><span class="line">print(<span class="string">'Input image shape:'</span>, x.shape)</span><br><span class="line">my_image = scipy.misc.imread(img_path)</span><br><span class="line">imshow(my_image)</span><br><span class="line">print(<span class="string">"class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = "</span>)</span><br><span class="line">print(model.predict(x))</span><br></pre></td></tr></table></figure><p><img src="/2020/01/04/deeplearning-ai笔记（4-2）/1578212564151.png" alt="1578212564151"></p><p>You can also print a summary of your model by running the following code.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br></pre></td><td class="code"><pre><span class="line">____________________________________________________________________________________________________</span><br><span class="line">Layer (type)                     Output Shape          Param #     Connected to                     </span><br><span class="line">====================================================================================================</span><br><span class="line">input_1 (InputLayer)             (None, 64, 64, 3)     0                                            </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">zero_padding2d_1 (ZeroPadding2D) (None, 70, 70, 3)     0           input_1[0][0]                    </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">conv1 (Conv2D)                   (None, 32, 32, 64)    9472        zero_padding2d_1[0][0]           </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn_conv1 (BatchNormalization)    (None, 32, 32, 64)    256         conv1[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_4 (Activation)        (None, 32, 32, 64)    0           bn_conv1[0][0]                   </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2D)   (None, 15, 15, 64)    0           activation_4[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2a_branch2a (Conv2D)          (None, 15, 15, 64)    4160        max_pooling2d_1[0][0]            </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2a_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_5 (Activation)        (None, 15, 15, 64)    0           bn2a_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2a_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_5[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2a_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2a_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_6 (Activation)        (None, 15, 15, 64)    0           bn2a_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2a_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_6[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2a_branch1 (Conv2D)           (None, 15, 15, 256)   16640       max_pooling2d_1[0][0]            </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2a_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2a_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2a_branch1 (BatchNormalization (None, 15, 15, 256)   1024        res2a_branch1[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_2 (Add)                      (None, 15, 15, 256)   0           bn2a_branch2c[0][0]              </span><br><span class="line">                                                                   bn2a_branch1[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_7 (Activation)        (None, 15, 15, 256)   0           add_2[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2b_branch2a (Conv2D)          (None, 15, 15, 64)    16448       activation_7[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2b_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_8 (Activation)        (None, 15, 15, 64)    0           bn2b_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2b_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_8[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2b_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2b_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_9 (Activation)        (None, 15, 15, 64)    0           bn2b_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2b_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_9[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2b_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2b_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_3 (Add)                      (None, 15, 15, 256)   0           bn2b_branch2c[0][0]              </span><br><span class="line">                                                                   activation_7[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_10 (Activation)       (None, 15, 15, 256)   0           add_3[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2c_branch2a (Conv2D)          (None, 15, 15, 64)    16448       activation_10[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2c_branch2a (BatchNormalizatio (None, 15, 15, 64)    256         res2c_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_11 (Activation)       (None, 15, 15, 64)    0           bn2c_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2c_branch2b (Conv2D)          (None, 15, 15, 64)    36928       activation_11[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2c_branch2b (BatchNormalizatio (None, 15, 15, 64)    256         res2c_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_12 (Activation)       (None, 15, 15, 64)    0           bn2c_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res2c_branch2c (Conv2D)          (None, 15, 15, 256)   16640       activation_12[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn2c_branch2c (BatchNormalizatio (None, 15, 15, 256)   1024        res2c_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_4 (Add)                      (None, 15, 15, 256)   0           bn2c_branch2c[0][0]              </span><br><span class="line">                                                                   activation_10[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_13 (Activation)       (None, 15, 15, 256)   0           add_4[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3a_branch2a (Conv2D)          (None, 8, 8, 128)     32896       activation_13[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3a_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3a_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_14 (Activation)       (None, 8, 8, 128)     0           bn3a_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3a_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_14[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3a_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3a_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_15 (Activation)       (None, 8, 8, 128)     0           bn3a_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3a_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_15[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3a_branch1 (Conv2D)           (None, 8, 8, 512)     131584      activation_13[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3a_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3a_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3a_branch1 (BatchNormalization (None, 8, 8, 512)     2048        res3a_branch1[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_5 (Add)                      (None, 8, 8, 512)     0           bn3a_branch2c[0][0]              </span><br><span class="line">                                                                   bn3a_branch1[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_16 (Activation)       (None, 8, 8, 512)     0           add_5[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3b_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_16[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3b_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3b_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_17 (Activation)       (None, 8, 8, 128)     0           bn3b_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3b_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_17[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3b_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3b_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_18 (Activation)       (None, 8, 8, 128)     0           bn3b_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3b_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_18[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3b_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3b_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_6 (Add)                      (None, 8, 8, 512)     0           bn3b_branch2c[0][0]              </span><br><span class="line">                                                                   activation_16[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_19 (Activation)       (None, 8, 8, 512)     0           add_6[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3c_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_19[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3c_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3c_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_20 (Activation)       (None, 8, 8, 128)     0           bn3c_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3c_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_20[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3c_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3c_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_21 (Activation)       (None, 8, 8, 128)     0           bn3c_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3c_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_21[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3c_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3c_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_7 (Add)                      (None, 8, 8, 512)     0           bn3c_branch2c[0][0]              </span><br><span class="line">                                                                   activation_19[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_22 (Activation)       (None, 8, 8, 512)     0           add_7[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3d_branch2a (Conv2D)          (None, 8, 8, 128)     65664       activation_22[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3d_branch2a (BatchNormalizatio (None, 8, 8, 128)     512         res3d_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_23 (Activation)       (None, 8, 8, 128)     0           bn3d_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3d_branch2b (Conv2D)          (None, 8, 8, 128)     147584      activation_23[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3d_branch2b (BatchNormalizatio (None, 8, 8, 128)     512         res3d_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_24 (Activation)       (None, 8, 8, 128)     0           bn3d_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res3d_branch2c (Conv2D)          (None, 8, 8, 512)     66048       activation_24[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn3d_branch2c (BatchNormalizatio (None, 8, 8, 512)     2048        res3d_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_8 (Add)                      (None, 8, 8, 512)     0           bn3d_branch2c[0][0]              </span><br><span class="line">                                                                   activation_22[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_25 (Activation)       (None, 8, 8, 512)     0           add_8[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4a_branch2a (Conv2D)          (None, 4, 4, 256)     131328      activation_25[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4a_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4a_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_26 (Activation)       (None, 4, 4, 256)     0           bn4a_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4a_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_26[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4a_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4a_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_27 (Activation)       (None, 4, 4, 256)     0           bn4a_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4a_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_27[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4a_branch1 (Conv2D)           (None, 4, 4, 1024)    525312      activation_25[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4a_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4a_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4a_branch1 (BatchNormalization (None, 4, 4, 1024)    4096        res4a_branch1[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_9 (Add)                      (None, 4, 4, 1024)    0           bn4a_branch2c[0][0]              </span><br><span class="line">                                                                   bn4a_branch1[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_28 (Activation)       (None, 4, 4, 1024)    0           add_9[0][0]                      </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4b_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_28[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4b_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4b_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_29 (Activation)       (None, 4, 4, 256)     0           bn4b_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4b_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_29[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4b_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4b_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_30 (Activation)       (None, 4, 4, 256)     0           bn4b_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4b_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_30[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4b_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4b_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_10 (Add)                     (None, 4, 4, 1024)    0           bn4b_branch2c[0][0]              </span><br><span class="line">                                                                   activation_28[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_31 (Activation)       (None, 4, 4, 1024)    0           add_10[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4c_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_31[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4c_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4c_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_32 (Activation)       (None, 4, 4, 256)     0           bn4c_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4c_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_32[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4c_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4c_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_33 (Activation)       (None, 4, 4, 256)     0           bn4c_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4c_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_33[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4c_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4c_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_11 (Add)                     (None, 4, 4, 1024)    0           bn4c_branch2c[0][0]              </span><br><span class="line">                                                                   activation_31[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_34 (Activation)       (None, 4, 4, 1024)    0           add_11[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4d_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_34[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4d_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4d_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_35 (Activation)       (None, 4, 4, 256)     0           bn4d_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4d_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_35[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4d_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4d_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_36 (Activation)       (None, 4, 4, 256)     0           bn4d_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4d_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_36[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4d_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4d_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_12 (Add)                     (None, 4, 4, 1024)    0           bn4d_branch2c[0][0]              </span><br><span class="line">                                                                   activation_34[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_37 (Activation)       (None, 4, 4, 1024)    0           add_12[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4e_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_37[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4e_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4e_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_38 (Activation)       (None, 4, 4, 256)     0           bn4e_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4e_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_38[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4e_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4e_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_39 (Activation)       (None, 4, 4, 256)     0           bn4e_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4e_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_39[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4e_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4e_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_13 (Add)                     (None, 4, 4, 1024)    0           bn4e_branch2c[0][0]              </span><br><span class="line">                                                                   activation_37[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_40 (Activation)       (None, 4, 4, 1024)    0           add_13[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4f_branch2a (Conv2D)          (None, 4, 4, 256)     262400      activation_40[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4f_branch2a (BatchNormalizatio (None, 4, 4, 256)     1024        res4f_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_41 (Activation)       (None, 4, 4, 256)     0           bn4f_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4f_branch2b (Conv2D)          (None, 4, 4, 256)     590080      activation_41[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4f_branch2b (BatchNormalizatio (None, 4, 4, 256)     1024        res4f_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_42 (Activation)       (None, 4, 4, 256)     0           bn4f_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res4f_branch2c (Conv2D)          (None, 4, 4, 1024)    263168      activation_42[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn4f_branch2c (BatchNormalizatio (None, 4, 4, 1024)    4096        res4f_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_14 (Add)                     (None, 4, 4, 1024)    0           bn4f_branch2c[0][0]              </span><br><span class="line">                                                                   activation_40[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_43 (Activation)       (None, 4, 4, 1024)    0           add_14[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5a_branch2a (Conv2D)          (None, 2, 2, 512)     524800      activation_43[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5a_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5a_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_44 (Activation)       (None, 2, 2, 512)     0           bn5a_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5a_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_44[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5a_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5a_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_45 (Activation)       (None, 2, 2, 512)     0           bn5a_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5a_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_45[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5a_branch1 (Conv2D)           (None, 2, 2, 2048)    2099200     activation_43[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5a_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5a_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5a_branch1 (BatchNormalization (None, 2, 2, 2048)    8192        res5a_branch1[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_15 (Add)                     (None, 2, 2, 2048)    0           bn5a_branch2c[0][0]              </span><br><span class="line">                                                                   bn5a_branch1[0][0]               </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_46 (Activation)       (None, 2, 2, 2048)    0           add_15[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5b_branch2a (Conv2D)          (None, 2, 2, 512)     1049088     activation_46[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5b_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5b_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_47 (Activation)       (None, 2, 2, 512)     0           bn5b_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5b_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_47[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5b_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5b_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_48 (Activation)       (None, 2, 2, 512)     0           bn5b_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5b_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_48[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5b_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5b_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_16 (Add)                     (None, 2, 2, 2048)    0           bn5b_branch2c[0][0]              </span><br><span class="line">                                                                   activation_46[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_49 (Activation)       (None, 2, 2, 2048)    0           add_16[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5c_branch2a (Conv2D)          (None, 2, 2, 512)     1049088     activation_49[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5c_branch2a (BatchNormalizatio (None, 2, 2, 512)     2048        res5c_branch2a[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_50 (Activation)       (None, 2, 2, 512)     0           bn5c_branch2a[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5c_branch2b (Conv2D)          (None, 2, 2, 512)     2359808     activation_50[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5c_branch2b (BatchNormalizatio (None, 2, 2, 512)     2048        res5c_branch2b[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_51 (Activation)       (None, 2, 2, 512)     0           bn5c_branch2b[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">res5c_branch2c (Conv2D)          (None, 2, 2, 2048)    1050624     activation_51[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">bn5c_branch2c (BatchNormalizatio (None, 2, 2, 2048)    8192        res5c_branch2c[0][0]             </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">add_17 (Add)                     (None, 2, 2, 2048)    0           bn5c_branch2c[0][0]              </span><br><span class="line">                                                                   activation_49[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">activation_52 (Activation)       (None, 2, 2, 2048)    0           add_17[0][0]                     </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_52[0][0]              </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)              (None, 2048)          0           avg_pool[0][0]                   </span><br><span class="line">____________________________________________________________________________________________________</span><br><span class="line">fc6 (Dense)                      (None, 6)             12294       flatten_1[0][0]                  </span><br><span class="line">====================================================================================================</span><br><span class="line">Total params: 23,600,006</span><br><span class="line">Trainable params: 23,546,886</span><br><span class="line">Non-trainable params: 53,120</span><br><span class="line">____________________________________________________________________________________________________</span><br></pre></td></tr></table></figure><p>Finally, run the code below to visualize your ResNet50. You can also download a .png picture of your model by going to “File -&gt; Open…-&gt; model.png”.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_model(model, to_file=<span class="string">'model.png'</span>)</span><br><span class="line">SVG(model_to_dot(model).create(prog=<span class="string">'dot'</span>, format=<span class="string">'svg'</span>))</span><br></pre></td></tr></table></figure><h3 id="What-you-should-remember"><a href="#What-you-should-remember" class="headerlink" title="What you should remember"></a>What you should remember</h3><ul><li>Very deep “plain” networks don’t work in practice because they are hard to train due to vanishing gradients.</li><li>The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function.</li><li>There are two main types of blocks: The identity block and the convolutional block.</li><li>Very deep Residual Networks are built by stacking these blocks together.</li></ul><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>This notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the GitHub repository of Francois Chollet:</p><ul><li>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - <a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition (2015)</a></li><li>Francois Chollet’s GitHub repository: <a href="https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py" target="_blank" rel="noopener">https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py</a></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://mooc.study.163.com/university/deeplearning_ai#/c" target="_blank" rel="noopener">https://mooc.study.163.com/university/deeplearning_ai#/c</a></p><p><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">https://www.coursera.org/specializations/deep-learning</a></p><p><a href="https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes" target="_blank" rel="noopener">https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes</a></p><p><a href="https://blog.csdn.net/Koala_Tree/article/details/79913655" target="_blank" rel="noopener">https://blog.csdn.net/Koala_Tree/article/details/79913655</a></p></div><div><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束-------------</div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019/11/22/deeplearning-ai笔记（4-1）/" rel="next" title="deeplearning-ai笔记（4-1）"><i class="fa fa-chevron-left"></i> deeplearning-ai笔记（4-1）</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2020/01/06/deeplearning-ai笔记（4-3）/" rel="prev" title="deeplearning-ai笔记（4-3）">deeplearning-ai笔记（4-3） <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/kikyo.jpg" alt="Kikyō"><p class="site-author-name" itemprop="name">Kikyō</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">41</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">4</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">8</span> <span class="site-state-item-name">标签</span></a></div></nav></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#深度卷积网络：实例探究（Deep-convolutional-models-case-studies）"><span class="nav-text">深度卷积网络：实例探究（Deep convolutional models: case studies）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-为什么要进行实例探究？（Why-look-at-case-studies-）"><span class="nav-text">2.1 为什么要进行实例探究？（Why look at case studies?）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-经典网络（Classic-networks）"><span class="nav-text">2.2 经典网络（Classic networks）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LeNet-5"><span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AlexNet"><span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#VGGNet"><span class="nav-text">VGGNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-残差网络-ResNets-（Residual-Networks-ResNets-）"><span class="nav-text">2.3 残差网络(ResNets)（Residual Networks (ResNets)）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-残差网络为什么有用？（Why-ResNets-work-）"><span class="nav-text">2.4 残差网络为什么有用？（Why ResNets work?）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-网络中的网络以及-1×1-卷积（Network-in-Network-and-1×1-convolutions）"><span class="nav-text">2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-谷歌-Inception-网络简介（Inception-network-motivation）"><span class="nav-text">2.6 谷歌 Inception 网络简介（Inception network motivation）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#计算成本"><span class="nav-text">计算成本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-Inception-网络（Inception-network）"><span class="nav-text">2.7 Inception 网络（Inception network）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-8-使用开源的实现方案（Using-open-source-implementations）"><span class="nav-text">2.8 使用开源的实现方案（Using open-source implementations）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-9-迁移学习（Transfer-Learning）"><span class="nav-text">2.9 迁移学习（Transfer Learning）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-10-数据增强（Data-augmentation）"><span class="nav-text">2.10 数据增强（Data augmentation）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-11-计算机视觉现状（The-state-of-computer-vision）"><span class="nav-text">2.11 计算机视觉现状（The state of computer vision）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keras-tutorial-Emotion-Detection-in-Images-of-Faces"><span class="nav-text">Keras tutorial - Emotion Detection in Images of Faces</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-are-we-using-Keras"><span class="nav-text">Why are we using Keras?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Updates"><span class="nav-text">Updates</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#If-you-were-working-on-the-notebook-before-this-update…"><span class="nav-text">If you were working on the notebook before this update…</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#List-of-updates"><span class="nav-text">List of updates</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Emotion-Tracking"><span class="nav-text">1 - Emotion Tracking</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Building-a-model-in-Keras"><span class="nav-text">2 - Building a model in Keras</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Variable-naming-convention"><span class="nav-text">Variable naming convention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Objects-as-functions"><span class="nav-text">Objects as functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step-1-create-the-model"><span class="nav-text">Step 1: create the model.</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step-2-compile-the-model"><span class="nav-text">Step 2: compile the model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step-3-train-the-model"><span class="nav-text">Step 3: train the model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Step-4-evaluate-model"><span class="nav-text">Step 4: evaluate model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Expected-performance"><span class="nav-text">Expected performance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Tips-for-improving-your-model"><span class="nav-text">Tips for improving your model</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Conclusion"><span class="nav-text">3 - Conclusion</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Key-Points-to-remember"><span class="nav-text">Key Points to remember</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Test-with-your-own-image-Optional"><span class="nav-text">4 - Test with your own image (Optional)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Other-useful-functions-in-Keras-Optional"><span class="nav-text">5 - Other useful functions in Keras (Optional)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Residual-Networks"><span class="nav-text">Residual Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Updates-1"><span class="nav-text">Updates</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#If-you-were-working-on-the-notebook-before-this-update…-1"><span class="nav-text">If you were working on the notebook before this update…</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#List-of-updates-1"><span class="nav-text">List of updates</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-The-problem-of-very-deep-neural-networks"><span class="nav-text">1 - The problem of very deep neural networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Building-a-Residual-Network"><span class="nav-text">2 - Building a Residual Network</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-The-identity-block"><span class="nav-text">2.1 - The identity block</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-The-convolutional-block"><span class="nav-text">2.2 - The convolutional block</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Building-your-first-ResNet-model-50-layers"><span class="nav-text">3 - Building your first ResNet model (50 layers)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Test-on-your-own-image-Optional-Ungraded"><span class="nav-text">4 - Test on your own image (Optional/Ungraded)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-you-should-remember"><span class="nav-text">What you should remember</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-text">参考资料</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">Kikyō</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">Site words total count&#58;</span> <span title="Site words total count">165.7k</span></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,r=document.getElementById(e),s=document.getElementById(o),a=function(){var t=r.value.trim().toLowerCase(),e=t.split(/[\s\-]+/);e.length>1&&e.push(t);var o=[];if(t.length>0&&n.forEach(function(n){function r(e,o,n,r){for(var s=r[r.length-1],a=s.position,i=s.word,l=[],h=0;a+i.length<=n&&0!=r.length;){i===t&&h++,l.push({position:a,length:i.length});var p=a+i.length;for(r.pop();0!=r.length&&(s=r[r.length-1],a=s.position,i=s.word,p>a);)r.pop()}return c+=h,{hits:l,start:o,end:n,searchTextCount:h}}function s(t,e){var o="",n=e.start;return e.hits.forEach(function(e){o+=t.substring(n,e.position);var r=e.position+e.length;o+='<b class="search-keyword">'+t.substring(e.position,r)+"</b>",n=r}),o+=t.substring(n,e.end)}var a=!1,i=0,c=0,l=n.title.trim(),h=l.toLowerCase(),p=n.content.trim().replace(/<[^>]+>/g,""),u=p.toLowerCase(),f=decodeURIComponent(n.url),d=[],g=[];if(""!=l&&(e.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());(s=e.indexOf(t,r))>-1;)a.push({position:s,word:t}),r=s+n;return a}d=d.concat(e(t,h,!1)),g=g.concat(e(t,u,!1))}),(d.length>0||g.length>0)&&(a=!0,i=d.length+g.length)),a){[d,g].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var v=[];0!=d.length&&v.push(r(l,0,l.length,d));for(var $=[];0!=g.length;){var C=g[g.length-1],m=C.position,x=C.word,w=m-20,y=m+80;0>w&&(w=0),y<m+x.length&&(y=m+x.length),y>p.length&&(y=p.length),$.push(r(p,w,y,g))}$.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var T=parseInt("1");T>=0&&($=$.slice(0,T));var b="";b+=0!=v.length?"<li><a href='"+f+"' class='search-result-title'>"+s(l,v[0])+"</a>":"<li><a href='"+f+"' class='search-result-title'>"+l+"</a>",$.forEach(function(t){b+="<a href='"+f+'\'><p class="search-result">'+s(p,t)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:c,hitCount:i,id:o.length})}}),1===e.length&&""===e[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{o.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var a='<ul class="search-result-list">';o.forEach(function(t){a+=t.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),isfetched===!1?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){var e=27===t.which&&$(".search-popup").is(":visible");e&&onPopupClose()})</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html><!-- rebuild by neat -->