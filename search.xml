<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（一）]]></title>
    <url>%2F2019%2F08%2F14%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[神经网络和深度学习—神经网络基础（Basics of Neural Network programming）二分类（Binary Classification）符号定义 ：$x$：表示一个$n_x$维数据，为输入数据，维度为$(n_x,1)$；$y$：表示输出结果，取值为$(0,1)$；$(x^{(i)},y^{(i)})$：表示第$i$组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据；$X=[x^{(1)},x^{(2)},…,x^{(m)}]$：表示所有的训练数据集的输入值，放在一个 $n_x×m$的矩阵中，其中$m$表示样本数目;$Y=[y^{(1)},y^{(2)},…,y^{(m)}]$：对应表示所有训练数据集的输出值，维度为$1×m$。逻辑回归（Logistic Regression）逻辑回归中：$\hat{y}={w}^{T}x+b$引入$sigmoid$函数：$\begin{align}\sigma \left( z \right)&amp;=\frac{1}{1+{e^{-z}}} \\ \sigma’(z)&amp;=\frac{1}{(1+{e^{-z}})^2}\times e^{-z}\\ &amp;=\sigma(z)\frac{e^{-z}}{1+{e^{-z}}}\\ &amp;=\sigma(z)(1-\sigma(z))\end{align}$定义$\hat{y}=\sigma \left( {\theta ^{T}}x \right)$的sigmoid函数。有一组参数向量${\theta _{0}},{\theta _{1}},{\theta_{2}},…,{\theta _{n_{x}}}$，此时${\theta_{0}}$就充当了$b$，而剩下的${\theta_{1}}$ 直到${\theta_{n_{x}}}$充当了$w$$\theta.shape=(w.shape+1,1)$逻辑回归的代价函数（Logistic Regression Cost Function）逻辑回归中用到的损失函数是：$L\left( \hat{y},y \right)=-y\log(\hat{y})-(1-y)\log (1-\hat{y})$，不使用平方错误是因为平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。当$y=1$时，$L=-\log (\hat{y})$，如果$\hat{y}$越接近1，$L\left( \hat{y},y \right)\approx 0$，表示预测效果越好。当$y=0$时，$L=-\log (1-\hat{y})$，如果$\hat{y}$越接近0，$L\left( \hat{y},y \right)\approx 0$，表示预测效果越好。算法的代价函数是对$m$个样本的损失函数求和然后除以$m$:$J\left( w,b \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( {\hat{y}^{(i)}},{y^{(i)}} \right)}=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( -{y^{(i)}}\log {\hat{y}^{(i)}}-(1-{y^{(i)}})\log (1-{\hat{y}^{(i)}}) \right)}$梯度下降法（Gradient Descent）用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。每次迭代更新的修正表达式：$ w:=w-\alpha\dfrac{\partial J(w,b)}{\partial w}$$b:=b-\alpha\dfrac{\partial J(w,b)}{\partial b}$$\partial $ 表示求偏导符号，可以读作round，$\frac{\partial J(w,b)}{\partial w}$ 就是函数$J(w,b)$ 对$w$ 求偏导，在代码中我们会使用$dw$ 表示这个结果，$\frac{\partial J(w,b)}{\partial b}$ 就是函数$J(w,b)$对$b$ 求偏导，在代码中我们会使用$db$ 表示这个结果，小写字母$d$ 用在求导数（derivative），即函数只有一个参数，偏导数符号$\partial $ 用在求偏导（partial derivative），即函数含有两个以上的参数。逻辑回归中的梯度下降（Logistic Regression Gradient Descent）假设样本只有两个特征${x_{1}}$和${x_{2}}$，为了计算$z$，我们需要输入参数${w_1}$、${w_2}$ 和$b$，除此之外还有特征值${x_1}$和${x_2}$。因此$z$的计算公式为：$z={w_1}{x_1}+{w_2}{x_2}+b$回想一下逻辑回归的公式定义如下：$\hat{y}=a=\sigma (z)$其中$z={w^T}x+b$$\sigma \left( z \right)=\frac{1}{1+e^{-z}}$损失函数：$L( {\hat{y}^{(i)}},{y^{(i)}})=-{y^{(i)}}\log {\hat{y}^{(i)}}-(1-{y^{(i)}})\log (1-{\hat{y}^{(i)}})$代价函数：$J\left( w,b \right)=\frac{1}{m}\sum \nolimits_{i}^{m}{L( {\hat{y}^{(i)}},{y^{(i)}})}$假设现在只考虑单个样本的情况，单个样本的代价函数定义如下：$L(a,y)=-(y\log (a)+(1-y)\log (1-a))$反向传播过程：前面过程的da、dz求导：$da = \dfrac{\partial L}{\partial a}=-\dfrac{y}{a}+\dfrac{1-y}{1-a}\\dz = \dfrac{\partial L}{\partial z}=\dfrac{\partial L}{\partial a}\cdot\dfrac{\partial a}{\partial z}=(-\dfrac{y}{a}+\dfrac{1-y}{1-a})\cdot a(1-a)=a-y$再对w1、w2和b进行求导：$dw_{1} = \dfrac{\partial L}{\partial w_{1}}=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial w_{1}}=x_{1}\cdot dz=x_{1}(a-y)$$db = \dfrac{\partial L}{\partial b }=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial b }=1\cdot dz=a-y$梯度下降法：$w_{1}:=w_{1}-\alpha dw_{1}$$w_{2}:=w_{2}-\alpha dw_{2}$$b:=b-\alpha db$推导过程导数：一阶泰勒展开式这里需要一点数学基础，对泰勒展开式有些了解。简单地来说，一阶泰勒展开式利用的就是函数的局部线性近似这个概念。我们以一阶泰勒展开式为例：A和B均为向量，α为两个向量之间的夹角。A和B的乘积为：m 个样本的梯度下降（Gradient Descent on m Examples）对m个样本来说，其Cost function表达式如下：$z^{(i)}= w^{T}x^{(i)}+b\\\hat y^{(i)}=a^{(i)}=\sigma(z^{(i)})\\J(w,b)=\dfrac{1}{m}\sum \limits_{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum \limits_{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]$Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式：$dw_{1} =\dfrac{1}{m}\sum \limits_{i=1}^{m}x_{1}^{(i)}(a^{(i)}-y^{(i)})$$db = \dfrac{1}{m}\sum \limits_{i=1}^{m}(a^{(i)}-y^{(i)})$向量化（Vectorization）在逻辑回归中你需要去计算$z=w^Tx+b$，$w$、$x$都是列向量。如果你有很多的特征那么就会有一个非常大的向量，所以$w\in {\mathbb{R}^{n_{x}}}$ , $x\in{\mathbb{R}^{n_{x}}}$，所以如果你想使用非向量化方法去计算${w^T}x$，你需要用如下方式（python）123456z = 0for i in range(n_x): z += w[i]*x[i] z += b这是一个非向量化的实现，你会发现这真的很慢，作为一个对比，向量化实现将会非常直接计算$w^Tx$，代码如下：z=np.dot(w,x)+ba=sigmoid(z)逻辑回归向量化输入矩阵$X$：$(n_x,m)$权重矩阵$w$：$(n_x,1)$偏置$b$：为一个常数输出矩阵$Y$：$(1,m)$所有m个样本的线性输出Z可以用矩阵表示：$Z=w^TX+b$$dZ$对于m个样本，维度为$(1,m)$，表示为： $dZ = A - Y$$db$表示为： $db = \dfrac{1}{m}\sum \limits _{i=1}^{m}dz^{(i)}$$dw表示为： $$dw = \dfrac{1}{m}X\cdot dZ^{T}$单次迭代梯度下降算法流程12345678Z = np.dot(w.T,X) + bA = sigmoid(Z)dZ = A-Ydw = 1/m*np.dot(X,dZ.T)db = 1/m*np.sum(dZ)w = w - alpha*dwb = b - alpha*db关于Python的numpy点乘：np.multiply(a,b)矩阵乘法：np.dot(a,b) 或 np.matmul(a,b) 或 a.dot(b)*在 np.array 为点乘，在 np.matrix 为矩阵乘法np.outer 表示的是两个向量相乘，拿第一个向量的元素分别与第二个向量所有元素相乘得到结果的一行理解好秩、轴和纬度logistic 损失函数的解释（Explanation of logistic regression cost function）Cost function的由来：预测输出$\hat{y}$的表达式：$\hat y =\sigma(w^{T}x+b)$其中，$\sigma(z)=\dfrac{1}{1+e^{-z}}$$\hat{y}$可以看作预测输出为正类（+1）的概率：$\hat y = P(y=1|x)$当$y=1$时，$P(y|x)=\hat y$；$y=0$时，$P(y|x)=1-\hat y$$P(y|x)=\hat y^{y}(1-\hat y )^{(1-y)}$,两边取$log$$\log P(y|x)=\log\left[\hat y^{y}(1-\hat y )^{(1-y)}\right]=y\log\hat y+(1-y)\log(1-\hat y)$Loss function，我们期望其值越小越好：$L(\hat y, y)=-(y\log\hat y+(1-y)\log(1-\hat y))$对于m个训练样本来说，假设样本之间是独立同分布的，我们总是希望训练样本判断正确的概率越大越好，则有：$\max \prod\limits_{i=1}^{m} {P(y^{(i)}|x^{(i)})}$同样引入$log$函数，加负号，则可以得到Cost function：$J(w,b)=\dfrac{1}{m}\sum \limits _{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum \limits _{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]$作业Python Basics with Numpy (optional assignment)Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.Instructions:Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.You will learn to:Build the general architecture of a learning algorithm, including:Initializing parametersCalculating the cost function and its gradientUsing an optimization algorithm (gradient descent)Gather all three functions above into a main model function, in the right order.1 - Building basic functions with numpyNumpy is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org). In this exercise you will learn several key numpy functions such as np.exp, np.log, and np.reshape. You will need to know how to use these functions for future assignments.1.1 - sigmoid function, np.exp()Before using np.exp(), you will use math.exp() to implement the sigmoid function. You will then see why np.exp() is preferable to math.exp().Exercise: Build a function that returns the sigmoid of a real number x. Use math.exp(x) for the exponential function.Reminder:$sigmoid(x) = \frac{1}{1+e^{-x}}$ is sometimes also known as the logistic function. It is a non-linear function used not only in Machine Learning (Logistic Regression), but also in Deep Learning.To refer to a function belonging to a specific package you could call it using package_name.function(). Run the code below to see an example with math.exp().1234567891011121314151617181920# GRADED FUNCTION: basic_sigmoidimport mathdef basic_sigmoid(x): """ Compute sigmoid of x. Arguments: x -- A scalar Return: s -- sigmoid(x) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0 / (1 + math.exp(-1.0 * x)) ### END CODE HERE ### return s12basic_sigmoid(3)# 0.9525741268224334Actually, we rarely use the “math” library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful.123### One reason why we use "numpy" instead of "math" in Deep Learning ###x = [1, 2, 3]basic_sigmoid(x) # you will see this give an error when you run it, because x is a vector.In fact, if $ x = (x_1, x_2, …, x_n)$ is a row vector then $np.exp(x)$ will apply the exponential function to every element of x. The output will thus be: $np.exp(x) = (e^{x_1}, e^{x_2}, …, e^{x_n})$12345import numpy as np# example of np.expx = np.array([1, 2, 3])print(np.exp(x)) # result is (exp(1), exp(2), exp(3))Furthermore, if x is a vector, then a Python operation such as $s = x + 3$ or $s = \frac{1}{x}$ will output s as a vector of the same size as x.123# example of vector operationx = np.array([1, 2, 3])print (x + 3)Any time you need more info on a numpy function, we encourage you to look at the official documentation.You can also create a new cell in the notebook and write np.exp? (for example) to get quick access to the documentation.Exercise: Implement the sigmoid function using numpy.Instructions: x could now be either a real number, a vector, or a matrix. The data structures we use in numpy to represent these shapes (vectors, matrices…) are called numpy arrays. You don’t need to know more for now.\text{For } x \in \mathbb{R}^n \text{, } sigmoid(x) = sigmoid\begin{pmatrix} x_1 \\ x_2 \\ ... \\ x_n \\ \end{pmatrix} = \begin{pmatrix} \frac{1}{1+e^{-x_1}} \\ \frac{1}{1+e^{-x_2}} \\ ... \\ \frac{1}{1+e^{-x_n}} \\ \end{pmatrix}1234567891011121314151617181920# GRADED FUNCTION: sigmoidimport numpy as np # this means you can access numpy functions by writing np.function() instead of numpy.function()def sigmoid(x): """ Compute the sigmoid of x Arguments: x -- A scalar or numpy array of any size Return: s -- sigmoid(x) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0 / (1 + np.exp(-1.0 * x)) ### END CODE HERE ### return s123x = np.array([1, 2, 3])sigmoid(x)# array([ 0.73105858, 0.88079708, 0.95257413])1.2 - Sigmoid gradientAs you’ve seen in lecture, you will need to compute gradients to optimize loss functions using backpropagation. Let’s code your first gradient function.Exercise: Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is:sigmoid\_derivative(x) = \sigma'(x) = \sigma(x) (1 - \sigma(x))You often code this function in two steps:Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.Compute $\sigma’(x) = s(1-s)$1234567891011121314151617181920# GRADED FUNCTION: sigmoid_derivativedef sigmoid_derivative(x): """ Compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x. You can store the output of the sigmoid function into variables and then use it to calculate the gradient. Arguments: x -- A scalar or numpy array Return: ds -- Your computed gradient. """ ### START CODE HERE ### (≈ 2 lines of code) s = 1.0 / (1 + np.exp(-1.0 * x)) ds = s * (1 - s) ### END CODE HERE ### return ds123x = np.array([1, 2, 3])print ("sigmoid_derivative(x) = " + str(sigmoid_derivative(x)))# sigmoid_derivative(x) = [ 0.19661193 0.10499359 0.04517666]1.3 - Reshaping arraysTwo common numpy functions used in deep learning are np.shape and np.reshape().X.shape is used to get the shape (dimension) of a matrix/vector X.X.reshape(…) is used to reshape X into some other dimension.For example, in computer science, an image is represented by a 3D array of shape $(length, height, depth = 3)$. However, when you read an image as the input of an algorithm you convert it to a vector of shape $(lengthheight3, 1)$. In other words, you “unroll”, or reshape, the 3D array into a 1D vector.Exercise: Implement image2vector() that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:1v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = cPlease don’t hardcode the dimensions of image as a constant. Instead look up the quantities you need with image.shape[0], etc.123456789101112131415# GRADED FUNCTION: image2vectordef image2vector(image): """ Argument: image -- a numpy array of shape (length, height, depth) Returns: v -- a vector of shape (length*height*depth, 1) """ ### START CODE HERE ### (≈ 1 line of code) v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1)) ### END CODE HERE ### return v1234567891011121314# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB valuesimage = np.array([[[ 0.67826139, 0.29380381], [ 0.90714982, 0.52835647], [ 0.4215251 , 0.45017551]], [[ 0.92814219, 0.96677647], [ 0.85304703, 0.52351845], [ 0.19981397, 0.27417313]], [[ 0.60659855, 0.00533165], [ 0.10820313, 0.49978937], [ 0.34144279, 0.94630077]]])print ("image2vector(image) = " + str(image2vector(image)))123456789101112131415161718image2vector(image) = [[ 0.67826139] [ 0.29380381] [ 0.90714982] [ 0.52835647] [ 0.4215251 ] [ 0.45017551] [ 0.92814219] [ 0.96677647] [ 0.85304703] [ 0.52351845] [ 0.19981397] [ 0.27417313] [ 0.60659855] [ 0.00533165] [ 0.10820313] [ 0.49978937] [ 0.34144279] [ 0.94630077]]1.4 - Normalizing rowsAnother common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean changing x to $ \frac{x}{| x|} $ (dividing each row vector of x by its norm).For example, ifx = \begin{bmatrix} 0 & 3 & 4 \\ 2 & 6 & 4 \\ \end{bmatrix}then\| x\| = np.linalg.norm(x, axis = 1, keepdims = True) = \begin{bmatrix} 5 \\ \sqrt{56} \\ \end{bmatrix}andx\_normalized = \frac{x}{\| x\|} = \begin{bmatrix} 0 & \frac{3}{5} & \frac{4}{5} \\ \frac{2}{\sqrt{56}} & \frac{6}{\sqrt{56}} & \frac{4}{\sqrt{56}} \\ \end{bmatrix}Note that you can divide matrices of different sizes and it works fine: this is called broadcasting and you’re going to learn about it in part 5.Exercise: Implement normalizeRows() to normalize the rows of a matrix. After applying this function to an input matrix x, each row of x should be a vector of unit length (meaning length 1).12345678910111213141516171819202122# GRADED FUNCTION: normalizeRowsdef normalizeRows(x): """ Implement a function that normalizes each row of the matrix x (to have unit length). Argument: x -- A numpy matrix of shape (n, m) Returns: x -- The normalized (by row) numpy matrix. You are allowed to modify x. """ ### START CODE HERE ### (≈ 2 lines of code) # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True) x_norm = np.linalg.norm(x, axis=1, keepdims = True) # Divide x by its norm. x = x / x_norm ### END CODE HERE ### return x123456x = np.array([ [0, 3, 4], [1, 6, 4]])print("normalizeRows(x) = " + str(normalizeRows(x)))# normalizeRows(x) = [[ 0. 0.6 0.8 ]# [ 0.13736056 0.82416338 0.54944226]]Note:In normalizeRows(), you can try to print the shapes of x_norm and x, and then rerun the assessment. You’ll find out that they have different shapes. This is normal given that x_norm takes the norm of each row of x. So x_norm has the same number of rows but only 1 column. So how did it work when you divided x by x_norm? This is called broadcasting and we’ll talk about it now!1.5 - Broadcasting and the softmax functionA very important concept to understand in numpy is “broadcasting”. It is very useful for performing mathematical operations between arrays of different shapes. For the full details on broadcasting, you can read the official broadcasting documentation.Exercise: Implement a softmax function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about softmax in the second course of this specialization.Instructions:$\begin{align} \text{for } x \in \mathbb{R}^{1\times n} \text{, } softmax(x) &amp;= softmax(\begin{bmatrix}x_1 &amp;&amp;x_2 &amp;&amp;… &amp;&amp;x_n\end{bmatrix}) \\&amp;= \begin{bmatrix}\frac{e^{x_1}}{\sum_{j}e^{x_j}} &amp;&amp;\frac{e^{x_2}}{\sum_{j}e^{x_j}} &amp;&amp;… &amp;&amp;\frac{e^{x_n}}{\sum_{j}e^{x_j}}\end{bmatrix} \end{align}$\text{for a matrix } x \in \mathbb{R}^{m \times n} \text{, $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }\begin{align}softmax(x) &= softmax\begin{bmatrix} x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\ x_{21} & x_{22} & x_{23} & \dots & x_{2n} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & x_{m3} & \dots & x_{mn} \end{bmatrix} \\&= \begin{bmatrix} \frac{e^{x_{11}}}{\sum_{j}e^{x_{1j}}} & \frac{e^{x_{12}}}{\sum_{j}e^{x_{1j}}} & \frac{e^{x_{13}}}{\sum_{j}e^{x_{1j}}} & \dots & \frac{e^{x_{1n}}}{\sum_{j}e^{x_{1j}}} \\ \frac{e^{x_{21}}}{\sum_{j}e^{x_{2j}}} & \frac{e^{x_{22}}}{\sum_{j}e^{x_{2j}}} & \frac{e^{x_{23}}}{\sum_{j}e^{x_{2j}}} & \dots & \frac{e^{x_{2n}}}{\sum_{j}e^{x_{2j}}} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ \frac{e^{x_{m1}}}{\sum_{j}e^{x_{mj}}} & \frac{e^{x_{m2}}}{\sum_{j}e^{x_{mj}}} & \frac{e^{x_{m3}}}{\sum_{j}e^{x_{mj}}} & \dots & \frac{e^{x_{mn}}}{\sum_{j}e^{x_{mj}}} \end{bmatrix} \\ &= \begin{pmatrix} softmax\text{(first row of x)} \\ softmax\text{(second row of x)} \\ ... \\ softmax\text{(last row of x)} \\ \end{pmatrix} \end{align}123456789101112131415161718192021222324252627# GRADED FUNCTION: softmaxdef softmax(x): """Calculates the softmax for each row of the input x. Your code should work for a row vector and also for matrices of shape (n, m). Argument: x -- A numpy matrix of shape (n,m) Returns: s -- A numpy matrix equal to the softmax of x, of shape (n,m) """ ### START CODE HERE ### (≈ 3 lines of code) # Apply exp() element-wise to x. Use np.exp(...). x_exp = np.exp(x) # n x m # Create a vector x_sum that sums each row of x_exp. Use np.sum(..., axis = 1, keepdims = True). x_sum = np.sum(x_exp, axis = 1, keepdims = True) # n x 1 # Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting. s = x_exp / x_sum ### END CODE HERE ### return s12345678x = np.array([ [9, 2, 5, 0, 0], [7, 5, 0, 0 ,0]])print("softmax(x) = " + str(softmax(x)))# softmax(x) = [[ 9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04# 1.21052389e-04]# [ 8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04 # 8.01252314e-04]]Note:If you print the shapes of x_exp, x_sum and s above and rerun the assessment cell, you will see that x_sum is of shape (2,1) while x_exp and s are of shape (2,5). x_exp/x_sum works due to python broadcasting.Congratulations! You now have a pretty good understanding of python numpy and have implemented a few useful functions that you will be using in deep learning.What you need to remember:np.exp(x) works for any np.array x and applies the exponential function to every coordinatethe sigmoid function and its gradientimage2vector is commonly used in deep learningnp.reshape is widely used. In the future, you’ll see that keeping your matrix/vector dimensions straight will go toward eliminating a lot of bugs.numpy has efficient built-in functionsbroadcasting is extremely useful2) VectorizationIn deep learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is computationally efficient, you will use vectorization. For example, try to tell the difference between the following implementations of the dot/outer/elementwise product.123456789101112131415161718192021222324252627282930313233343536373839import timex1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###tic = time.process_time()dot = 0for i in range(len(x1)): dot+= x1[i]*x2[i]toc = time.process_time()print ("dot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC OUTER PRODUCT IMPLEMENTATION ###tic = time.process_time()outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zerosfor i in range(len(x1)): for j in range(len(x2)): outer[i,j] = x1[i]*x2[j]toc = time.process_time()print ("outer = " + str(outer) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC ELEMENTWISE IMPLEMENTATION ###tic = time.process_time()mul = np.zeros(len(x1))for i in range(len(x1)): mul[i] = x1[i]*x2[i]toc = time.process_time()print ("elementwise multiplication = " + str(mul) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy arraytic = time.process_time()gdot = np.zeros(W.shape[0])for i in range(W.shape[0]): for j in range(len(x1)): gdot[i] += W[i,j]*x1[j]toc = time.process_time()print ("gdot = " + str(gdot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")12345678910111213141516171819202122232425262728293031323334353637dot = 278 ----- Computation time = 0.0818910000000006msouter = [[ 81. 18. 18. 81. 0. 81. 18. 45. 0. 0. 81. 18. 45. 0. 0.] [ 18. 4. 4. 18. 0. 18. 4. 10. 0. 0. 18. 4. 10. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 63. 14. 14. 63. 0. 63. 14. 35. 0. 0. 63. 14. 35. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 81. 18. 18. 81. 0. 81. 18. 45. 0. 0. 81. 18. 45. 0. 0.] [ 18. 4. 4. 18. 0. 18. 4. 10. 0. 0. 18. 4. 10. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] ----- Computation time = 0.36966300000007557mselementwise multiplication = [ 81. 4. 10. 0. 0. 63. 10. 0. 0. 0. 81. 4. 25. 0. 0.] ----- Computation time = 0.10338200000004072msgdot = [ 24.54816166 26.72329382 24.6612841 ] ----- Computation time = 0.24241599999985652ms1234567891011121314151617181920212223242526x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]### VECTORIZED DOT PRODUCT OF VECTORS ###tic = time.process_time()dot = np.dot(x1,x2)toc = time.process_time()print ("dot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED OUTER PRODUCT ###tic = time.process_time()outer = np.outer(x1,x2)toc = time.process_time()print ("outer = " + str(outer) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED ELEMENTWISE MULTIPLICATION ###tic = time.process_time()mul = np.multiply(x1,x2)toc = time.process_time()print ("elementwise multiplication = " + str(mul) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED GENERAL DOT PRODUCT ###tic = time.process_time()dot = np.dot(W,x1)toc = time.process_time()print ("gdot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")12345678910111213141516171819202122dot = 278 ----- Computation time = 0.08295099999999778msouter = [[81 18 18 81 0 81 18 45 0 0 81 18 45 0 0] [18 4 4 18 0 18 4 10 0 0 18 4 10 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [63 14 14 63 0 63 14 35 0 0 63 14 35 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [81 18 18 81 0 81 18 45 0 0 81 18 45 0 0] [18 4 4 18 0 18 4 10 0 0 18 4 10 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] ----- Computation time = 0.1127830000000607mselementwise multiplication = [81 4 10 0 0 63 10 0 0 0 81 4 25 0 0] ----- Computation time = 0.11321799999985949msgdot = [ 24.54816166 26.72329382 24.6612841 ] ----- Computation time = 0.06825100000007467msAs you may have noticed, the vectorized implementation is much cleaner and more efficient. For bigger vectors/matrices, the differences in running time become even bigger.Note that np.dot() performs a matrix-matrix or matrix-vector multiplication. This is different from np.multiply() and the * operator (which is equivalent to .* in Matlab/Octave), which performs an element-wise multiplication.2.1 Implement the L1 and L2 loss functionsExercise: Implement the numpy vectorized version of the L1 loss. You may find the function abs(x) (absolute value of x) useful.Reminder:The loss is used to evaluate the performance of your model. The bigger your loss is, the more different your predictions ($ \hat{y} $) are from the true values ($y$). In deep learning, you use optimization algorithms like Gradient Descent to train your model and to minimize the cost.L1 loss is defined as:\begin{align} & L_1(\hat{y}, y) = \sum_{i=0}^m|y^{(i)} - \hat{y}^{(i)}| \end{align}1234567891011121314151617# GRADED FUNCTION: L1def L1(yhat, y): """ Arguments: yhat -- vector of size m (predicted labels) y -- vector of size m (true labels) Returns: loss -- the value of the L1 loss function defined above """ ### START CODE HERE ### (≈ 1 line of code) loss = np.sum(np.abs(y - yhat)) ### END CODE HERE ### return loss1234yhat = np.array([.9, 0.2, 0.1, .4, .9])y = np.array([1, 0, 0, 1, 1])print("L1 = " + str(L1(yhat,y)))# L1 = 1.1Exercise: Implement the numpy vectorized version of the L2 loss. There are several way of implementing the L2 loss but you may find the function np.dot() useful. As a reminder, if $x = [x_1, x_2, …, x_n]$, then np.dot(x,x) = $\sum_{j=0}^n x_j^{2}$.L2 loss is defined as\begin{align} & L_2(\hat{y},y) = \sum_{i=0}^m(y^{(i)} - \hat{y}^{(i)})^2 \end{align}1234567891011121314151617# GRADED FUNCTION: L2def L2(yhat, y): """ Arguments: yhat -- vector of size m (predicted labels) y -- vector of size m (true labels) Returns: loss -- the value of the L2 loss function defined above """ ### START CODE HERE ### (≈ 1 line of code) loss = np.sum(np.power(y - yhat, 2)) ### END CODE HERE ### return loss1234yhat = np.array([.9, 0.2, 0.1, .4, .9])y = np.array([1, 0, 0, 1, 1])print("L2 = " + str(L2(yhat,y)))# L2 = 0.43Congratulations on completing this assignment. We hope that this little warm-up exercise helps you in the future assignments, which will be more exciting and interesting!What to remember:Vectorization is very important in deep learning. It provides computational efficiency and clarity.You have reviewed the L1 and L2 loss.You are familiar with many numpy functions such as np.sum, np.dot, np.multiply, np.maximum, etc…Logistic Regression with a Neural Network mindsetWelcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.Instructions:Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.You will learn to:Build the general architecture of a learning algorithm, including:Initializing parametersCalculating the cost function and its gradientUsing an optimization algorithm (gradient descent)Gather all three functions above into a main model function, in the right order.1 - PackagesFirst, let’s run the cell below to import all the packages that you will need during this assignment.numpy is the fundamental package for scientific computing with Python.h5py is a common package to interact with a dataset that is stored on an H5 file.matplotlib is a famous library to plot graphs in Python.PIL and scipy are used here to test your model with your own picture at the end.123456789import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset%matplotlib inline2 - Overview of the Problem setProblem Statement: You are given a dataset (“data.h5”) containing:- a training set of m_train images labeled as cat (y=1) or non-cat (y=0) - a test set of m_test images labeled as cat or non-cat - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px). You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat.Let’s get more familiar with the dataset. Load the data by running the following code.12# Loading the data (cat/non-cat)train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()We added “_orig” at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don’t need any preprocessing).Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the index value and re-run to see other images.1234# Example of a pictureindex = 25plt.imshow(train_set_x_orig[index])print ("y = " + str(train_set_y[:, index]) + ", it's a '" + classes[np.squeeze(train_set_y[:, index])].decode("utf-8") + "' picture.")Many software bugs in deep learning come from having matrix/vector dimensions that don’t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs.Exercise: Find the values for:123- m_train (number of training examples)- m_test (number of test examples)- num_px (= height = width of a training image)Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0].1234567891011121314### START CODE HERE ### (≈ 3 lines of code)m_train = train_set_x_orig.shape[0]m_test = test_set_x_orig.shape[0]num_px = train_set_x_orig.shape[1]### END CODE HERE ###print ("Number of training examples: m_train = " + str(m_train))print ("Number of testing examples: m_test = " + str(m_test))print ("Height/Width of each image: num_px = " + str(num_px))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_set_x shape: " + str(train_set_x_orig.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x shape: " + str(test_set_x_orig.shape))print ("test_set_y shape: " + str(test_set_y.shape))12345678Number of training examples: m_train = 209Number of testing examples: m_test = 50Height/Width of each image: num_px = 64Each image is of size: (64, 64, 3)train_set_x shape: (209, 64, 64, 3)train_set_y shape: (1, 209)test_set_x shape: (50, 64, 64, 3)test_set_y shape: (1, 50)For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $$ num_px $$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.Exercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $$ num_px $$ 3, 1).A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$$c$$d, a) is to use:X_flatten = X.reshape(X.shape[0], -1).T # X.T is the transpose of X123456789101112# Reshape the training and test examples### START CODE HERE ### (≈ 2 lines of code)train_set_x_flatten = train_set_x_orig.reshape(m_train, -1).Ttest_set_x_flatten = test_set_x_orig.reshape(m_test, -1).T### END CODE HERE ###print ("train_set_x_flatten shape: " + str(train_set_x_flatten.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))print ("test_set_y shape: " + str(test_set_y.shape))print ("sanity check after reshaping: " + str(train_set_x_flatten[0:5,0]))12345train_set_x_flatten shape: (12288, 209)train_set_y shape: (1, 209)test_set_x_flatten shape: (12288, 50)test_set_y shape: (1, 50)sanity check after reshaping: [17 31 56 22 33]To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).Let’s standardize our dataset.12train_set_x = train_set_x_flatten/255.test_set_x = test_set_x_flatten/255.What you need to remember:Common steps for pre-processing a new dataset are:Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …)Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)“Standardize” the data3 - General Architecture of the learning algorithmIt’s time to design a simple algorithm to distinguish cat images from non-cat images.You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why Logistic Regression is actually a very simple Neural Network!Mathematical expression of the algorithm:For one example $x^{(i)}$:$z^{(i)} = w^T x^{(i)} + b$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$ \mathcal{L}(a^{(i)}, y^{(i)}) = - y^{(i)} \log(a^{(i)}) - (1-y^{(i)} ) \log(1-a^{(i)})$The cost is then computed by summing over all training examples:J = \frac{1}{m} \sum \limits_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})Key steps:In this exercise, you will carry out the following steps:1234- Initialize the parameters of the model- Learn the parameters for the model by minimizing the cost - Use the learned parameters to make predictions (on the test set)- Analyse the results and conclude4 - Building the parts of our algorithmThe main steps for building a Neural Network are:Define the model structure (such as number of input features)Initialize the model’s parametersLoop:Calculate current loss (forward propagation)Calculate current gradient (backward propagation)Update parameters (gradient descent)You often build 1-3 separately and integrate them into one function we call model().4.1 - Helper functionsExercise: Using your code from “Python Basics”, implement sigmoid(). As you’ve seen in the figure above, you need to compute $sigmoid( w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. Use np.exp().123456789101112131415161718# GRADED FUNCTION: sigmoiddef sigmoid(z): """ Compute the sigmoid of z Arguments: z -- A scalar or numpy array of any size. Return: s -- sigmoid(z) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0/(1+np.exp(-z)) ### END CODE HERE ### return s12print ("sigmoid([0, 2]) = " + str(sigmoid(np.array([0,2]))))# sigmoid([0, 2]) = [ 0.5 0.88079708]4.2 - Initializing parametersExercise: Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don’t know what numpy function to use, look up np.zeros() in the Numpy library’s documentation.1234567891011121314151617181920212223# GRADED FUNCTION: initialize_with_zerosdef initialize_with_zeros(dim): """ This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0. Argument: dim -- size of the w vector we want (or number of parameters in this case) Returns: w -- initialized vector of shape (dim, 1) b -- initialized scalar (corresponds to the bias) """ ### START CODE HERE ### (≈ 1 line of code) w = np.zeros((dim, 1)) b = 0 ### END CODE HERE ### assert(w.shape == (dim, 1)) assert(isinstance(b, float) or isinstance(b, int)) return w, b1234567dim = 2w, b = initialize_with_zeros(dim)print ("w = " + str(w))print ("b = " + str(b))# w = [[ 0.]# [ 0.]]# b = 0For image inputs, w will be of shape (num_px $\times$ num_px $\times$ 3, 1).4.3 - Forward and Backward propagationNow that your parameters are initialized, you can do the “forward” and “backward” propagation steps for learning the parameters.Exercise: Implement a function propagate() that computes the cost function and its gradient.Hints:Forward Propagation:You get XYou compute $A = \sigma(w^T X + b) = (a^{(1)}, a^{(2)}, …, a^{(m-1)}, a^{(m)})$You calculate the cost function: $J = -\frac{1}{m}\sum \limits_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$Here are the two formulas you will be using:$\frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T$$\frac{\partial J}{\partial b} = \frac{1}{m} \sum \limits_{i=1}^m (a^{(i)}-y^{(i)}) $1234567891011121314151617181920212223242526272829303132333435363738394041424344# GRADED FUNCTION: propagatedef propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(np.dot(w.T, X)+b) # compute activation cost = (-1.0 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = (1.0 / m) * np.dot(X,(A-Y).T) db = (1.0 / m) * np.sum(A-Y) ### END CODE HERE ### assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) assert(cost.shape == ()) grads = &#123;"dw": dw, "db": db&#125; return grads, cost123456789w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])grads, cost = propagate(w, b, X, Y)print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"]))print ("cost = " + str(cost))# dw = [[ 0.99845601]# [ 2.39507239]]# db = 0.00145557813678# cost = 5.801545319394.4 - OptimizationYou have initialized your parameters.You are also able to compute a cost function and its gradient.Now, you want to update the parameters using gradient descent.Exercise: Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\theta$, the update rule is $ \theta = \theta - \alpha \text{ } d\theta$, where $\alpha$ is the learning rate.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# GRADED FUNCTION: optimizedef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): """ This function optimizes w and b by running a gradient descent algorithm Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of shape (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- True to print the loss every 100 steps Returns: params -- dictionary containing the weights w and bias b grads -- dictionary containing the gradients of the weights and bias with respect to the cost function costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve. Tips: You basically need to write down two steps and iterate through them: 1) Calculate the cost and the gradient for the current parameters. Use propagate(). 2) Update the parameters using gradient descent rule for w and b. """ costs = [] for i in range(num_iterations): # Cost and gradient calculation (≈ 1-4 lines of code) ### START CODE HERE ### grads, cost = propagate(w, b, X, Y) ### END CODE HERE ### # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # update rule (≈ 2 lines of code) ### START CODE HERE ### w = w - learning_rate * dw b = b - learning_rate * db ### END CODE HERE ### # Record the costs if i % 100 == 0: costs.append(cost) # Print the cost every 100 training iterations if print_cost and i % 100 == 0: print ("Cost after iteration %i: %f" %(i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs123456params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print ("w = " + str(params["w"]))print ("b = " + str(params["b"]))print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"]))123456w = [[ 0.19033591] [ 0.12259159]]b = 1.92535983008dw = [[ 0.67752042] [ 1.41625495]]db = 0.219194504541Exercise: The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function. There are two steps to computing predictions:Calculate $\hat{Y} = A = \sigma(w^T X + b)$Convert the entries of a into 0 (if activation &lt;= 0.5) or 1 (if activation &gt; 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this).12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: predictdef predict(w, b, X): ''' Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Returns: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X ''' m = X.shape[1] Y_prediction = np.zeros((1,m)) w = w.reshape(X.shape[0], 1) # Compute vector "A" predicting the probabilities of a cat being present in the picture ### START CODE HERE ### (≈ 1 line of code) A = sigmoid(np.dot(w.T, X) + b) ### END CODE HERE ### for i in range(A.shape[1]): # Convert probabilities A[0,i] to actual predictions p[0,i] ### START CODE HERE ### (≈ 4 lines of code) if A[0,i] &gt; 0.5: Y_prediction[0,i] = 1 else: Y_prediction[0,i] = 0 ### END CODE HERE ### assert(Y_prediction.shape == (1, m)) return Y_prediction12345w = np.array([[0.1124579],[0.23106775]])b = -0.3X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])print ("predictions = " + str(predict(w, b, X)))# predictions = [[ 1. 1. 0.]]What to remember:You’ve implemented several functions that:Initialize (w,b)Optimize the loss iteratively to learn parameters (w,b):computing the cost and its gradientupdating the parameters using gradient descentUse the learned (w,b) to predict the labels for a given set of examples5 - Merge all functions into a modelYou will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.Exercise: Implement the model function. Use the following notation:123- Y_prediction_test for your predictions on the test set- Y_prediction_train for your predictions on the train set- w, costs, grads for the outputs of optimize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# GRADED FUNCTION: modeldef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): """ Builds the logistic regression model by calling the function you've implemented previously Arguments: X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train) Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train) X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test) Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test) num_iterations -- hyperparameter representing the number of iterations to optimize the parameters learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize() print_cost -- Set to true to print the cost every 100 iterations Returns: d -- dictionary containing information about the model. """ ### START CODE HERE ### # initialize parameters with zeros (≈ 1 line of code) w, b = initialize_with_zeros(X_train.shape[0]) # Gradient descent (≈ 1 line of code) parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost) # Retrieve parameters w and b from dictionary "parameters" w = parameters["w"] b = parameters["b"] # Predict test/train set examples (≈ 2 lines of code) Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) ### END CODE HERE ### # Print train/test Errors print("train accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100)) print("test accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) d = &#123;"costs": costs, "Y_prediction_test": Y_prediction_test, "Y_prediction_train" : Y_prediction_train, "w" : w, "b" : b, "learning_rate" : learning_rate, "num_iterations": num_iterations&#125; return d1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)12345678910111213141516171819202122Cost after iteration 0: 0.693147Cost after iteration 100: 0.584508Cost after iteration 200: 0.466949Cost after iteration 300: 0.376007Cost after iteration 400: 0.331463Cost after iteration 500: 0.303273Cost after iteration 600: 0.279880Cost after iteration 700: 0.260042Cost after iteration 800: 0.242941Cost after iteration 900: 0.228004Cost after iteration 1000: 0.214820Cost after iteration 1100: 0.203078Cost after iteration 1200: 0.192544Cost after iteration 1300: 0.183033Cost after iteration 1400: 0.174399Cost after iteration 1500: 0.166521Cost after iteration 1600: 0.159305Cost after iteration 1700: 0.152667Cost after iteration 1800: 0.146542Cost after iteration 1900: 0.140872train accuracy: 99.04306220095694 %test accuracy: 70.0 %Comment: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test accuracy is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you’ll build an even better classifier next week!Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the index variable) you can look at predictions on pictures of the test set.1234# Example of a picture that was wrongly classified.index = 1plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))print ("y = " + str(test_set_y[0,index]) + ", you predicted that it is a \"" + classes[d["Y_prediction_test"][0,index]].decode("utf-8") + "\" picture.")Let’s also plot the cost function and the gradients.1234567# Plot learning curve (with costs)costs = np.squeeze(d['costs'])plt.plot(costs)plt.ylabel('cost')plt.xlabel('iterations (per hundreds)')plt.title("Learning rate =" + str(d["learning_rate"]))plt.show()Interpretation:You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting.6 - Further analysis (optional/ungraded exercise)Congratulations on building your first image classification model. Let’s analyze it further, and examine possible choices for the learning rate $\alpha$.Choice of learning rateReminder:In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\alpha$ determines how rapidly we update the parameters. If the learning rate is too large we may “overshoot” the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That’s why it is crucial to use a well-tuned learning rate.Let’s compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens.1234567891011121314151617learning_rates = [0.01, 0.001, 0.0001]models = &#123;&#125;for i in learning_rates: print ("learning rate is: " + str(i)) models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False) print ('\n' + "-------------------------------------------------------" + '\n')for i in learning_rates: plt.plot(np.squeeze(models[str(i)]["costs"]), label= str(models[str(i)]["learning_rate"]))plt.ylabel('cost')plt.xlabel('iterations (hundreds)')legend = plt.legend(loc='upper center', shadow=True)frame = legend.get_frame()frame.set_facecolor('0.90')plt.show()Interpretation:Different learning rates give different costs and thus different predictions results.If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost).A lower cost doesn’t mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.In deep learning, we usually recommend that you:Choose the learning rate that better minimizes the cost function.If your model overfits, use other techniques to reduce overfitting. (We’ll talk about this in later videos.)7 - Test with your own image (optional/ungraded exercise)Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Change your image&#39;s name in the following code 4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)! 12345678910111213## START CODE HERE ## (PUT YOUR IMAGE NAME) my_image = "my_image.jpg" # change this to the name of your image file ## END CODE HERE ### We preprocess the image to fit your algorithm.fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))image = image/255.my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).Tmy_predicted_image = predict(d["w"], d["b"], my_image)plt.imshow(image)print("y = " + str(np.squeeze(my_predicted_image)) + ", your algorithm predicts a \"" + classes[int(np.squeeze(my_predicted_image)),].decode("utf-8") + "\" picture.")What to remember from this assignment:Preprocessing the dataset is important.You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().Tuning the learning rate (which is an example of a “hyperparameter”) can make a big difference to the algorithm. You will see more examples of this later in this course!Finally, if you’d like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:- Play with the learning rate and the number of iterations - Try different initialization methods and compare the results Test other preprocessings (center the data, or divide each row by its standard deviation)参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655https://blog.csdn.net/pengchengliu/article/details/80932232https://www.coursera.org/learn/neural-networks-deep-learning/notebook/zAgPl/logistic-regression-with-a-neural-network-mindset]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习入门-基于Python的理论实现》笔记]]></title>
    <url>%2F2019%2F08%2F13%2F%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8-%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E5%AE%9E%E7%8E%B0%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章：Python入门略。第二章：感知机简单例子$x_1,x_2$是输入信号，$y$是输出信号，$w_1,w_2$是权重。图中的圈称为”神经元”，或者“节点”。只有传送过来的信号总和超过某个阈值$\theta$，才会输出1。数学公式表示：$y=\left\{\begin{aligned}0 \quad (w_1x_1+w_2x_2\le\theta) \\1 \quad(w_1x_1+w_2x_2\gt \theta) \end{aligned} \right.$导入权重和偏置$y=\left\{\begin{aligned}0 \quad (b+w_1x_1+w_2x_2\le0) \\1 \quad(b+w_1x_1+w_2x_2\gt 0) \end{aligned} \right.$$\theta=-b$简单实现与门12345678910111213141516171819202122import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = AND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 0# (1, 0) -&gt; 0# (0, 1) -&gt; 0# (1, 1) -&gt; 1非门1234567891011121314151617181920212223# coding: utf-8import numpy as npdef NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = NAND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 1# (1, 0) -&gt; 1# (0, 1) -&gt; 1# (1, 1) -&gt; 0或门123456789101112131415161718# coding: utf-8import numpy as npdef OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = OR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))感知机的可视化图：灰色区域是感知机输出0的区域，这个区域与或门的性质一致异或门感知机的局限性就在于它只能表示由一条直线分割的空间。通过组合与门、与非门、或门实现异或门1234567891011121314151617# coding: utf-8from and_gate import ANDfrom or_gate import ORfrom nand_gate import NANDdef XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y# 多层感知机if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = XOR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))第三章：神经网络简单例子感知机公式可改写成$y=h(b+w_1x_1+w_2x_2)$$h(x)=\left\{\begin{aligned}0 \quad (x\le0) \\1 \quad(x\gt 0) \end{aligned} \right.$激活函数$加权总和a=h(b+w_1x_1+w_2x_2)$$激活函数转换这总和y=h(a)$sigmoid$h(x)=\frac{1} {(1+e^{-x)} }$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef sigmoid(x): return 1 / (1 + np.exp(-x)) X = np.arange(-5.0, 5.0, 0.1)Y = sigmoid(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1)plt.show()阶跃函数$h(x)=\left\{\begin{aligned}1 \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef step_function(x): return np.array(x &gt; 0, dtype=np.int)X = np.arange(-5.0, 5.0, 0.1)Y = step_function(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1) plt.show()ReLU函数$h(x)=\left\{\begin{aligned}x \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-1.0, 5.5)plt.show()3层神经网络的实现$a_1^{(1)}=w_{11}^{(1)}x_1+w_{12}^{(1)}x_2+b_1^{(1)}$矩阵乘法表示：$\bf{A}^{(1)}=XW^{(1)}+B^{(1)}$ 1x2 2x3 = 1x3输出层的设计恒等函数softmax函数$y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}$实现softmax函数的注意事项：超大值无法表示的问题，即溢出，在进行计算机的运算时必须注意，为了防止溢出，一般会加上或减去输入信号的最大值，如下公式中的$C’$：$\begin{align}y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}&amp;=\frac{Ce^{(a_k)}}{C\sum \limits _{i=1} ^{n} e^{(a_i)}}\\&amp;=\frac{e^{(a_k+logC)}}{\sum \limits _{i=1} ^{n} e^{(a_i+logC)}}\\&amp;=\frac{e^{(a_k+C’)}}{\sum \limits _{i=1} ^{n} e^{(a_i+C’)}}\end{align}$手写数字识别1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8import sys, ossys.path.append(os.pardir) # 親ディレクトリのファイルをインポートするための設定import numpy as npimport picklefrom dataset.mnist import load_mnistfrom common.functions import sigmoid, softmaxdef get_data(): (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_testdef init_network(): with open(&quot;sample_weight.pkl&quot;, &apos;rb&apos;) as f: network = pickle.load(f) return networkdef predict(network, x): w1, w2, w3 = network[&apos;W1&apos;], network[&apos;W2&apos;], network[&apos;W3&apos;] b1, b2, b3 = network[&apos;b1&apos;], network[&apos;b2&apos;], network[&apos;b3&apos;] a1 = np.dot(x, w1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, w2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, w3) + b3 y = softmax(a3) return yx, t = get_data()network = init_network()batch_size = 100 # バッチの数accuracy_cnt = 0for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size])print(&quot;Accuracy:&quot; + str(float(accuracy_cnt) / len(x)))——————————————-有空再做笔记——————————————-参考资料《深度学习入门-基于Python的理论实现》https://github.com/oreilly-japan/deep-learning-from-scratch]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法小结]]></title>
    <url>%2F2019%2F08%2F02%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[排序汇总插入排序算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：从第一个元素开始，该元素可以认为已经被排序；取出下一个元素，在已经排序的元素序列中从后向前扫描；如果该元素（已排序）大于新元素，将该元素移到下一位置；重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；将新元素插入到该位置后；重复步骤2~5。动图演示代码描述123456789101112int insert_sort(int *arr, int n)&#123; int i, j; for (i = 1; i &lt; n; i++)&#123; if (arr[i] &lt; arr[i - 1])&#123; int temp = arr[i]; for (j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--) arr[j + 1] = arr[j]; arr[j + 1] = temp; &#125; &#125; return 0;&#125;优化折半插入排序123456789101112131415161718192021void binary_insert_sort(int* arr, int n) &#123; int i, j, mid, low, high, temp; for (i = 1; i &lt; n; i++)&#123; temp = arr[i]; low = 0; high = i; while (low &lt;= high)&#123; mid = (low + high) / 2; if (temp &gt; arr[mid])&#123; low = mid + 1; &#125; else &#123; high = mid - 1; &#125; &#125; for (j = i - 1; j &gt;= low; j--)&#123; arr[j + 1] = arr[j]; &#125; arr[low] = temp; &#125;&#125;希尔排序1959年Shell发明，第一个突破$O(n^2)$的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：选择一个增量序列$t_1,t_2,…,t_k，$其中$t_i&gt;t_j$，$t_k=1$；按增量序列个数k，对序列进行k 趟排序；每趟排序，根据对应的增量$t_i$，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。动图演示算法描述通常写法通常写法12345678910111213for (gap = n / 2; gap &gt; 0; gap /= 2)&#123; for (j = gap; j &lt; n; j++)&#123;//从数组第gap个元素开始 if (a[j] &lt; a[j - gap])&#123;//每个元素与自己组内的数据进行直接插入排序 int temp = a[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; a[k] &gt; temp)&#123; a[k + gap] = a[k]; k -= gap; &#125; a[k + gap] = temp; &#125; &#125;&#125;另一种写法1234for (gap = n / 2; gap &gt; 0; gap /= 2) for (i = gap; i &lt; n; i++) for (j = i - gap; j &gt;= 0 &amp;&amp; a[j] &gt; a[j + gap]; j -= gap) swap(a[j], a[j + gap]);增量序列$Shell：1，…，N/8，N/4，N/2 \quad 最坏O(n^2)$$Hibbard：{1, 3, …, 2^k-1} \quad 最坏O(n^3/2) \quad 猜想T(avg) = O(n^5/4)$$Sedgewick：{1, 5, 19, 41, 109…}该序列中的项或者是94^i - 92^i + 1或者是4^i - 3*2^i + 1$$猜想T(avg) = O(n^7/6) \quad T(worst)O(n^4/3)$选择排序算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：初始状态：无序区为$R[1..n]$，有序区为空；第$i$趟排序($i=1,2,3…n-1)$开始时，当前有序区和无序区分别为$R[1..i-1]$和$R(i..n）$。该趟排序从当前无序区中-选出关键字最小的记录 $R[k]$，将它与无序区的第1个记录$R$交换，使$R[1..i]$和$R[i+1..n)$分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；$n-1$趟结束，数组有序化了。动图演示代码描述1234567891011121314151617void select_sort(int number[])&#123; int i, j, min; for(i = 1; i &lt; MAX; i++) &#123; min = i; for(j = i+1; j &lt;= MAX; j++) &#123; if(number[min] &gt; number[j]) min = j; &#125; if(min != i)&#123; array[min] = array[min] + array[i]; array[i] = array[min] - array[i]; array[min] = array[min] - array[i]; &#125; &#125;&#125;优化每次查找时不仅找出最小值，还找出最大值，分别插到前面和后面，可以减少一半的查询时间。ps:也有人说是负优化12345678910111213141516171819202122232425void select_sort_plus(int array[], int size)&#123; int left = 0;//查找的左边界 int right = size - 1;//查找的右边界 while(left &lt; right) &#123; int min = left; int max = right; for (int i = left; i &lt;= right; i++)&#123; if (array[min]&gt;array[i])min = i; if (array[max] &lt; array[i])max = i; if (array[min] &lt; array[left]) &#123; array[min] = array[min] + array[left]; array[left] = array[min] - array[left]; array[min] = array[min] - array[left]; &#125; if (array[max] &gt; array[right]) &#123; array[max] = array[max] + array[right]; array[right] = array[max] - array[right]; array[max] = array[max] - array[right]; &#125; &#125; right--; left++; &#125;&#125;堆排序算法描述将初始待排序关键字序列$(R1,R2….Rn)$构建成大顶堆，此堆为初始的无序区；将堆顶元素$R[1]$与最后一个元素$R[n]$交换，此时得到新的无序区$(R1,R2,……Rn-1)$和新的有序区$(Rn)$,且满足$R[1,2…n-1]$&lt;=$R[n]$；由于交换后新的堆顶$R[1]$可能违反堆的性质，因此需要对当前无序区$(R1,R2,……Rn-1)$调整为新堆，然后再次将$R[1]$与无序区最后一个元素交换，得到新的无序区$(R1,R2….Rn-2)$和新的有序区$(Rn-1,Rn)$。不断重复此过程直到有序区的元素个数为$n-1$，则整个排序过程完成。动图演示代码描述1234567891011121314151617181920212223242526272829int build_heap(int arr[], int left, int right)&#123; int child,tmp; for (tmp = arr[left]; 2 * left + 1 &lt; right; left = child) &#123; //注意数组下标是从0开始的，所以左孩子的求发不是2*i child = 2 * left + 1; if (child != right - 1 &amp;&amp; arr[child + 1] &gt; arr[child]) ++child; //找到最大的儿子节点 if (tmp &lt; arr[child]) arr[left] = arr[child]; else break; &#125; arr[left] = tmp; return 0;&#125;//堆排序int heap_sort(int arr[], int left, int right)&#123; int i; for (i = left + (right - left) / 2; i &gt;= 0; --i) //构造堆 build_heap(arr, i, right); for (i = right; i&gt;0; --i)&#123; //将最大元素（根）与数组末尾元素交换，从而删除最大元素，重新构造堆 swap(arr,0, i); build_heap(arr, 0, i); &#125; return 0;&#125;冒泡排序算法描述比较相邻的元素。如果第一个比第二个大，就交换它们两个；对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；针对所有的元素重复以上的步骤，除了最后一个；重复步骤1~3，直到排序完成。动图演示代码描述12345678910111213void bubble_sort(int a[], int n)&#123; int i, j, temp; for (j = 0; j &lt; n - 1; j++)&#123; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125; &#125;&#125;算法分析稳定最好情况 顺序 $T=O(n)$最坏情况 逆序 $T=O(n^2)$优化1.定义一个flag，用来判断有没有进行交换，如果在某次内层循环中没有交换操作，就说明此时数组已经是有序了的，不用再进行判断，这样可以节省时间。12345678910111213141516171819void bubble_sort(int a[], int n)&#123; int i, j, temp; // C语言没有bool int isSorted = 0; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; &#125; &#125; if(isSorted == 0) break; &#125;&#125;2.每一次交换记录最后一次交换的位置，为零的时候就停止。12345678910111213141516171819202122void bubble_sort(int a[], int n)&#123; int i, j, temp; int isSorted = 0; int last = 0; int border = n - 1; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; border; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; last = i; &#125; &#125; border = last; if(isSorted = 0) break; &#125;&#125;3.鸡尾酒排序左右交替比较，交换例子第一次第二次第三次last没有变，结束原本排序8次，现在只需要3次记下两个边界值，分离出有序区。1234567891011121314151617181920212223242526272829303132333435363738def CockTailSort(array): """ :param array: 无序数组 :return: 有序数组 """ # 左右侧最后一次交换位置和左右边界 last_left = last_right = left_sort_border = 0 right_sort_border = len(array) - 1 i = j = 0 while i &lt; len(array) / 2: # 有序标记，每一轮的初始是true is_sorted = True j = left_sort_border while j &lt; right_sort_border: if array[j] &gt; array[j + 1]: array[j], array[j + 1] = array[j + 1], array[j] # 有元素交换，不是有序 is_sorted = False last_right = j j += 1 right_sort_border = last_right if is_sorted: break # 偶数轮之前，重新标记为true is_sorted = True j = right_sort_border while j &gt; left_sort_border: if array[j] &lt; array[j - 1]: array[j], array[j - 1] = array[j - 1], array[j] # 有元素交换，不是有序 is_sorted = False last_left = j j -= 1 left_sort_border = last_left if is_sorted: break i += 1 return array快速排序算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：从数列中挑出一个元素，称为 “基准”（pivot）；重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。动图演示代码描述左右指针法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴。设置两个变量$left = 0;right = N - 1$;从$left$一直向后走，直到找到一个大于$key$的值，$right$从后至前，直至找到一个小于$key$的值，然后交换这两个数。重复第三步，一直往后找，直到$left$和$right$相遇，这时将$key$放置$left$的位置即可。1234567891011121314int PartSort(int* array,int left,int right) &#123; int&amp; key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; swap(array[left],array[right]); &#125; swap(array[left],key); return left; &#125;挖坑法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴，也是初始的坑位。设置两个变量$left = 0;right = N - 1;$从$left$一直向后走，直到找到一个大于$key$的值，然后将该数放入坑中，坑位变成了$array[left]$。$right$一直向前走，直到找到一个小于$key$的值，然后将该数放入坑中，坑位变成了$array[right]$。重复3和4的步骤，直到$left$和$right$相遇，然后将$key$放入最后一个坑位。123456789101112131415int PartSort(int* array,int left,int right) &#123; int key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; array[right] = array[left]; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; array[left] = array[right]; &#125; array[right] = key; return right;&#125;前后指针法定义变量$cur$指向序列的开头，定义变量$pre$指向$cur$的前一个位置。当$array[cur] &lt; key$时，$cur$和$pre$同时往后走，如果$array[cur]&gt;key$，$cur$往后走，$pre$留在大于$key$的数值前一个位置。当$array[cur]$再次 &lt; $key$时，交换$array[cur]$和$array[pre]$。123456789101112131415161718int PartSort(int* array,int left,int right) &#123; if(left &lt; right)&#123; int key = array[right]; int cur = left; int pre = cur - 1; while(cur &lt; right) &#123; while(array[cur] &lt; key &amp;&amp; ++pre != cur)&#123; //如果找到小于key的值，并且cur和pre之间有距离时则进行交换。 //注意两个条件的先后位置不能更换 swap(array[cur],array[pre]); &#125; ++cur; &#125; swap(array[++pre],array[right]); return pre; &#125; return -1; &#125;非递归实现递归的算法主要是在划分子区间，如果要非递归实现快排，只要使用一个栈来保存区间就可以了。一般将递归程序改成非递归首先想到的就是使用栈，因为递归本身就是一个压栈的过程。1234567891011121314151617181920212223242526void QuickSortNotR(int* array,int left,int right)&#123; assert(array); stack&lt;int&gt; s; s.push(left); s.push(right);//后入的right，所以要先拿right while(!s.empty)//栈不为空 &#123; int right = s.top(); s.pop(); int left = s.top(); s.pop(); int index = PartSort(array,left,right); if((index - 1) &gt; left)//左子序列 &#123; s.push(left); s.push(index - 1); &#125; if((index + 1) &lt; right)//右子序列 &#123; s.push(index + 1); s.push(right); &#125; &#125;&#125;优化优化一：当待排序序列的长度分割到一定大小后，使用插入排序原因：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排。截止范围：待排序序列长度N = 10，虽然在5~20之间任一截止范围都有可能产生类似的结果，这种做法也避免了一些有害的退化情形。优化二：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割举例：待排序序列 1 4 6 7 6 6 7 6 8 6三数取中选取基准：下标为4的数6转换后，待分割序列：6 4 6 7 1 6 7 6 8 6​ 基准key：6本次划分后，未对与key元素相等处理的结果：1 4 6 6 7 6 7 6 8 6下次的两个子序列为：1 4 6 和 7 6 7 6 8 6本次划分后，对与key元素相等处理的结果：1 4 6 6 6 6 6 7 8 7下次的两个子序列为：1 4 和 7 8 7经过对比，我们可以看出，在一次划分后，把与key相等的元素聚在一起，能减少迭代次数，效率会提高不少具体过程：在处理过程中，会有两个步骤第一步，在划分过程中，把与key相等元素放入数组的两端第二步，划分结束后，把与key相等的元素移到枢轴周围归并排序算法描述把长度为n的输入序列分成两个长度为n/2的子序列；对这两个子序列分别采用归并排序；将两个排序好的子序列合并成一个最终的排序序列。动图演示代码描述递归实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/将数组b[]中的数复制到数组a[]中 template&lt;class Type&gt; void Copy(Type a[],Type b[],int left,int right) &#123; for(int i=left;i&lt;=right;i++) a[i]=b[i]; &#125; //将已排好序的数组合并到数组b[]中 template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) //i的取值范围为 [left,mid], j的取值范围为 [mid+1,right] &#123; if(a[i]&lt;a[j]) //取左右两边数组中较小的元素放入数组b中，最后得到的数组b即为有序 b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) //说明右边的数组的元素个数多 for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;i&lt;=mid;i++) b[k++]=a[z]; &#125; //将待排序集合一分为二，直至待排序集合只剩下一个元素为止， //然后不断合并两个排好序的数组段 template&lt;class Type&gt; void MergeSort(Type a[],int left,int right) &#123; Type *b=new Type [maxn]; if(left&lt;right) //控制待排序数组中至少有两个元素，一个元素时为有序 &#123; int i=(left+right)/2; //取数组中点，将数组尽量均等划分 MergeSort(a,left,i); //将左半段进行递归排序 MergeSort(a,i+1,right); //将右半段进行递归排序 Merge(a,b,left,i,right); //合并到数组b Copy(a,b,left,right); //复制到数组a &#125; delete[] b; &#125;非递归实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) &#123; if(a[i]&lt;a[j]) b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;z&lt;=mid;z++) b[k++]=a[z]; &#125; //合并大小为s的相邻子数组 template&lt;class Type&gt; void MergePass(Type x[],Type y[],int s,int n) &#123; int i=0; while(i+2*s-1&lt;n) &#123; Merge(x,y,i,i+s-1,i+2*s-1); //合并大小为s的相邻2段子数组 i+=2*s; &#125; if(i+s&lt;n) //剩下的元素个数m满足：s&lt;= m &lt;2*s Merge(x,y,i,i+s-1,n-1); else //剩下的元素个数m满足：m&lt;s for(int j=i;j&lt;=n-1;j++) y[j]=x[j]; &#125; template&lt;class Type&gt; void MergeSort(Type c[],int n) &#123; Type *d=new Type [n]; int s=1; while(s&lt;n) &#123; MergePass(c,d,s,n); //合并到数组d s+=s; MergePass(d,c,s,n); //合并到数组c s+=s; &#125; delete[] b; &#125;计数排序计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。算法描述找出待排序的数组中最大和最小的元素；统计数组中每个值为i的元素出现的次数，存入数组C的第i项；对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。动图演示代码描述12345678910111213141516171819202122232425262728void CountSort(int* array, int size) &#123; assert(array); int max = array[0];//序列中的最大值 int min = array[0];//序列中的最小值 for(int i = 0;i &lt; size;++i) &#123; if(array[i] &gt;= max) &#123; max = array[i]; &#125; else &#123; min = array[i]; &#125; &#125; int range = max - min + 1;//需要开辟的空间大小 int* count = new int[range]; memset(count,0,sizeof(int)*range);//辅助空间初始化为0,0代表没有那个数 for(int i = 0;i &lt; size;++i) &#123; count[array[i] - min]++;//array[i]-min是将该数对应到辅助空间的下标 &#125; int index = 0; //遍历辅助空间 for(int i = 0;i &lt; range;++i) &#123; //下标处的数值是几，说明该数出现了几次 while(count[i]--) &#123; array[index++] = i + min;//将下标处的数对应回原数组 &#125; &#125; delete[] count;&#125;桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。算法描述设置一个定量的数组当作空桶；遍历输入数据，并且把数据一个一个放到对应的桶里去；对每个不是空的桶进行排序；从不是空的桶里把排好序的数据拼接起来。动图演示代码描述12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#pragma once//每一个节点的结构struct node&#123; int key; //关键字，在桶中统计桶中数据量，在数据节点中就是节点的数据 struct node *next;&#125;;//声明：void PrintBucketSort(node** bucket, int bucket_size);int f(int x);void BucketSort(int* a, int size,int bucket_size)&#123; assert(a); //给桶申请空间 node** bucket = new node*[bucket_size*sizeof(node)]; //初始化 for (int i = 0; i &lt; bucket_size; ++i) &#123; bucket[i] = new node[sizeof(node)]; //每一个桶 bucket[i]-&gt;key = 0; bucket[i]-&gt;next = nullptr; &#125; for (int j = 0; j &lt; size; ++j) &#123; node* sub_node = new node[sizeof(node)]; //桶下的每一个节点 sub_node-&gt;key = a[j]; sub_node-&gt;next = nullptr; //计算这数据在哪个桶中 int num = f(a[j]); //让一个指针指向这个桶号的头 node* sub_head = bucket[num]; //开始插入 if (sub_head-&gt;next == nullptr) &#123; bucket[num]-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; //该桶号不为空，那么插入排序 else &#123; while (sub_head-&gt;next != nullptr &amp;&amp; sub_node-&gt;key &gt;= sub_head-&gt;next-&gt;key) &#123; sub_head = sub_head-&gt;next; &#125; sub_node-&gt;next = sub_head-&gt;next; sub_head-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; &#125; //打印 PrintBucketSort(bucket, bucket_size);&#125;//映射函数int f(int x)&#123; return (x / 10);&#125;//打印void PrintBucketSort(node** bucket, int bucket_size)&#123; //多少桶链(桶号) for (int i = 0; i &lt; bucket_size; ++i) &#123; node* cur = bucket[i]-&gt;next; while (cur) &#123; cout &lt;&lt; cur-&gt;key &lt;&lt; " "; cur = cur-&gt;next; &#125; &#125; cout &lt;&lt; endl;&#125;void Test7()&#123; int a[10] = &#123; 49, 38, 35, 97, 76, 73, 27, 49, 34, 78 &#125;; cout &lt;&lt; "桶排序" &lt;&lt; endl; BucketSort(a, 10, 10); //桶数据最大才97，所以需要10个桶&#125;归并排序算法描述取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点）动图演示代码描述LSD+MSD1234//伪代码如下RADIXSORT(A,d) for i = 1 to d use a stable sort to sort array A on digit i表排序算法描述又称间接排序，排序时不调整元素的实际位置，而是定义一个额外的数组作为“表”（table）。根据元素的关键字大小来调整元素对应下标在表中的位置。动图演示物理排序经过表排序后，得到了排好序的table数组，但是如果需要调整元素的实际位置，那就需要物理排序。分别对每个环里面的元素按照物理排序，取出环中一个元素，保存在临时变量中，由于空出了一个位置，就可以将该位置上本来应该放置的元素移动过来，又空出一个位置，继续移动，直到环中元素访问完成，将保存在临时变量中的元素放在最后一个空位。这就完成了一个环的物理排序。如何判断一个环的结束：每访问一个空位i后，就令table[i]=i。当发现table[i]==i时，环就结束了。代码描述12345678910111213141516171819202122struct Element &#123; ElementType Data; // data可以是任意类型 ElementType key; // 关键字只要可比即可&#125;// 物理排序过程 Elements = 元素数组， table = 表数组，假设表数组已经排好了void Sort(Element[] Elements, int[] table, int N) &#123; for (i = 0; i &lt; N; i++) &#123; Temp = Elements[i]; int j = i; while (table[j] != j) &#123; Elements[j] = Elements[table[j]]; // 把实际该置于j位置的元素置于J NextIndex = table[j]; // 记录下一个元素的位置 table[j] = j; j = NextIndex; // 让j跳到下一个元素 &#125; if (Elements[j] != Temp) &#123; // 说明该环不止一个元素，需要进行temp的赋值 Elements[j] = Temp; &#125; &#125;&#125;复杂度分析​ * 最好情况：初始即有序​ * 最坏情况：​ * 有$⌊N/2⌋$个环，每个环包含2个元素需要$⌊3N/2⌋$次元素移动 $T=O(mN)$，$m$是每个元素复制的时间其他排序算法睡眠排序Stooge排序Bogo 排序参考资料https://mooc.study.163.com/course/1000033001?tid=2402970002https://www.cnblogs.com/chengxiao/category/880910.htmlhttps://blog.csdn.net/qq_36528114/article/details/78667034《漫画算法：小灰的算法之旅》]]></content>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 3 - Image Sentiment Classification]]></title>
    <url>%2F2019%2F04%2F11%2FHomework-3-Image-Sentiment-Classification%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，情感图片分类情感图片分类导入相关库123import pandas as pdimport numpy as npfrom matplotlib import pyplot as plt数据处理123df_train = pd.read_csv("train.csv")df_test = pd.read_csv("test.csv")df_train.info()1sentiment = ['angry','disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']123456789plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure(figsize=(6,4))ax = fig.add_subplot(111)# plt.hist(train_df['label'], 7)df_train['label'].value_counts().plot(kind='bar')plt.ylabel("人数")plt.show()df_train['label'].value_counts()12123456# 传入来的每张图片feature都是字符串X = df_train.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X = np.array(X.map(lambda x: x.reshape(48,48,1)).values.tolist()) X = (X/255.0*0.99) + 0.001X.shape# (28709, 48, 48, 1)12345X_test = df_test.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X_test = np.array(X_test.map(lambda x: x.reshape(48,48,1)).values.tolist()) X_test = (X_test/255.0*0.99) + 0.001X_test.shape# (7178, 48, 48, 1)123y = df_train.label.values.reshape(-1, 1)y.shape# (28709, 1)123456# 查看一张图片fig = plt.figure(figsize=(3, 3))ax = fig.subplots(1)ax.imshow(X[0].reshape(48, 48), cmap = 'gray')plt.xlabel(sentiment[int(y[0])])plt.show()开始训练123456789import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, \ Flatten, BatchNormalization, InputLayer, Input, Activationfrom tensorflow.keras.optimizers import RMSpropfrom tensorflow.keras.models import Modelfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard1234# one-hoty = keras.utils.to_categorical(y, 7)y.shape# (28709, 7)1234from sklearn.model_selection import train_test_splitX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)X_train.shape, X_valid.shape, y_train.shape, y_valid.shape# ((20096, 48, 48, 1), (8613, 48, 48, 1), (20096, 7), (8613, 7))12CNN1234567891011121314151617181920212223242526272829303132cnn_model = Sequential()# 48*48*1 -&gt; 48*48*64cnn_model.add(Conv2D(filters= 64, kernel_size=(5, 5), strides=1, padding='Same', activation='relu',input_shape=(48,48,1)))# -&gt;24*24*64 cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25)) # -&gt; 24*24*128cnn_model.add(Conv2D(filters= 128, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;12*12*128cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25))# -&gt; 12*12*256cnn_model.add(Conv2D(filters= 256, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;6*6*256cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.5))# -&gt;9216cnn_model.add(Flatten())cnn_model.add(BatchNormalization())# -&gt;128cnn_model.add(Dense(128, activation='relu')) # -&gt;7cnn_model.add(BatchNormalization())cnn_model.add(Dense(7, activation='softmax'))12batch_size = 64epochs = 100 # 1012# optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234cnn_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])123456789101112131415161718# class_weight = 'auto', 用于处理skewed classes# 也可以model.compile(.... metrics=[Precision, Recall])# 或者# from sklearn.utils.class_weight import compute_class_weight# class_weight = compute_class_weight(class_weight='balanced',# classes=np.unique(train_data.label),# y=train_data.label)# model.fit(... class_weight=class_weight)# import os# os.environ["CUDA_VISIBLE_DEVICES"] = "0"cnn_result = cnn_model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto') # callbacks=[tensorboard]12345678910# 查看accfig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(cnn_result.history['loss'], label='Train Loss')ax[0].plot(cnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(cnn_result.history['acc'], label='Train acc')ax[1].plot(cnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()DNN123456789101112131415161718192021222324#DNN modelinputs = Input(shape=(48,48,1))dnn = Flatten()(inputs)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.25)(dnn)dnn = Dense(1024)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(7)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('softmax')(dnn)1234567outputs = dnndnn_model = Model(inputs=inputs, outputs=outputs)# tensorboard = TensorBoard(log_dir="logs/&#123;&#125;".format(time()))dnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])123456dnn_result = model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto')123456789fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(dnn_result.history['loss'], label='Train Loss')ax[0].plot(dnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(dnn_result.history['acc'], label='Train acc')ax[1].plot(dnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()保存h5文件12cnn_model.save('cnn.h5')dnn_model.save('dnn.h5')模型分析混淆矩阵绘制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from sklearn.metrics import confusion_matrixdef plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues): """ This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. """ if not title: if normalize: title = 'Normalized confusion matrix' else: title = 'Confusion matrix, without normalization' # Compute confusion matrix cm = confusion_matrix(y_true, y_pred) # Only use the labels that appear in the data #classes = classes[unique_labels(y_true, y_pred)] if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print("Normalized confusion matrix") else: print('Confusion matrix, without normalization') print(cm) fig, ax = plt.subplots() im = ax.imshow(cm, interpolation='nearest', cmap=cmap) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=title, ylabel='True label', xlabel='Predicted label') # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor") # Loop over data dimensions and create text annotations. fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha="center", va="center", color="white" if cm[i, j] &gt; thresh else "black") fig.tight_layout() return ax1234567cnn_predict = cnn_model.predict(X_valid)cnn_cls = np.argmax(cnn_predict, axis=1)dnn_predict = dnn_model.predict(X_valid)dnn_cls = np.argmax(dnn_predict, axis=1)y_label = data = [np.argmax(one_hot)for one_hot in y_valid]1plot_confusion_matrix(y_label, cnn_cls, sentiment)1plot_confusion_matrix(y_label, dnn_cls, sentiment)错误图片查看1234true_cls = pd.Series(y_label, name='true_cls')[y_label!=cnn_cls]wrong_cls = pd.Series(cnn_cls, name='wrong_cls')[y_label!=cnn_cls]wrong = pd.concat([true_cls, wrong_cls], axis = 1)特征图查看卷积核的可视化参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HWhttps://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Titanic: Machine Learning from Disaster]]></title>
    <url>%2F2019%2F04%2F06%2FTitanic-Machine-Learning-from-Disaster%2F</url>
    <content type="text"><![CDATA[Kaggle入坑题目数据处理导入基础库1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns读取并处理数据1234train_data = pd.read_csv('train.csv')test_data = pd.read_csv('test.csv')# train_data.columns.valuestrain_data.head()#查看前五行1train_data.info()#查看数据信息123456# 查看空值数目print('train_data:')print(train_data.isnull().sum())print("-"*20)print('test_data:')print(test_data.isnull().sum())train_data中891位乘客信息，其中属性Age，Cabin和Embarked有数据丢失。test_data中，属性Age，Fare和Cabin有数据丢失。对于缺少数据，使用年龄的中位数填补年龄空值，去除丢失Embarked，Fare属性的数据。对于Cabin属性，种类很多，观察其是否丢失与是否存活之间的关系，将Cabin属性分为是否丢失两类。1234567891011121314plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure() fig.set(alpha=0.2) # 设定图表颜色alpha参数 not_null_cabin = train_data.Survived[train_data.Cabin.isnull()].value_counts() null_cabin = train_data.Survived[train_data.Cabin.notnull()].value_counts() df = pd.DataFrame(&#123;'Cabin丢失':not_null_cabin , 'Cabin未丢失':null_cabin&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("是否存活") plt.ylabel("人数") plt.show()# train_data.Cabin.value_counts()12345678910111213141516171819202122 # 使用年龄的中位数填补年龄空值train_data['Age'].fillna(train_data['Age'].median(), inplace = True)test_data['Age'].fillna(test_data['Age'].median(), inplace = True)# Cabin根据是否缺失分为两类train_data.loc[ (train_data.Cabin.notnull()), 'Cabin' ] = "Yes"train_data.loc[ (train_data.Cabin.isnull()), 'Cabin' ] = "No"test_data.loc[ (test_data.Cabin.notnull()), 'Cabin' ] = "Yes"test_data.loc[ (test_data.Cabin.isnull()), 'Cabin' ] = "No" # 去除丢失Embarked，Fare的数据train_data = train_data.dropna()# test_data补充test_data.loc[ (test_data.Fare.isnull()), 'Fare' ] = test_data['Fare'].median()# 去除无关数据PassengerId和Tickettrain_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)test_id = test_data.PassengerIdtest_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)train_data.info()# test_data.info()进一步处理数据12345678910111213141516171819202122232425262728293031323334def clean_data(dataset): # 新建家庭大小属性：堂兄弟/妹个数 + 父母与小孩个数 dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 # 是否仅有自身一人，1：是，0：否 dataset['IsAlone'] = 1 dataset['IsAlone'].loc[dataset['FamilySize'] &gt; 1] = 0 # 分离出称谓 Mr/Mrs/Miss/Master... dataset['Title'] = dataset['Name'].str.split(", ", expand=True)[1].str.split(".", expand=True)[0] # 比起把Fare和Age当作特征列，将这些列的值进行二进制转换更为合理。 # Scikit-Learn 开发了新的估计器 KBinsDiscretizer 来执行这一操作。 # 它不仅将这些值转换为二进制码，还会对其进行编码。 # 也可以通过 Pandas 的 cut 和 qcut 函数手动完成这个过程。 # qcut据这些值的频率来选择箱子的均匀间隔，即每个箱子中含有的数的数量是相同的 dataset['FareBin'] = pd.qcut(dataset['Fare'], 4) # cut将根据值本身来选择箱子均匀间隔，即每个箱子的间距都是相同的 dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)clean_data(train_data)clean_data(test_data) # print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (train_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctrain_data['Title'] = train_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(train_data['Title'].value_counts())12345678# print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (test_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctest_data['Title'] = test_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(test_data['Title'].value_counts())123456789101112# from sklearn.preprocessing import OneHotEncoder, LabelEncoder# LabelEncoder()对不连续的数字或文本编号# 这里使用one-hotdummy = ['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Title', 'Embarked', 'FamilySize', 'IsAlone','FareBin', 'AgeBin'] Target = ['Survived']train_dummy = pd.get_dummies(train_data[dummy])test_dummy = pd.get_dummies(test_data[dummy])train_dummy.columns.values1train_dummy = train_dummy.drop(['Age', 'Fare'], axis=1)123456from sklearn import model_selectiontrain_x_dummy, valid_x_dummy, train_y, valid_y = model_selection.train_test_split \ (train_dummy, train_data[Target], random_state = 0)train_x_dummy.shape, valid_x_dummy.shape, train_y.shape, valid_y.shape# ((666, 26), (223, 26), (666, 1), (223, 1))进行数据分析12345678for x in ['Pclass', 'Sex','SibSp', 'Parch', 'Cabin', 'Embarked', \ 'FamilySize', 'IsAlone', 'Title']: # 打印和Survived相关的属性，'Age'和'Fare' 除外 print('Survival Correlation by:', x) print(train_data[[x, "Survived"]].groupby(x, as_index=False).mean()) print('-'*10, '\n')# print(pd.crosstab(train_x_dummy.Pclass, train_y.Survived))12345678910111213141516171819202122232425262728293031323334# plt.figure(figsize=[18,10])# plt.subplot(231)# plt.boxplot(x=train_data['Fare'], showmeans = True, meanline = True)# plt.subplot(232)# plt.boxplot(train_data['Age'], showmeans = True, meanline = True)# plt.subplot(233)# plt.boxplot(train_data['FamilySize'], showmeans = True, meanline = True)# plt.subplot(234)# plt.hist(x = [train_data[train_data['Survived']==1]['Fare'], \# train_data[train_data['Survived']==0]['Fare']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(235)# plt.hist(x = [train_data[train_data['Survived']==1]['Age'], \# train_data[train_data['Survived']==0]['Age']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(236)# plt.hist(x = [train_data[train_data['Survived']==1]['FamilySize'], \# train_data[train_data['Survived']==0]['FamilySize']], # stacked=True, label = ['Survived','Dead'])fig, saxis = plt.subplots(2,3,figsize=(18,10))sns.boxplot(y = 'Fare', hue = 'Survived', data = train_data, ax = saxis[0,0])sns.boxplot(y = 'Age', hue = 'Survived', data = train_data, ax = saxis[0,1])sns.boxplot(y = 'FamilySize', hue = 'Survived', data = train_data, ax = saxis[0,2])sns.barplot(x = 'FareBin', y = 'Survived', data = train_data, ax = saxis[1,0])sns.barplot(x = 'AgeBin', y = 'Survived', data = train_data, ax = saxis[1,1])sns.barplot(x = 'FamilySize', y = 'Survived', data = train_data, ax = saxis[1,2])123456789fig, saxis = plt.subplots(2, 3,figsize=(18,10))sns.barplot(x = 'Embarked', y = 'Survived', data=train_data, ax = saxis[0,0])sns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=train_data, ax = saxis[0,1])sns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=train_data, ax = saxis[0,2])sns.pointplot(x = 'FareBin', y = 'Survived', data=train_data, ax = saxis[1,0])sns.pointplot(x = 'AgeBin', y = 'Survived', data=train_data, ax = saxis[1,1])sns.pointplot(x = 'FamilySize', y = 'Survived', data=train_data, ax = saxis[1,2])12345fig, saxis = plt.subplots(1,3,figsize=(18,5))sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=train_data, ax = saxis[0])sns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=train_data, ax = saxis[1])sns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=train_data, ax = saxis[2])12345678910fig, saxis = plt.subplots(1, 2,figsize=(12,5))sns.pointplot(x="FamilySize", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[0])sns.pointplot(x="Pclass", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[1])123e = sns.FacetGrid(train_data, col = 'Embarked')e.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')e.add_legend()1234e = sns.FacetGrid(train_data, hue = 'Survived', aspect=4 )e.map(sns.kdeplot, 'Age', shade= True )e.set(xlim=(0 , train_data['Age'].max()))e.add_legend()123e = sns.FacetGrid(train_data, row = 'Sex', col = 'Pclass', hue = 'Survived')e.map(plt.hist, 'Age', alpha = .75)e.add_legend()12e = sns.pairplot(train_data, hue = 'Survived', palette = 'deep', height=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )e.set(xticklabels=[])12345678910111213141516171819# 热力图def correlation_heatmap(df): _ , ax = plt.subplots(figsize =(14, 12)) colormap = sns.diverging_palette(220, 10, as_cmap = True) # 创建分散颜色 _ = sns.heatmap( df.corr(), cmap = colormap, square=True, # 设置热力图矩阵小块形状，默认值是False cbar_kws=&#123;'shrink':.9 &#125;, # 热力图侧边绘制颜色刻度条时，相关字体设置，默认值是None ax=ax, annot=True, # 在热力图每个方格写入数据；如果是矩阵，在热力图每个方格写入该矩阵对应位置数据，默认值是False linewidths=0.1,vmax=1.0, linecolor='white', # vmax热力图的颜色取值最大范围 annot_kws=&#123;'fontsize':12 &#125; ) plt.title('Pearson Correlation of Features', y=1.05, size=15)correlation_heatmap(train_data)选择MLA进行训练1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, \ neighbors, svm, tree, discriminant_analysisfrom xgboost import XGBClassifierfrom sklearn.linear_model import stochastic_gradientMLA = [ # 集成方法 ensemble.AdaBoostClassifier(), ensemble.BaggingClassifier(), ensemble.ExtraTreesClassifier(), ensemble.GradientBoostingClassifier(), ensemble.RandomForestClassifier(), # 高斯过程 gaussian_process.GaussianProcessClassifier(), # 广义线性模型 linear_model.LogisticRegressionCV(), linear_model.PassiveAggressiveClassifier(max_iter=5), linear_model.RidgeClassifierCV(), stochastic_gradient.SGDClassifier(max_iter=5), linear_model.Perceptron(max_iter=5), # 朴素贝叶斯 naive_bayes.BernoulliNB(), naive_bayes.GaussianNB(), #邻近算法 neighbors.KNeighborsClassifier(), # 支持向量机 svm.SVC(probability=True), svm.NuSVC(probability=True), svm.LinearSVC(), # 树 tree.DecisionTreeClassifier(), tree.ExtraTreeClassifier(), # 判别分析 discriminant_analysis.LinearDiscriminantAnalysis(), discriminant_analysis.QuadraticDiscriminantAnalysis(), # xgboost XGBClassifier() ]123456789101112131415161718192021222324252627282930313233343536from sklearn.preprocessing import StandardScaler# X = pd.concat([train_x_dummy,valid_x_dummy])# y = pd.concat([train_y,valid_y])# 防止线性相关X = train_dummy.drop(['Sex_male', 'Cabin_No'], axis=1)y = train_data[Target]# 标准化scaler = StandardScaler()scaler.fit(X) X = scaler.fit_transform(X)MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', \ 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']MLA_compare = pd.DataFrame(columns = MLA_columns)cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )row_index = 0for alg in MLA: MLA_name = alg.__class__.__name__ MLA_compare.loc[row_index, 'MLA Name'] = MLA_name MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params()) cv_results = model_selection.cross_validate(alg, X, y.values.ravel(), cv = cv_split, return_train_score=True) MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean() MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3 row_index+=1MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)MLA_compare123456sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare)plt.title('Machine Learning Algorithm Accuracy Score \n')plt.xlabel('Accuracy Score (%)')plt.ylabel('Algorithm')plt.show()12345678910111213141516171819202122232425262728vote_est = [ # Ensemble Methods ('ada', ensemble.AdaBoostClassifier()), ('bc', ensemble.BaggingClassifier()), ('etc',ensemble.ExtraTreesClassifier()), ('gbc', ensemble.GradientBoostingClassifier()), ('rfc', ensemble.RandomForestClassifier()), # Gaussian Processes ('gpc', gaussian_process.GaussianProcessClassifier()), # GLM ('lr', linear_model.LogisticRegressionCV()), # Navies Bayes ('bnb', naive_bayes.BernoulliNB()), ('gnb', naive_bayes.GaussianNB()), # Nearest Neighbor ('knn', neighbors.KNeighborsClassifier()), # SVM ('svc', svm.SVC(probability=True)), # xgboost ('xgb', XGBClassifier())]1234567891011121314151617181920212223import warningswarnings.filterwarnings("ignore")# Hard Votevote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')vote_hard_cv = model_selection.cross_validate(vote_hard, X, y.values.ravel(), cv = cv_split)vote_hard.fit(X, y.values.ravel())print("Hard Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['train_score'].mean()*100)) print("Hard Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['test_score'].mean()*100))print("Hard Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilitiesvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')vote_soft_cv = model_selection.cross_validate(vote_soft, X, y.values.ravel(), cv = cv_split)vote_soft.fit(X, y.values.ravel())print("Soft Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['train_score'].mean()*100)) print("Soft Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['test_score'].mean()*100))print("Soft Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_soft_cv['test_score'].std()*100*3))print('-'*10)进行网格调参123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136import timegrid_n_estimator = [10, 50, 100, 300]grid_ratio = [.1, .25, .5, .75, 1.0]grid_learn = [.01, .03, .05, .1, .25]grid_max_depth = [2, 4, 6, 8, 10, None]grid_min_samples = [5, 10, .03, .05, .10]grid_criterion = ['gini', 'entropy']grid_bool = [True, False]grid_seed = [0]grid_param = [ [&#123; #AdaBoostClassifier 'n_estimators': grid_n_estimator, #default=50 'learning_rate': grid_learn, #default=1 #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R 'random_state': grid_seed &#125;], [&#123; #BaggingClassifier 'n_estimators': grid_n_estimator, #default=10 'max_samples': grid_ratio, #default=1.0 'random_state': grid_seed &#125;], [&#123; #ExtraTreesClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'random_state': grid_seed &#125;], [&#123; #GradientBoostingClassifier #'loss': ['deviance', 'exponential'], #default=’deviance’ 'learning_rate': [.05], 'n_estimators': [300], #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse” 'max_depth': grid_max_depth, #default=3 'random_state': grid_seed &#125;], [&#123; #RandomForestClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'oob_score': [True], #default=False 'random_state': grid_seed &#125;], [&#123; #GaussianProcessClassifier 'max_iter_predict': grid_n_estimator, #default: 100 'random_state': grid_seed &#125;], [&#123; #LogisticRegressionCV 'fit_intercept': grid_bool, #default: True #'penalty': ['l1','l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs 'random_state': grid_seed &#125;], [&#123; #BernoulliNB 'alpha': grid_ratio, #default: 1.0 &#125;], #GaussianNB [&#123;&#125;], [&#123; #KNeighborsClassifier 'n_neighbors': [1,2,3,4,5,6,7], #default: 5 'weights': ['uniform', 'distance'], #default = ‘uniform’ 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'] &#125;], [&#123; #SVC #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1,2,3,4,5], #default=1.0 'gamma': grid_ratio, #edfault: auto 'decision_function_shape': ['ovo', 'ovr'], #default:ovr 'probability': [True], 'random_state': grid_seed &#125;], [&#123; #XGBClassifier 'learning_rate': grid_learn, #default: .3 'max_depth': [1,2,4,6,8,10], #default 2 'n_estimators': grid_n_estimator, 'seed': grid_seed &#125;] ]start_total = time.perf_counter() for clf, param in zip (vote_est, grid_param): #print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm #print(param) start = time.perf_counter() best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'roc_auc') best_search.fit(X, y.values.ravel()) run = time.perf_counter() - start best_param = best_search.best_params_ print('The best parameter for &#123;&#125; is &#123;&#125; with a runtime of &#123;:.2f&#125; seconds.'\ .format(clf[1].__class__.__name__, best_param, run)) clf[1].set_params(**best_param) run_total = time.perf_counter() - start_totalprint('Total optimization time was &#123;:.2f&#125; minutes.'.format(run_total/60))print('-'*10)1234567891011121314151617181920212223242526# Hard Vote or majority rules w/Tuned Hyperparametersgrid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')grid_hard_cv = model_selection.cross_validate(grid_hard, X, y.values.ravel(), cv = cv_split)grid_hard.fit(X, y.values.ravel())print("Hard Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['train_score'].mean()*100)) print("Hard Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].mean()*100))print("Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilities w/Tuned Hyperparametersgrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')grid_soft_cv = model_selection.cross_validate(grid_soft, X, y.values.ravel(), cv = cv_split)grid_soft.fit(X, y.values.ravel())print("Soft Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ .format(grid_soft_cv['train_score'].mean()*100)) print("Soft Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].mean()*100))print("Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].std()*100*3))print('-'*10)保存预测结果1234X_test = test_dummy.drop(['Sex_male', 'Cabin_No'], axis=1).valuesy_test = grid_hard.predict(X_test)f = pd.DataFrame(&#123;'PassengerId':test_id.values, 'Survived':y_test&#125;)f.to_csv("C:/Users/DHX17/Jupyter/Kaggle/titanic/ans.csv", index=False)参考资料https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 手写数字识别]]></title>
    <url>%2F2019%2F03%2F31%2FMNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[摘要使用神经网络进行MNIST手写数字识别《Python神经网络编程》代码导入相关库123import numpy as npfrom scipy.special import expitimport matplotlib.pyplot as plt搭建神经网络12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class neuralNetwork: def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes self.lr = learningrate #随机初始化权重，当然权重在0到1之间（不含）。这里通过高斯函数产生权重 #其中均值是零，方差是1/sqrt(连接数)，当然连接数等于节点数。后一个是矩阵hnodes行， # numpy.random.normal(loc=0.0, scale=1.0, size=None) self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes)) self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes)) self.activation_function = lambda x: expit(x) pass def train(self,inputs_list, targets_list): inputs = np.array(inputs_list, ndmin=2).T targets = np.array(targets_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who,hidden_outputs) final_outputs = self.activation_function(final_inputs) #误差 output_errors = targets - final_outputs hidden_errors = np.dot(self.who.T, output_errors) #权重更新 self.who += self.lr*np.dot((output_errors*final_outputs*(1.0 - final_outputs)), np.transpose(hidden_outputs)) self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs)) pass def query(self, inputs_list): inputs = np.array(inputs_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who, hidden_outputs) final_outputs = self.activation_function(final_inputs) return final_outputs数据处理1234567input_nodes = 784 hidden_nodes = 100 output_nodes = 10 learning_rate = 0.3n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)1234#导入训练数据 training_data_file = open('./mnist_train_100.csv','r') training_data_list = training_data_file.readlines() training_data_file.close()1training_data_list[0]123all_values = training_data_list[0].split(',')image_array = np.asfarray(all_values[1:]).reshape((28, 28))plt.imshow(image_array, cmap='Greys', interpolation='None')进行数据训练123456789for record in training_data_list: all_values = record.split(',') #输入数据数学处理，使其在0.01到1之间.颜色的范围是[0,255] inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01 #初始化目标值，使其在0.01到0.99之间 targets = np.zeros(output_nodes) + 0.01 targets[int(record[0])] = 0.99 n.train(inputs,targets) pass123test_data_file = open('./mnist_test_10.csv','r') test_data_list = test_data_file.readlines() test_data_file.close()12345678all_values = test_data_list[0].split(',')correct_label = int(all_values[0])image_array = np.asfarray(all_values[1:]).reshape((28,28))plt.imshow(image_array,cmap='Greys')inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01outputs = n.query(inputs)label = np.argmax(outputs) #argmax返回最大值的索引值print("correct:&#123;0&#125;, predict:&#123;1&#125;".format(correct_label, label))1234567891011121314151617181920scorecard = []#多个数据检测for record in test_data_list: all_values = record.split(',') correct_label = int(all_values[0]) print(correct_label, "correct label") inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01 outputs = n.query(inputs) label = np.argmax(outputs) print(label, "network's answer") if(label == correct_label): scorecard.append(1) else: scorecard.append(0) print(scorecard) # [1, 0, 1, 1, 1, 1, 1, 0, 0, 0]123scorecard_array = np.asarray(scorecard)print("performance = ", scorecard_array.sum() / scorecard_array.size)# performance = 0.6一些改进调整学习率多次运行改变网络形状基于Keras导入相关库12345678910111213141516import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sn# sklearn的mnist数据集是8x8# from sklearn.datasets import load_digits# from sklearn.preprocessing import LabelBinarizer# from sklearn.model_selection import train_test_split# from sklearn.metrics import confusion_matriximport kerasfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flattenfrom keras.optimizers import RMSpropfrom keras.preprocessing.image import ImageDataGeneratorfrom keras.callbacks import ModelCheckpoint处理数据1234567891011121314151617181920212223242526# 导入数据# digits = load_digits()# X = digits.data# y = digits.target# X /= 8# y = LabelBinarizer().fit_transform(y)# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)# X_train.shape, X_test.shape, y_train.shape, y_test.shape# (X_train, y_train), (X_test, y_test) = mnist.load_data()path = 'datasets/mnist.npz' f = np.load(path)X_train, y_train = f['x_train'], f['y_train']X_test, y_test = f['x_test'], f['y_test']f.close()X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)X_test = X_test.reshape(X_test.shape[0], 28, 28, 1) X_train = X_train.astype('float32')X_test = X_test.astype('float32') X_train /= 255 X_test /= 255X_train.shape, X_test.shape# ((60000, 28, 28, 1), (10000, 28, 28, 1))1234y_train = keras.utils.to_categorical(y_train, 10)y_test = keras.utils.to_categorical(y_test, 10)y_train.shape, y_test.shape# ((60000, 10), (10000, 10))12plt.imshow(X_train[0].reshape(28, 28), cmap='Greys', interpolation='None')y_train[0]搭建神经网络12345678910111213141516171819model = Sequential() # 使用3x3的卷积核，激活函数为ReLU# 池化核大小2x2model.add(Conv2D(filters=28, kernel_size=(3, 3), padding='Same', activation='relu',input_shape=(28,28,1)))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25)) model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25))# Fully connected layer.model.add(Flatten())model.add(Dense(256, activation='relu')) model.add(Dropout(0.25)) #10 outputsmodel.add(Dense(10, activation='softmax'))12batch_size = 250epochs = 1012optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])12345678910111213141516171819# reduce_lr = LearningRateScheduler(function)reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, #每次减少学习率的因子，学习率将以lr = lr*factor的形式被减少 patience=10, # 当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发 verbose=0, mode='auto', # 在min模式下，如果检测值触发学习率减少。在max模式下，当检测值不再上升则触发学习率减少。 min_delta=0.0001, # 用来确定是否进入检测值的“平原区” cooldown=0, # 学习率减少后，会经过cooldown个epoch才重新进行正常操作 min_lr=0.00001)gen = ImageDataGenerator(# featurewise_center=True,对输入的图片每个通道减去每个通道对应均值 # featurewise_std_normalization=True,每张图片减去样本均值, 使得每个样本均值为0 rotation_range=20, # 旋转范围 zoom_range= 0.2, # 缩放范围 width_shift_range=0.2, # 水平平移范围 height_shift_range=0.2, # 垂直平移范围 horizontal_flip=True) #水平反转train_generator = gen.flow(X_train, y_train, batch_size=batch_size)123456result = model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs= epochs, validation_data=(X_test, y_test), verbose =2, callbacks=[reduce_lr])12345678910fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(result.history['loss'], label='Train Loss')ax[0].plot(result.history['val_loss'], label='Validation Loss')ax[1].plot(result.history['acc'], label='Train acc')ax[1].plot(result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()参考文献《Python神经网络编程》代码https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork/]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 2 - Income Prediction]]></title>
    <url>%2F2019%2F03%2F29%2FHomework-2-Income-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，收入预测收入预测导入相关库123456import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom random import shufflefrom math import floor, logfrom numpy.linalg import inv数据处理12train_data = pd.read_csv("train.csv")train_data.info()1train_data.head()对数据进行可视化观察12345678910111213141516171819202122232425262728293031323334353637383940plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231)train_data.income.value_counts().plot(kind='bar')plt.xlabel("收入情况")plt.ylabel("人数") ax2 = plt.subplot(232)train_data.education.value_counts().plot(kind='bar')plt.ylabel("人数")# #plt.xticks([1, 2, 3])plt.xlabel("教育情况")ax3 = plt.subplot(233)plt.hist(train_data.age,20)# #plt.yticks([0, 1])plt.ylabel('人数')plt.xlabel('年龄')ax4 = plt.subplot(234)train_data.sex.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel('性别')ax5 = plt.subplot(235)train_data.workclass.value_counts().plot(kind='bar')plt.ylabel("人数") plt.xlabel("所属企业类型")ax6 = plt.subplot(236)train_data.race.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel("种族")# 调整每隔子图之间的距离 plt.tight_layout()plt.show()1234567# 将&gt;50K转为1，&lt;=50K转为0， 方便数据可视化操作# 使用train_data.income[train_data.income == " &gt;50K"] = 1# 会弹出A value is trying to be set on a copy of a slice from a DataFrame.# 修改数据最好不要使用链式操作train_data.loc[train_data.income == " &gt;50K", 'income'] = 1train_data.loc[train_data.income ==" &lt;=50K", 'income'] = 0train_data.head()12345678910fig = plt.figure() fig.set(alpha=0.2) male = train_data.income[train_data.sex == ' Male'].value_counts() female = train_data.income[train_data.sex == ' Female'].value_counts() df=pd.DataFrame(&#123;'male':male, 'female':female&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("收入情况") plt.ylabel("人数") plt.show()train_data[["sex", "income"]].groupby(['sex'], as_index=False).mean().sort_values(by='income', ascending=False)查看学历对应的收入情况12345678910111213141516171819202122232425262728293031323334fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231) train_data.income[train_data.education == ' HS-grad'].value_counts().plot(kind='bar', label=" HS-grad", color='red') ax1.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax1.legend(["HS研究生学位"], loc='best') ax2 = plt.subplot(232) train_data.income[train_data.education == ' Doctorate'].value_counts().plot(kind='bar', label=" Doctorate", color='lightblue') ax2.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax2.legend(["博士学位"], loc='best') ax3 = plt.subplot(233) train_data.income[train_data.education == ' Masters'].value_counts().plot(kind='bar', label=" Masters", color='blue') ax3.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax3.legend(["硕士学位"], loc='best') ax4 = plt.subplot(234) train_data.income[train_data.education == ' Bachelors'].value_counts().plot(kind='bar', label=" Bachelors", color='pink') ax4.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax4.legend(["学士学位"], loc='best') ax5 = plt.subplot(235) train_data.income[train_data.education == ' Assoc-voc'].value_counts().plot(kind='bar', label=" Assoc-voc", color='steelblue') ax5.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax5.legend(["副学士学位"], loc='best') ax6 = plt.subplot(236) train_data.income[train_data.education == ' Some-college'].value_counts().plot(kind='bar', label=" Some-college", color='#FA2479') ax6.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax6.legend(["本科生学位"], loc='best') plt.show()12# 各国家人数train_data.native_country.value_counts()将所有含有缺失值的行都去掉，可以使用RandomForestRegressor填补缺失12345678910111213141516171819202122232425262728# from sklearn.ensemble import RandomForestRegressor# 使用RandomForestRegressor填补缺失的年龄属性# def set_missing_workclass(df):# # 把已有的数值型特征取出来丢进RandomForestRegressor中# workclass_df = df[['workclass','age', 'education', 'race', 'income']]## # 提取未知值和已知值# known_workclass = workclass_df[workclass_df.workclass.notnull()].values# unknown_workclass = workclass_df[workclass_df.workclass.isnull()].values # # y即目标workclass# y = known_workclass[:, 0] # # X即特征属性值# X = known_workclass[:, 1:] # # fit到RandomForestRegressor之中# rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)# rfr.fit(X, y) # # 用得到的模型进行未知年龄结果预测# predictedAges = rfr.predict(unknown_workclass[:, 1::]) # # 用得到的预测结果填补原缺失数据# df.loc[ (df.workclass.isnull()), 'workclass' ] = predictedAges # return df, rfr# train_data, rfr = set_missing_ages(train_data)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def dataProcess_X(raw_data): if "income" in raw_data.columns: # data = raw_data.drop(["sex", 'income'], axis=1) data = raw_data.drop(["income"], axis=1) else: # data = raw_data.drop(["sex"], axis=1) pass # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'], value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() # 剔除没有用的数据特征fnlwgt # fnlwgt: 连续性数值变量；人口普查员认为观察值的人数 data.drop(['fnlwgt'], axis=1) # 处理sex data.loc[data.sex == " Male", 'sex'] = 1 data.loc[data.sex ==" Female", 'sex'] = 0 listObjectColumn = [col for col in data.columns if data[col].dtypes == "object"] #读取非数字的column listNonObjedtColumn = [x for x in list(data) if x not in listObjectColumn] ObjectData = data[listObjectColumn] NonObjectData = data[listNonObjedtColumn] # NonObjectData.insert(0 ,"sex", (raw_data["sex"] == " Female").astype(np.int)) # 使用pd.get_dummies()特征因子化 # 也可以使用one-hot # from sklearn.feature_extraction import DictVectorizer # dict_vect=DictVectorizer(sparse=False) # X_train=dict_vect.fit_transform(X_train.to_dict(orient='record')) # X_test=dict_vect.transform(X_test.to_dict(orient='record')) # dict_vect.feature_names_ ObjectData = pd.get_dummies(ObjectData) data = pd.concat([NonObjectData, ObjectData], axis=1) X = data.astype("int64") # 标准化 X = (X - X.mean()) / X.std() return np.array(X)def dataProcess_y(raw_data): data = raw_data.copy() # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'],value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() try: # y = data['income'] # y = pd.DataFrame((y ==' &gt;50K').astype("int64"), columns=["income"]) data.loc[data.income == " &gt;50K", 'income'] = 1 data.loc[data.income == " &lt;=50K", 'income'] = 0 except: pass y = np.array(data['income']) y = y.reshape(y.shape[0], 1) return yX_train = dataProcess_X(train_data)y_train = dataProcess_y(train_data)X_train.shape, y_train.shape# ((30162, 103), (30162, 1))导入测试集12345test_data = pd.read_csv("test.csv")X_test = dataProcess_X(train_data)y_test = dataProcess_y(train_data)X_test.shape, y_test.shape# ((30162, 103), (30162, 1))12345678910111213141516171819202122def _shuffle(X, y): #X and Y are np.array randomize = np.arange(X.shape[0]) np.random.shuffle(randomize) return (X[randomize], y[randomize])def split_valid_set(X, y, percentage): all_size = X.shape[0] valid_size = int(floor(all_size * percentage)) X, y = _shuffle(X, y) X_valid, y_valid = X[ : valid_size], y[ : valid_size] X_train, y_train = X[valid_size:], y[valid_size:] return X_train, y_train, X_valid, y_valid# 也可用sklearn函数打散数据# from sklearn.model_selection import train_test_split# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=1)X_train, y_train, X_valid, y_valid = split_valid_set(X_train, y_train, 0.1)X_train.shape, y_train.shape, X_valid.shape, y_valid.shape# ((27146, 103), (27146, 1), (3016, 103), (3016, 1))Generative方法123456789101112131415161718192021222324252627282930313233343536373839404142def train(X_train, y_train): # vaild_set_percetange = 0.1 # X_train, Y_train, X_valid, Y_valid = split_valid_set(X, Y, vaild_set_percetange) #Gussian distribution parameters train_data_size = X_train.shape[0] cnt1 = 0 cnt2 = 0 mu1 = np.zeros((1, X_train.shape[1])) mu2 = np.zeros((1, X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: # &gt;50k mu1 += X_train[i] cnt1 += 1 else: mu2 += X_train[i] cnt2 += 1 mu1 /= cnt1 mu2 /= cnt2 sigma1 = np.zeros((X_train.shape[1], X_train.shape[1])) sigma2 = np.zeros((X_train.shape[1], X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: sigma1 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu1), X_train[i] - mu1) else: sigma2 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu2), X_train[i] - mu2) sigma1 /= cnt1 sigma2 /= cnt2 shared_sigma = (float(cnt1) / train_data_size) * sigma1 + (float(cnt2) / train_data_size) * sigma2 N1 = cnt1 N2 = cnt2 return mu1, mu2, shared_sigma, N1, N2mu1, mu2, shared_sigma, N1, N2 = train(X_train, y_train)mu1.shape, mu2.shape, shared_sigma.shape, N1, N212345def sigmoid(z): res = 1 / (1.0 + np.exp(-z)) return np.clip(res, 1e-8, (1-(1e-8)))# from scipy.special import expit1234567891011121314151617def valid(funname, X, Y, mu1, mu2, shared_sigma, N1, N2): sigma_inv = inv(shared_sigma) w = np.dot((mu1-mu2), sigma_inv) X_t = X.T b = (-0.5) * np.dot(np.dot(mu1, sigma_inv), mu1.T) + (0.5) * np.dot(np.dot(mu2, sigma_inv), mu2.T) + np.log(float(N1)/N2) a = np.dot(w,X_t) + b y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))valid("train", X_train, y_train, mu1, mu2, shared_sigma, N1, N2)valid("valid", X_valid, y_valid, mu1, mu2, shared_sigma, N1, N2)valid("test", X_test, y_test, mu1, mu2, shared_sigma, N1, N2)# train acc = 0.837140# valid acc = 0.851459# test acc = 0.838572Discriminative方法mini_batch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# mini_batch def train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) l_rate = 0.0001 batch_size = 32 train_dataz_size = len(X_train) step_num = int(floor(train_dataz_size / batch_size)) epoch_num = 300 list_cost = [] total_loss = 0.0 for epoch in range(1, epoch_num): total_loss = 0.0 X_train, y_train = _shuffle(X_train, y_train) for idx in range(1, step_num): X = X_train[idx*batch_size:(idx+1)*batch_size] #32*104 Y = y_train[idx*batch_size:(idx+1)*batch_size] #32*1 s_grad = np.zeros((1,len(X[0]))) z = np.dot(X, w.T) # 32*104*104*1 y = sigmoid(z) # squeeze 函数：从数组的形状中删除单维度条目，即把shape中为1的维度去掉 # loss = y - np.squeeze(Y) loss = y - Y cross_entropy = -1 * (np.dot(Y.T, np.log(y)) + np.dot((1 - Y.T),\ np.log(1 - y)))/ len(Y) total_loss += cross_entropy[0][0] #grad = np.sum(-1 * X * (np.squeeze(Y) - y).reshape((batch_size, 1)), axis=0) grad = np.sum(np.dot((y - Y).T, X), axis=0) #1*32*32*104 # grad = np.dot(X.T, loss) w = w - l_rate * grad # s_grad += grad ** 2 # ada = np.sqrt(s_grad) # w = w - l_rate * grad / ada list_cost.append(total_loss) # valid(X_valid, Y_valid, w) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wdef valid(funname, X, Y, w): a = np.dot(w, X.T) y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))X_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)Ada12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Adadef train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) s_grad = np.zeros((1, len(X_train[0]))) l_rate = 0.1 epoch_num = 10000 list_cost = [] total_loss = 0.0 X = X_train y = y_train for epoch in range(epoch_num): z = np.dot(X, w.T) # n*104*104*1 Y = sigmoid(z) loss = Y - y cross_entropy = -1 * (np.dot(y.T, np.log(Y)) + np.dot((1 - y.T),\ np.log(1 - Y)))/ len(y) if abs(total_loss - cross_entropy[0][0]) &lt; 10**-9: break else: total_loss = cross_entropy[0][0] list_cost.append(total_loss) grad = np.sum(np.dot((Y - y).T, X), axis=0) #1*104 s_grad += grad**2 ada = np.sqrt(s_grad) w = w - l_rate * grad / ada print("times:", len(list_cost)) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wX_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)使用Kreas12from keras.models import Sequentialfrom keras.layers import Dense, Activation1234567891011121314151617model = Sequential()model.add(Dense(units=600, activation='sigmoid', input_dim=103))model.add(Dense(units=600, activation='sigmoid'))model.add(Dense(units=1, activation='sigmoid'))model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])model.fit(X_train, y_train, batch_size=32, epochs=50)score = model.evaluate(X_test, y_test)result = np.squeeze(model.predict(X_test))# print('Total loss on Testing set: ', score[0])# print('Accuracy of Testing set: ', score[1])# Total loss on Testing set: 0.2154487861520091# Accuracy of Testing set: 0.90295736357400741234y_ = np.around(result).astype(np.int)result = (np.squeeze(y_test) == y_)print('Test acc = %f' % (float(result.sum()) / X_test.shape[0]))# Test acc = 0.902957使用Tensorflow搭建3层神经网络1import tensorflow as tf12345678910111213141516171819xs = tf.placeholder(tf.float32, [None, 103])ys = tf.placeholder(tf.float32, [None, 1])w1 = tf.Variable(tf.random_normal([103, 600], stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([600, 600], stddev=1, seed=1))w3 = tf.Variable(tf.random_normal([600, 1], stddev=1, seed=1))a = tf.nn.relu(tf.matmul(xs, w1))b = tf.sigmoid(tf.matmul(a, w2))y = tf.sigmoid(tf.matmul(b, w3))# a = tf.matmul(xs, w1)# y = tf.matmul(a, w2)y_ = tf.round(y)cross_entropy = -tf.reduce_mean(ys*tf.log(tf.clip_by_value(y,1e-10,1.0)))train_step = tf.train.GradientDescentOptimizer(0.001).minimize(cross_entropy)correct_prediction = tf.equal(y_, ys)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))1234567891011result = Nonewith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for step in range(101): # training sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train&#125;) result = sess.run(y, feed_dict=&#123;xs: X_train, ys: y_train&#125;) if step % 100 == 0: print("accuracy:",sess.run(accuracy, feed_dict=&#123;xs: X_train, ys: y_train&#125;))# accuracy: 0.7285788随机森林和XGBoost1234# 随机森林from sklearn import metricsfrom sklearn.ensemble import RandomForestClassifierrfc=RandomForestClassifier()123# XGBoostfrom xgboost import XGBClassifierxgbc=XGBClassifier()123456# 选取k-1折的数据进行模型训练import warningswarnings.filterwarnings("ignore")from sklearn.model_selection import cross_val_score cross_val_score(rfc,X_train, y_train.ravel(),cv=5).mean(), cross_val_score(xgbc,X_train, y_train.ravel(),cv=5).mean()# (0.8434758405223647, 0.8613788898712886)12345#默认随机森林预测rfc.fit(X_train, y_train)rfc_y_predict = rfc.predict(X_valid)rfc.score(X_valid, y_valid)# 0.839854111405835512345# XGBoost预测xgbc.fit(X_train, y_train)xgbc_y_predict = xgbc.predict(X_valid)xgbc.score(X_valid, y_valid)# 0.862068965517241312345from sklearn.metrics import classification_reportprint('随机森林的预测准确率:')print(classification_report(y_valid, rfc_y_predict, target_names=['result'])) print('XGBoost的预测准确率:') print(classification_report(y_valid, xgbc_y_predict, target_names=['result']))保存数据1234# df = pd.DataFrame(&#123;"id": np.arange(1, 16282), "label": y_&#125;)# if not os.path.exists(output_dir):# os.mkdir(output_dir)# df.to_csv(os.path.join(output_dir + 'nn_output.csv'), sep='\t', index=False)参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 1 - PM2.5 Prediction]]></title>
    <url>%2F2019%2F03%2F25%2FHomework-1-PM2-5-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业一，PM2.5预测PM2.5预测1. 导入相关库123import numpy as npimport pandas as pdimport matplotlib.pyplot as plt2. 数据处理1234train_data = pd.read_csv("train.csv")# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data.info() # 240条数据，每条数据18个feature12345# 将RAINFALL值为NR的数据置0train_data[train_data[train_data['Obvservations']=='RAINFALL'].iloc[:,3:] == 'NR'] = 0# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data[train_data['Obvservations']=='RAINFALL'].head()123456789101112tempxlist = [] tempylist = [] # 一天内总共有24-10+1 =15条记录for j in range(0, 240): for i in range(15): tempx = np.array(train_data.iloc[j*18:(j+1)*18,3:].iloc[:, i:i+9], float).reshape(1, 18*9) tempy = np.array(train_data.iloc[j*18+9:j*18+10,3:].iloc[:, i+9], float) # tempx = pm2_5.iloc[:,i:i+9] #使用前9小时数据作为feature # tempy = pm2_5.iloc[:,i+9] #使用第10个小数数据作为lable tempxlist.append(tempx) tempylist.append(tempy)12345678# X = np.array(pd.concat(tempxlist), float)X = np.concatenate(tempxlist, axis=0)# 插入列向量[1;1;...;1;]X = np.insert(X, 0, values=np.ones((1, X.shape[0])), axis=1)# y = np.array(pd.concat(tempylist), float)y = np.concatenate(tempylist, axis=0)y = y.reshape(y.shape[0], 1)X, y12X.shape, y.shape# ((3600, 163), (3600, 1))12# 特征归一化(Feature Scaling)X = (X - X.mean()) / X.std()12345# 代价函数def cost(y, w): temp = np.dot(X,w) loss = np.square(y - temp) return np.sum(loss)/len(y)3. 开始训练adagrad123456789101112131415161718192021# adagraddef ada(X, y, w, lr, iteration, lambdaL2): list_cost = [] s_grad = np.zeros([len(X[0]), 1]) for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2*w s_grad += grad**2 ada = np.sqrt(s_grad) w = w - lr*grad/ada return w, list_costlr_ada = 10w_ada = np.zeros([X.shape[1], 1])w_ada, list_cost_ada = ada(X, y, w_ada, lr_ada, 10000, 0.)cost(y, w_ada)# 38.190334888655144SGD1234567891011121314151617181920# SGDdef SGD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) rand = np.random.randint(0, len(X)) grad = X[rand].reshape(X.shape[1], 1)*loss[rand].reshape(loss.shape[1], 1)/len(X) + lambdaL2*w w = w - lr*grad return w, list_costw_sgd = np.zeros([X.shape[1], 1])lr_sgd = 0.1w_sgd, list_cost_sgd = SGD(X, y, w_sgd, lr_sgd, 10000, 0.)cost(y, w_sgd)# 209.00938349734912GD1234567891011121314151617def GD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X, w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2 * w w = w - lr*grad return w, list_costw_gd = np.zeros([X.shape[1], 1])lr_gd = 0.01w_gd, list_cost_gd = GD(X, y, w_gd, lr_gd, 10000, 0.)cost(y, w_gd)# 44.80863160107732正规方程1234#close formw_cf = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)cost_wcf = np.sum((X.dot(w_cf)-y)**2) / len(X)hori = [cost_wcf for i in range(10000-3)]12345678910fig = plt.figure(figsize=(12,8))plt.plot(np.arange(len(list_cost_ada[3:])), list_cost_ada[3:], 'b', label="ada")plt.plot(np.arange(len(list_cost_sgd[3:])), list_cost_sgd[3:], 'g', label='sgd')plt.plot(np.arange(len(list_cost_gd[3:])), list_cost_gd[3:], 'r', label='gd')plt.plot(np.arange(len(list_cost_ada[3:])), hori, 'y--', label='close-form')plt.title('Train Process')plt.xlabel('Iteration')plt.ylabel('Loss Function(Quadratic)')plt.legend()plt.show()4. 使用Sklearn1234from sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import cross_val_predictfrom sklearn import metrics1234567X_train, X_test, y_train, y_test = train_test_split(X[:, 1:], y, random_state=1)linreg = LinearRegression()linreg.fit(X_train, y_train)predicted = cross_val_predict(linreg, X, y, cv=10)# linreg.intercept_, linreg.coef_metrics.mean_squared_error(y, predicted)# 42.576599287222915. 使用Tensorflow1import tensorflow as tf1234567891011121314151617181920212223242526272829303132333435363738def linear_regression(X_data, y_data, alpha, epoch, optimizer=tf.train.GradientDescentOptimizer): tf.reset_default_graph() xs = tf.placeholder(tf.float32, [None, X_data.shape[1]]) ys = tf.placeholder(tf.float32, [None, 1]) W = tf.Variable(tf.random_uniform([X_data.shape[1], 1], -10.0, 10.0)) y_pred = tf.matmul(xs, W) loss = tf.reduce_mean(tf.square(ys - y_pred)) if optimizer == tf.train.GradientDescentOptimizer: alpha = 0.01 elif optimizer == tf.train.AdagradOptimizer: alpha = 10 elif optimizer == tf.train.AdamOptimizer: alpha = 0.1 elif optimizer == tf.train.FtrlOptimizer: alpha = 10 elif optimizer == tf.train.RMSPropOptimizer: alpha = 10 opt = optimizer(learning_rate=alpha) opt_operation = opt.minimize(loss) # run the session with tf.Session() as sess: sess.run(tf.global_variables_initializer()) loss_data = [] for i in range(epoch): _, loss_val, W_val = sess.run([opt_operation, loss, W], feed_dict=&#123;xs: X_data, ys: y_data&#125;) loss_data.append(loss_val) if len(loss_data) &gt; 1 and np.abs(loss_data[-1] - loss_data[-2]) &lt; 10 ** -9: break tf.reset_default_graph() return &#123;'loss': loss_data, 'parameters': W_val&#125; # just want to return in row vector format123456789101112131415161718epoch = 10000alpha = 0.0001# 各种优化函数optimizer_dict=&#123;'GD': tf.train.GradientDescentOptimizer, 'Adagrad': tf.train.AdagradOptimizer, #'Adam': tf.train.AdamOptimizer, #'Ftrl': tf.train.FtrlOptimizer, #'RMS': tf.train.RMSPropOptimizer #'Momentum': tf.train.MomentumOptimizer两个参数 &#125;results = []t_loss = dict()for name in optimizer_dict: # 这里X应该是X[:, 1:] res = linear_regression(X, y, alpha, epoch, optimizer=optimizer_dict[name]) res['name'] = name t_loss[name] = res results.append(res)1234567891011121314fig, ax = plt.subplots(figsize=(16, 9))for res in results: loss_data = res['loss'] ax.plot(np.arange(len(loss_data[10:])), loss_data[10:], label=res['name'])ax.plot(np.arange(len(list_cost_ada[10:])), hori[0: 9990], label='close-form') ax.set_xlabel('epoch', fontsize=18)ax.set_ylabel('cost', fontsize=18)ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)ax.set_title('different optimizer', fontsize=18)plt.show()12t_loss["Adagrad"]["loss"][-1], t_loss["GD"]["loss"][-1]# (39.07505, 168.04092)6. 保存数据123test_data = pd.read_csv("test.csv")# pm2_5_test = test_data[test_data['AMB_TEMP'] == 'PM2.5'].iloc[:,2:]# pm2_5_test.info()1234# 对X_test进行一系列数据处理即可# X_test = np.array(pm2_5_test, float)# X_test = np.insert(X_test, 0, values=np.ones((1, X_test.shape[0])), axis=1)X_test12345#预测y_star = np.dot(X_test, w)y_pre = pd.read_csv("sampleSubmission.csv")y_pre.value = y_stary_pre.to_csv('predict.csv', index=False)参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好]]></title>
    <url>%2F2019%2F02%2F28%2F%E4%BD%A0%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[那些都是很好很好的，可我偏偏不喜欢。]]></content>
  </entry>
</search>
