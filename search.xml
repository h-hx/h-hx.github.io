<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（一）]]></title>
    <url>%2F2019%2F08%2F13%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[神经网络和深度学习—神经网络基础（Basics of Neural Network programming）二分类（Binary Classification）符号定义 ：$x$：表示一个$n_x$维数据，为输入数据，维度为$(n_x,1)$；$y$：表示输出结果，取值为$(0,1)$；$(x^{(i)},y^{(i)})$：表示第$i$组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据；$X=[x^{(1)},x^{(2)},…,x^{(m)}]$：表示所有的训练数据集的输入值，放在一个 $n_x×m$的矩阵中，其中$m$表示样本数目;$Y=[y^{(1)},y^{(2)},…,y^{(m)}]$：对应表示所有训练数据集的输出值，维度为$1×m$。逻辑回归（Logistic Regression）逻辑回归中：$\hat{y}={w}^{T}x+b$引入$sigmoid$函数：$\begin{align}\sigma \left( z \right)&amp;=\frac{1}{1+{e^{-z}}} \\ \sigma’(z)&amp;=\frac{1}{(1+{e^{-z}})^2}\times e^{-z}\\ &amp;=\sigma(z)\frac{e^{-z}}{1+{e^{-z}}}\\ &amp;=\sigma(z)(1-\sigma(z))\end{align}$定义$\hat{y}=\sigma \left( {\theta ^{T}}x \right)$的sigmoid函数。有一组参数向量${\theta _{0}},{\theta _{1}},{\theta_{2}},…,{\theta _{n_{x}}}$，此时${\theta_{0}}$就充当了$b$，而剩下的${\theta_{1}}$ 直到${\theta_{n_{x}}}$充当了$w$$\theta.shape=(w.shape+1,1)$]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习入门-基于Python的理论实现》笔记]]></title>
    <url>%2F2019%2F08%2F13%2F%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8-%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E5%AE%9E%E7%8E%B0%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章：Python入门略。第二章：感知机简单例子$x_1,x_2$是输入信号，$y$是输出信号，$w_1,w_2$是权重。图中的圈称为”神经元”，或者“节点”。只有传送过来的信号总和超过某个阈值$\theta$，才会输出1。数学公式表示：$y=\left\{\begin{aligned}0 \quad (w_1x_1+w_2x_2\le\theta) \\1 \quad(w_1x_1+w_2x_2\gt \theta) \end{aligned} \right.$导入权重和偏置$y=\left\{\begin{aligned}0 \quad (b+w_1x_1+w_2x_2\le0) \\1 \quad(b+w_1x_1+w_2x_2\gt 0) \end{aligned} \right.$$\theta=-b$简单实现与门12345678910111213141516171819202122import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = AND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 0# (1, 0) -&gt; 0# (0, 1) -&gt; 0# (1, 1) -&gt; 1非门1234567891011121314151617181920212223# coding: utf-8import numpy as npdef NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = NAND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 1# (1, 0) -&gt; 1# (0, 1) -&gt; 1# (1, 1) -&gt; 0或门123456789101112131415161718# coding: utf-8import numpy as npdef OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = OR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))感知机的可视化图：灰色区域是感知机输出0的区域，这个区域与或门的性质一致异或门感知机的局限性就在于它只能表示由一条直线分割的空间。通过组合与门、与非门、或门实现异或门1234567891011121314151617# coding: utf-8from and_gate import ANDfrom or_gate import ORfrom nand_gate import NANDdef XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y# 多层感知机if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = XOR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))第三章：神经网络简单例子感知机公式可改写成$y=h(b+w_1x_1+w_2x_2)$$h(x)=\left\{\begin{aligned}0 \quad (x\le0) \\1 \quad(x\gt 0) \end{aligned} \right.$激活函数$加权总和a=h(b+w_1x_1+w_2x_2)$$激活函数转换这总和y=h(a)$sigmoid$h(x)=\frac{1} {(1+e^{-x)} }$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef sigmoid(x): return 1 / (1 + np.exp(-x)) X = np.arange(-5.0, 5.0, 0.1)Y = sigmoid(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1)plt.show()阶跃函数$h(x)=\left\{\begin{aligned}1 \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef step_function(x): return np.array(x &gt; 0, dtype=np.int)X = np.arange(-5.0, 5.0, 0.1)Y = step_function(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1) plt.show()ReLU函数$h(x)=\left\{\begin{aligned}x \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-1.0, 5.5)plt.show()3层神经网络的实现$a_1^{(1)}=w_{11}^{(1)}x_1+w_{12}^{(1)}x_2+b_1^{(1)}$矩阵乘法表示：$\bf{A}^{(1)}=XW^{(1)}+B^{(1)}$ 1x2 2x3 = 1x3输出层的设计恒等函数softmax函数$y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}$实现softmax函数的注意事项：超大值无法表示的问题，即溢出，在进行计算机的运算时必须注意，为了防止溢出，一般会加上或减去输入信号的最大值，如下公式中的$C’$：$\begin{align}y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}&amp;=\frac{Ce^{(a_k)}}{C\sum \limits _{i=1} ^{n} e^{(a_i)}}\\&amp;=\frac{e^{(a_k+logC)}}{\sum \limits _{i=1} ^{n} e^{(a_i+logC)}}\\&amp;=\frac{e^{(a_k+C’)}}{\sum \limits _{i=1} ^{n} e^{(a_i+C’)}}\end{align}$手写数字识别1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8import sys, ossys.path.append(os.pardir) # 親ディレクトリのファイルをインポートするための設定import numpy as npimport picklefrom dataset.mnist import load_mnistfrom common.functions import sigmoid, softmaxdef get_data(): (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_testdef init_network(): with open(&quot;sample_weight.pkl&quot;, &apos;rb&apos;) as f: network = pickle.load(f) return networkdef predict(network, x): w1, w2, w3 = network[&apos;W1&apos;], network[&apos;W2&apos;], network[&apos;W3&apos;] b1, b2, b3 = network[&apos;b1&apos;], network[&apos;b2&apos;], network[&apos;b3&apos;] a1 = np.dot(x, w1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, w2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, w3) + b3 y = softmax(a3) return yx, t = get_data()network = init_network()batch_size = 100 # バッチの数accuracy_cnt = 0for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size])print(&quot;Accuracy:&quot; + str(float(accuracy_cnt) / len(x)))——————————————-有空再做笔记——————————————-参考资料《深度学习入门-基于Python的理论实现》https://github.com/oreilly-japan/deep-learning-from-scratch]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法小结]]></title>
    <url>%2F2019%2F08%2F02%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[排序汇总插入排序算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：从第一个元素开始，该元素可以认为已经被排序；取出下一个元素，在已经排序的元素序列中从后向前扫描；如果该元素（已排序）大于新元素，将该元素移到下一位置；重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；将新元素插入到该位置后；重复步骤2~5。动图演示代码描述123456789101112int insert_sort(int *arr, int n)&#123; int i, j; for (i = 1; i &lt; n; i++)&#123; if (arr[i] &lt; arr[i - 1])&#123; int temp = arr[i]; for (j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--) arr[j + 1] = arr[j]; arr[j + 1] = temp; &#125; &#125; return 0;&#125;优化折半插入排序123456789101112131415161718192021void binary_insert_sort(int* arr, int n) &#123; int i, j, mid, low, high, temp; for (i = 1; i &lt; n; i++)&#123; temp = arr[i]; low = 0; high = i; while (low &lt;= high)&#123; mid = (low + high) / 2; if (temp &gt; arr[mid])&#123; low = mid + 1; &#125; else &#123; high = mid - 1; &#125; &#125; for (j = i - 1; j &gt;= low; j--)&#123; arr[j + 1] = arr[j]; &#125; arr[low] = temp; &#125;&#125;希尔排序1959年Shell发明，第一个突破$O(n^2)$的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：选择一个增量序列$t_1,t_2,…,t_k，$其中$t_i&gt;t_j$，$t_k=1$；按增量序列个数k，对序列进行k 趟排序；每趟排序，根据对应的增量$t_i$，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。动图演示算法描述通常写法通常写法12345678910111213for (gap = n / 2; gap &gt; 0; gap /= 2)&#123; for (j = gap; j &lt; n; j++)&#123;//从数组第gap个元素开始 if (a[j] &lt; a[j - gap])&#123;//每个元素与自己组内的数据进行直接插入排序 int temp = a[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; a[k] &gt; temp)&#123; a[k + gap] = a[k]; k -= gap; &#125; a[k + gap] = temp; &#125; &#125;&#125;另一种写法1234for (gap = n / 2; gap &gt; 0; gap /= 2) for (i = gap; i &lt; n; i++) for (j = i - gap; j &gt;= 0 &amp;&amp; a[j] &gt; a[j + gap]; j -= gap) swap(a[j], a[j + gap]);增量序列$Shell：1，…，N/8，N/4，N/2 \quad 最坏O(n^2)$$Hibbard：{1, 3, …, 2^k-1} \quad 最坏O(n^3/2) \quad 猜想T(avg) = O(n^5/4)$$Sedgewick：{1, 5, 19, 41, 109…}该序列中的项或者是94^i - 92^i + 1或者是4^i - 3*2^i + 1$$猜想T(avg) = O(n^7/6) \quad T(worst)O(n^4/3)$选择排序算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：初始状态：无序区为$R[1..n]$，有序区为空；第$i$趟排序($i=1,2,3…n-1)$开始时，当前有序区和无序区分别为$R[1..i-1]$和$R(i..n）$。该趟排序从当前无序区中-选出关键字最小的记录 $R[k]$，将它与无序区的第1个记录$R$交换，使$R[1..i]$和$R[i+1..n)$分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；$n-1$趟结束，数组有序化了。动图演示代码描述1234567891011121314151617void select_sort(int number[])&#123; int i, j, min; for(i = 1; i &lt; MAX; i++) &#123; min = i; for(j = i+1; j &lt;= MAX; j++) &#123; if(number[min] &gt; number[j]) min = j; &#125; if(min != i)&#123; array[min] = array[min] + array[i]; array[i] = array[min] - array[i]; array[min] = array[min] - array[i]; &#125; &#125;&#125;优化每次查找时不仅找出最小值，还找出最大值，分别插到前面和后面，可以减少一半的查询时间。ps:也有人说是负优化12345678910111213141516171819202122232425void select_sort_plus(int array[], int size)&#123; int left = 0;//查找的左边界 int right = size - 1;//查找的右边界 while(left &lt; right) &#123; int min = left; int max = right; for (int i = left; i &lt;= right; i++)&#123; if (array[min]&gt;array[i])min = i; if (array[max] &lt; array[i])max = i; if (array[min] &lt; array[left]) &#123; array[min] = array[min] + array[left]; array[left] = array[min] - array[left]; array[min] = array[min] - array[left]; &#125; if (array[max] &gt; array[right]) &#123; array[max] = array[max] + array[right]; array[right] = array[max] - array[right]; array[max] = array[max] - array[right]; &#125; &#125; right--; left++; &#125;&#125;堆排序算法描述将初始待排序关键字序列$(R1,R2….Rn)$构建成大顶堆，此堆为初始的无序区；将堆顶元素$R[1]$与最后一个元素$R[n]$交换，此时得到新的无序区$(R1,R2,……Rn-1)$和新的有序区$(Rn)$,且满足$R[1,2…n-1]$&lt;=$R[n]$；由于交换后新的堆顶$R[1]$可能违反堆的性质，因此需要对当前无序区$(R1,R2,……Rn-1)$调整为新堆，然后再次将$R[1]$与无序区最后一个元素交换，得到新的无序区$(R1,R2….Rn-2)$和新的有序区$(Rn-1,Rn)$。不断重复此过程直到有序区的元素个数为$n-1$，则整个排序过程完成。动图演示代码描述1234567891011121314151617181920212223242526272829int build_heap(int arr[], int left, int right)&#123; int child,tmp; for (tmp = arr[left]; 2 * left + 1 &lt; right; left = child) &#123; //注意数组下标是从0开始的，所以左孩子的求发不是2*i child = 2 * left + 1; if (child != right - 1 &amp;&amp; arr[child + 1] &gt; arr[child]) ++child; //找到最大的儿子节点 if (tmp &lt; arr[child]) arr[left] = arr[child]; else break; &#125; arr[left] = tmp; return 0;&#125;//堆排序int heap_sort(int arr[], int left, int right)&#123; int i; for (i = left + (right - left) / 2; i &gt;= 0; --i) //构造堆 build_heap(arr, i, right); for (i = right; i&gt;0; --i)&#123; //将最大元素（根）与数组末尾元素交换，从而删除最大元素，重新构造堆 swap(arr,0, i); build_heap(arr, 0, i); &#125; return 0;&#125;冒泡排序算法描述比较相邻的元素。如果第一个比第二个大，就交换它们两个；对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；针对所有的元素重复以上的步骤，除了最后一个；重复步骤1~3，直到排序完成。动图演示代码描述12345678910111213void bubble_sort(int a[], int n)&#123; int i, j, temp; for (j = 0; j &lt; n - 1; j++)&#123; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125; &#125;&#125;算法分析稳定最好情况 顺序 $T=O(n)$最坏情况 逆序 $T=O(n^2)$优化1.定义一个flag，用来判断有没有进行交换，如果在某次内层循环中没有交换操作，就说明此时数组已经是有序了的，不用再进行判断，这样可以节省时间。12345678910111213141516171819void bubble_sort(int a[], int n)&#123; int i, j, temp; // C语言没有bool int isSorted = 0; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; &#125; &#125; if(isSorted == 0) break; &#125;&#125;2.每一次交换记录最后一次交换的位置，为零的时候就停止。12345678910111213141516171819202122void bubble_sort(int a[], int n)&#123; int i, j, temp; int isSorted = 0; int last = 0; int border = n - 1; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; border; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; last = i; &#125; &#125; border = last; if(isSorted = 0) break; &#125;&#125;3.鸡尾酒排序左右交替比较，交换例子第一次第二次第三次last没有变，结束原本排序8次，现在只需要3次记下两个边界值，分离出有序区。1234567891011121314151617181920212223242526272829303132333435363738def CockTailSort(array): """ :param array: 无序数组 :return: 有序数组 """ # 左右侧最后一次交换位置和左右边界 last_left = last_right = left_sort_border = 0 right_sort_border = len(array) - 1 i = j = 0 while i &lt; len(array) / 2: # 有序标记，每一轮的初始是true is_sorted = True j = left_sort_border while j &lt; right_sort_border: if array[j] &gt; array[j + 1]: array[j], array[j + 1] = array[j + 1], array[j] # 有元素交换，不是有序 is_sorted = False last_right = j j += 1 right_sort_border = last_right if is_sorted: break # 偶数轮之前，重新标记为true is_sorted = True j = right_sort_border while j &gt; left_sort_border: if array[j] &lt; array[j - 1]: array[j], array[j - 1] = array[j - 1], array[j] # 有元素交换，不是有序 is_sorted = False last_left = j j -= 1 left_sort_border = last_left if is_sorted: break i += 1 return array快速排序算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：从数列中挑出一个元素，称为 “基准”（pivot）；重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。动图演示代码描述左右指针法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴。设置两个变量$left = 0;right = N - 1$;从$left$一直向后走，直到找到一个大于$key$的值，$right$从后至前，直至找到一个小于$key$的值，然后交换这两个数。重复第三步，一直往后找，直到$left$和$right$相遇，这时将$key$放置$left$的位置即可。1234567891011121314int PartSort(int* array,int left,int right) &#123; int&amp; key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; swap(array[left],array[right]); &#125; swap(array[left],key); return left; &#125;挖坑法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴，也是初始的坑位。设置两个变量$left = 0;right = N - 1;$从$left$一直向后走，直到找到一个大于$key$的值，然后将该数放入坑中，坑位变成了$array[left]$。$right$一直向前走，直到找到一个小于$key$的值，然后将该数放入坑中，坑位变成了$array[right]$。重复3和4的步骤，直到$left$和$right$相遇，然后将$key$放入最后一个坑位。123456789101112131415int PartSort(int* array,int left,int right) &#123; int key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; array[right] = array[left]; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; array[left] = array[right]; &#125; array[right] = key; return right;&#125;前后指针法定义变量$cur$指向序列的开头，定义变量$pre$指向$cur$的前一个位置。当$array[cur] &lt; key$时，$cur$和$pre$同时往后走，如果$array[cur]&gt;key$，$cur$往后走，$pre$留在大于$key$的数值前一个位置。当$array[cur]$再次 &lt; $key$时，交换$array[cur]$和$array[pre]$。123456789101112131415161718int PartSort(int* array,int left,int right) &#123; if(left &lt; right)&#123; int key = array[right]; int cur = left; int pre = cur - 1; while(cur &lt; right) &#123; while(array[cur] &lt; key &amp;&amp; ++pre != cur)&#123; //如果找到小于key的值，并且cur和pre之间有距离时则进行交换。 //注意两个条件的先后位置不能更换 swap(array[cur],array[pre]); &#125; ++cur; &#125; swap(array[++pre],array[right]); return pre; &#125; return -1; &#125;非递归实现递归的算法主要是在划分子区间，如果要非递归实现快排，只要使用一个栈来保存区间就可以了。一般将递归程序改成非递归首先想到的就是使用栈，因为递归本身就是一个压栈的过程。1234567891011121314151617181920212223242526void QuickSortNotR(int* array,int left,int right)&#123; assert(array); stack&lt;int&gt; s; s.push(left); s.push(right);//后入的right，所以要先拿right while(!s.empty)//栈不为空 &#123; int right = s.top(); s.pop(); int left = s.top(); s.pop(); int index = PartSort(array,left,right); if((index - 1) &gt; left)//左子序列 &#123; s.push(left); s.push(index - 1); &#125; if((index + 1) &lt; right)//右子序列 &#123; s.push(index + 1); s.push(right); &#125; &#125;&#125;优化优化一：当待排序序列的长度分割到一定大小后，使用插入排序原因：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排。截止范围：待排序序列长度N = 10，虽然在5~20之间任一截止范围都有可能产生类似的结果，这种做法也避免了一些有害的退化情形。优化二：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割举例：待排序序列 1 4 6 7 6 6 7 6 8 6三数取中选取基准：下标为4的数6转换后，待分割序列：6 4 6 7 1 6 7 6 8 6​ 基准key：6本次划分后，未对与key元素相等处理的结果：1 4 6 6 7 6 7 6 8 6下次的两个子序列为：1 4 6 和 7 6 7 6 8 6本次划分后，对与key元素相等处理的结果：1 4 6 6 6 6 6 7 8 7下次的两个子序列为：1 4 和 7 8 7经过对比，我们可以看出，在一次划分后，把与key相等的元素聚在一起，能减少迭代次数，效率会提高不少具体过程：在处理过程中，会有两个步骤第一步，在划分过程中，把与key相等元素放入数组的两端第二步，划分结束后，把与key相等的元素移到枢轴周围归并排序算法描述把长度为n的输入序列分成两个长度为n/2的子序列；对这两个子序列分别采用归并排序；将两个排序好的子序列合并成一个最终的排序序列。动图演示代码描述递归实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/将数组b[]中的数复制到数组a[]中 template&lt;class Type&gt; void Copy(Type a[],Type b[],int left,int right) &#123; for(int i=left;i&lt;=right;i++) a[i]=b[i]; &#125; //将已排好序的数组合并到数组b[]中 template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) //i的取值范围为 [left,mid], j的取值范围为 [mid+1,right] &#123; if(a[i]&lt;a[j]) //取左右两边数组中较小的元素放入数组b中，最后得到的数组b即为有序 b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) //说明右边的数组的元素个数多 for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;i&lt;=mid;i++) b[k++]=a[z]; &#125; //将待排序集合一分为二，直至待排序集合只剩下一个元素为止， //然后不断合并两个排好序的数组段 template&lt;class Type&gt; void MergeSort(Type a[],int left,int right) &#123; Type *b=new Type [maxn]; if(left&lt;right) //控制待排序数组中至少有两个元素，一个元素时为有序 &#123; int i=(left+right)/2; //取数组中点，将数组尽量均等划分 MergeSort(a,left,i); //将左半段进行递归排序 MergeSort(a,i+1,right); //将右半段进行递归排序 Merge(a,b,left,i,right); //合并到数组b Copy(a,b,left,right); //复制到数组a &#125; delete[] b; &#125;非递归实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) &#123; if(a[i]&lt;a[j]) b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;z&lt;=mid;z++) b[k++]=a[z]; &#125; //合并大小为s的相邻子数组 template&lt;class Type&gt; void MergePass(Type x[],Type y[],int s,int n) &#123; int i=0; while(i+2*s-1&lt;n) &#123; Merge(x,y,i,i+s-1,i+2*s-1); //合并大小为s的相邻2段子数组 i+=2*s; &#125; if(i+s&lt;n) //剩下的元素个数m满足：s&lt;= m &lt;2*s Merge(x,y,i,i+s-1,n-1); else //剩下的元素个数m满足：m&lt;s for(int j=i;j&lt;=n-1;j++) y[j]=x[j]; &#125; template&lt;class Type&gt; void MergeSort(Type c[],int n) &#123; Type *d=new Type [n]; int s=1; while(s&lt;n) &#123; MergePass(c,d,s,n); //合并到数组d s+=s; MergePass(d,c,s,n); //合并到数组c s+=s; &#125; delete[] b; &#125;计数排序计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。算法描述找出待排序的数组中最大和最小的元素；统计数组中每个值为i的元素出现的次数，存入数组C的第i项；对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。动图演示代码描述12345678910111213141516171819202122232425262728void CountSort(int* array, int size) &#123; assert(array); int max = array[0];//序列中的最大值 int min = array[0];//序列中的最小值 for(int i = 0;i &lt; size;++i) &#123; if(array[i] &gt;= max) &#123; max = array[i]; &#125; else &#123; min = array[i]; &#125; &#125; int range = max - min + 1;//需要开辟的空间大小 int* count = new int[range]; memset(count,0,sizeof(int)*range);//辅助空间初始化为0,0代表没有那个数 for(int i = 0;i &lt; size;++i) &#123; count[array[i] - min]++;//array[i]-min是将该数对应到辅助空间的下标 &#125; int index = 0; //遍历辅助空间 for(int i = 0;i &lt; range;++i) &#123; //下标处的数值是几，说明该数出现了几次 while(count[i]--) &#123; array[index++] = i + min;//将下标处的数对应回原数组 &#125; &#125; delete[] count;&#125;桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。算法描述设置一个定量的数组当作空桶；遍历输入数据，并且把数据一个一个放到对应的桶里去；对每个不是空的桶进行排序；从不是空的桶里把排好序的数据拼接起来。动图演示代码描述12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#pragma once//每一个节点的结构struct node&#123; int key; //关键字，在桶中统计桶中数据量，在数据节点中就是节点的数据 struct node *next;&#125;;//声明：void PrintBucketSort(node** bucket, int bucket_size);int f(int x);void BucketSort(int* a, int size,int bucket_size)&#123; assert(a); //给桶申请空间 node** bucket = new node*[bucket_size*sizeof(node)]; //初始化 for (int i = 0; i &lt; bucket_size; ++i) &#123; bucket[i] = new node[sizeof(node)]; //每一个桶 bucket[i]-&gt;key = 0; bucket[i]-&gt;next = nullptr; &#125; for (int j = 0; j &lt; size; ++j) &#123; node* sub_node = new node[sizeof(node)]; //桶下的每一个节点 sub_node-&gt;key = a[j]; sub_node-&gt;next = nullptr; //计算这数据在哪个桶中 int num = f(a[j]); //让一个指针指向这个桶号的头 node* sub_head = bucket[num]; //开始插入 if (sub_head-&gt;next == nullptr) &#123; bucket[num]-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; //该桶号不为空，那么插入排序 else &#123; while (sub_head-&gt;next != nullptr &amp;&amp; sub_node-&gt;key &gt;= sub_head-&gt;next-&gt;key) &#123; sub_head = sub_head-&gt;next; &#125; sub_node-&gt;next = sub_head-&gt;next; sub_head-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; &#125; //打印 PrintBucketSort(bucket, bucket_size);&#125;//映射函数int f(int x)&#123; return (x / 10);&#125;//打印void PrintBucketSort(node** bucket, int bucket_size)&#123; //多少桶链(桶号) for (int i = 0; i &lt; bucket_size; ++i) &#123; node* cur = bucket[i]-&gt;next; while (cur) &#123; cout &lt;&lt; cur-&gt;key &lt;&lt; " "; cur = cur-&gt;next; &#125; &#125; cout &lt;&lt; endl;&#125;void Test7()&#123; int a[10] = &#123; 49, 38, 35, 97, 76, 73, 27, 49, 34, 78 &#125;; cout &lt;&lt; "桶排序" &lt;&lt; endl; BucketSort(a, 10, 10); //桶数据最大才97，所以需要10个桶&#125;归并排序算法描述取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点）动图演示代码描述LSD+MSD1234//伪代码如下RADIXSORT(A,d) for i = 1 to d use a stable sort to sort array A on digit i表排序算法描述又称间接排序，排序时不调整元素的实际位置，而是定义一个额外的数组作为“表”（table）。根据元素的关键字大小来调整元素对应下标在表中的位置。动图演示物理排序经过表排序后，得到了排好序的table数组，但是如果需要调整元素的实际位置，那就需要物理排序。分别对每个环里面的元素按照物理排序，取出环中一个元素，保存在临时变量中，由于空出了一个位置，就可以将该位置上本来应该放置的元素移动过来，又空出一个位置，继续移动，直到环中元素访问完成，将保存在临时变量中的元素放在最后一个空位。这就完成了一个环的物理排序。如何判断一个环的结束：每访问一个空位i后，就令table[i]=i。当发现table[i]==i时，环就结束了。代码描述12345678910111213141516171819202122struct Element &#123; ElementType Data; // data可以是任意类型 ElementType key; // 关键字只要可比即可&#125;// 物理排序过程 Elements = 元素数组， table = 表数组，假设表数组已经排好了void Sort(Element[] Elements, int[] table, int N) &#123; for (i = 0; i &lt; N; i++) &#123; Temp = Elements[i]; int j = i; while (table[j] != j) &#123; Elements[j] = Elements[table[j]]; // 把实际该置于j位置的元素置于J NextIndex = table[j]; // 记录下一个元素的位置 table[j] = j; j = NextIndex; // 让j跳到下一个元素 &#125; if (Elements[j] != Temp) &#123; // 说明该环不止一个元素，需要进行temp的赋值 Elements[j] = Temp; &#125; &#125;&#125;复杂度分析​ * 最好情况：初始即有序​ * 最坏情况：​ * 有$⌊N/2⌋$个环，每个环包含2个元素需要$⌊3N/2⌋$次元素移动 $T=O(mN)$，$m$是每个元素复制的时间其他排序算法睡眠排序Stooge排序Bogo 排序参考资料https://mooc.study.163.com/course/1000033001?tid=2402970002https://www.cnblogs.com/chengxiao/category/880910.htmlhttps://blog.csdn.net/qq_36528114/article/details/78667034《漫画算法：小灰的算法之旅》]]></content>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 3 - Image Sentiment Classification]]></title>
    <url>%2F2019%2F04%2F11%2FHomework-3-Image-Sentiment-Classification%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，情感图片分类情感图片分类导入相关库123import pandas as pdimport numpy as npfrom matplotlib import pyplot as plt数据处理123df_train = pd.read_csv("train.csv")df_test = pd.read_csv("test.csv")df_train.info()1sentiment = ['angry','disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']123456789plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure(figsize=(6,4))ax = fig.add_subplot(111)# plt.hist(train_df['label'], 7)df_train['label'].value_counts().plot(kind='bar')plt.ylabel("人数")plt.show()df_train['label'].value_counts()12123456# 传入来的每张图片feature都是字符串X = df_train.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X = np.array(X.map(lambda x: x.reshape(48,48,1)).values.tolist()) X = (X/255.0*0.99) + 0.001X.shape# (28709, 48, 48, 1)12345X_test = df_test.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X_test = np.array(X_test.map(lambda x: x.reshape(48,48,1)).values.tolist()) X_test = (X_test/255.0*0.99) + 0.001X_test.shape# (7178, 48, 48, 1)123y = df_train.label.values.reshape(-1, 1)y.shape# (28709, 1)123456# 查看一张图片fig = plt.figure(figsize=(3, 3))ax = fig.subplots(1)ax.imshow(X[0].reshape(48, 48), cmap = 'gray')plt.xlabel(sentiment[int(y[0])])plt.show()开始训练123456789import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, \ Flatten, BatchNormalization, InputLayer, Input, Activationfrom tensorflow.keras.optimizers import RMSpropfrom tensorflow.keras.models import Modelfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard1234# one-hoty = keras.utils.to_categorical(y, 7)y.shape# (28709, 7)1234from sklearn.model_selection import train_test_splitX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)X_train.shape, X_valid.shape, y_train.shape, y_valid.shape# ((20096, 48, 48, 1), (8613, 48, 48, 1), (20096, 7), (8613, 7))12CNN1234567891011121314151617181920212223242526272829303132cnn_model = Sequential()# 48*48*1 -&gt; 48*48*64cnn_model.add(Conv2D(filters= 64, kernel_size=(5, 5), strides=1, padding='Same', activation='relu',input_shape=(48,48,1)))# -&gt;24*24*64 cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25)) # -&gt; 24*24*128cnn_model.add(Conv2D(filters= 128, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;12*12*128cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25))# -&gt; 12*12*256cnn_model.add(Conv2D(filters= 256, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;6*6*256cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.5))# -&gt;9216cnn_model.add(Flatten())cnn_model.add(BatchNormalization())# -&gt;128cnn_model.add(Dense(128, activation='relu')) # -&gt;7cnn_model.add(BatchNormalization())cnn_model.add(Dense(7, activation='softmax'))12batch_size = 64epochs = 100 # 1012# optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234cnn_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])123456789101112131415161718# class_weight = 'auto', 用于处理skewed classes# 也可以model.compile(.... metrics=[Precision, Recall])# 或者# from sklearn.utils.class_weight import compute_class_weight# class_weight = compute_class_weight(class_weight='balanced',# classes=np.unique(train_data.label),# y=train_data.label)# model.fit(... class_weight=class_weight)# import os# os.environ["CUDA_VISIBLE_DEVICES"] = "0"cnn_result = cnn_model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto') # callbacks=[tensorboard]12345678910# 查看accfig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(cnn_result.history['loss'], label='Train Loss')ax[0].plot(cnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(cnn_result.history['acc'], label='Train acc')ax[1].plot(cnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()DNN123456789101112131415161718192021222324#DNN modelinputs = Input(shape=(48,48,1))dnn = Flatten()(inputs)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.25)(dnn)dnn = Dense(1024)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(7)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('softmax')(dnn)1234567outputs = dnndnn_model = Model(inputs=inputs, outputs=outputs)# tensorboard = TensorBoard(log_dir="logs/&#123;&#125;".format(time()))dnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])123456dnn_result = model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto')123456789fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(dnn_result.history['loss'], label='Train Loss')ax[0].plot(dnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(dnn_result.history['acc'], label='Train acc')ax[1].plot(dnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()保存h5文件12cnn_model.save('cnn.h5')dnn_model.save('dnn.h5')模型分析混淆矩阵绘制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from sklearn.metrics import confusion_matrixdef plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues): """ This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. """ if not title: if normalize: title = 'Normalized confusion matrix' else: title = 'Confusion matrix, without normalization' # Compute confusion matrix cm = confusion_matrix(y_true, y_pred) # Only use the labels that appear in the data #classes = classes[unique_labels(y_true, y_pred)] if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print("Normalized confusion matrix") else: print('Confusion matrix, without normalization') print(cm) fig, ax = plt.subplots() im = ax.imshow(cm, interpolation='nearest', cmap=cmap) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=title, ylabel='True label', xlabel='Predicted label') # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor") # Loop over data dimensions and create text annotations. fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha="center", va="center", color="white" if cm[i, j] &gt; thresh else "black") fig.tight_layout() return ax1234567cnn_predict = cnn_model.predict(X_valid)cnn_cls = np.argmax(cnn_predict, axis=1)dnn_predict = dnn_model.predict(X_valid)dnn_cls = np.argmax(dnn_predict, axis=1)y_label = data = [np.argmax(one_hot)for one_hot in y_valid]1plot_confusion_matrix(y_label, cnn_cls, sentiment)1plot_confusion_matrix(y_label, dnn_cls, sentiment)错误图片查看1234true_cls = pd.Series(y_label, name='true_cls')[y_label!=cnn_cls]wrong_cls = pd.Series(cnn_cls, name='wrong_cls')[y_label!=cnn_cls]wrong = pd.concat([true_cls, wrong_cls], axis = 1)特征图查看卷积核的可视化参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HWhttps://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Titanic: Machine Learning from Disaster]]></title>
    <url>%2F2019%2F04%2F06%2FTitanic-Machine-Learning-from-Disaster%2F</url>
    <content type="text"><![CDATA[Kaggle入坑题目数据处理导入基础库1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns读取并处理数据1234train_data = pd.read_csv('train.csv')test_data = pd.read_csv('test.csv')# train_data.columns.valuestrain_data.head()#查看前五行1train_data.info()#查看数据信息123456# 查看空值数目print('train_data:')print(train_data.isnull().sum())print("-"*20)print('test_data:')print(test_data.isnull().sum())train_data中891位乘客信息，其中属性Age，Cabin和Embarked有数据丢失。test_data中，属性Age，Fare和Cabin有数据丢失。对于缺少数据，使用年龄的中位数填补年龄空值，去除丢失Embarked，Fare属性的数据。对于Cabin属性，种类很多，观察其是否丢失与是否存活之间的关系，将Cabin属性分为是否丢失两类。1234567891011121314plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure() fig.set(alpha=0.2) # 设定图表颜色alpha参数 not_null_cabin = train_data.Survived[train_data.Cabin.isnull()].value_counts() null_cabin = train_data.Survived[train_data.Cabin.notnull()].value_counts() df = pd.DataFrame(&#123;'Cabin丢失':not_null_cabin , 'Cabin未丢失':null_cabin&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("是否存活") plt.ylabel("人数") plt.show()# train_data.Cabin.value_counts()12345678910111213141516171819202122 # 使用年龄的中位数填补年龄空值train_data['Age'].fillna(train_data['Age'].median(), inplace = True)test_data['Age'].fillna(test_data['Age'].median(), inplace = True)# Cabin根据是否缺失分为两类train_data.loc[ (train_data.Cabin.notnull()), 'Cabin' ] = "Yes"train_data.loc[ (train_data.Cabin.isnull()), 'Cabin' ] = "No"test_data.loc[ (test_data.Cabin.notnull()), 'Cabin' ] = "Yes"test_data.loc[ (test_data.Cabin.isnull()), 'Cabin' ] = "No" # 去除丢失Embarked，Fare的数据train_data = train_data.dropna()# test_data补充test_data.loc[ (test_data.Fare.isnull()), 'Fare' ] = test_data['Fare'].median()# 去除无关数据PassengerId和Tickettrain_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)test_id = test_data.PassengerIdtest_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)train_data.info()# test_data.info()进一步处理数据12345678910111213141516171819202122232425262728293031323334def clean_data(dataset): # 新建家庭大小属性：堂兄弟/妹个数 + 父母与小孩个数 dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 # 是否仅有自身一人，1：是，0：否 dataset['IsAlone'] = 1 dataset['IsAlone'].loc[dataset['FamilySize'] &gt; 1] = 0 # 分离出称谓 Mr/Mrs/Miss/Master... dataset['Title'] = dataset['Name'].str.split(", ", expand=True)[1].str.split(".", expand=True)[0] # 比起把Fare和Age当作特征列，将这些列的值进行二进制转换更为合理。 # Scikit-Learn 开发了新的估计器 KBinsDiscretizer 来执行这一操作。 # 它不仅将这些值转换为二进制码，还会对其进行编码。 # 也可以通过 Pandas 的 cut 和 qcut 函数手动完成这个过程。 # qcut据这些值的频率来选择箱子的均匀间隔，即每个箱子中含有的数的数量是相同的 dataset['FareBin'] = pd.qcut(dataset['Fare'], 4) # cut将根据值本身来选择箱子均匀间隔，即每个箱子的间距都是相同的 dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)clean_data(train_data)clean_data(test_data) # print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (train_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctrain_data['Title'] = train_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(train_data['Title'].value_counts())12345678# print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (test_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctest_data['Title'] = test_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(test_data['Title'].value_counts())123456789101112# from sklearn.preprocessing import OneHotEncoder, LabelEncoder# LabelEncoder()对不连续的数字或文本编号# 这里使用one-hotdummy = ['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Title', 'Embarked', 'FamilySize', 'IsAlone','FareBin', 'AgeBin'] Target = ['Survived']train_dummy = pd.get_dummies(train_data[dummy])test_dummy = pd.get_dummies(test_data[dummy])train_dummy.columns.values1train_dummy = train_dummy.drop(['Age', 'Fare'], axis=1)123456from sklearn import model_selectiontrain_x_dummy, valid_x_dummy, train_y, valid_y = model_selection.train_test_split \ (train_dummy, train_data[Target], random_state = 0)train_x_dummy.shape, valid_x_dummy.shape, train_y.shape, valid_y.shape# ((666, 26), (223, 26), (666, 1), (223, 1))进行数据分析12345678for x in ['Pclass', 'Sex','SibSp', 'Parch', 'Cabin', 'Embarked', \ 'FamilySize', 'IsAlone', 'Title']: # 打印和Survived相关的属性，'Age'和'Fare' 除外 print('Survival Correlation by:', x) print(train_data[[x, "Survived"]].groupby(x, as_index=False).mean()) print('-'*10, '\n')# print(pd.crosstab(train_x_dummy.Pclass, train_y.Survived))12345678910111213141516171819202122232425262728293031323334# plt.figure(figsize=[18,10])# plt.subplot(231)# plt.boxplot(x=train_data['Fare'], showmeans = True, meanline = True)# plt.subplot(232)# plt.boxplot(train_data['Age'], showmeans = True, meanline = True)# plt.subplot(233)# plt.boxplot(train_data['FamilySize'], showmeans = True, meanline = True)# plt.subplot(234)# plt.hist(x = [train_data[train_data['Survived']==1]['Fare'], \# train_data[train_data['Survived']==0]['Fare']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(235)# plt.hist(x = [train_data[train_data['Survived']==1]['Age'], \# train_data[train_data['Survived']==0]['Age']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(236)# plt.hist(x = [train_data[train_data['Survived']==1]['FamilySize'], \# train_data[train_data['Survived']==0]['FamilySize']], # stacked=True, label = ['Survived','Dead'])fig, saxis = plt.subplots(2,3,figsize=(18,10))sns.boxplot(y = 'Fare', hue = 'Survived', data = train_data, ax = saxis[0,0])sns.boxplot(y = 'Age', hue = 'Survived', data = train_data, ax = saxis[0,1])sns.boxplot(y = 'FamilySize', hue = 'Survived', data = train_data, ax = saxis[0,2])sns.barplot(x = 'FareBin', y = 'Survived', data = train_data, ax = saxis[1,0])sns.barplot(x = 'AgeBin', y = 'Survived', data = train_data, ax = saxis[1,1])sns.barplot(x = 'FamilySize', y = 'Survived', data = train_data, ax = saxis[1,2])123456789fig, saxis = plt.subplots(2, 3,figsize=(18,10))sns.barplot(x = 'Embarked', y = 'Survived', data=train_data, ax = saxis[0,0])sns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=train_data, ax = saxis[0,1])sns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=train_data, ax = saxis[0,2])sns.pointplot(x = 'FareBin', y = 'Survived', data=train_data, ax = saxis[1,0])sns.pointplot(x = 'AgeBin', y = 'Survived', data=train_data, ax = saxis[1,1])sns.pointplot(x = 'FamilySize', y = 'Survived', data=train_data, ax = saxis[1,2])12345fig, saxis = plt.subplots(1,3,figsize=(18,5))sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=train_data, ax = saxis[0])sns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=train_data, ax = saxis[1])sns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=train_data, ax = saxis[2])12345678910fig, saxis = plt.subplots(1, 2,figsize=(12,5))sns.pointplot(x="FamilySize", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[0])sns.pointplot(x="Pclass", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[1])123e = sns.FacetGrid(train_data, col = 'Embarked')e.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')e.add_legend()1234e = sns.FacetGrid(train_data, hue = 'Survived', aspect=4 )e.map(sns.kdeplot, 'Age', shade= True )e.set(xlim=(0 , train_data['Age'].max()))e.add_legend()123e = sns.FacetGrid(train_data, row = 'Sex', col = 'Pclass', hue = 'Survived')e.map(plt.hist, 'Age', alpha = .75)e.add_legend()12e = sns.pairplot(train_data, hue = 'Survived', palette = 'deep', height=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )e.set(xticklabels=[])12345678910111213141516171819# 热力图def correlation_heatmap(df): _ , ax = plt.subplots(figsize =(14, 12)) colormap = sns.diverging_palette(220, 10, as_cmap = True) # 创建分散颜色 _ = sns.heatmap( df.corr(), cmap = colormap, square=True, # 设置热力图矩阵小块形状，默认值是False cbar_kws=&#123;'shrink':.9 &#125;, # 热力图侧边绘制颜色刻度条时，相关字体设置，默认值是None ax=ax, annot=True, # 在热力图每个方格写入数据；如果是矩阵，在热力图每个方格写入该矩阵对应位置数据，默认值是False linewidths=0.1,vmax=1.0, linecolor='white', # vmax热力图的颜色取值最大范围 annot_kws=&#123;'fontsize':12 &#125; ) plt.title('Pearson Correlation of Features', y=1.05, size=15)correlation_heatmap(train_data)选择MLA进行训练1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, \ neighbors, svm, tree, discriminant_analysisfrom xgboost import XGBClassifierfrom sklearn.linear_model import stochastic_gradientMLA = [ # 集成方法 ensemble.AdaBoostClassifier(), ensemble.BaggingClassifier(), ensemble.ExtraTreesClassifier(), ensemble.GradientBoostingClassifier(), ensemble.RandomForestClassifier(), # 高斯过程 gaussian_process.GaussianProcessClassifier(), # 广义线性模型 linear_model.LogisticRegressionCV(), linear_model.PassiveAggressiveClassifier(max_iter=5), linear_model.RidgeClassifierCV(), stochastic_gradient.SGDClassifier(max_iter=5), linear_model.Perceptron(max_iter=5), # 朴素贝叶斯 naive_bayes.BernoulliNB(), naive_bayes.GaussianNB(), #邻近算法 neighbors.KNeighborsClassifier(), # 支持向量机 svm.SVC(probability=True), svm.NuSVC(probability=True), svm.LinearSVC(), # 树 tree.DecisionTreeClassifier(), tree.ExtraTreeClassifier(), # 判别分析 discriminant_analysis.LinearDiscriminantAnalysis(), discriminant_analysis.QuadraticDiscriminantAnalysis(), # xgboost XGBClassifier() ]123456789101112131415161718192021222324252627282930313233343536from sklearn.preprocessing import StandardScaler# X = pd.concat([train_x_dummy,valid_x_dummy])# y = pd.concat([train_y,valid_y])# 防止线性相关X = train_dummy.drop(['Sex_male', 'Cabin_No'], axis=1)y = train_data[Target]# 标准化scaler = StandardScaler()scaler.fit(X) X = scaler.fit_transform(X)MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', \ 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']MLA_compare = pd.DataFrame(columns = MLA_columns)cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )row_index = 0for alg in MLA: MLA_name = alg.__class__.__name__ MLA_compare.loc[row_index, 'MLA Name'] = MLA_name MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params()) cv_results = model_selection.cross_validate(alg, X, y.values.ravel(), cv = cv_split, return_train_score=True) MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean() MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3 row_index+=1MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)MLA_compare123456sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare)plt.title('Machine Learning Algorithm Accuracy Score \n')plt.xlabel('Accuracy Score (%)')plt.ylabel('Algorithm')plt.show()12345678910111213141516171819202122232425262728vote_est = [ # Ensemble Methods ('ada', ensemble.AdaBoostClassifier()), ('bc', ensemble.BaggingClassifier()), ('etc',ensemble.ExtraTreesClassifier()), ('gbc', ensemble.GradientBoostingClassifier()), ('rfc', ensemble.RandomForestClassifier()), # Gaussian Processes ('gpc', gaussian_process.GaussianProcessClassifier()), # GLM ('lr', linear_model.LogisticRegressionCV()), # Navies Bayes ('bnb', naive_bayes.BernoulliNB()), ('gnb', naive_bayes.GaussianNB()), # Nearest Neighbor ('knn', neighbors.KNeighborsClassifier()), # SVM ('svc', svm.SVC(probability=True)), # xgboost ('xgb', XGBClassifier())]1234567891011121314151617181920212223import warningswarnings.filterwarnings("ignore")# Hard Votevote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')vote_hard_cv = model_selection.cross_validate(vote_hard, X, y.values.ravel(), cv = cv_split)vote_hard.fit(X, y.values.ravel())print("Hard Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['train_score'].mean()*100)) print("Hard Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['test_score'].mean()*100))print("Hard Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilitiesvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')vote_soft_cv = model_selection.cross_validate(vote_soft, X, y.values.ravel(), cv = cv_split)vote_soft.fit(X, y.values.ravel())print("Soft Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['train_score'].mean()*100)) print("Soft Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['test_score'].mean()*100))print("Soft Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_soft_cv['test_score'].std()*100*3))print('-'*10)进行网格调参123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136import timegrid_n_estimator = [10, 50, 100, 300]grid_ratio = [.1, .25, .5, .75, 1.0]grid_learn = [.01, .03, .05, .1, .25]grid_max_depth = [2, 4, 6, 8, 10, None]grid_min_samples = [5, 10, .03, .05, .10]grid_criterion = ['gini', 'entropy']grid_bool = [True, False]grid_seed = [0]grid_param = [ [&#123; #AdaBoostClassifier 'n_estimators': grid_n_estimator, #default=50 'learning_rate': grid_learn, #default=1 #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R 'random_state': grid_seed &#125;], [&#123; #BaggingClassifier 'n_estimators': grid_n_estimator, #default=10 'max_samples': grid_ratio, #default=1.0 'random_state': grid_seed &#125;], [&#123; #ExtraTreesClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'random_state': grid_seed &#125;], [&#123; #GradientBoostingClassifier #'loss': ['deviance', 'exponential'], #default=’deviance’ 'learning_rate': [.05], 'n_estimators': [300], #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse” 'max_depth': grid_max_depth, #default=3 'random_state': grid_seed &#125;], [&#123; #RandomForestClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'oob_score': [True], #default=False 'random_state': grid_seed &#125;], [&#123; #GaussianProcessClassifier 'max_iter_predict': grid_n_estimator, #default: 100 'random_state': grid_seed &#125;], [&#123; #LogisticRegressionCV 'fit_intercept': grid_bool, #default: True #'penalty': ['l1','l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs 'random_state': grid_seed &#125;], [&#123; #BernoulliNB 'alpha': grid_ratio, #default: 1.0 &#125;], #GaussianNB [&#123;&#125;], [&#123; #KNeighborsClassifier 'n_neighbors': [1,2,3,4,5,6,7], #default: 5 'weights': ['uniform', 'distance'], #default = ‘uniform’ 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'] &#125;], [&#123; #SVC #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1,2,3,4,5], #default=1.0 'gamma': grid_ratio, #edfault: auto 'decision_function_shape': ['ovo', 'ovr'], #default:ovr 'probability': [True], 'random_state': grid_seed &#125;], [&#123; #XGBClassifier 'learning_rate': grid_learn, #default: .3 'max_depth': [1,2,4,6,8,10], #default 2 'n_estimators': grid_n_estimator, 'seed': grid_seed &#125;] ]start_total = time.perf_counter() for clf, param in zip (vote_est, grid_param): #print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm #print(param) start = time.perf_counter() best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'roc_auc') best_search.fit(X, y.values.ravel()) run = time.perf_counter() - start best_param = best_search.best_params_ print('The best parameter for &#123;&#125; is &#123;&#125; with a runtime of &#123;:.2f&#125; seconds.'\ .format(clf[1].__class__.__name__, best_param, run)) clf[1].set_params(**best_param) run_total = time.perf_counter() - start_totalprint('Total optimization time was &#123;:.2f&#125; minutes.'.format(run_total/60))print('-'*10)1234567891011121314151617181920212223242526# Hard Vote or majority rules w/Tuned Hyperparametersgrid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')grid_hard_cv = model_selection.cross_validate(grid_hard, X, y.values.ravel(), cv = cv_split)grid_hard.fit(X, y.values.ravel())print("Hard Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['train_score'].mean()*100)) print("Hard Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].mean()*100))print("Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilities w/Tuned Hyperparametersgrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')grid_soft_cv = model_selection.cross_validate(grid_soft, X, y.values.ravel(), cv = cv_split)grid_soft.fit(X, y.values.ravel())print("Soft Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ .format(grid_soft_cv['train_score'].mean()*100)) print("Soft Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].mean()*100))print("Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].std()*100*3))print('-'*10)保存预测结果1234X_test = test_dummy.drop(['Sex_male', 'Cabin_No'], axis=1).valuesy_test = grid_hard.predict(X_test)f = pd.DataFrame(&#123;'PassengerId':test_id.values, 'Survived':y_test&#125;)f.to_csv("C:/Users/DHX17/Jupyter/Kaggle/titanic/ans.csv", index=False)参考资料https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 手写数字识别]]></title>
    <url>%2F2019%2F03%2F31%2FMNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[摘要使用神经网络进行MNIST手写数字识别《Python神经网络编程》代码导入相关库123import numpy as npfrom scipy.special import expitimport matplotlib.pyplot as plt搭建神经网络12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class neuralNetwork: def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes self.lr = learningrate #随机初始化权重，当然权重在0到1之间（不含）。这里通过高斯函数产生权重 #其中均值是零，方差是1/sqrt(连接数)，当然连接数等于节点数。后一个是矩阵hnodes行， # numpy.random.normal(loc=0.0, scale=1.0, size=None) self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes)) self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes)) self.activation_function = lambda x: expit(x) pass def train(self,inputs_list, targets_list): inputs = np.array(inputs_list, ndmin=2).T targets = np.array(targets_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who,hidden_outputs) final_outputs = self.activation_function(final_inputs) #误差 output_errors = targets - final_outputs hidden_errors = np.dot(self.who.T, output_errors) #权重更新 self.who += self.lr*np.dot((output_errors*final_outputs*(1.0 - final_outputs)), np.transpose(hidden_outputs)) self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs)) pass def query(self, inputs_list): inputs = np.array(inputs_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who, hidden_outputs) final_outputs = self.activation_function(final_inputs) return final_outputs数据处理1234567input_nodes = 784 hidden_nodes = 100 output_nodes = 10 learning_rate = 0.3n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)1234#导入训练数据 training_data_file = open('./mnist_train_100.csv','r') training_data_list = training_data_file.readlines() training_data_file.close()1training_data_list[0]123all_values = training_data_list[0].split(',')image_array = np.asfarray(all_values[1:]).reshape((28, 28))plt.imshow(image_array, cmap='Greys', interpolation='None')进行数据训练123456789for record in training_data_list: all_values = record.split(',') #输入数据数学处理，使其在0.01到1之间.颜色的范围是[0,255] inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01 #初始化目标值，使其在0.01到0.99之间 targets = np.zeros(output_nodes) + 0.01 targets[int(record[0])] = 0.99 n.train(inputs,targets) pass123test_data_file = open('./mnist_test_10.csv','r') test_data_list = test_data_file.readlines() test_data_file.close()12345678all_values = test_data_list[0].split(',')correct_label = int(all_values[0])image_array = np.asfarray(all_values[1:]).reshape((28,28))plt.imshow(image_array,cmap='Greys')inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01outputs = n.query(inputs)label = np.argmax(outputs) #argmax返回最大值的索引值print("correct:&#123;0&#125;, predict:&#123;1&#125;".format(correct_label, label))1234567891011121314151617181920scorecard = []#多个数据检测for record in test_data_list: all_values = record.split(',') correct_label = int(all_values[0]) print(correct_label, "correct label") inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01 outputs = n.query(inputs) label = np.argmax(outputs) print(label, "network's answer") if(label == correct_label): scorecard.append(1) else: scorecard.append(0) print(scorecard) # [1, 0, 1, 1, 1, 1, 1, 0, 0, 0]123scorecard_array = np.asarray(scorecard)print("performance = ", scorecard_array.sum() / scorecard_array.size)# performance = 0.6一些改进调整学习率多次运行改变网络形状基于Keras导入相关库12345678910111213141516import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sn# sklearn的mnist数据集是8x8# from sklearn.datasets import load_digits# from sklearn.preprocessing import LabelBinarizer# from sklearn.model_selection import train_test_split# from sklearn.metrics import confusion_matriximport kerasfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flattenfrom keras.optimizers import RMSpropfrom keras.preprocessing.image import ImageDataGeneratorfrom keras.callbacks import ModelCheckpoint处理数据1234567891011121314151617181920212223242526# 导入数据# digits = load_digits()# X = digits.data# y = digits.target# X /= 8# y = LabelBinarizer().fit_transform(y)# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)# X_train.shape, X_test.shape, y_train.shape, y_test.shape# (X_train, y_train), (X_test, y_test) = mnist.load_data()path = 'datasets/mnist.npz' f = np.load(path)X_train, y_train = f['x_train'], f['y_train']X_test, y_test = f['x_test'], f['y_test']f.close()X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)X_test = X_test.reshape(X_test.shape[0], 28, 28, 1) X_train = X_train.astype('float32')X_test = X_test.astype('float32') X_train /= 255 X_test /= 255X_train.shape, X_test.shape# ((60000, 28, 28, 1), (10000, 28, 28, 1))1234y_train = keras.utils.to_categorical(y_train, 10)y_test = keras.utils.to_categorical(y_test, 10)y_train.shape, y_test.shape# ((60000, 10), (10000, 10))12plt.imshow(X_train[0].reshape(28, 28), cmap='Greys', interpolation='None')y_train[0]搭建神经网络12345678910111213141516171819model = Sequential() # 使用3x3的卷积核，激活函数为ReLU# 池化核大小2x2model.add(Conv2D(filters=28, kernel_size=(3, 3), padding='Same', activation='relu',input_shape=(28,28,1)))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25)) model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25))# Fully connected layer.model.add(Flatten())model.add(Dense(256, activation='relu')) model.add(Dropout(0.25)) #10 outputsmodel.add(Dense(10, activation='softmax'))12batch_size = 250epochs = 1012optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])12345678910111213141516171819# reduce_lr = LearningRateScheduler(function)reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, #每次减少学习率的因子，学习率将以lr = lr*factor的形式被减少 patience=10, # 当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发 verbose=0, mode='auto', # 在min模式下，如果检测值触发学习率减少。在max模式下，当检测值不再上升则触发学习率减少。 min_delta=0.0001, # 用来确定是否进入检测值的“平原区” cooldown=0, # 学习率减少后，会经过cooldown个epoch才重新进行正常操作 min_lr=0.00001)gen = ImageDataGenerator(# featurewise_center=True,对输入的图片每个通道减去每个通道对应均值 # featurewise_std_normalization=True,每张图片减去样本均值, 使得每个样本均值为0 rotation_range=20, # 旋转范围 zoom_range= 0.2, # 缩放范围 width_shift_range=0.2, # 水平平移范围 height_shift_range=0.2, # 垂直平移范围 horizontal_flip=True) #水平反转train_generator = gen.flow(X_train, y_train, batch_size=batch_size)123456result = model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs= epochs, validation_data=(X_test, y_test), verbose =2, callbacks=[reduce_lr])12345678910fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(result.history['loss'], label='Train Loss')ax[0].plot(result.history['val_loss'], label='Validation Loss')ax[1].plot(result.history['acc'], label='Train acc')ax[1].plot(result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()参考文献《Python神经网络编程》代码https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork/]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 2 - Income Prediction]]></title>
    <url>%2F2019%2F03%2F29%2FHomework-2-Income-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，收入预测收入预测导入相关库123456import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom random import shufflefrom math import floor, logfrom numpy.linalg import inv数据处理12train_data = pd.read_csv("train.csv")train_data.info()1train_data.head()对数据进行可视化观察12345678910111213141516171819202122232425262728293031323334353637383940plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231)train_data.income.value_counts().plot(kind='bar')plt.xlabel("收入情况")plt.ylabel("人数") ax2 = plt.subplot(232)train_data.education.value_counts().plot(kind='bar')plt.ylabel("人数")# #plt.xticks([1, 2, 3])plt.xlabel("教育情况")ax3 = plt.subplot(233)plt.hist(train_data.age,20)# #plt.yticks([0, 1])plt.ylabel('人数')plt.xlabel('年龄')ax4 = plt.subplot(234)train_data.sex.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel('性别')ax5 = plt.subplot(235)train_data.workclass.value_counts().plot(kind='bar')plt.ylabel("人数") plt.xlabel("所属企业类型")ax6 = plt.subplot(236)train_data.race.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel("种族")# 调整每隔子图之间的距离 plt.tight_layout()plt.show()1234567# 将&gt;50K转为1，&lt;=50K转为0， 方便数据可视化操作# 使用train_data.income[train_data.income == " &gt;50K"] = 1# 会弹出A value is trying to be set on a copy of a slice from a DataFrame.# 修改数据最好不要使用链式操作train_data.loc[train_data.income == " &gt;50K", 'income'] = 1train_data.loc[train_data.income ==" &lt;=50K", 'income'] = 0train_data.head()12345678910fig = plt.figure() fig.set(alpha=0.2) male = train_data.income[train_data.sex == ' Male'].value_counts() female = train_data.income[train_data.sex == ' Female'].value_counts() df=pd.DataFrame(&#123;'male':male, 'female':female&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("收入情况") plt.ylabel("人数") plt.show()train_data[["sex", "income"]].groupby(['sex'], as_index=False).mean().sort_values(by='income', ascending=False)查看学历对应的收入情况12345678910111213141516171819202122232425262728293031323334fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231) train_data.income[train_data.education == ' HS-grad'].value_counts().plot(kind='bar', label=" HS-grad", color='red') ax1.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax1.legend(["HS研究生学位"], loc='best') ax2 = plt.subplot(232) train_data.income[train_data.education == ' Doctorate'].value_counts().plot(kind='bar', label=" Doctorate", color='lightblue') ax2.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax2.legend(["博士学位"], loc='best') ax3 = plt.subplot(233) train_data.income[train_data.education == ' Masters'].value_counts().plot(kind='bar', label=" Masters", color='blue') ax3.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax3.legend(["硕士学位"], loc='best') ax4 = plt.subplot(234) train_data.income[train_data.education == ' Bachelors'].value_counts().plot(kind='bar', label=" Bachelors", color='pink') ax4.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax4.legend(["学士学位"], loc='best') ax5 = plt.subplot(235) train_data.income[train_data.education == ' Assoc-voc'].value_counts().plot(kind='bar', label=" Assoc-voc", color='steelblue') ax5.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax5.legend(["副学士学位"], loc='best') ax6 = plt.subplot(236) train_data.income[train_data.education == ' Some-college'].value_counts().plot(kind='bar', label=" Some-college", color='#FA2479') ax6.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax6.legend(["本科生学位"], loc='best') plt.show()12# 各国家人数train_data.native_country.value_counts()将所有含有缺失值的行都去掉，可以使用RandomForestRegressor填补缺失12345678910111213141516171819202122232425262728# from sklearn.ensemble import RandomForestRegressor# 使用RandomForestRegressor填补缺失的年龄属性# def set_missing_workclass(df):# # 把已有的数值型特征取出来丢进RandomForestRegressor中# workclass_df = df[['workclass','age', 'education', 'race', 'income']]## # 提取未知值和已知值# known_workclass = workclass_df[workclass_df.workclass.notnull()].values# unknown_workclass = workclass_df[workclass_df.workclass.isnull()].values # # y即目标workclass# y = known_workclass[:, 0] # # X即特征属性值# X = known_workclass[:, 1:] # # fit到RandomForestRegressor之中# rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)# rfr.fit(X, y) # # 用得到的模型进行未知年龄结果预测# predictedAges = rfr.predict(unknown_workclass[:, 1::]) # # 用得到的预测结果填补原缺失数据# df.loc[ (df.workclass.isnull()), 'workclass' ] = predictedAges # return df, rfr# train_data, rfr = set_missing_ages(train_data)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def dataProcess_X(raw_data): if "income" in raw_data.columns: # data = raw_data.drop(["sex", 'income'], axis=1) data = raw_data.drop(["income"], axis=1) else: # data = raw_data.drop(["sex"], axis=1) pass # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'], value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() # 剔除没有用的数据特征fnlwgt # fnlwgt: 连续性数值变量；人口普查员认为观察值的人数 data.drop(['fnlwgt'], axis=1) # 处理sex data.loc[data.sex == " Male", 'sex'] = 1 data.loc[data.sex ==" Female", 'sex'] = 0 listObjectColumn = [col for col in data.columns if data[col].dtypes == "object"] #读取非数字的column listNonObjedtColumn = [x for x in list(data) if x not in listObjectColumn] ObjectData = data[listObjectColumn] NonObjectData = data[listNonObjedtColumn] # NonObjectData.insert(0 ,"sex", (raw_data["sex"] == " Female").astype(np.int)) # 使用pd.get_dummies()特征因子化 # 也可以使用one-hot # from sklearn.feature_extraction import DictVectorizer # dict_vect=DictVectorizer(sparse=False) # X_train=dict_vect.fit_transform(X_train.to_dict(orient='record')) # X_test=dict_vect.transform(X_test.to_dict(orient='record')) # dict_vect.feature_names_ ObjectData = pd.get_dummies(ObjectData) data = pd.concat([NonObjectData, ObjectData], axis=1) X = data.astype("int64") # 标准化 X = (X - X.mean()) / X.std() return np.array(X)def dataProcess_y(raw_data): data = raw_data.copy() # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'],value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() try: # y = data['income'] # y = pd.DataFrame((y ==' &gt;50K').astype("int64"), columns=["income"]) data.loc[data.income == " &gt;50K", 'income'] = 1 data.loc[data.income == " &lt;=50K", 'income'] = 0 except: pass y = np.array(data['income']) y = y.reshape(y.shape[0], 1) return yX_train = dataProcess_X(train_data)y_train = dataProcess_y(train_data)X_train.shape, y_train.shape# ((30162, 103), (30162, 1))导入测试集12345test_data = pd.read_csv("test.csv")X_test = dataProcess_X(train_data)y_test = dataProcess_y(train_data)X_test.shape, y_test.shape# ((30162, 103), (30162, 1))12345678910111213141516171819202122def _shuffle(X, y): #X and Y are np.array randomize = np.arange(X.shape[0]) np.random.shuffle(randomize) return (X[randomize], y[randomize])def split_valid_set(X, y, percentage): all_size = X.shape[0] valid_size = int(floor(all_size * percentage)) X, y = _shuffle(X, y) X_valid, y_valid = X[ : valid_size], y[ : valid_size] X_train, y_train = X[valid_size:], y[valid_size:] return X_train, y_train, X_valid, y_valid# 也可用sklearn函数打散数据# from sklearn.model_selection import train_test_split# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=1)X_train, y_train, X_valid, y_valid = split_valid_set(X_train, y_train, 0.1)X_train.shape, y_train.shape, X_valid.shape, y_valid.shape# ((27146, 103), (27146, 1), (3016, 103), (3016, 1))Generative方法123456789101112131415161718192021222324252627282930313233343536373839404142def train(X_train, y_train): # vaild_set_percetange = 0.1 # X_train, Y_train, X_valid, Y_valid = split_valid_set(X, Y, vaild_set_percetange) #Gussian distribution parameters train_data_size = X_train.shape[0] cnt1 = 0 cnt2 = 0 mu1 = np.zeros((1, X_train.shape[1])) mu2 = np.zeros((1, X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: # &gt;50k mu1 += X_train[i] cnt1 += 1 else: mu2 += X_train[i] cnt2 += 1 mu1 /= cnt1 mu2 /= cnt2 sigma1 = np.zeros((X_train.shape[1], X_train.shape[1])) sigma2 = np.zeros((X_train.shape[1], X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: sigma1 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu1), X_train[i] - mu1) else: sigma2 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu2), X_train[i] - mu2) sigma1 /= cnt1 sigma2 /= cnt2 shared_sigma = (float(cnt1) / train_data_size) * sigma1 + (float(cnt2) / train_data_size) * sigma2 N1 = cnt1 N2 = cnt2 return mu1, mu2, shared_sigma, N1, N2mu1, mu2, shared_sigma, N1, N2 = train(X_train, y_train)mu1.shape, mu2.shape, shared_sigma.shape, N1, N212345def sigmoid(z): res = 1 / (1.0 + np.exp(-z)) return np.clip(res, 1e-8, (1-(1e-8)))# from scipy.special import expit1234567891011121314151617def valid(funname, X, Y, mu1, mu2, shared_sigma, N1, N2): sigma_inv = inv(shared_sigma) w = np.dot((mu1-mu2), sigma_inv) X_t = X.T b = (-0.5) * np.dot(np.dot(mu1, sigma_inv), mu1.T) + (0.5) * np.dot(np.dot(mu2, sigma_inv), mu2.T) + np.log(float(N1)/N2) a = np.dot(w,X_t) + b y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))valid("train", X_train, y_train, mu1, mu2, shared_sigma, N1, N2)valid("valid", X_valid, y_valid, mu1, mu2, shared_sigma, N1, N2)valid("test", X_test, y_test, mu1, mu2, shared_sigma, N1, N2)# train acc = 0.837140# valid acc = 0.851459# test acc = 0.838572Discriminative方法mini_batch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# mini_batch def train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) l_rate = 0.0001 batch_size = 32 train_dataz_size = len(X_train) step_num = int(floor(train_dataz_size / batch_size)) epoch_num = 300 list_cost = [] total_loss = 0.0 for epoch in range(1, epoch_num): total_loss = 0.0 X_train, y_train = _shuffle(X_train, y_train) for idx in range(1, step_num): X = X_train[idx*batch_size:(idx+1)*batch_size] #32*104 Y = y_train[idx*batch_size:(idx+1)*batch_size] #32*1 s_grad = np.zeros((1,len(X[0]))) z = np.dot(X, w.T) # 32*104*104*1 y = sigmoid(z) # squeeze 函数：从数组的形状中删除单维度条目，即把shape中为1的维度去掉 # loss = y - np.squeeze(Y) loss = y - Y cross_entropy = -1 * (np.dot(Y.T, np.log(y)) + np.dot((1 - Y.T),\ np.log(1 - y)))/ len(Y) total_loss += cross_entropy[0][0] #grad = np.sum(-1 * X * (np.squeeze(Y) - y).reshape((batch_size, 1)), axis=0) grad = np.sum(np.dot((y - Y).T, X), axis=0) #1*32*32*104 # grad = np.dot(X.T, loss) w = w - l_rate * grad # s_grad += grad ** 2 # ada = np.sqrt(s_grad) # w = w - l_rate * grad / ada list_cost.append(total_loss) # valid(X_valid, Y_valid, w) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wdef valid(funname, X, Y, w): a = np.dot(w, X.T) y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))X_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)Ada12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Adadef train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) s_grad = np.zeros((1, len(X_train[0]))) l_rate = 0.1 epoch_num = 10000 list_cost = [] total_loss = 0.0 X = X_train y = y_train for epoch in range(epoch_num): z = np.dot(X, w.T) # n*104*104*1 Y = sigmoid(z) loss = Y - y cross_entropy = -1 * (np.dot(y.T, np.log(Y)) + np.dot((1 - y.T),\ np.log(1 - Y)))/ len(y) if abs(total_loss - cross_entropy[0][0]) &lt; 10**-9: break else: total_loss = cross_entropy[0][0] list_cost.append(total_loss) grad = np.sum(np.dot((Y - y).T, X), axis=0) #1*104 s_grad += grad**2 ada = np.sqrt(s_grad) w = w - l_rate * grad / ada print("times:", len(list_cost)) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wX_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)使用Kreas12from keras.models import Sequentialfrom keras.layers import Dense, Activation1234567891011121314151617model = Sequential()model.add(Dense(units=600, activation='sigmoid', input_dim=103))model.add(Dense(units=600, activation='sigmoid'))model.add(Dense(units=1, activation='sigmoid'))model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])model.fit(X_train, y_train, batch_size=32, epochs=50)score = model.evaluate(X_test, y_test)result = np.squeeze(model.predict(X_test))# print('Total loss on Testing set: ', score[0])# print('Accuracy of Testing set: ', score[1])# Total loss on Testing set: 0.2154487861520091# Accuracy of Testing set: 0.90295736357400741234y_ = np.around(result).astype(np.int)result = (np.squeeze(y_test) == y_)print('Test acc = %f' % (float(result.sum()) / X_test.shape[0]))# Test acc = 0.902957使用Tensorflow搭建3层神经网络1import tensorflow as tf12345678910111213141516171819xs = tf.placeholder(tf.float32, [None, 103])ys = tf.placeholder(tf.float32, [None, 1])w1 = tf.Variable(tf.random_normal([103, 600], stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([600, 600], stddev=1, seed=1))w3 = tf.Variable(tf.random_normal([600, 1], stddev=1, seed=1))a = tf.nn.relu(tf.matmul(xs, w1))b = tf.sigmoid(tf.matmul(a, w2))y = tf.sigmoid(tf.matmul(b, w3))# a = tf.matmul(xs, w1)# y = tf.matmul(a, w2)y_ = tf.round(y)cross_entropy = -tf.reduce_mean(ys*tf.log(tf.clip_by_value(y,1e-10,1.0)))train_step = tf.train.GradientDescentOptimizer(0.001).minimize(cross_entropy)correct_prediction = tf.equal(y_, ys)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))1234567891011result = Nonewith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for step in range(101): # training sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train&#125;) result = sess.run(y, feed_dict=&#123;xs: X_train, ys: y_train&#125;) if step % 100 == 0: print("accuracy:",sess.run(accuracy, feed_dict=&#123;xs: X_train, ys: y_train&#125;))# accuracy: 0.7285788随机森林和XGBoost1234# 随机森林from sklearn import metricsfrom sklearn.ensemble import RandomForestClassifierrfc=RandomForestClassifier()123# XGBoostfrom xgboost import XGBClassifierxgbc=XGBClassifier()123456# 选取k-1折的数据进行模型训练import warningswarnings.filterwarnings("ignore")from sklearn.model_selection import cross_val_score cross_val_score(rfc,X_train, y_train.ravel(),cv=5).mean(), cross_val_score(xgbc,X_train, y_train.ravel(),cv=5).mean()# (0.8434758405223647, 0.8613788898712886)12345#默认随机森林预测rfc.fit(X_train, y_train)rfc_y_predict = rfc.predict(X_valid)rfc.score(X_valid, y_valid)# 0.839854111405835512345# XGBoost预测xgbc.fit(X_train, y_train)xgbc_y_predict = xgbc.predict(X_valid)xgbc.score(X_valid, y_valid)# 0.862068965517241312345from sklearn.metrics import classification_reportprint('随机森林的预测准确率:')print(classification_report(y_valid, rfc_y_predict, target_names=['result'])) print('XGBoost的预测准确率:') print(classification_report(y_valid, xgbc_y_predict, target_names=['result']))保存数据1234# df = pd.DataFrame(&#123;"id": np.arange(1, 16282), "label": y_&#125;)# if not os.path.exists(output_dir):# os.mkdir(output_dir)# df.to_csv(os.path.join(output_dir + 'nn_output.csv'), sep='\t', index=False)参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 1 - PM2.5 Prediction]]></title>
    <url>%2F2019%2F03%2F25%2FHomework-1-PM2-5-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业一，PM2.5预测PM2.5预测1. 导入相关库123import numpy as npimport pandas as pdimport matplotlib.pyplot as plt2. 数据处理1234train_data = pd.read_csv("train.csv")# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data.info() # 240条数据，每条数据18个feature12345# 将RAINFALL值为NR的数据置0train_data[train_data[train_data['Obvservations']=='RAINFALL'].iloc[:,3:] == 'NR'] = 0# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data[train_data['Obvservations']=='RAINFALL'].head()123456789101112tempxlist = [] tempylist = [] # 一天内总共有24-10+1 =15条记录for j in range(0, 240): for i in range(15): tempx = np.array(train_data.iloc[j*18:(j+1)*18,3:].iloc[:, i:i+9], float).reshape(1, 18*9) tempy = np.array(train_data.iloc[j*18+9:j*18+10,3:].iloc[:, i+9], float) # tempx = pm2_5.iloc[:,i:i+9] #使用前9小时数据作为feature # tempy = pm2_5.iloc[:,i+9] #使用第10个小数数据作为lable tempxlist.append(tempx) tempylist.append(tempy)12345678# X = np.array(pd.concat(tempxlist), float)X = np.concatenate(tempxlist, axis=0)# 插入列向量[1;1;...;1;]X = np.insert(X, 0, values=np.ones((1, X.shape[0])), axis=1)# y = np.array(pd.concat(tempylist), float)y = np.concatenate(tempylist, axis=0)y = y.reshape(y.shape[0], 1)X, y12X.shape, y.shape# ((3600, 163), (3600, 1))12# 特征归一化(Feature Scaling)X = (X - X.mean()) / X.std()12345# 代价函数def cost(y, w): temp = np.dot(X,w) loss = np.square(y - temp) return np.sum(loss)/len(y)3. 开始训练adagrad123456789101112131415161718192021# adagraddef ada(X, y, w, lr, iteration, lambdaL2): list_cost = [] s_grad = np.zeros([len(X[0]), 1]) for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2*w s_grad += grad**2 ada = np.sqrt(s_grad) w = w - lr*grad/ada return w, list_costlr_ada = 10w_ada = np.zeros([X.shape[1], 1])w_ada, list_cost_ada = ada(X, y, w_ada, lr_ada, 10000, 0.)cost(y, w_ada)# 38.190334888655144SGD1234567891011121314151617181920# SGDdef SGD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) rand = np.random.randint(0, len(X)) grad = X[rand].reshape(X.shape[1], 1)*loss[rand].reshape(loss.shape[1], 1)/len(X) + lambdaL2*w w = w - lr*grad return w, list_costw_sgd = np.zeros([X.shape[1], 1])lr_sgd = 0.1w_sgd, list_cost_sgd = SGD(X, y, w_sgd, lr_sgd, 10000, 0.)cost(y, w_sgd)# 209.00938349734912GD1234567891011121314151617def GD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X, w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2 * w w = w - lr*grad return w, list_costw_gd = np.zeros([X.shape[1], 1])lr_gd = 0.01w_gd, list_cost_gd = GD(X, y, w_gd, lr_gd, 10000, 0.)cost(y, w_gd)# 44.80863160107732正规方程1234#close formw_cf = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)cost_wcf = np.sum((X.dot(w_cf)-y)**2) / len(X)hori = [cost_wcf for i in range(10000-3)]12345678910fig = plt.figure(figsize=(12,8))plt.plot(np.arange(len(list_cost_ada[3:])), list_cost_ada[3:], 'b', label="ada")plt.plot(np.arange(len(list_cost_sgd[3:])), list_cost_sgd[3:], 'g', label='sgd')plt.plot(np.arange(len(list_cost_gd[3:])), list_cost_gd[3:], 'r', label='gd')plt.plot(np.arange(len(list_cost_ada[3:])), hori, 'y--', label='close-form')plt.title('Train Process')plt.xlabel('Iteration')plt.ylabel('Loss Function(Quadratic)')plt.legend()plt.show()4. 使用Sklearn1234from sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import cross_val_predictfrom sklearn import metrics1234567X_train, X_test, y_train, y_test = train_test_split(X[:, 1:], y, random_state=1)linreg = LinearRegression()linreg.fit(X_train, y_train)predicted = cross_val_predict(linreg, X, y, cv=10)# linreg.intercept_, linreg.coef_metrics.mean_squared_error(y, predicted)# 42.576599287222915. 使用Tensorflow1import tensorflow as tf1234567891011121314151617181920212223242526272829303132333435363738def linear_regression(X_data, y_data, alpha, epoch, optimizer=tf.train.GradientDescentOptimizer): tf.reset_default_graph() xs = tf.placeholder(tf.float32, [None, X_data.shape[1]]) ys = tf.placeholder(tf.float32, [None, 1]) W = tf.Variable(tf.random_uniform([X_data.shape[1], 1], -10.0, 10.0)) y_pred = tf.matmul(xs, W) loss = tf.reduce_mean(tf.square(ys - y_pred)) if optimizer == tf.train.GradientDescentOptimizer: alpha = 0.01 elif optimizer == tf.train.AdagradOptimizer: alpha = 10 elif optimizer == tf.train.AdamOptimizer: alpha = 0.1 elif optimizer == tf.train.FtrlOptimizer: alpha = 10 elif optimizer == tf.train.RMSPropOptimizer: alpha = 10 opt = optimizer(learning_rate=alpha) opt_operation = opt.minimize(loss) # run the session with tf.Session() as sess: sess.run(tf.global_variables_initializer()) loss_data = [] for i in range(epoch): _, loss_val, W_val = sess.run([opt_operation, loss, W], feed_dict=&#123;xs: X_data, ys: y_data&#125;) loss_data.append(loss_val) if len(loss_data) &gt; 1 and np.abs(loss_data[-1] - loss_data[-2]) &lt; 10 ** -9: break tf.reset_default_graph() return &#123;'loss': loss_data, 'parameters': W_val&#125; # just want to return in row vector format123456789101112131415161718epoch = 10000alpha = 0.0001# 各种优化函数optimizer_dict=&#123;'GD': tf.train.GradientDescentOptimizer, 'Adagrad': tf.train.AdagradOptimizer, #'Adam': tf.train.AdamOptimizer, #'Ftrl': tf.train.FtrlOptimizer, #'RMS': tf.train.RMSPropOptimizer #'Momentum': tf.train.MomentumOptimizer两个参数 &#125;results = []t_loss = dict()for name in optimizer_dict: # 这里X应该是X[:, 1:] res = linear_regression(X, y, alpha, epoch, optimizer=optimizer_dict[name]) res['name'] = name t_loss[name] = res results.append(res)1234567891011121314fig, ax = plt.subplots(figsize=(16, 9))for res in results: loss_data = res['loss'] ax.plot(np.arange(len(loss_data[10:])), loss_data[10:], label=res['name'])ax.plot(np.arange(len(list_cost_ada[10:])), hori[0: 9990], label='close-form') ax.set_xlabel('epoch', fontsize=18)ax.set_ylabel('cost', fontsize=18)ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)ax.set_title('different optimizer', fontsize=18)plt.show()12t_loss["Adagrad"]["loss"][-1], t_loss["GD"]["loss"][-1]# (39.07505, 168.04092)6. 保存数据123test_data = pd.read_csv("test.csv")# pm2_5_test = test_data[test_data['AMB_TEMP'] == 'PM2.5'].iloc[:,2:]# pm2_5_test.info()1234# 对X_test进行一系列数据处理即可# X_test = np.array(pm2_5_test, float)# X_test = np.insert(X_test, 0, values=np.ones((1, X_test.shape[0])), axis=1)X_test12345#预测y_star = np.dot(X_test, w)y_pre = pd.read_csv("sampleSubmission.csv")y_pre.value = y_stary_pre.to_csv('predict.csv', index=False)参考文献http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好]]></title>
    <url>%2F2019%2F02%2F28%2F%E4%BD%A0%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[那些都是很好很好的，可我偏偏不喜欢。]]></content>
  </entry>
</search>
