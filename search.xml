<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据挖掘-闭序列模式挖掘]]></title>
    <url>%2F2021%2F09%2F12%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E9%97%AD%E5%BA%8F%E5%88%97%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98%2F</url>
    <content type="text"><![CDATA[Closed sequential patterns mining关于闭序列模式，其满足如下定义。Closed Pattern：给定所有序列模式集合$AS$，若有序列模式$S_a$满足$S_a$ $\in$ $AS$ $\land$ $\not$ $\exists$ $S_b$ $\in$ $AS$， $S_a$ $\subset$ $S_b$ $\land$ $sup(S_a)$ $=$ $sup(S_b)$，（这个关系也称作吸收）则$S_a$是一条闭序列模式。BIDEBIDE是基于PrefixSpan和BI-Directional closure checking scheme的一个算法。与CloSpan相比，它不需要花费空间存储候选集。相关定义定义1 （First instance of a prefix sequence）：给定一个输入序列$S$和前缀序列$p$，则$p$的第一个实例为：从$S$开头，直到完全包含$p$。例如：$p$ = &lt;$AB$&gt;，$S$ = &lt;$ABBCA$&gt;，$LI(P, S)$ = &lt;$ABB$&gt;$p$ = &lt;$AB$&gt;，$S$ = &lt;$ACBAB$&gt;，$LI(P, S)$ = &lt;$ACB$&gt;定义2 （Projected sequence of a prefix sequence）：前缀序列投影数据库。BI-Directional Extension closure checking scheme在此之前，提一下与CloSpan类似的技巧。对于已经挖掘的当前闭序列：超序列检查：可以移除已经挖掘的非闭序列。例如：当已经挖掘了&lt;$AB$&gt;:4，若新序列为&lt;$ABC$&gt;:4，则可以移除&lt;$AB$&gt;。子序列检查：可以移除待加入的新非闭序列。例如：当已经挖掘了&lt;$AB$&gt;:4，若新序列为&lt;$B$&gt;:4，则可以移除&lt;$B$&gt;。对于上述两个检查，很明显需要存储候选集（即当前闭序列）。如果当前序列为$S$=&lt;$e_1e_2…e_n$&gt;，那么其超闭序列$S’$可能为&lt;$e_1e_2…e_nd$&gt;，&lt;$de_1e_2…e_n$&gt;，&lt;$e_1e_2…d…e_n$&gt;。其中第一种我们称呼$d$为forward-extension event （向后扩展事件），后两种称呼$d$为backward-extension event （向前扩展事件）。定理1 （BI-Directional Extension closure checking）：如果对于前缀序列$S_p$不存在向前扩展事件或向后扩展事件，则$S_p$必须是闭序列；反之不是。为了使用该定理，我们引入如下引理。引理1（Forward-extension event checking）: 对于前缀序列$S_p$， 它的向后事件集合等价于支持度为$SUP^{SDB}(S_p)$的局部频繁项集。意思就是，向后可以扩展的项，如果扩展后支持度不下降，它就是一个向后扩展事件。定义4 （Last instance of a prefix sequence）：前缀序列的最后一个实例。给定前缀序列$p$，和包含它的序列$S$，$LI(p, S)$则为从$S$开头直到$p$最后一个元素全部出现。例如：$p$ = &lt;$AB$&gt;，$S$ = &lt;$ABBCA$&gt;，$LI(P, S)$ = &lt;$ABB$&gt;定义5 （The i-th last-in-last appearance w.r.t. a prefix sequence）：给定前缀序列$S_p$ = &lt;$e_1…e_n$&gt;和$S$，若（1）$i$ = $n$ ，那么$LL_i(S_p, S)$ 为$e_i$在$LI(p, S)$的最后位置 ；（2）如果$1$ $\leq$ $i$ $&lt;$ $n$，那么$LL_i(S_p, S)$为$e_i$在$LI(p, S)$的最后位置且$LL_i$必须出现早于$LL_{i+1}$。例如：$S$ = &lt;$CAABC$&gt;，$S_P$ = &lt;$AB$&gt;，$LL_1$ 为 &lt;$CAAB$&gt;中$A$的最后位置。定义6 （The i-th maximum period of a prefix sequence）：前缀序列的第$i$个极大区域。给定前缀序列$S_p$ = &lt;$e_1…e_n$&gt;和$S$，若（1）$1$ $\le$ $i$ $&lt;$ $n$ ，那么为$FI(S_{p-1}, S)$和$LL_i$之间的片段；（2）如果$i$ = $1$，那么为$LL_1$之前的片段。例如：$S$ = &lt;$ABCB$&gt;，$S_p$ = &lt;$AB$&gt;，当$i$ = $2$，则为&lt;$BC$&gt; (不包括边界)；当$i$ = $1$，则为$\emptyset$引理2（Backward-extension event checking）: 对于前缀序列$S_p$ = &lt;$e_1…e_n$&gt;，如果存在$i$（$1$ $\le$ $i$ $\le$ $n$）和存在一个项$e’$出现在所有包含$S_p$序列的$i! -! th$极大区域，那么$e’$就是一个关于$S_p$向前扩展事件（项）。这里有几个疑问：（1）怎么证明引理2找出了所有能向前扩展的项？BackScan搜索空间剪枝方法尽管上述思路能获得更为紧密的结果，但是并不能提高效率。对于上述前缀树图，我们可以看到$B$是非闭合的，它可被$AB$吸收。可能在$A$的挖掘中就获得了$AB$，然而可以停止挖掘$B$吗？显然不行，若有$BA$或者$BD$支持度不降的序列将可能被忽略了。定义7（The i-th last-in-first appearance w.r.t. a prefix sequence）：给定前缀序列$S_p$ = &lt;$e_1…e_n$&gt;和$S$，若（1）$i$ = $n$ ，那么$LF_i(S_p, S)$ 为$e_i$在$FI(p, S)$的最后位置 ；（2）如果$1$ $\leq$ $i$ $&lt;$ $n$，那么$LF_i(S_p, S)$为$e_i$在$LF(p, S)$的最后位置且$LF_i$必须出现早于$LF_{i+1}$。例如：$S$ = &lt;$CAABC$&gt;，$S_P$ = &lt;$CA$&gt;，$LF_2$ 为 &lt;$CA$&gt;中$A$的第一个位置。定义8 （The i-th semi-maximum period of a prefix sequence）：前缀序列的第$i$个半极大区域。给定前缀序列$S_p$ = &lt;$e_1…e_n$&gt;和$S$，若（1）$1$ $&lt;$ $i$ $\le$ $n$ ，那么$FI(S_{p-1}, S)$和$LF_i$的片段；（2）如果$i$ = $1$，那么为$FL_1$之前的片段。例如：$S$ = &lt;$ABCB$&gt;，$S_p$ = &lt;$AC$&gt;，当$i$ = $2$，则为&lt;$B$&gt; (不包括边界)；当$i$ = $1$，则为$\emptyset$定理2 （BackScan search space pruning）：对于前缀序列$S_p$ = &lt;$e_1…e_n$&gt;，如果存在$i$（$1$ $\le$ $i$ $\le$ $n$）和存在一个项$e’$出现在所有包含$S_p$序列的$i! -! th$极大区域，那么可以停止增长$S_p$。似懂非懂~ScanSkip优化技巧经过上述讨论，我们知道最复杂的步骤就是极大区间相关的步骤。假设有前缀序列$S_p$ = &lt;$e_1…e_n$&gt;，支持度为$SUP_{S_p}$，其各个$i! -! th$极大区间为：{ $MP_{1}^{i}\dots MP_{SUP_{S_p}}^{i}$}。通过扫描这些$MP$，我们可以得到各个$SI_{k}^{i}$则可扩展项的集合为$SI_{k}^{i}$的交集，记为$\cap_{SI^{i}}$我们需要关心的是$\cap_{SI^{i}}$是否为空，我们可以在中途进行判断，一旦为空就终止求交集。同样的思路也能运用到BackScan。算法内容复杂度分析详见论文，我也不懂。参考文献[1] Wang, J., and J. Han. “BIDE: Efficient Mining of Frequent Closed Sequences.” Proceedings. 20th International Conference on Data Engineering, 2004, pp. 79–90.]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘-连续序列模式挖掘]]></title>
    <url>%2F2021%2F08%2F31%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98%2F</url>
    <content type="text"><![CDATA[Contiguous Sequential Pattern Mining在序列模式挖掘中，有几种方法被用于压缩序列模式，从而减少序列模式输出。其中一种输出方法是只输出闭合序列模式，另一种则是只输出极大序列模式。Closed Pattern：给定所有序列模式集合$AS$，若有序列模式$S_a$满足$S_a$ $\in$ $AS$ $\land$ $\not$ $\exists$ $S_b$ $\in$ $AS$， $S_a$ $\subset$ $S_b$ $\land$ $sup(S_a)$ $=$ $sup(S_b)$，（这个关系也称作吸收）则$S_a$是一条闭合序列模式。Max Pattern：给定所有序列模式集合$AS$，若有序列模式$S_a$满足$S_a$ $\in$ $AS$ $\land$ $\not$ $\exists$ $S_b$ $\in$ $AS$， $S_a$ $\subset$ $S_b$， 则$S_a$是一条极大序列模式。CSP是无损的，MSP则是有损的。CCSPNCCSPAN引入了一种新的片段增长方案来生成潜在的模式。通过使用n-gram模型将原始序列分割成一组片段，然后在增长序列时，保证每个片段的项严格保持初始邻接和顺序。搜索空间剪枝在此之前，定义$S_{pre}$为序列$S$的前$l$ $-$ $1$ 个元素，即去掉最后一个元素。定义$S_{post}$为序列$S$的后$l$ $-$ $1$ 个元素，即去掉第一个元素。由于随着序列模式增长，序列的支持度是下降的，那么对于序列$S$来说，必然满足$sup(S)$ $\ge$ $sup(S_{pre})$ 和 $sup(S)$ $\ge$ $sup(S_{post})$。则有如下推论，若$sup(S_{pre})$或者$sup(S_{post})$小于$min_sup$，则$S$可以被剪枝。片段剪枝判断当前处理的序列片段是否已经处理过了，通常这个过程使用哈希表。前后子序列剪枝利用上述推论，队前后子序列进行判断。支持度剪枝判断当前序列支持度是否大于$min_sup$。闭合序列模式检测传统的方法是在得到的$AS$集合中进行遍历，这样的复杂度会达到$O(N^2)$。利用序列吸收的传递性，每当获得$F_{k-1}$和$F_{k}$时，就遍历判断$F_k$的序列是否存在前后子序列位于$F_{k-1}$。算法内容init-gen初始化函数，一般都是计算每项的支持度，找出频繁项，生成$F_{1}$这些。（第3-5行）首先扫描数据库，对序列分割得到$S$，然后遍历传给ConSP-gen函数进行判断和剪枝。（第8行）进行闭合序列模式检测。CCPMCCPM使用了通配符解决带有噪音的数据集，该算法基于PrefixSpan和BIDE算法。参考文献[1] Zhang, Jingsong, et al. “CCSpan: Mining Closed Contiguous Sequential Patterns.” Knowledge Based Systems, vol. 89, 2015, pp. 1–13.[2] Abboud, Yacine, et al. “CCPM: A Scalable and Noise-Resistant Closed Contiguous Sequential Patterns Mining Algorithm.” International Conference on Machine Learning and Data Mining in Pattern Recognition, vol. 89, 2017, pp. 147–162.]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘-序列模式挖掘]]></title>
    <url>%2F2021%2F06%2F12%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98%2F</url>
    <content type="text"><![CDATA[Sequential Pattern Mining序列数据库中序列模式的挖掘算法GSPGSP是一个类Apriori算法 ，主要步骤为：1、扫描序列数据库，得到序列长度为1的序列模式$L1$2、根据长度$i$的种子集$Li$通过连接和剪枝操作生成$C(i+1)$；然后扫描数据库进行剪枝，生成序列模式$L(i+1)$3、重复第二步，直到没有新的序列模式或新的候选序列模式产生为止连接操作若序列$S1$和$S2$长度一致且$S1$去掉首项与$S2$去掉尾项一致：1）若$S2$的最后两个事件属于相同项集（元素），则$S2$ 的最后一个事件在合并后的序列中是$S1$的最后一个元素的一部分;$&lt;(1,2) (3)&gt; + &lt;(2) (3,4)&gt; = &lt;(1,2) (3,4)&gt;$2）若$S2$的最后两个事件属于不同项集（元素），则$S2$ 的最后一个事件在合并后的序列中是$S1$的一个新尾项;$&lt;(1) (2) (3)&gt; + &lt;(2) (3) (4)&gt; = &lt;(1) (2) (3) (4)&gt;$注意： $&lt;(1) (2, 3)&gt;$ 和$&lt;(2) (3, 4)&gt;$不能合并SPADESPADE (Sequential PAttern Discovery using Equivalence classes)的主要特征有：1、使用了垂直id-list数据库格式，每个项相关联的是它发生的序列id，以及时间戳。2、使用基于序列格的方法将原始的搜索空间（格）分解成更小的片段（子格），这些片段可以在主存中独立处理。（通常需要三次数据库扫描，或者只扫描一次带有一些预处理信息的扫描，从而将I/O成本降到最低）3、将问题分解与模式搜索解耦。提出两种不同的搜索策略来列举每个子格中的频繁序列：广度优先和深度优先搜索。序列枚举：基于序列格的方法定义1：对于集合$P$，$P$上的偏序是二元关系$\le$，当$X,Y,Z \in P$，有如下关系：1）自反性：$X \le X$2）反对称性：$X \le Y$且$Y \le X$，则$X=Y$3）转移性：$X \le Y, Y\le Z$，则$X \le Z$此时$P$是一个有序集合。定义2：$P$为有序集合，$S \subseteq P$。一个项$X \in P$是$S$的上限时（如果$s \le X, \quad s \in S$）。S的最小上界称为连接，记为$\vee S$；最大上界称为满足，记为$\land S$。$P$的最大项记为$\top $，最小项记为$\bot$。]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘-序列规则挖掘]]></title>
    <url>%2F2021%2F05%2F24%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%BA%8F%E5%88%97%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%2F</url>
    <content type="text"><![CDATA[Sequential Rule Mining序列数据库中序列规则的挖掘算法RuleGen该算法是最早提出的算法，原理简单。算法内容CMRules属性1：对于交易数据库$T$任意关联规则$r:X \rightarrow Y$，有$conf(r)\ge sup(r)$$sup(X\rightarrow Y)=sup(X\cup Y)/|T|,\; Conf(X \rightarrow Y)=sup(X\cup Y)/sup(X)$属性2：对于数据库$S$的任意序列规则$r:X \Rightarrow Y$，$seqConf(r) \ge seqSup(r)$衡量属性：$seqSup(X \Rightarrow Y)=sup(X \centerdot Y)/|S|,\quad seqConf(X \Rightarrow Y )=sup(X \centerdot Y)/sup(X)$$sup(X \centerdot Y)$表示$X$出现后$Y$出现的支持度注：序列规则的左侧和右侧部分的项是无序的。将序列数据库$SD$移除时间信息的话，可以得到交易数据库$SD’$。对于序列规则$r:X \Rightarrow Y$ ，有对应的关联规则$r’:X \rightarrow Y$。属性3：对于数据库$SD$的任意序列规则$r:X \Rightarrow Y$，$sup(r’) \ge seqSup(r)$$sup(r’)=sup(X \cup Y)/|SD’| ,\quad seqSup(r)=sup(X \centerdot Y)/|SD|$属性4：对于数据库$SD$的任意序列规则$r:X \Rightarrow Y$，$conf(r’) \ge seqConf(r)$算法内容完整性证明定理1：对于给定的$minconf \le miSeqConf, \quad minsup \le minSeqSup$，发先的所有序列规则都满足$minSeqConf,minSeqSup$。假设有序列规则$r$满足$seqSup(r) \ge minSeqSup, \quad minsup &gt; sup(r’)$（假设对应的$r’$不频繁）又$sup(r’) \ge seqSup(r)$，则可以得到$minsup &gt; sup(r’) \ge seqSup(r) \ge minSeqSup$固选择$minSeqSup \ge minsup$，则不存在该序列规则$r$同理可证置信度。推论1： 如果选择$minconf=minSeqConf$和$minsup=minSeqSup$，则该算法更有效率。正确性证明定理2：CMRules算法不会生成无效规则。（在step3时候，会进行无效规则过滤。）优化使用$Apriori-TID$算法可以使step3更又效率。合并step2和step3可以减少内存开销。时间复杂度分析step1与序列数量线性相关step2主要取决于选择的算法，$Apriori$算法的复杂度为$O(d^2n)$step3将每个候选规则与包含其先行项的序列集进行检查，最优和最差情况复杂度分别为$|S| \times minsup$和$|S|$。CMDeoCMDeo是一个通过递归逐级搜索的算法，主要依靠左扩展和右扩展两个过程。属性5（左扩展，序列支持度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的左侧，那么$seqSup(r) \ge seqSup(r^o)$$seqSup(r)=sup(X \centerdot Y)/|S|, \quad seqSup(r^o)=sup(X\cup\{i\} \centerdot Y)/|S|$属性6（右扩展，序列支持度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的右侧，那么$seqSup(r) \ge seqSup(r^o)$由属性5和属性6可以知道通过左扩展和右扩展生成的规则在序列支持度上是单调递减的。属性7（左扩展，序列置信度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的左侧，那么$seqConf(r)$和$ seqConf(r^o)$无法确认大小$seqConf(r)=sup(X \centerdot Y)/|sup(X)|,\quad seqConf(r^o)=sup(X\cup\{i\} \centerdot Y)/sup(X\cup\{i\})$属性8（右扩展，序列置信度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的右侧，那么$seqConf(r) \ge seqConf(r^o)$由属性7和属性8可以知道置信度是非单调的，因此只能选择序列支持度进行剪枝。处理过程123找出所有有效的1*1规则通过左右扩展得到2*1和1*2的规则，扫描序列数据库计算其支持度和置信度将有效的规则递归进行左右扩展，知道没有规则。在处理中，会面临两个问题。同样的规则可能由左扩展或着右扩展得到为了解决这个问题，规定左扩展后不能进行右扩展。一条规则可能生成两次对于$\{b,c\}\Rightarrow \{d\}$可能$\{b\}\Rightarrow\{d\}$或者$\{c\}\Rightarrow\{d\}$生成而来，这就造成一条规则可能生成多次。为了解决这个问题，规定依照字母表大小排序，只有待添加项大于集合所有的项，才能进行添加。RuleGrowth如果存在$k(1 \le k \le n)$，使得$X \subseteq U_{i=1}^{k} I_i, \quad Y \subseteq U_{i=k+1}^{n} I_i$，则说明偏序规则$X \Rightarrow Y$出现在序列中。如$\{a,b,c\} \Rightarrow \{e,f,g\}$出现在$\{a,b\},\{c\},\{f\},\{g\},\{e\}$中$sids(X\Rightarrow Y)$表示出现该规则的序列ID集合$sup(X \Rightarrow Y)=|sids(X \Rightarrow Y)|/|S|,\quad conf(X \Rightarrow Y)=|sids(X \Rightarrow Y)|/|sids(X)|$RuleGrowth通过扫描包含规则的序列（深度优先搜索）将项目添加到规则中，从而找到更大的规则，而CMDeo结合成对的规则来生成候选规则（广度优先搜索）。属性1（左扩展，支持度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的左侧，那么$sup(r) \ge sup(r^o)$$sup(r)=|sids(X \Rightarrow Y)|/|S|, \quad sup(r^o)=|sids(X\cup \{i\} \Rightarrow Y)|/|S|$属性2（右扩展，支持度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的右侧，那么$sup(r) \ge sup(r^o)$属性3（左扩展，置信度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的左侧，那么$conf(r)$和$ conf(r^o)$无法确认大小属性4（右扩展，置信度的影响）：如果$i$被加到规则$r:X \Rightarrow Y$的左侧，那么$conf(r) \ge conf(r^o)$属性5（规则的sid集及其项集）：对于任意序列规则$r:X \Rightarrow Y$，$sids(X \Rightarrow Y)\subseteq sids(X)\cap sids(Y)$属性6（从左、右扩展得到的规则的sid集）：对于任意从扩展得到的序列规则$r’$，其满足$sids(r’) \subseteq sids(r)$首次出现：规定项$X$在一个序列$s=I_1,I_2,…I_n$的首次出现集$I_k(k尽可能小)$满足$X \subseteq U_{i=1}^k$最后出现：规定项$X$在一个序列$s=I_1,I_2,…I_n$的最后出现集$I_k(k尽可能大)$满足$X \subseteq U_{i=k}^n$算法内容1、算法首先扫描数据库一次，以计算每个$c$项的$sids(c)$，然后确定满足$minsup$的所有$c$项2、算法使用(1)得到的c项，生成所有$1*1$的有效规则5-7、算法扫描序列$s \in (sids(i)\cap sids(j))$，计算$sids$8-10、满足$minsup$进行左、右扩展11、满足$minconf$进行输出如何确定哪些项用于执行左右扩展并获取有效规则？该问题可以划分为两个子问题。（1）确定可以扩展规则$I=&gt;J$以产生频繁规则的项目；（2）评估通过扩展获得的频繁规则是否有效。对于问题（1），为了确保项可以扩展到规则$r:I \Rightarrow J$，首先扫描所有序列$s \in sids(I \Rightarrow J)$，只有满足$c \notin I, \quad c \notin J$、$c$出现的位置介于$fo(I)$和$lo(J)$之间、$sup(c) \ge minsup \times |S|$，项$c$才会被添加。对于问题（2），可以用过计算置信度得以解决。如何保证通过递归执行左/右扩展找到所有有效的规则？属性1和属性2表明了规则的支持度是单调递减的。我们如何保证没有规则被发现两次？与CMDeo做法一致。左/右扩展算法内容传入了规则$r:I \Rightarrow J $、序列集$sids(I)$和$sids(I \Rightarrow J)$1、扫描每个序列$sid \in sids(I \Rightarrow J)$，对于其中满足条件的$c$项，记录$sids(I\cup\{c\}\Rightarrow J)$2-7、对于满足$minsup$的$c$项，求出$sids(I\cup\{c\})$，然后递归进行左扩展8、满足$minconf$进行输出注：左扩展的关键是找到$c$项，找到后为了计算置信度，也要求出$sids(I\cup\{c\})$。大致过程可以简述为：找到$I\cup\{c\} \Rightarrow J$的$c$项，并进行相关计算。关于4-5有一个错误的理解是：我们知道$sids(I\cup\{c\}\Rightarrow J)$里面的所有序列，不就知道了$sids(I\cup\{c\})$吗？显然错误，因为$sids(I)$的序列有一部分并不包含$J$，但可以有$c$，在右扩展这部分是一样的就不用计算了。优化1、在左/右扩展中，首先出现和最后出现需要进行序列扫描。无疑，这一步可以在扫描数据库进行计算，并使用哈希表保存。2、这时候$1*1$规则的生成可以通过哈希表判断位置，以便生成$I \Rightarrow J$或者$J \Rightarrow I$。3、同理修改了执行左扩展和右扩展的方式，以利用关于第一次和最后一次出现的信息。ERMiner定义8（规则等价类）：对于序列数据库，记$R$为频繁序列规则集，$I$为所有项的项集。左等价类$LE_{\{W\},i}=\{W\rightarrow Y|Y \subseteq I \land |Y|=i\}$，右等价类$RE_{\{W\},i}=\{X\rightarrow W|X \subseteq I \land |X|=i\}$例如：$LE_{\{c\},1}=\{\{c\}\rightarrow \{f\},\{c\}\rightarrow \{e\}\}$，$RE_{\{e,f\},1}=\{\{a\}\rightarrow \{e,f\},\{c\}\rightarrow \{e,f\}\}$定义9（左/右合并）：规定两个规则$r:W\rightarrow X,s:W\rightarrow Y$，其中$r,s \in LE_{W,i},\quad |X\cap Y|=|X-1|$。通过左合并可以生成规则$W\rightarrow X\cup Y$。右合并与其类似。那么规则$1$ $$ $1$通过左合并可生成$1$ $$ $2$的规则，通过右合并可生成$2$ $*$ $1$的规则。具有窗口大小约束的序列数据库序列规则挖掘算法TRuleGrowth发现滑动窗口中出现的规则有几个重要的好处。1、通过修剪搜索空间，可以将执行时间减少几个数量级。2、生成一组小得多的规则，从而减少存储规则所需的磁盘空间，并使用户更容易分析结果。3、当使用规则进行预测时，设置窗口约束可以提高预测精度。规则$X \Rightarrow Y$出现在序列$s=I_1,I_2…I_N$需要满足$X \subseteq U_{i=j}^{k}I_k, \quad Y\subseteq U_{i=k+1}^{m}$，其中$1\le j \le k &lt; m \le n$，$m-j+1 \le window_size$参考文献[1] Zaki, Mohammed J. “SPADE: An Efficient Algorithm for Mining Frequent Sequences.” Machine Learning, vol. 42, no. 1, 2001, pp. 31–60.[2] Fournier-Viger, Philippe, et al. “CMRules: Mining Sequential Rules Common to Several Sequences.” Knowledge Based Systems, vol. 25, no. 1, 2012, pp. 63–76.[3] Fournier-Viger, Philippe, et al. “Mining Partially-Ordered Sequential Rules Common to Multiple Sequences.” IEEE Transactions on Knowledge and Data Engineering, vol. 27, no. 8, 2015, pp. 2203–2216.[4] Fournier-Viger, Philippe, et al. “ERMiner: Sequential Rule Mining Using Equivalence Classes.” PAKDD 2006 International Workshop on Knowledge Discovery in Life Science Literature, KDLL 2006, 2014, pp. 108–119.]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法模板]]></title>
    <url>%2F2021%2F03%2F10%2F%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[搜索深度优先搜索（DFS）12345678910// init data// ...dfs(0, 0);void dfs()&#123; // border // ... // return dfs()&#125;广度优先搜索（BFS）1234567891011121314queue&lt;node&gt; q;void bfs()&#123; while(!q.empty())&#123; // border // ... // return node a = q.front(); q.pop(); // for // ... // q.push(tmp); &#125;&#125;动态规划最大连续子序列$dp[i] = max(dp[i],\quad dp[i-1]+a[i])$123456789dp[1] = a[1];for(int i = 2; i &lt;= n; i++)&#123; dp[i] = max(a[i], dp[i-1]+a[i]);&#125;int k = 1;for(int i = 2; i &lt;= n; i++)&#123; if(dp[i] &gt; dp[k]) k = i;&#125;最长不下降子序列（LIS）$dp[i] = max\{1,\quad dp[j]+1\};\quad if \quad a[j]&lt;a[i]$123456789for(int i = 1; i &lt;= n; i++)&#123; dp[i] = 1; for(int j = 1; j &lt; i; j++)&#123; if(a[i] &gt;= a[j])&#123; dp[i] = max(dp[i], dp[j]+1); &#125; &#125; ans = max(ans, dp[i]);&#125;最长公共子序列（LCS）dp[i][j] =\left\{ \begin{aligned} dp[i-1][j-1]+1,\quad a[i]==b[j] \\ max\{dp[i-1][j], dp[i][j-1]\},\quad a[i]!=b[j] \end{aligned} \right.1234567891011121314151617// borderfor(int i = 0; i &lt;= n; i++)&#123; d[i][0] = 0;&#125;for(int j = 0; j &lt;= m; j++)&#123; dp[j][0] = 0;&#125;// dpfor(int i = 1; i &lt;= n; i++)&#123; for(int j = 1; j &lt;= m; j++)&#123; if(a[i] == b[j])&#123; dp[i][j] = dp[i-1][j-1] + 1; &#125;else&#123; dp[i][j] = max(dp[i-1][j], dp[i][j-1]); &#125; &#125;&#125;最长回文串dp[i][j] =\left\{ \begin{aligned} dp[i+1][j-1],\quad s[i]==s[j] \\ 0,\quad s[i]!=s[j] \end{aligned} \right.1234567891011121314151617181920// borderfor(int i = 1; i &lt;= n; i++)&#123; dp[i][i] = 1; if(i &lt; n)&#123; if(s[i] == s[i+1])&#123; dp[i][i+1] = 2; ans = 2; &#125; &#125;&#125;// dpfor(int l = 3; l &lt;= n; l++)&#123; for(int i = 1; i+l-1 &lt;= n;i++)&#123; int j = i+l-1; if(s[i] == s[j] &amp;&amp; dp[i+1][j-1] == 1)&#123; dp[i][j] = 1; ans = l; &#125; &#125;&#125;背包问题0-1背包一维dp数组$dp[v] = max(dp[v],\quad dp[v-w[i]]+c[i])$12345for(int i = 1; i &lt;= n; i++)&#123; for(int v = V; v &gt;= w[i]; v--)&#123; dp[v] = max(dp[v], dp[v-w[i]]+c[i]); &#125;&#125;完全背包一维dp数组123456// 正向枚举for(int i = 1; i &lt;= n; i++)&#123; for(int v = 0; v &lt;= V; v++)&#123; dp[v] = max(dp[v], dp[v-w[i]]+c[i]); &#125;&#125;STLstack123456push(elem);pop();top();empty();size();queue1234567push(elem);pop();front();back();empty();size();链表快慢指针一般流程为：初始化两个指针构建两个指针距离同时移动两个指针找中间值一般的思路是：先遍历一次链表，记录住一共有多少个节点，然后，再次遍历找寻中点。现在：指针a一次走两步，指针b一次走一步。判断链表中的环指针a和指针b只要有速度差，那么总能相遇。剑指 Offer 22. 链表中倒数第k个节点见LeetCode。未完待续~参考资料《算法笔记》（胡凡/曾磊）https://www.jianshu.com/p/21b4b8d7d31b]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hadoop安装教程]]></title>
    <url>%2F2020%2F03%2F22%2FHadoop%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装Ubuntu虚拟机安装具体参考https://blog.csdn.net/m0_37634416/article/details/90240342?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-taskWin10子系统具体参考https://blog.csdn.net/li528405176/article/details/82263534子系统迁移具体参考https://blog.csdn.net/oppend/article/details/103384616子系统访问Win101ln -s /mnt/c/Users/Data ~/win10安装Java环境在终端下执行命令123sudo apt-get updatesudo apt-get install openjdk-7-jre-headlesssudo apt-get install openjdk-7-jdkE: 软件包 openjdk-7-jre 没有可安装候选先添加包含openjdk-7的仓库12sudo add-apt-repository ppa:openjdk-r/ppa sudo apt-get updateE: 有未能满足的依赖关系。请尝试不指明软件包的名字来运行“apt-get -f install”(也可以指定一个解决办法)。1sudo apt-get --fix-broken install其它安装JDK方法可参考https://www.wikihow.com/Install-Java-on-Linux创建hadoop用户组12sudo addgroup hadoopsudo adduser --ingroup hadoop hduser为hduser生产SSH密钥对安装SSH1sudo apt-get install openssh-serverhduser登陆123su hdusercd ~ssh-keygen -t rsa -f id_rsa1234567891011121314The key fingerprint is:SHA256:3N8g6PnxrveMOL1DKIvxX286HyGp88lknFutYkbxVrc hduser@DESKTOP-60J19L5The key's randomart image is:+---[RSA 2048]----+| || || || . o .. o|| S o.+o..o|| .....=o=oE || +oo++B.+ .|| . o..@OB.o || .=B@X* |+----[SHA256]-----+1234mkdir .sshmv id_rsa* .ssh/cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keyschmod 644 .ssh/authorized_keys通过SSH验证登陆到本机1ssh localhost出现ssh: connect to host localhost port 22: Connection refused先检查是否安装ssh12ps -e|grep sshdps aux | grep ssh1sudo service ssh restart禁用IPv6在root下执行1sudo vim /etc/sysctl.conf插入123net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1安装Hadoop1wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz1234sudo tar -zxf ~/win10/hadoop-2.7.7.tar.gz -C /usr/localcd /usr/local/sudo mv ./hadoop-2.7.7/ ./hadoopsudo chown -R hduser ./hadoop检测hadoop是否可用12./bin/hadoop versioncd /usr/local/hadoop配置变量创建Namenode 和 Datanode文件夹12mkdir -p hadoop_tmp/hdfs/namenodemkdir -p hadoop_tmp/hdfs/datanode配置PATH环境变量1234567891011export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbinexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib1source ~/.bashrc在/usr/local下1vim hadoop/etc/hadoop/hadoop-env.sh1export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162修改配置文件core-site .xml 文件修改1vim hadoop/etc/hadoop/core-site.xml1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;hdfs-site.xml 文件修改1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/home/hduser/hadoop_tmp/hdfs/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/home/hduser/hadoop_tmp/hdfs/datanode&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;yarn-site.xml文件修改12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;mapred-site.xml文件修改1cp hadoop/etc/hadoop/mapred-site.xml.template hadoop/etc/hadoop/mapred-site.xml1234&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;格式化 namenode1hdfs namenode -format启动Hadoop123start-dfs.sh #ECDSA key fingerprint is SHA256:DItIvfqZ3IIleZ5vCeR7rsyV9heXw1I9JX7KRYtEfO4.start-yarn.sh mr-jobhistory-daemon.sh start historyserver判断是否启动成功12345678hduser@DESKTOP-60J19L5:~$ jps4721 Jps4387 NodeManager3705 NameNode3834 DataNode4252 ResourceManager4077 SecondaryNameNode4509 JobHistoryServer访问http://127.0.0.1:8088/cluster和http://127.0.0.1:50070/dfshealth.html#tab-overview搭建集群具体参考：https://xuri.me/2016/03/22/setup-hadoop-on-ubuntu-multi-node-cluster.htmlhttp://dblab.xmu.edu.cn/blog/install-hadoop-cluster/]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（5-1）]]></title>
    <url>%2F2020%2F03%2F16%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%885-1%EF%BC%89%2F</url>
    <content type="text"><![CDATA[循环序列模型（Recurrent Neural Networks）1.1 为什么选择序列模型？（Why Sequence Models?）1.2 数学符号（Notation）比如要建立一个序列模型，用于识别句中人名位置的序列模型，即命名实体识别问题。用$x^{\langle t \rangle}$来索引这个序列的中间位置。$t$意味着它们是时序序列，但不论是否是时序序列，我们都将用$t$来索引序列中的位置。$T_{x}$和$T_{y}$来表示输入和输出序列的长度。在这个例子中，如果有一张词表，并且使用one-hot表示法来表示词典里的每个单词。用这样的表示方式表示$X$，用序列模型在$X$和目标输出$Y$之间学习建立一个映射，把它当作监督学习的问题。对于不在词表的单词，用&lt;UNK&gt;作为标记。1.3 循环神经网络模型（Recurrent Neural Network Model）怎样才能建立一个模型，建立一个神经网络来学习$X$到$Y$的映射。可以尝试的方法之一是使用标准神经网络，将它们输入到一个标准神经网络中，经过一些隐藏层，最终会输出9个值为0或1的项，它表明每个输入单词是否是人名的一部分。但是这样会有个主要问题：输入和输出数据在不同例子中可能有不同的长度。即使每个句子都有最大长度，使用填充（pad）或零填充（zero pad）使每个输入语句都达到最大长度，但仍然看起来不是一个好的表达方式。这种朴素的神经网络结果并不能共享从文本不同位置所学习到的特征 。卷积神经网络中学到的特征的快速地推广到图片其他位置 。并且使用one-hot向量，这会是一个十分庞大的输入层，第一层的权重矩阵也会有着巨量的参数。Recurrent Neural Networks要开始整个流程，在零时刻需要构造一个激活值$a^{\langle 0 \rangle}$，这通常是零向量。有些研究人员会随机用其他方法初始化$a^{\langle 0 \rangle}$。循环神经网络是从左向右扫描数据，同时每个时间步的参数也是共享的。$W_{\text{ax}}$来表示管理着从$x^{\langle t \rangle}$到隐藏层的连接，每个时间步使用的都是相同的参数$W_{\text{ax}}$。$W_{aa}$来决定激活值$a^{\langle t \rangle}$ 到隐藏层的连接 。$W_{ya}$ 管理隐藏层到激活值$y^{\langle t \rangle}$的连接。在这个循环神经网络中，它的意思是在预测${\hat{y}}^{\langle 3 \rangle}$时，不仅要使用$x^{\langle 3 \rangle}$的信息，还要使用来自$x^{\langle 1 \rangle}$和$x^{\langle 2 \rangle}$的信息，因为来自$x^{\langle 1 \rangle}$的信息可以通过这样的路径（上图编号1所示的路径）来帮助预测${\hat{y}}^{\langle 3 \rangle}$。这个循环神经网络的一个缺点就是它只使用了这个序列中之前的信息来做出预测，尤其当预测${\hat{y}}^{\langle 3 \rangle}$时，它没有用到$x^{\langle 4 \rangle}$，$x^{\langle 5 \rangle}$，$x^{\langle 6 \rangle}$等等的信息。Forward Propagation$a^{\langle 1 \rangle} = g_{1}(W_{aa}a^{\langle 0 \rangle} + W_{ax}x^{\langle 1 \rangle} + b_{a})$$\hat y^{\langle 1 \rangle} = g_{2}(W_{ya}a^{\langle 1 \rangle} + b_{y})$循环神经网络用的激活函数经常是tanh，不过有时候也会用ReLU，但是tanh是更通常的选择，有其他方法来避免梯度消失问题。如果它是一个二分问题，使用sigmoid函数作为激活函数，如果是$k$类别分类问题的话，那么可以选用softmax作为激活函数。更一般的情况下，在$t$时刻，$a^{\langle t \rangle} = g_{1}(W_{aa}a^{\langle t - 1 \rangle} + W_{ax}x^{\langle t \rangle} + b_{a})$$\hat y^{\langle t \rangle} = g_{2}(W_{ya}a^{\langle t \rangle} + b_{y})$简化这些符号：$a^{\langle t \rangle} =g(W_{a}\left\lbrack a^{\langle t-1 \rangle},x^{\langle t \rangle} \right\rbrack +b_{a})$$\hat y^{\langle t \rangle} = g(W_{y}a^{\langle t \rangle} +b_{y})$其中：$[ {W_{aa}}\vdots {W_{ax}}]=W_{a}$，如果$a$是100维的，$x$是10,000维的，那么$W_{aa}$就是个$（100，100）$维的矩阵，$W_{ax}$就是个$（100，10000）$维的矩阵，因此如果将这两个矩阵堆起来，$W_{a}$就会是个$（100，10100）$维的矩阵。$\begin{bmatrix}a^{\langle t-1 \rangle} \\ x^{\langle t \rangle} \\\end{bmatrix}$，就是个10,100维的向量。RNN前向传播示意图：1.4 通过时间的反向传播（Backpropagation through time）为了计算反向传播，先定义一个元素损失函数（上图编号1所示）$L^{\langle t \rangle}( \hat y^{\langle t \rangle},y^{\langle t \rangle}) = - y^{\langle t \rangle}\log\hat y^{\langle t \rangle}-( 1-\hat y^{\langle t \rangle})log(1-\hat y^{\langle t \rangle})$定义整个序列的损失函数，将$L$定义为（上图编号2所示）$L(\hat y,y) = \ \sum \limits_{t = 1}^{T_{x}}{L^{\langle t \rangle}(\hat y^{\langle t \rangle},y^{\langle t \rangle})}$RNN反向传播示意图：1.5 不同类型的循环神经网络（Different types of RNNs）对于其他一些应用，$T_{x}$和$T_{y}$并不一定相等。many-to-manymany-to-oneone-to-oneone-to-many1.6 语言模型和序列生成（Language model and sequence generation）一个语音识别模型可能算出第一句话的概率是$P( \text{The apple and pair salad}) = 3.2 \times 10^{-13}$，而第二句话的概率是$P\left(\text{The apple and pear salad} \right) = 5.7 \times 10^{-10}$，比较这两个概率值，语音识别系统将会选择第二句话。使用RNN构建语言模型：训练集：一个很大的语言文本语料库；Tokenize：将句子使用字典库标记化；其中，未出现在字典库中的词使用UNK来表示；第一步：使用零向量对输出进行预测，即预测第一个单词是某个单词的可能性；第二步：通过前面的输入，逐步预测后面一个单词出现的概率；训练网络：使用softmax损失函数计算损失，对网络进行参数更新，提升语言模型的准确率。softmax损失函数，$L\left( \hat y^{\langle t \rangle},y^{\langle t \rangle}\right) = - \sum_{i}^{}{y_{i}^{\langle t \rangle}\log\hat y_{i}^{\langle t \rangle}}$总体损失函数（上图编号9所示）$L = \sum_{t}^{}{L^{\langle t \rangle}\left( \hat y^{\langle t \rangle},y^{\langle t \rangle} \right)}$1.7 对新序列采样（Sampling novel sequences）记住一个序列模型模拟了任意特定单词序列的概率，我们要做的就是对这些概率分布进行采样来生成一个新的单词序列。下图编号1所示的网络已经被上方所展示的结构训练训练过了，而为了进行采样（下图编号2所示的网络），你要做一些截然不同的事情。首先输入$x^{\langle 1 \rangle}=0$，$a^{\langle 0 \rangle}=0$, 在这第一个时间步，我们得到所有可能的输出经过softmax层后可能的概率，根据这个softmax的分布，进行随机采样，获取第一个随机采样单词 $y^{\langle 1 \rangle}$然后继续下一个时间步，我们以刚刚采样得到的$y^{\langle 1 \rangle}$作为下一个时间步的输入，进而softmax层会预测下一个输出$y^{\langle 2 \rangle}$如果字典中有结束的标志如：EOS，那么输出是该符号时则表示结束；若没有这种标志，则我们可以自行设置结束的时间步。上面的模型是基于词汇的语言模型，我们还可以构建基于字符的语言模型，其中每个单词和符号则表示一个相应的输入或者输出：在这种情况下，你的字典仅包含从a到z的字母，可能还会有空格符，如果你需要的话，还可以有数字0到9，如果你想区分字母大小写，你可以再加上大写的字母。基于字符的语言模型一个主要缺点就是你最后会得到太多太长的序列。 其对于捕捉句子前后依赖关系，也就是句子前部分如何影响后面部分，不如基于词汇的语言模型那样效果好；同时基于字符的语言模型训练代价比较高。所以目前的趋势和常见的均是基于词汇的语言模型。但随着计算机运算能力的增强，在一些特定的情况下，也会开始使用基于字符的语言模型。1.8 循环神经网络的梯度消失（Vanishing gradients with RNNs）假如看到这个句子（上图编号1所示），“The cat, which already ate ……, was full.”，前后应该保持一致，因为cat是单数，所以应该用was。“The cats, which ate ……, were full.”（上图编号2所示），cats是复数，所以用were。这个例子中的句子有长期的依赖，最前面的单词对句子后面的单词有影响。但是我们目前见到的基本的RNN模型（上图编号3所示的网络模型），不擅长捕获这种长期依赖效应。如果这是个很深的神经网络，从输出$\hat y$得到的梯度很难传播回去，很难影响靠前层的权重，很难影响前面层（编号5所示的层）的计算。对于有同样问题的RNN，首先从左到右前向传播，然后反向传播。但是反向传播会很困难，因为同样的梯度消失的问题，后面层的输出误差（上图编号6所示）很难影响前面层（上图编号7所示的层）的计算。对于梯度消失问题，在RNN的结构中是我们首要关心的问题，也更难解决；虽然梯度爆炸在RNN中也会出现，但对于梯度爆炸问题，因为参数会指数级的梯度，会让我们的网络参数变得很大，得到很多的Nan或者数值溢出，所以梯度爆炸是很容易发现的，我们的解决方法就是用梯度修剪，也就是观察梯度向量，如果其大于某个阈值，则对其进行缩放，保证它不会太大。1.9 GRU单元（Gated Recurrent Unit（GRU））简化过的GRU单元GRU单元将会有个新的变量称为$c$，代表细胞（cell），即记忆细胞（下图编号1所示）。GRU实际上输出了激活值$a^{\langle t \rangle}$，$c^{\langle t \rangle} = a^{\langle t \rangle}$（下图编号2所示）。在每个时间步，我们将用一个候选值重写记忆细胞，即${c}^{\langle t \rangle}$的值，${c}^{\langle t \rangle} =tanh(W_{c}\left\lbrack c^{\langle t-1 \rangle},x^{\langle t \rangle} \right\rbrack +b_{c})$，所以${c}^{\langle t \rangle }$的值就是个替代值，代替表示$c^{\langle t \rangle}$的值（下图编号3所示）。更新门$\Gamma_{u}$，这个一直在0到1之间的门值，$\Gamma_{u}= \sigma(W_{u}\left\lbrack c^{\langle t-1 \rangle},x^{\langle t \rangle} \right\rbrack +b_{u})$。$c^{\langle t \rangle} = \Gamma_{u}{c}^{\langle t \rangle} +\left( 1- \Gamma_{u} \right)c^{\langle t-1 \rangle}$ ，记忆细胞的更新规则，门控值处于0-1之间，根据跟新公式能够有效地缓解梯度消失的问题。其中， $c^{}、\widetilde c^{}、{\Gamma _u}$ 均具有相同的维度。完整的GRU单元完整的GRU单元还存在另外一个门$\Gamma_{r}$，以决定每个时间步的候选值，$\Gamma_{r}$门告诉你计算出的下一个$c^{\langle t \rangle}$的候选值${c}^{\langle t \rangle}$跟$c^{\langle t-1 \rangle}$有多大的相关性，公式如下：1.10 长短期记忆（LSTM（long short term memory）unit）LSTM中，使用了单独的更新门$Γ_u$和遗忘门$Γ_f$，以及一个输出门$Γ_o$，其主要的公式如下：$\widetilde c^{} = \tanh (W_{c}[a^{}, x^{}] + b_{c}) \\ {\Gamma _u}=\sigma (W_{u}[a^{}, x^{}] + b_{u}) \\ {\Gamma _f}=\sigma (W_{f}[a^{}, x^{}] + b_{f}) \\{\Gamma _o}=\sigma (W_{o}[a^{}, x^{}] + b_{o}) \\ c^{} = {\Gamma _u}\widetilde c^{} + {\Gamma _f}c^{} \\ a^{} = {\Gamma _o}*\tanh c^{}$“偷窥孔连接”就是门值不仅取决于$a^{\langle t-1 \rangle}$和$x^{\langle t \rangle}$，也取决于上一个记忆细胞的值（$c^{\langle t-1 \rangle}$）。LSTM反向传播计算：门求偏导：$d \Gamma_o^{\langle t \rangle} = da_{next}\tanh(c_{next}) \Gamma_o^{\langle t \rangle}*(1-\Gamma_o^{\langle t \rangle})\tag{1}$$d c^{\langle t \rangle} = (dc_{next}\Gamma_u^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) \Gamma_u^{\langle t \rangle} da_{next}) * (1-( c^{\langle t \rangle})^2) \tag{2}$$d\Gamma_u^{\langle t \rangle} = (dc_{next} c^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) c^{\langle t \rangle} da_{next})\Gamma_u^{\langle t \rangle}*(1-\Gamma_u^{\langle t \rangle})\tag{3}$$d\Gamma_f^{\langle t \rangle} = (dc_{next} c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) c_{prev} da_{next})\Gamma_f^{\langle t \rangle}*(1-\Gamma_f^{\langle t \rangle})\tag{4}$参数求偏导 ：$ dW_f = d\Gamma_f^{\langle t \rangle} \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{5} $$ dW_u = d\Gamma_u^{\langle t \rangle} \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{6} $$ dW_c = d c^{\langle t \rangle} \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{7} $$ dW_o = d\Gamma_o^{\langle t \rangle} \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{8}$为了计算$db_f, db_u, db_c, db_o$ 需要各自对$d\Gamma_f^{\langle t \rangle}, d\Gamma_u^{\langle t \rangle}, d c^{\langle t \rangle}, d\Gamma_o^{\langle t \rangle}$ 求和。最后，计算隐藏状态、记忆状态和输入的偏导数：$ da_{prev} = W_f^Td\Gamma_f^{\langle t \rangle} + W_u^T d\Gamma_u^{\langle t \rangle}+ W_c^T d c^{\langle t \rangle} + W_o^T d\Gamma_o^{\langle t \rangle} \tag{9}$$ dc_{prev} = dc_{next}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1- \tanh(c_{next})^2)\Gamma_f^{\langle t \rangle}da_{next} \tag{10}$$ dx^{\langle t \rangle} = W_f^Td\Gamma_f^{\langle t \rangle} + W_u^T d\Gamma_u^{\langle t \rangle}+ W_c^T d c_t + W_o^T * d\Gamma_o^{\langle t \rangle}\tag{11} $1.11 双向循环神经网络（Bidirectional RNN）双向RNN则可以解决单向RNN存在的弊端。在BRNN中，不仅有从左向右的前向连接层，还存在一个从右向左的反向连接层。$\hat y^{\langle t \rangle} =g(W_{g}\left\lbrack {\overrightarrow{a}}^{\langle t \rangle},{\overleftarrow{a}}^{\langle t \rangle} \right\rbrack +b_{y})$1.12 深层循环神经网络（Deep RNNs）一个标准的神经网络，首先是输入$x$，然后堆叠上隐含层，所以这里应该有激活值，比如说第一层是$a^{\left\lbrack 1 \right\rbrack}$，接着堆叠上下一层，激活值$a^{\left\lbrack 2 \right\rbrack}$，可以再加一层$a^{\left\lbrack 3 \right\rbrack}$，然后得到预测值$\hat{y}$。深层的RNN网络跟这个有点像，用手画的这个网络（下图编号1所示），然后把它按时间展开就是了。Building your Recurrent Neural Network - Step by StepWelcome to Course 5’s first assignment! In this assignment, you will implement key components of a Recurrent Neural Network in numpy.Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have “memory”. They can read inputs $x^{\langle t \rangle}$ (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a unidirectional RNN to take information from the past to process later inputs. A bidirectional RNN can take context from both the past and the future.Notation:Superscript $[l]$ denotes an object associated with the $l^{th}$ layer.Superscript $(i)$ denotes an object associated with the $i^{th}$ example.Superscript $\langle t \rangle$ denotes an object at the $t^{th}$ time-step.Subscript $i$ denotes the $i^{th}$ entry of a vector.Example:$a^{(2)[3]\langle4 \rangle}_5$ denotes the activation of the 2nd training example (2), 3rd layer [3], 4th time step, and 5th entry in the vector.Pre-requisitesWe assume that you are already familiar with numpy.To refresh your knowledge of numpy, you can review course 1 of this specialization “Neural Networks and Deep Learning”.Specifically, review the week 2 assignment “Python Basics with numpy (optional)”.Be careful when modifying the starter codeWhen working on graded functions, please remember to only modify the code that is between the1#### START CODE HEREand1#### END CODE HEREIn particular, Be careful to not modify the first line of graded routines. These start with:1# GRADED FUNCTION: routine_nameThe automatic grader (autograder) needs these to locate the function.Even a change in spacing will cause issues with the autograder.It will return ‘failed’ if these are modified or missing.”Updates for 3aIf you were working on the notebook before this update…The current notebook is version “3a”.You can find your original work saved in the notebook with the previous version name (“v3”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updates“Forward propagation for the basic RNN”, added sections to clarify variable names and shapes:“Dimensions of $x^{\langle t \rangle}$”“Hidden State $a$”,“Dimensions of hidden state $a^{\langle t \rangle}$”“Dimensions of prediction $y^{\langle t \rangle}$”rnn_cell_forward:Added additional hints.Updated figure 2.rnn_forwardSet xt in a separate line of code to clarify what code is expected; added additional hints.Clarifies instructions to specify dimensions (2D or 3D), and clarifies variable names.Additional HintsClarifies when the basic RNN works well.Updated figure 3.“About the gates” replaced with “overview of gates and states”:Updated to include conceptual description of each gate’s purpose, and an explanation of each equation.Added sections about the cell state, hidden state, and prediction.Lists variable names that are used in the code, and notes when they differ from the variables used in the equations.Lists shapes of the variables.Updated figure 4.lstm_forwardAdded instructions, noting the shapes of the variables.Added hints about c and c_next to help students avoid copy-by-reference mistakes.Set xt in a separate line to make this step explicit.dimensionclarified use of $x^{(i)\langle t \rangle}$ in dimension descriptionBackward descriptionUpdated figure 6 and 7rnn_cell_backwardchanged ‘dtanh’ to ‘dz’ to avoid confusion with the output of the tanhfixed naming of ‘b’ in test section, changed to ‘ba’, updated resultsrnn_backwardmodified instructions in comments to sum da and gradients from previous timestepslstm_cell_backwardupdated equations and description to fix errors.Added Figure 8modified equations to use the term dlower_case_gamma vs dGamma - the previous naming confused the location of the gate derivative.removed redundant lines for equations 7-10, changed equation numbers to match new equation numberslstm_backwardremoved comment listing dc as argument.added da_prevt and dc_prevt to for loop and recalculated resultsin test, added “Wy” and “by” zero fill as it is required for lstm_forward.Renamed global variables so that they do not conflict with local variables within the function.Spelling, grammar and wording corrections.For unit tests, updated print statements and “expected output” for easier comparisons.Many thanks to mentors and students for suggested improvements and fixes in the assignments for course 5!Let’s first import all the packages that you will need during this assignment.12import numpy as npfrom rnn_utils import *1 - Forward propagation for the basic Recurrent Neural NetworkLater this week, you will generate music using an RNN. The basic RNN that you will implement has the structure below. In this example, $T_x = T_y$.Dimensions of input $x$Input with $n_x$ number of unitsFor a single timestep of a single input example, $x^{(i) \langle t \rangle }$ is a one-dimensional input vector.Using language as an example, a language with a 5000 word vocabulary could be one-hot encoded into a vector that has 5000 units. So $x^{(i)\langle t \rangle}$ would have the shape (5000,).We’ll use the notation $n_x$ to denote the number of units in a single timestep of a single training example.Time steps of size $T_{x}$A recurrent neural network has multiple time steps, which we’ll index with $t$.In the lessons, we saw a single training example $x^{(i)}$ consist of multiple time steps $T_x$. For example, if there are 10 time steps, $T_{x} = 10$Batches of size $m$Let’s say we have mini-batches, each with 20 training examples.To benefit from vectorization, we’ll stack 20 columns of $x^{(i)}$ examples.For example, this tensor has the shape (5000,20,10).We’ll use $m$ to denote the number of training examples.So the shape of a mini-batch is $(n_x,m,T_x)$3D Tensor of shape $(n_{x},m,T_{x})$The 3-dimensional tensor $x$ of shape $(n_x,m,T_x)$ represents the input $x$ that is fed into the RNN.Taking a 2D slice for each time step: $x^{\langle t \rangle}$At each time step, we’ll use a mini-batches of training examples (not just a single example).So, for each time step $t$, we’ll use a 2D slice of shape $(n_x,m)$.We’re referring to this 2D slice as $x^{\langle t \rangle}$. The variable name in the code is xt.Definition of hidden state $a$The activation $a^{\langle t \rangle}$ that is passed to the RNN from one time step to another is called a “hidden state.”Dimensions of hidden state $a$Similar to the input tensor $x$, the hidden state for a single training example is a vector of length $n_{a}$.If we include a mini-batch of $m$ training examples, the shape of a mini-batch is $(n_{a},m)$.When we include the time step dimension, the shape of the hidden state is $(n_{a}, m, T_x)$We will loop through the time steps with index $t$, and work with a 2D slice of the 3D tensor.We’ll refer to this 2D slice as $a^{\langle t \rangle}$.In the code, the variable names we use are either a_prev or a_next, depending on the function that’s being implemented.The shape of this 2D slice is $(n_{a}, m)$Dimensions of prediction $\hat{y}$Similar to the inputs and hidden states, $\hat{y}$ is a 3D tensor of shape $(n_{y}, m, T_{y})$.$n_{y}$: number of units in the vector representing the prediction.$m$: number of examples in a mini-batch.$T_{y}$: number of time steps in the prediction.For a single time step $t$, a 2D slice $\hat{y}^{\langle t \rangle}$ has shape $(n_{y}, m)$.In the code, the variable names are:y_pred: $\hat{y}$yt_pred: $\hat{y}^{\langle t \rangle}$Here’s how you can implement an RNN:Steps:Implement the calculations needed for one time-step of the RNN.Implement a loop over $T_x$ time-steps in order to process all the inputs, one at a time.1.1 - RNN cellA recurrent neural network can be seen as the repeated use of a single cell. You are first going to implement the computations for a single time-step. The following figure describes the operations for a single time-step of an RNN cell.rnn cell versus rnn_cell_forwardNote that an RNN cell outputs the hidden state $a^{\langle t \rangle}$.The rnn cell is shown in the figure as the inner box which has solid lines.The function that we will implement, rnn_cell_forward, also calculates the prediction $\hat{y}^{\langle t \rangle}$The rnn_cell_forward is shown in the figure as the outer box that has dashed lines.Exercise: Implement the RNN-cell described in Figure (2).Instructions:Compute the hidden state with tanh activation: $a^{\langle t \rangle} = \tanh(W_{aa} a^{\langle t-1 \rangle} + W_{ax} x^{\langle t \rangle} + b_a)$.Using your new hidden state $a^{\langle t \rangle}$, compute the prediction $\hat{y}^{\langle t \rangle} = softmax(W_{ya} a^{\langle t \rangle} + b_y)$. We provided the function softmax.Store $(a^{\langle t \rangle}, a^{\langle t-1 \rangle}, x^{\langle t \rangle}, parameters)$ in a cache.Return $a^{\langle t \rangle}$ , $\hat{y}^{\langle t \rangle}$ and cacheAdditional Hintsnumpy.tanhWe’ve created a softmax function that you can use. It is located in the file ‘rnn_utils.py’ and has been imported.For matrix multiplication, use numpy.dot123456789101112131415161718192021222324252627282930313233343536373839# GRADED FUNCTION: rnn_cell_forwarddef rnn_cell_forward(xt, a_prev, parameters): """ Implements a single forward step of the RNN-cell as described in Figure (2) Arguments: xt -- your input data at timestep "t", numpy array of shape (n_x, m). a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m) parameters -- python dictionary containing: Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x) Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a) Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a) ba -- Bias, numpy array of shape (n_a, 1) by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1) Returns: a_next -- next hidden state, of shape (n_a, m) yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m) cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters) """ # Retrieve parameters from "parameters" Wax = parameters["Wax"] Waa = parameters["Waa"] Wya = parameters["Wya"] ba = parameters["ba"] by = parameters["by"] ### START CODE HERE ### (≈2 lines) # compute next activation state using the formula given above a_next = np.tanh(np.dot(Waa, a_prev) + np.dot(Wax, xt) + ba) # compute output of the current cell using the formula given above yt_pred = softmax(np.dot(Wya, a_next) + by) ### END CODE HERE ### # store values you need for backward propagation in cache cache = (a_next, a_prev, xt, parameters) return a_next, yt_pred, cache123456789101112131415np.random.seed(1)xt_tmp = np.random.randn(3,10)a_prev_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Waa'] = np.random.randn(5,5)parameters_tmp['Wax'] = np.random.randn(5,3)parameters_tmp['Wya'] = np.random.randn(2,5)parameters_tmp['ba'] = np.random.randn(5,1)parameters_tmp['by'] = np.random.randn(2,1)a_next_tmp, yt_pred_tmp, cache_tmp = rnn_cell_forward(xt_tmp, a_prev_tmp, parameters_tmp)print("a_next[4] = \n", a_next_tmp[4])print("a_next.shape = \n", a_next_tmp.shape)print("yt_pred[1] =\n", yt_pred_tmp[1])print("yt_pred.shape = \n", yt_pred_tmp.shape)1.2 - RNN forward passA recurrent neural network (RNN) is a repetition of the RNN cell that you’ve just built.If your input sequence of data is 10 time steps long, then you will re-use the RNN cell 10 times.Each cell takes two inputs at each time step:$a^{\langle t-1 \rangle}$: The hidden state from the previous cell.$x^{\langle t \rangle}$: The current time-step’s input data.It has two outputs at each time step:A hidden state ($a^{\langle t \rangle}$)A prediction ($y^{\langle t \rangle}$)The weights and biases $(W_{aa}, b_{a}, W_{ax}, b_{x})$ are re-used each time step.They are maintained between calls to rnn_cell_forward in the ‘parameters’ dictionary.Exercise: Code the forward propagation of the RNN described in Figure (3).Instructions:Create a 3D array of zeros, $a$ of shape $(n_{a}, m, T_{x})$ that will store all the hidden states computed by the RNN.Create a 3D array of zeros, $\hat{y}$, of shape $(n_{y}, m, T_{x})$ that will store the predictions.Note that in this case, $T_{y} = T_{x}$ (the prediction and input have the same number of time steps).Initialize the 2D hidden state a_next by setting it equal to the initial hidden state, $a_{0}$.At each time step $t$:Get $x^{\langle t \rangle}$, which is a 2D slice of $x$ for a single time step $t$.$x^{\langle t \rangle}$ has shape $(n_{x}, m)$$x$ has shape $(n_{x}, m, T_{x})$Update the 2D hidden state $a^{\langle t \rangle}$ (variable name a_next), the prediction $\hat{y}^{\langle t \rangle}$ and the cache by running rnn_cell_forward.$a^{\langle t \rangle}$ has shape $(n_{a}, m)$Store the 2D hidden state in the 3D tensor $a$, at the $t^{th}$ position.$a$ has shape $(n_{a}, m, T_{x})$Store the 2D $\hat{y}^{\langle t \rangle}$ prediction (variable name yt_pred) in the 3D tensor $\hat{y}_{pred}$ at the $t^{th}$ position.$\hat{y}^{\langle t \rangle}$ has shape $(n_{y}, m)$$\hat{y}$ has shape $(n_{y}, m, T_x)$Append the cache to the list of caches.Return the 3D tensor $a$ and $\hat{y}$, as well as the list of caches.Additional Hintsnp.zerosIf you have a 3 dimensional numpy array and are indexing by its third dimension, you can use array slicing like this: var_name[:,:,i].1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# GRADED FUNCTION: rnn_forwarddef rnn_forward(x, a0, parameters): """ Implement the forward propagation of the recurrent neural network described in Figure (3). Arguments: x -- Input data for every time-step, of shape (n_x, m, T_x). a0 -- Initial hidden state, of shape (n_a, m) parameters -- python dictionary containing: Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a) Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x) Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a) ba -- Bias numpy array of shape (n_a, 1) by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1) Returns: a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x) y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x) caches -- tuple of values needed for the backward pass, contains (list of caches, x) """ # Initialize "caches" which will contain the list of all caches caches = [] # Retrieve dimensions from shapes of x and parameters["Wya"] n_x, m, T_x = x.shape n_y, n_a = parameters["Wya"].shape ### START CODE HERE ### # initialize "a" and "y_pred" with zeros (≈2 lines) a = np.zeros((n_a, m, T_x)) y_pred = np.zeros((n_y, m, T_x)) # Initialize a_next (≈1 line) a_next = a0 # loop over all time-steps of the input 'x' (1 line) for t in range(T_x): # Update next hidden state, compute the prediction, get the cache (≈2 lines) xt = x[:, :, t] a_next, yt_pred, cache = rnn_cell_forward(xt, a_next, parameters) # Save the value of the new "next" hidden state in a (≈1 line) a[:,:,t] = a_next # Save the value of the prediction in y (≈1 line) y_pred[:,:,t] = yt_pred # Append "cache" to "caches" (≈1 line) caches.append(cache) ### END CODE HERE ### # store values needed for backward propagation in cache caches = (caches, x) return a, y_pred, caches1234567891011121314151617np.random.seed(1)x_tmp = np.random.randn(3,10,4)a0_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Waa'] = np.random.randn(5,5)parameters_tmp['Wax'] = np.random.randn(5,3)parameters_tmp['Wya'] = np.random.randn(2,5)parameters_tmp['ba'] = np.random.randn(5,1)parameters_tmp['by'] = np.random.randn(2,1)a_tmp, y_pred_tmp, caches_tmp = rnn_forward(x_tmp, a0_tmp, parameters_tmp)print("a[4][1] = \n", a_tmp[4][1])print("a.shape = \n", a_tmp.shape)print("y_pred[1][3] =\n", y_pred_tmp[1][3])print("y_pred.shape = \n", y_pred_tmp.shape)print("caches[1][1][3] =\n", caches_tmp[1][1][3])print("len(caches) = \n", len(caches_tmp))Congratulations! You’ve successfully built the forward propagation of a recurrent neural network from scratch.Situations when this RNN will perform better:This will work well enough for some applications, but it suffers from the vanishing gradient problems.The RNN works best when each output $\hat{y}^{\langle t \rangle}$ can be estimated using “local” context.“Local” context refers to information that is close to the prediction’s time step $t$.More formally, local context refers to inputs $x^{\langle t’ \rangle}$ and predictions $\hat{y}^{\langle t \rangle}$ where $t’$ is close to $t$.In the next part, you will build a more complex LSTM model, which is better at addressing vanishing gradients. The LSTM will be better able to remember a piece of information and keep it saved for many timesteps.2 - Long Short-Term Memory (LSTM) networkThe following figure shows the operations of an LSTM-cell.Similar to the RNN example above, you will start by implementing the LSTM cell for a single time-step. Then you can iteratively call it from inside a “for-loop” to have it process an input with $T_x$ time-steps.Overview of gates and states- Forget gate $\mathbf{\Gamma}_{f}$Let’s assume we are reading words in a piece of text, and plan to use an LSTM to keep track of grammatical structures, such as whether the subject is singular (“puppy”) or plural (“puppies”).If the subject changes its state (from a singular word to a plural word), the memory of the previous state becomes outdated, so we “forget” that outdated state.The “forget gate” is a tensor containing values that are between 0 and 1.If a unit in the forget gate has a value close to 0, the LSTM will “forget” the stored state in the corresponding unit of the previous cell state.If a unit in the forget gate has a value close to 1, the LSTM will mostly remember the corresponding value in the stored state.Equation\mathbf{\Gamma}_f^{\langle t \rangle} = \sigma(\mathbf{W}_f[\mathbf{a}^{\langle t-1 \rangle}, \mathbf{x}^{\langle t \rangle}] + \mathbf{b}_f)\tag{1}Explanation of the equation:$\mathbf{W_{f}}$ contains weights that govern the forget gate’s behavior.The previous time step’s hidden state $[a^{\langle t-1 \rangle}$ and current time step’s input $x^{\langle t \rangle}]$ are concatenated together and multiplied by $\mathbf{W_{f}}$.A sigmoid function is used to make each of the gate tensor’s values $\mathbf{\Gamma}_f^{\langle t \rangle}$ range from 0 to 1.The forget gate $\mathbf{\Gamma}_f^{\langle t \rangle}$ has the same dimensions as the previous cell state $c^{\langle t-1 \rangle}$.This means that the two can be multiplied together, element-wise.Multiplying the tensors $\mathbf{\Gamma}_f^{\langle t \rangle} * \mathbf{c}^{\langle t-1 \rangle}$ is like applying a mask over the previous cell state.If a single value in $\mathbf{\Gamma}_f^{\langle t \rangle}$ is 0 or close to 0, then the product is close to 0.This keeps the information stored in the corresponding unit in $\mathbf{c}^{\langle t-1 \rangle}$ from being remembered for the next time step.Similarly, if one value is close to 1, the product is close to the original value in the previous cell state.The LSTM will keep the information from the corresponding unit of $\mathbf{c}^{\langle t-1 \rangle}$, to be used in the next time step.Variable names in the codeThe variable names in the code are similar to the equations, with slight differences.Wf: forget gate weight $\mathbf{W}_{f}$Wb: forget gate bias $\mathbf{W}_{b}$ft: forget gate $\Gamma_f^{\langle t \rangle}$Candidate value ${\mathbf{c}}^{\langle t \rangle}$The candidate value is a tensor containing information from the current time step that may be stored in the current cell state $\mathbf{c}^{\langle t \rangle}$.Which parts of the candidate value get passed on depends on the update gate.The candidate value is a tensor containing values that range from -1 to 1.The tilde “~” is used to differentiate the candidate ${\mathbf{c}}^{\langle t \rangle}$ from the cell state $\mathbf{c}^{\langle t \rangle}$.Equation\mathbf{c}^{\langle t \rangle} = \tanh\left( \mathbf{W}_{c} [\mathbf{a}^{\langle t - 1 \rangle}, \mathbf{x}^{\langle t \rangle}] + \mathbf{b}_{c} \right) \tag{3}Explanation of the equationThe ‘tanh’ function produces values between -1 and +1.Variable names in the codecct: candidate value $\mathbf{c}^{\langle t \rangle}$- Update gate $\mathbf{\Gamma}_{i}$We use the update gate to decide what aspects of the candidate ${\mathbf{c}}^{\langle t \rangle}$ to add to the cell state $c^{\langle t \rangle}$.The update gate decides what parts of a “candidate” tensor ${\mathbf{c}}^{\langle t \rangle}$ are passed onto the cell state $\mathbf{c}^{\langle t \rangle}$.The update gate is a tensor containing values between 0 and 1.When a unit in the update gate is close to 1, it allows the value of the candidate ${\mathbf{c}}^{\langle t \rangle}$ to be passed onto the hidden state $\mathbf{c}^{\langle t \rangle}$When a unit in the update gate is close to 0, it prevents the corresponding value in the candidate from being passed onto the hidden state.Notice that we use the subscript “i” and not “u”, to follow the convention used in the literature.Equation\mathbf{\Gamma}_i^{\langle t \rangle} = \sigma(\mathbf{W}_i[a^{\langle t-1 \rangle}, \mathbf{x}^{\langle t \rangle}] + \mathbf{b}_i)\tag{2}Explanation of the equationSimilar to the forget gate, here $\mathbf{\Gamma}_i^{\langle t \rangle}$, the sigmoid produces values between 0 and 1.The update gate is multiplied element-wise with the candidate, and this product ($\mathbf{\Gamma}_{i}^{\langle t \rangle} * {c}^{\langle t \rangle}$) is used in determining the cell state $\mathbf{c}^{\langle t \rangle}$.Variable names in code (Please note that they’re different than the equations)In the code, we’ll use the variable names found in the academic literature. These variables don’t use “u” to denote “update”.Wi is the update gate weight $\mathbf{W}_i$ (not “Wu”)bi is the update gate bias $\mathbf{b}_i$ (not “bu”)it is the forget gate $\mathbf{\Gamma}_i^{\langle t \rangle}$ (not “ut”)- Cell state $\mathbf{c}^{\langle t \rangle}$The cell state is the “memory” that gets passed onto future time steps.The new cell state $\mathbf{c}^{\langle t \rangle}$ is a combination of the previous cell state and the candidate value.Equation\mathbf{c}^{\langle t \rangle} = \mathbf{\Gamma}_f^{\langle t \rangle}* \mathbf{c}^{\langle t-1 \rangle} + \mathbf{\Gamma}_{i}^{\langle t \rangle} *\mathbf{c}^{\langle t \rangle} \tag{4}Explanation of equationThe previous cell state $\mathbf{c}^{\langle t-1 \rangle}$ is adjusted (weighted) by the forget gate $\mathbf{\Gamma}_{f}^{\langle t \rangle}$and the candidate value ${\mathbf{c}}^{\langle t \rangle}$, adjusted (weighted) by the update gate $\mathbf{\Gamma}_{i}^{\langle t \rangle}$Variable names and shapes in the codec: cell state, including all time steps, $\mathbf{c}$ shape $(n_{a}, m, T)$c_next: new (next) cell state, $\mathbf{c}^{\langle t \rangle}$ shape $(n_{a}, m)$c_prev: previous cell state, $\mathbf{c}^{\langle t-1 \rangle}$, shape $(n_{a}, m)$- Output gate $\mathbf{\Gamma}_{o}$The output gate decides what gets sent as the prediction (output) of the time step.The output gate is like the other gates. It contains values that range from 0 to 1.Equation\mathbf{\Gamma}_o^{\langle t \rangle}= \sigma(\mathbf{W}_o[\mathbf{a}^{\langle t-1 \rangle}, \mathbf{x}^{\langle t \rangle}] + \mathbf{b}_{o})\tag{5}Explanation of the equationThe output gate is determined by the previous hidden state $\mathbf{a}^{\langle t-1 \rangle}$ and the current input $\mathbf{x}^{\langle t \rangle}$The sigmoid makes the gate range from 0 to 1.Variable names in the codeWo: output gate weight, $\mathbf{W_o}$bo: output gate bias, $\mathbf{b_o}$ot: output gate, $\mathbf{\Gamma}_{o}^{\langle t \rangle}$- Hidden state $\mathbf{a}^{\langle t \rangle}$The hidden state gets passed to the LSTM cell’s next time step.It is used to determine the three gates ($\mathbf{\Gamma}_{f}, \mathbf{\Gamma}_{u}, \mathbf{\Gamma}_{o}$) of the next time step.The hidden state is also used for the prediction $y^{\langle t \rangle}$.Equation\mathbf{a}^{\langle t \rangle} = \mathbf{\Gamma}_o^{\langle t \rangle} * \tanh(\mathbf{c}^{\langle t \rangle})\tag{6}Explanation of equationThe hidden state $\mathbf{a}^{\langle t \rangle}$ is determined by the cell state $\mathbf{c}^{\langle t \rangle}$ in combination with the output gate $\mathbf{\Gamma}_{o}$.The cell state state is passed through the “tanh” function to rescale values between -1 and +1.The output gate acts like a “mask” that either preserves the values of $\tanh(\mathbf{c}^{\langle t \rangle})$ or keeps those values from being included in the hidden state $\mathbf{a}^{\langle t \rangle}$Variable names and shapes in the codea: hidden state, including time steps. $\mathbf{a}$ has shape $(n_{a}, m, T_{x})$a_prev: hidden state from previous time step. $\mathbf{a}^{\langle t-1 \rangle}$ has shape $(n_{a}, m)$a_next: hidden state for next time step. $\mathbf{a}^{\langle t \rangle}$ has shape $(n_{a}, m)$- Prediction $\mathbf{y}^{\langle t \rangle}_{pred}$The prediction in this use case is a classification, so we’ll use a softmax.The equation is:\mathbf{y}^{\langle t \rangle}_{pred} = \textrm{softmax}(\mathbf{W}_{y} \mathbf{a}^{\langle t \rangle} + \mathbf{b}_{y})Variable names and shapes in the codey_pred: prediction, including all time steps. $\mathbf{y}_{pred}$ has shape $(n_{y}, m, T_{x})$. Note that $(T_{y} = T_{x})$ for this example.yt_pred: prediction for the current time step $t$. $\mathbf{y}^{\langle t \rangle}_{pred}$ has shape $(n_{y}, m)$2.1 - LSTM cellExercise: Implement the LSTM cell described in the Figure (4).Instructions:Concatenate the hidden state $a^{\langle t-1 \rangle}$ and input $x^{\langle t \rangle}$ into a single matrix:concat = \begin{bmatrix} a^{\langle t-1 \rangle} \\ x^{\langle t \rangle} \end{bmatrix}Compute all the formulas 1 through 6 for the gates, hidden state, and cell state.Compute the prediction $y^{\langle t \rangle}$.Additional HintsYou can use numpy.concatenate. Check which value to use for the axis parameter.The functions sigmoid() and softmax are imported from rnn_utils.py.numpy.tanhUse np.dot for matrix multiplication.Notice that the variable names Wi, bi refer to the weights and biases of the update gate. There are no variables named “Wu” or “bu” in this function.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# GRADED FUNCTION: lstm_cell_forwarddef lstm_cell_forward(xt, a_prev, c_prev, parameters): """ Implement a single forward step of the LSTM-cell as described in Figure (4) Arguments: xt -- your input data at timestep "t", numpy array of shape (n_x, m). a_prev -- Hidden state at timestep "t-1", numpy array of shape (n_a, m) c_prev -- Memory state at timestep "t-1", numpy array of shape (n_a, m) parameters -- python dictionary containing: Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x) bf -- Bias of the forget gate, numpy array of shape (n_a, 1) Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x) bi -- Bias of the update gate, numpy array of shape (n_a, 1) Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x) bc -- Bias of the first "tanh", numpy array of shape (n_a, 1) Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x) bo -- Bias of the output gate, numpy array of shape (n_a, 1) Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a) by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1) Returns: a_next -- next hidden state, of shape (n_a, m) c_next -- next memory state, of shape (n_a, m) yt_pred -- prediction at timestep "t", numpy array of shape (n_y, m) cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters) Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde), c stands for the cell state (memory) """ # Retrieve parameters from "parameters" Wf = parameters["Wf"] # forget gate weight bf = parameters["bf"] Wi = parameters["Wi"] # update gate weight (notice the variable name) bi = parameters["bi"] # (notice the variable name) Wc = parameters["Wc"] # candidate value weight bc = parameters["bc"] Wo = parameters["Wo"] # output gate weight bo = parameters["bo"] Wy = parameters["Wy"] # prediction weight by = parameters["by"] # Retrieve dimensions from shapes of xt and Wy n_x, m = xt.shape n_y, n_a = Wy.shape ### START CODE HERE ### # Concatenate a_prev and xt (≈1 line) concat = np.concatenate((a_prev, xt), axis=0) # Compute values for ft (forget gate), it (update gate), # cct (candidate value), c_next (cell state), # ot (output gate), a_next (hidden state) (≈6 lines) ft = sigmoid(np.dot(Wf, concat) + bf) # forget gate it = sigmoid(np.dot(Wi, concat) + bi) # update gate cct = np.tanh(np.dot(Wc, concat) + bc) # candidate value c_next = ft*c_prev + it*cct # cell state ot = sigmoid(np.dot(Wo, concat) + bo) # output gate a_next = ot*np.tanh(c_next) # hidden state # Compute prediction of the LSTM cell (≈1 line) yt_pred = softmax(np.dot(Wy, a_next) + by) ### END CODE HERE ### # store values needed for backward propagation in cache cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) return a_next, c_next, yt_pred, cache12345678910111213141516171819202122232425np.random.seed(1)xt_tmp = np.random.randn(3,10)a_prev_tmp = np.random.randn(5,10)c_prev_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wf'] = np.random.randn(5, 5+3)parameters_tmp['bf'] = np.random.randn(5,1)parameters_tmp['Wi'] = np.random.randn(5, 5+3)parameters_tmp['bi'] = np.random.randn(5,1)parameters_tmp['Wo'] = np.random.randn(5, 5+3)parameters_tmp['bo'] = np.random.randn(5,1)parameters_tmp['Wc'] = np.random.randn(5, 5+3)parameters_tmp['bc'] = np.random.randn(5,1)parameters_tmp['Wy'] = np.random.randn(2,5)parameters_tmp['by'] = np.random.randn(2,1)a_next_tmp, c_next_tmp, yt_tmp, cache_tmp = lstm_cell_forward(xt_tmp, a_prev_tmp, c_prev_tmp, parameters_tmp)print("a_next[4] = \n", a_next_tmp[4])print("a_next.shape = ", c_next_tmp.shape)print("c_next[2] = \n", c_next_tmp[2])print("c_next.shape = ", c_next_tmp.shape)print("yt[1] =", yt_tmp[1])print("yt.shape = ", yt_tmp.shape)print("cache[1][3] =\n", cache_tmp[1][3])print("len(cache) = ", len(cache_tmp))2.2 - Forward pass for LSTMNow that you have implemented one step of an LSTM, you can now iterate this over this using a for-loop to process a sequence of $T_x$ inputs.Exercise: Implement lstm_forward() to run an LSTM over $T_x$ time-steps.InstructionsGet the dimensions $n_x, n_a, n_y, m, T_x$ from the shape of the variables: x and parameters.Initialize the 3D tensors $a$, $c$ and $y$.$a$: hidden state, shape $(n_{a}, m, T_{x})$$c$: cell state, shape $(n_{a}, m, T_{x})$$y$: prediction, shape $(n_{y}, m, T_{x})$ (Note that $T_{y} = T_{x}$ in this example).Note Setting one variable equal to the other is a “copy by reference”. In other words, don’t do c = a, otherwise both these variables point to the same underlying variable.Initialize the 2D tensor $a^{\langle t \rangle}$$a^{\langle t \rangle}$ stores the hidden state for time step $t$. The variable name is a_next.$a^{\langle 0 \rangle}$, the initial hidden state at time step 0, is passed in when calling the function. The variable name is a0.$a^{\langle t \rangle}$ and $a^{\langle 0 \rangle}$ represent a single time step, so they both have the shape $(n_{a}, m)$Initialize $a^{\langle t \rangle}$ by setting it to the initial hidden state ($a^{\langle 0 \rangle}$) that is passed into the function.Initialize $c^{\langle t \rangle}$ with zeros.The variable name is c_next.$c^{\langle t \rangle}$ represents a single time step, so its shape is $(n_{a}, m)$Note: create c_next as its own variable with its own location in memory. Do not initialize it as a slice of the 3D tensor $c$. In other words, don’t do c_next = c[:,:,0].For each time step, do the following:From the 3D tensor $x$, get a 2D slice $x^{\langle t \rangle}$ at time step $t$.Call the lstm_cell_forward function that you defined previously, to get the hidden state, cell state, prediction, and cache.Store the hidden state, cell state and prediction (the 2D tensors) inside the 3D tensors.Also append the cache to the list of caches.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# GRADED FUNCTION: lstm_forwarddef lstm_forward(x, a0, parameters): """ Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (4). Arguments: x -- Input data for every time-step, of shape (n_x, m, T_x). a0 -- Initial hidden state, of shape (n_a, m) parameters -- python dictionary containing: Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x) bf -- Bias of the forget gate, numpy array of shape (n_a, 1) Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x) bi -- Bias of the update gate, numpy array of shape (n_a, 1) Wc -- Weight matrix of the first "tanh", numpy array of shape (n_a, n_a + n_x) bc -- Bias of the first "tanh", numpy array of shape (n_a, 1) Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x) bo -- Bias of the output gate, numpy array of shape (n_a, 1) Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a) by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1) Returns: a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x) y -- Predictions for every time-step, numpy array of shape (n_y, m, T_x) c -- The value of the cell state, numpy array of shape (n_a, m, T_x) caches -- tuple of values needed for the backward pass, contains (list of all the caches, x) """ # Initialize "caches", which will track the list of all the caches caches = [] ### START CODE HERE ### Wy = parameters['Wy'] # saving parameters['Wy'] in a local variable in case students use Wy instead of parameters['Wy'] # Retrieve dimensions from shapes of x and parameters['Wy'] (≈2 lines) n_x, m, T_x = x.shape n_y, n_a = parameters['Wy'].shape # initialize "a", "c" and "y" with zeros (≈3 lines) a = np.zeros((n_a, m, T_x)) c = np.zeros((n_a, m, T_x)) y = np.zeros((n_y, m, T_x)) # Initialize a_next and c_next (≈2 lines) a_next = a0 c_next = np.zeros((n_a, m)) # loop over all time-steps for t in range(T_x): # Get the 2D slice 'xt' from the 3D input 'x' at time step 't' xt = x[:, :, t] # Update next hidden state, next memory state, compute the prediction, get the cache (≈1 line) a_next, c_next, yt, cache = lstm_cell_forward(xt, a_next, c_next, parameters) # Save the value of the new "next" hidden state in a (≈1 line) a[:,:,t] = a_next # Save the value of the next cell state (≈1 line) c[:,:,t] = c_next # Save the value of the prediction in y (≈1 line) y[:,:,t] = yt # Append the cache into caches (≈1 line) caches.append(cache) ### END CODE HERE ### # store values needed for backward propagation in cache caches = (caches, x) return a, y, c, cachesCongratulations! You have now implemented the forward passes for the basic RNN and the LSTM. When using a deep learning framework, implementing the forward pass is sufficient to build systems that achieve great performance.The rest of this notebook is optional, and will not be graded.3 - Backpropagation in recurrent neural networks (OPTIONAL / UNGRADED)In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers do not need to bother with the details of the backward pass. If however you are an expert in calculus and want to see the details of backprop in RNNs, you can work through this optional portion of the notebook.When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in recurrent neural networks you can calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are quite complicated and we did not derive them in lecture. However, we will briefly present them below.Note that this notebook does not implement the backward path from the Loss ‘J’ backwards to ‘a’. This would have included the dense layer and softmax which are a part of the forward path. This is assumed to be calculated elsewhere and the result passed to rnn_backward in ‘da’. It is further assumed that loss has been adjusted for batch size (m) and division by the number of examples is not required here.This section is optional and ungraded. It is more difficult and has fewer details regarding its implementation. This section only implements key elements of the full path.3.1 - Basic RNN backward passWe will start by computing the backward pass for the basic RNN-cell and then in the following sections, iterate through the cells.Recall from lecture, the shorthand for the partial derivative of cost relative to a variable is dVariable. For example, $\frac{\partial J}{\partial W_{ax}}$ is $dW_{ax}$. This will be used throughout the remaining sections.EquationsTo compute the rnn_cell_backward you can utilize the following equations. It is a good exercise to derive them by hand. Here, $*$ denotes element-wise multiplication while the absence of a symbol indicates matrix multiplication.$a^{\langle t \rangle} = \tanh(W_{ax} x^{\langle t \rangle} + W_{aa} a^{\langle t-1 \rangle} + b_{a})\tag{-}$$\displaystyle \frac{\partial \tanh(x)} {\partial x} = 1 - \tanh^2(x) \tag{-}$$\displaystyle {dW_{ax}} = da_{next} * ( 1-\tanh^2(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a}) ) x^{\langle t \rangle T}\tag{1}$$\displaystyle dW_{aa} = da_{next} * (( 1-\tanh^2(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a}) ) a^{\langle t-1 \rangle T}\tag{2}$$\displaystyle db_a = da_{next} * \sum_{batch}( 1-\tanh^2(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a}) )\tag{3}$$\displaystyle dx^{\langle t \rangle} = da_{next} * { W_{ax}}^T ( 1-\tanh^2(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a}) )\tag{4}$$\displaystyle da_{prev} = da_{next} * { W_{aa}}^T ( 1-\tanh^2(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a}) ) \tag{5}$Implementing rnn_cell_backwardThe results can be computed directly by implementing the equations above. However, the above can optionally be simplified by computing ‘dz’ and utlilizing the chain rule.This can be further simplified by noting that $\tanh(W_{ax}x^{\langle t \rangle}+W_{aa} a^{\langle t-1 \rangle} + b_{a})$ was computed and saved in the forward pass.To calculate dba, the ‘batch’ above is a sum across the horizontal (axis= 1) axis. Note that you should use the keepdims = True option.It may be worthwhile to review Course 1 Derivatives with a computational graph through Backpropagation Intuition, which decompose the calculation into steps using the chain rule.Matrix vector derivatives are described here, though the equations above incorporate the required transformations.Note rnn_cell_backward does not include the calculation of loss from $y \langle t \rangle$, this is incorporated into the incoming da_next. This is a slight mismatch with rnn_cell_forward which includes a dense layer and softmax.Note: in the code:$\displaystyle dx^{\langle t \rangle}$ is represented by dxt,$\displaystyle d W_{ax}$ is represented by dWax,$\displaystyle da_{prev}$ is represented by da_prev,$\displaystyle dW_{aa}$ is represented by dWaa,$\displaystyle db_{a}$ is represented by dba,dz is not derived above but can optionally be derived by students to simplify the repeated calculations.123456789101112131415161718192021222324np.random.seed(1)xt_tmp = np.random.randn(3,10)a_prev_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wax'] = np.random.randn(5,3)parameters_tmp['Waa'] = np.random.randn(5,5)parameters_tmp['Wya'] = np.random.randn(2,5)parameters_tmp['ba'] = np.random.randn(5,1)parameters_tmp['by'] = np.random.randn(2,1)a_next_tmp, yt_tmp, cache_tmp = rnn_cell_forward(xt_tmp, a_prev_tmp, parameters_tmp)da_next_tmp = np.random.randn(5,10)gradients_tmp = rnn_cell_backward(da_next_tmp, cache_tmp)print("gradients[\"dxt\"][1][2] =", gradients_tmp["dxt"][1][2])print("gradients[\"dxt\"].shape =", gradients_tmp["dxt"].shape)print("gradients[\"da_prev\"][2][3] =", gradients_tmp["da_prev"][2][3])print("gradients[\"da_prev\"].shape =", gradients_tmp["da_prev"].shape)print("gradients[\"dWax\"][3][1] =", gradients_tmp["dWax"][3][1])print("gradients[\"dWax\"].shape =", gradients_tmp["dWax"].shape)print("gradients[\"dWaa\"][1][2] =", gradients_tmp["dWaa"][1][2])print("gradients[\"dWaa\"].shape =", gradients_tmp["dWaa"].shape)print("gradients[\"dba\"][4] =", gradients_tmp["dba"][4])print("gradients[\"dba\"].shape =", gradients_tmp["dba"].shape)123456789101112131415161718192021222324np.random.seed(1)xt_tmp = np.random.randn(3,10)a_prev_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wax'] = np.random.randn(5,3)parameters_tmp['Waa'] = np.random.randn(5,5)parameters_tmp['Wya'] = np.random.randn(2,5)parameters_tmp['ba'] = np.random.randn(5,1)parameters_tmp['by'] = np.random.randn(2,1)a_next_tmp, yt_tmp, cache_tmp = rnn_cell_forward(xt_tmp, a_prev_tmp, parameters_tmp)da_next_tmp = np.random.randn(5,10)gradients_tmp = rnn_cell_backward(da_next_tmp, cache_tmp)print("gradients[\"dxt\"][1][2] =", gradients_tmp["dxt"][1][2])print("gradients[\"dxt\"].shape =", gradients_tmp["dxt"].shape)print("gradients[\"da_prev\"][2][3] =", gradients_tmp["da_prev"][2][3])print("gradients[\"da_prev\"].shape =", gradients_tmp["da_prev"].shape)print("gradients[\"dWax\"][3][1] =", gradients_tmp["dWax"][3][1])print("gradients[\"dWax\"].shape =", gradients_tmp["dWax"].shape)print("gradients[\"dWaa\"][1][2] =", gradients_tmp["dWaa"][1][2])print("gradients[\"dWaa\"].shape =", gradients_tmp["dWaa"].shape)print("gradients[\"dba\"][4] =", gradients_tmp["dba"][4])print("gradients[\"dba\"].shape =", gradients_tmp["dba"].shape)Backward pass through the RNNComputing the gradients of the cost with respect to $a^{\langle t \rangle}$ at every time-step $t$ is useful because it is what helps the gradient backpropagate to the previous RNN-cell. To do so, you need to iterate through all the time steps starting at the end, and at each step, you increment the overall $db_a$, $dW_{aa}$, $dW_{ax}$ and you store $dx$.Instructions:Implement the rnn_backward function. Initialize the return variables with zeros first and then loop through all the time steps while calling the rnn_cell_backward at each time timestep, update the other variables accordingly.Note that this notebook does not implement the backward path from the Loss ‘J’ backwards to ‘a’.This would have included the dense layer and softmax which are a part of the forward path.This is assumed to be calculated elsewhere and the result passed to rnn_backward in ‘da’.You must combine this with the loss from the previous stages when calling rnn_cell_backward (see figure 7 above).It is further assumed that loss has been adjusted for batch size (m).Therefore, division by the number of examples is not required here.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def rnn_backward(da, caches): """ Implement the backward pass for a RNN over an entire sequence of input data. Arguments: da -- Upstream gradients of all hidden states, of shape (n_a, m, T_x) caches -- tuple containing information from the forward pass (rnn_forward) Returns: gradients -- python dictionary containing: dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x) da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m) dWax -- Gradient w.r.t the input's weight matrix, numpy-array of shape (n_a, n_x) dWaa -- Gradient w.r.t the hidden state's weight matrix, numpy-arrayof shape (n_a, n_a) dba -- Gradient w.r.t the bias, of shape (n_a, 1) """ ### START CODE HERE ### # Retrieve values from the first cache (t=1) of caches (≈2 lines) (caches, x) = caches (a1, a0, x1, parameters) = caches[0] # Retrieve dimensions from da's and x1's shapes (≈2 lines) n_a, m, T_x = da.shape n_x, m = x1.shape # initialize the gradients with the right sizes (≈6 lines) dx = np.zeros((n_x, m, T_x)) dWax = np.zeros((n_a, n_x)) dWaa = np.zeros((n_a, n_a)) dba = np.zeros((n_a, 1)) da0 = np.zeros((n_a, m)) da_prevt = np.zeros((n_a, m)) # Loop through all the time steps for t in reversed(range(T_x)): # Compute gradients at time step t. Choose wisely the "da_next" and the "cache" to use in the backward propagation step. (≈1 line) gradients = rnn_cell_backward(da[:,:,t]+da_prevt, caches[t]) # !!!! # Retrieve derivatives from gradients (≈ 1 line) dxt, da_prevt, dWaxt, dWaat, dbat = gradients["dxt"], gradients["da_prev"], gradients["dWax"], gradients["dWaa"], gradients["dba"] # Increment global derivatives w.r.t parameters by adding their derivative at time-step t (≈4 lines) dx[:, :, t] = dxt dWax += dWaxt dWaa += dWaat dba += dbat # Set da0 to the gradient of a which has been backpropagated through all time-steps (≈1 line) da0 = da_prevt ### END CODE HERE ### # Store the gradients in a python dictionary gradients = &#123;"dx": dx, "da0": da0, "dWax": dWax, "dWaa": dWaa,"dba": dba&#125; return gradients123456789101112131415161718192021222324np.random.seed(1)x_tmp = np.random.randn(3,10,4)a0_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wax'] = np.random.randn(5,3)parameters_tmp['Waa'] = np.random.randn(5,5)parameters_tmp['Wya'] = np.random.randn(2,5)parameters_tmp['ba'] = np.random.randn(5,1)parameters_tmp['by'] = np.random.randn(2,1)a_tmp, y_tmp, caches_tmp = rnn_forward(x_tmp, a0_tmp, parameters_tmp)da_tmp = np.random.randn(5, 10, 4)gradients_tmp = rnn_backward(da_tmp, caches_tmp)print("gradients[\"dx\"][1][2] =", gradients_tmp["dx"][1][2])print("gradients[\"dx\"].shape =", gradients_tmp["dx"].shape)print("gradients[\"da0\"][2][3] =", gradients_tmp["da0"][2][3])print("gradients[\"da0\"].shape =", gradients_tmp["da0"].shape)print("gradients[\"dWax\"][3][1] =", gradients_tmp["dWax"][3][1])print("gradients[\"dWax\"].shape =", gradients_tmp["dWax"].shape)print("gradients[\"dWaa\"][1][2] =", gradients_tmp["dWaa"][1][2])print("gradients[\"dWaa\"].shape =", gradients_tmp["dWaa"].shape)print("gradients[\"dba\"][4] =", gradients_tmp["dba"][4])print("gradients[\"dba\"].shape =", gradients_tmp["dba"].shape)3.2 - LSTM backward pass3.2.1 One Step backwardThe LSTM backward pass is slighltly more complicated than the forward one.3.2.2 gate derivativesNote the location of the gate derivatives ($\gamma$..) between the dense layer and the activation function (see graphic above). This is convenient for computing parameter derivatives in the next step.$d\gamma_o^{\langle t \rangle} = da_{next}\tanh(c_{next}) \Gamma_o^{\langle t \rangle}*\left(1-\Gamma_o^{\langle t \rangle}\right)\tag{7}$$dp\widetilde{c}^{\langle t \rangle} = \left(dc_{next}\Gamma_u^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh^2(c_{next})) \Gamma_u^{\langle t \rangle} da_{next} \right) * \left(1-\left(\widetilde c^{\langle t \rangle}\right)^2\right) \tag{8}$$d\gamma_u^{\langle t \rangle} = \left(dc_{next}\widetilde{c}^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1-\tanh^2(c_{next})) \widetilde{c}^{\langle t \rangle} da_{next}\right)\Gamma_u^{\langle t \rangle}\left(1-\Gamma_u^{\langle t \rangle}\right)\tag{9}$$d\gamma_f^{\langle t \rangle} = \left(dc_{next} c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh^2(c_{next})) c_{prev} da_{next}\right)\Gamma_f^{\langle t \rangle}\left(1-\Gamma_f^{\langle t \rangle}\right)\tag{10}$3.2.3 parameter derivatives$ dW_f = d\gamma_f^{\langle t \rangle} \begin{bmatrix} a_{prev} \\ x_t\end{bmatrix}^T \tag{11} $$ dW_u = d\gamma_u^{\langle t \rangle} \begin{bmatrix} a_{prev} \\ x_t\end{bmatrix}^T \tag{12} $$ dW_c = dp\widetilde c^{\langle t \rangle} \begin{bmatrix} a_{prev} \\ x_t\end{bmatrix}^T \tag{13} $$ dW_o = d\gamma_o^{\langle t \rangle} \begin{bmatrix} a_{prev} \\ x_t\end{bmatrix}^T \tag{14}$To calculate $db_f, db_u, db_c, db_o$ you just need to sum across the horizontal (axis= 1) axis on $d\gamma_f^{\langle t \rangle}, d\gamma_u^{\langle t \rangle}, dp\widetilde c^{\langle t \rangle}, d\gamma_o^{\langle t \rangle}$ respectively. Note that you should have the keepdims = True option.$\displaystyle db_f = \sum_{batch}d\gamma_f^{\langle t \rangle}\tag{15}$$\displaystyle db_u = \sum_{batch}d\gamma_u^{\langle t \rangle}\tag{16}$$\displaystyle db_c = \sum_{batch}d\gamma_c^{\langle t \rangle}\tag{17}$$\displaystyle db_o = \sum_{batch}d\gamma_o^{\langle t \rangle}\tag{18}$Finally, you will compute the derivative with respect to the previous hidden state, previous memory state, and input.$ da_{prev} = W_f^T d\gamma_f^{\langle t \rangle} + W_u^T d\gamma_u^{\langle t \rangle}+ W_c^T dp\widetilde c^{\langle t \rangle} + W_o^T d\gamma_o^{\langle t \rangle} \tag{19}$Here, to account for concatenation, the weights for equations 19 are the first n_a, (i.e. $W_f = W_f[:,:n_a]$ etc…)$ dc_{prev} = dc_{next}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1- \tanh^2(c_{next}))\Gamma_f^{\langle t \rangle}da_{next} \tag{20}$$ dx^{\langle t \rangle} = W_f^T d\gamma_f^{\langle t \rangle} + W_u^T d\gamma_u^{\langle t \rangle}+ W_c^T dp\widetilde c^{\langle t \rangle} + W_o^T d\gamma_o^{\langle t \rangle}\tag{21} $where the weights for equation 21 are from n_a to the end, (i.e. $W_f = W_f[:,n_a:]$ etc…)Exercise: Implement lstm_cell_backward by implementing equations $7-21$ below.Note: In the code:$d\gamma_o^{\langle t \rangle}$ is represented by dot,$dp\widetilde{c}^{\langle t \rangle}$ is represented by dcct,$d\gamma_u^{\langle t \rangle}$ is represented by dit,$d\gamma_f^{\langle t \rangle}$ is represented by dft123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263def lstm_cell_backward(da_next, dc_next, cache): """ Implement the backward pass for the LSTM-cell (single time-step). Arguments: da_next -- Gradients of next hidden state, of shape (n_a, m) dc_next -- Gradients of next cell state, of shape (n_a, m) cache -- cache storing information from the forward pass Returns: gradients -- python dictionary containing: dxt -- Gradient of input data at time-step t, of shape (n_x, m) da_prev -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m) dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x) dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x) dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x) dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x) dWo -- Gradient w.r.t. the weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x) dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1) dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1) dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1) dbo -- Gradient w.r.t. biases of the output gate, of shape (n_a, 1) """ # Retrieve information from "cache" (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache ### START CODE HERE ### # Retrieve dimensions from xt's and a_next's shape (≈2 lines) n_x, m = xt.shape n_a, m = a_next.shape # Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10) (≈4 lines) dot = da_next*np.tanh(c_next)*ot*(1 - ot) dcct = (dc_next+da_next*ot*( 1- np.square(np.tanh(c_next))))*it*( 1-np.square(cct)) dit = (dc_next+da_next*ot*( 1- np.square(np.tanh(c_next))))*cct*it*(1-it) dft = (dc_next+da_next*ot*( 1- np.square(np.tanh(c_next))))*c_prev*ft*(1-ft) # Compute parameters related derivatives. Use equations (11)-(18) (≈8 lines) concat = np.concatenate((a_prev, xt), axis=0) dWf = np.dot( dft, concat.T) dWi = np.dot( dit, concat.T) dWc = np.dot( dcct, concat.T) dWo = np.dot( dot, concat.T) dbf = np.sum( dft, axis=1, keepdims=True) dbi = np.sum( dit, axis=1, keepdims=True) dbc = np.sum( dcct, axis=1, keepdims=True) dbo = np.sum( dot, axis=1, keepdims=True) # Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (19)-(21). (≈3 lines) da_prev = np.dot(parameters['Wf'][:,:n_a].T, dft) + np.dot(parameters['Wi'][:,:n_a].T, dit) + \ np.dot(parameters['Wc'][:,:n_a].T, dcct) + np.dot(parameters['Wo'][:,:n_a].T, dot) dc_prev = dc_next*ft + ot*(1-np.square(np.tanh(c_next)))*ft*da_next dxt = np.dot(parameters['Wf'][:,n_a:].T,dft)+np.dot(parameters['Wi'][:,n_a:].T,dit) + \ np.dot(parameters['Wc'][:,n_a:].T,dcct)+np.dot(parameters['Wo'][:,n_a:].T,dot) ### END CODE HERE ### # Save gradients in dictionary gradients = &#123;"dxt": dxt, "da_prev": da_prev, "dc_prev": dc_prev, "dWf": dWf,"dbf": dbf, "dWi": dWi,"dbi": dbi, "dWc": dWc,"dbc": dbc, "dWo": dWo,"dbo": dbo&#125; return gradients12345678910111213141516171819202122232425262728293031323334353637383940414243np.random.seed(1)xt_tmp = np.random.randn(3,10)a_prev_tmp = np.random.randn(5,10)c_prev_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wf'] = np.random.randn(5, 5+3)parameters_tmp['bf'] = np.random.randn(5,1)parameters_tmp['Wi'] = np.random.randn(5, 5+3)parameters_tmp['bi'] = np.random.randn(5,1)parameters_tmp['Wo'] = np.random.randn(5, 5+3)parameters_tmp['bo'] = np.random.randn(5,1)parameters_tmp['Wc'] = np.random.randn(5, 5+3)parameters_tmp['bc'] = np.random.randn(5,1)parameters_tmp['Wy'] = np.random.randn(2,5)parameters_tmp['by'] = np.random.randn(2,1)a_next_tmp, c_next_tmp, yt_tmp, cache_tmp = lstm_cell_forward(xt_tmp, a_prev_tmp, c_prev_tmp, parameters_tmp)da_next_tmp = np.random.randn(5,10)dc_next_tmp = np.random.randn(5,10)gradients_tmp = lstm_cell_backward(da_next_tmp, dc_next_tmp, cache_tmp)print("gradients[\"dxt\"][1][2] =", gradients_tmp["dxt"][1][2])print("gradients[\"dxt\"].shape =", gradients_tmp["dxt"].shape)print("gradients[\"da_prev\"][2][3] =", gradients_tmp["da_prev"][2][3])print("gradients[\"da_prev\"].shape =", gradients_tmp["da_prev"].shape)print("gradients[\"dc_prev\"][2][3] =", gradients_tmp["dc_prev"][2][3])print("gradients[\"dc_prev\"].shape =", gradients_tmp["dc_prev"].shape)print("gradients[\"dWf\"][3][1] =", gradients_tmp["dWf"][3][1])print("gradients[\"dWf\"].shape =", gradients_tmp["dWf"].shape)print("gradients[\"dWi\"][1][2] =", gradients_tmp["dWi"][1][2])print("gradients[\"dWi\"].shape =", gradients_tmp["dWi"].shape)print("gradients[\"dWc\"][3][1] =", gradients_tmp["dWc"][3][1])print("gradients[\"dWc\"].shape =", gradients_tmp["dWc"].shape)print("gradients[\"dWo\"][1][2] =", gradients_tmp["dWo"][1][2])print("gradients[\"dWo\"].shape =", gradients_tmp["dWo"].shape)print("gradients[\"dbf\"][4] =", gradients_tmp["dbf"][4])print("gradients[\"dbf\"].shape =", gradients_tmp["dbf"].shape)print("gradients[\"dbi\"][4] =", gradients_tmp["dbi"][4])print("gradients[\"dbi\"].shape =", gradients_tmp["dbi"].shape)print("gradients[\"dbc\"][4] =", gradients_tmp["dbc"][4])print("gradients[\"dbc\"].shape =", gradients_tmp["dbc"].shape)print("gradients[\"dbo\"][4] =", gradients_tmp["dbo"][4])print("gradients[\"dbo\"].shape =", gradients_tmp["dbo"].shape)3.3 Backward pass through the LSTM RNNThis part is very similar to the rnn_backward function you implemented above. You will first create variables of the same dimension as your return variables. You will then iterate over all the time steps starting from the end and call the one step function you implemented for LSTM at each iteration. You will then update the parameters by summing them individually. Finally return a dictionary with the new gradients.Instructions: Implement the lstm_backward function. Create a for loop starting from $T_x$ and going backward. For each step call lstm_cell_backward and update the your old gradients by adding the new gradients to them. Note that dxt is not updated but is stored.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970def lstm_backward(da, caches): """ Implement the backward pass for the RNN with LSTM-cell (over a whole sequence). Arguments: da -- Gradients w.r.t the hidden states, numpy-array of shape (n_a, m, T_x) dc -- Gradients w.r.t the memory states, numpy-array of shape (n_a, m, T_x) caches -- cache storing information from the forward pass (lstm_forward) Returns: gradients -- python dictionary containing: dx -- Gradient of inputs, of shape (n_x, m, T_x) da0 -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m) dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x) dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x) dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x) dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x) dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1) dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1) dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1) dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1) """ # Retrieve values from the first cache (t=1) of caches. (caches, x) = caches (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0] ### START CODE HERE ### # Retrieve dimensions from da's and x1's shapes (≈2 lines) n_a, m, T_x = da.shape n_x, m = x1.shape # initialize the gradients with the right sizes (≈12 lines) dx = np.zeros(( n_x, m, T_x)) da0 = np.zeros(( n_a, m)) da_prevt = np.zeros(( n_a, m)) dc_prevt = np.zeros(( n_a, m)) dWf = np.zeros(( n_a, n_a+n_x)) dWi = np.zeros(( n_a, n_a+n_x)) dWc = np.zeros(( n_a, n_a+n_x)) dWo = np.zeros(( n_a, n_a+n_x)) dbf = np.zeros(( n_a, 1)) dbi = np.zeros(( n_a, 1)) dbc = np.zeros(( n_a, 1)) dbo = np.zeros(( n_a, 1)) # loop back over the whole sequence for t in reversed(range(T_x)): # Compute all gradients using lstm_cell_backward gradients = lstm_cell_backward(da[:,:,t]+da_prevt, dc_prevt, caches[t]) # Store or add the gradient to the parameters' previous step's gradient dxt, da_prevt, dc_prevt = gradients['dxt'], gradients['da_prev'], gradients['dc_prev'] dx[:,:,t] = gradients['dxt'] dWf += gradients['dWf'] dWi += gradients['dWi'] dWc += gradients['dWc'] dWo += gradients['dWo'] dbf += gradients['dbf'] dbi += gradients['dbi'] dbc += gradients['dbc'] dbo += gradients['dbo'] # Set the first activation's gradient to the backpropagated gradient da_prev. da0 = da_prevt ### END CODE HERE ### # Store the gradients in a python dictionary gradients = &#123;"dx": dx, "da0": da0, "dWf": dWf,"dbf": dbf, "dWi": dWi,"dbi": dbi, "dWc": dWc,"dbc": dbc, "dWo": dWo,"dbo": dbo&#125; return gradients1234567891011121314151617181920212223242526272829303132333435363738394041np.random.seed(1)x_tmp = np.random.randn(3,10,7)a0_tmp = np.random.randn(5,10)parameters_tmp = &#123;&#125;parameters_tmp['Wf'] = np.random.randn(5, 5+3)parameters_tmp['bf'] = np.random.randn(5,1)parameters_tmp['Wi'] = np.random.randn(5, 5+3)parameters_tmp['bi'] = np.random.randn(5,1)parameters_tmp['Wo'] = np.random.randn(5, 5+3)parameters_tmp['bo'] = np.random.randn(5,1)parameters_tmp['Wc'] = np.random.randn(5, 5+3)parameters_tmp['bc'] = np.random.randn(5,1)parameters_tmp['Wy'] = np.zeros((2,5)) # unused, but needed for lstm_forwardparameters_tmp['by'] = np.zeros((2,1)) # unused, but needed for lstm_forwarda_tmp, y_tmp, c_tmp, caches_tmp = lstm_forward(x_tmp, a0_tmp, parameters_tmp)da_tmp = np.random.randn(5, 10, 4)gradients_tmp = lstm_backward(da_tmp, caches_tmp)print("gradients[\"dx\"][1][2] =", gradients_tmp["dx"][1][2])print("gradients[\"dx\"].shape =", gradients_tmp["dx"].shape)print("gradients[\"da0\"][2][3] =", gradients_tmp["da0"][2][3])print("gradients[\"da0\"].shape =", gradients_tmp["da0"].shape)print("gradients[\"dWf\"][3][1] =", gradients_tmp["dWf"][3][1])print("gradients[\"dWf\"].shape =", gradients_tmp["dWf"].shape)print("gradients[\"dWi\"][1][2] =", gradients_tmp["dWi"][1][2])print("gradients[\"dWi\"].shape =", gradients_tmp["dWi"].shape)print("gradients[\"dWc\"][3][1] =", gradients_tmp["dWc"][3][1])print("gradients[\"dWc\"].shape =", gradients_tmp["dWc"].shape)print("gradients[\"dWo\"][1][2] =", gradients_tmp["dWo"][1][2])print("gradients[\"dWo\"].shape =", gradients_tmp["dWo"].shape)print("gradients[\"dbf\"][4] =", gradients_tmp["dbf"][4])print("gradients[\"dbf\"].shape =", gradients_tmp["dbf"].shape)print("gradients[\"dbi\"][4] =", gradients_tmp["dbi"][4])print("gradients[\"dbi\"].shape =", gradients_tmp["dbi"].shape)print("gradients[\"dbc\"][4] =", gradients_tmp["dbc"][4])print("gradients[\"dbc\"].shape =", gradients_tmp["dbc"].shape)print("gradients[\"dbo\"][4] =", gradients_tmp["dbo"][4])print("gradients[\"dbo\"].shape =", gradients_tmp["dbo"].shape)Congratulations !Congratulations on completing this assignment. You now understand how recurrent neural networks work!Let’s go on to the next exercise, where you’ll use an RNN to build a character-level language model.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/specializations/deep-learninghttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（4-4）]]></title>
    <url>%2F2020%2F03%2F10%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%884-4%EF%BC%89%2F</url>
    <content type="text"><![CDATA[特殊应用：人脸识别和神经风格转换（Special applications: Face recognition &amp;Neural style transfer）4.1 什么是人脸识别？（What is face recognition?）人脸验证（face verification）和人脸识别（face recognition）4.2 One-Shot学习（One-shot learning）对于一个人脸识别系统，我们需要仅仅通过先前的一张人脸的图片或者说一个人脸的样例，就能够实现该人的识别，那么这样的问题就是one shot 问题。Similarity函数4.3 Siamese 网络（Siamese network）对于一个卷积神经网络结构，去掉最后的softmax层，将图片样本1输入网络，最后由网络输出一个N维的向量，这N维向量则代表输入图片样本1的编码。将不同人的图片样本输入相同参数的网络结构，得到各自相应的图片编码。将$x^{(1)}$和$x^{(2)}$的距离定义为这两幅图片的编码之差的范数，$d( x^{( 1)},x^{( 2)}) =|| f( x^{( 1)}) - f( x^{( 2)})||_{2}^{2}$。4.4 Triplet 损失（Triplet 损失）通常是让Anchor图片和Positive图片（Positive意味着是同一个人）的距离很接近。与Negative图片（Negative意味着是非同一个人）对比时，你让他们的距离离得更远一点。即：$|| f(A) - f(P)||^{2} \leq ||f(A) - f(N)||^{2}$）（$|| f(A) - f(P) ||^{2}$）就是$d(A,P)$，（$|| f(A) - f(N) ||^{2}$）是$d(A,N)$。为了避免所有图像的$f$都是一个零向量，总能满足这个方程。通常使用一个超参数$\alpha$使$|| f(A) - f(P)||^{2} -||f(A) - f(N)||^{2} +a\leq0$损失函数为：$L(A,P,N) = \max (||f(A) - f(P)||^{2} - ||f(A) - f(N)||^{2} + \alpha, \ 0)$4.5 人脸验证与二分类（Face verification and binary classification）Triplet loss是一个学习人脸识别卷积网络参数的好方法，还有其他学习参数的方法，让我们看看如何将人脸识别当成一个二分类问题。sigmoid函数应用到某些特征上$\hat y = \sigma(\sum_{k = 1}^{128}{w_{i}| f( x^{( i)})_{k} - f( x^{( j)})_{k}| + b})$还有其他不同的形式来计算绿色标记的这部分公式（$| f( x^{( i)})_{k} - f( x^{( j)})_{k}|$），比如说，公式可以是$\frac{(f( x^{( i)})_{k} - f(x^{( j)})_{k})^{2}}{f(x^{( i)})_{k} + f( x^{( j)})_{k}}$，这个公式也被叫做$\chi^{2}$公式，是一个希腊字母$\chi$，也被称为$\chi$平方相似度。4.6 什么是神经风格迁移？（What is neural style transfer?）4.7 CNN特征可视化（What are deep ConvNets learning?）我们希望看到不同层的隐藏单元的计算结果。依次对各个层进行如下操作：在当前层挑选一个隐藏单元；遍历训练集，找到最大化地激活了该运算单元的图片或者图片块；对该层的其他运算单元执行操作。4.8 代价函数（Cost function）怎么判断生成图像的好坏呢？我们把这个代价函数定义为两个部分。$J_{\text{content}}(C,G)$第一部分被称作内容代价，这是一个关于内容图片和生成图片的函数，它是用来度量生成图片$G$的内容与内容图片$C$的内容有多相似。$J_{\text{style}}(S,G)$然后我们会把结果加上一个风格代价函数，也就是关于$S$和$G$的函数，用来度量图片$G$的风格和图片$S$的风格的相似度。$J( G) = a J_{\text{content}}( C,G) + \beta J_{\text{style}}(S,G)$最后我们用两个超参数$a$和$\beta$来来确定内容代价和风格代价，两者之间的权重用两个超参数来确定。4.9 内容代价函数（Content cost function）风格迁移网络的代价函数有一个内容代价部分，还有一个风格代价部分。$J( G) = \alpha J_{\text{content}}( C,G) + \beta J_{\text{style}}(S,G)$定义内容代价函数如下：$J_{\text{content}}( C,G) = \frac{1}{2}|| a^{[l][C]} - a^{[l][G]}||^{2}$4.10 风格代价函数（Style cost function）$G$是一个矩阵，这个矩阵的高度和宽度都是$l$层的通道数。在这个矩阵中$k$和$k’$元素被用来描述$k$通道和$k’$通道之间的相关系数。具体地：$G_{kk^{‘}}^{l} = \sum_{i = 1}^{n_{H}^{[l]}}{\sum_{j = 1}^{n_{W}^{[l]}}{a_{i,\ j,\ k}^{l}a_{i,\ j,\ k^{‘}}^{l}}}$$G_{kk^{‘}}^{l} = \sum_{i = 1}^{n_{H}^{[l]}}{\sum_{j = 1}^{n_{W}^{[l]}}{a_{i,\ j,\ k}^{l}a_{i,\ j,\ k^{‘}}^{l}}}$4.11 一维到三维推广（1D and 3D generalizations of models）Face RecognitionIn this assignment, you will build a face recognition system. Many of the ideas presented here are from FaceNet. In lecture, we also talked about DeepFace.Face recognition problems commonly fall into two categories:Face Verification - “is this the claimed person?”. For example, at some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person. A mobile phone that unlocks using your face is also using face verification. This is a 1:1 matching problem.Face Recognition - “who is this person?”. For example, the video lecture showed a face recognition video of Baidu employees entering the office without needing to otherwise identify themselves. This is a 1:K matching problem.FaceNet learns a neural network that encodes a face image into a vector of 128 numbers. By comparing two such vectors, you can then determine if two pictures are of the same person.In this assignment, you will:Implement the triplet loss functionUse a pretrained model to map face images into 128-dimensional encodingsUse these encodings to perform face verification and face recognitionChannels-first notationIn this exercise, we will be using a pre-trained model which represents ConvNet activations using a “channels first” convention, as opposed to the “channels last” convention used in lecture and previous programming assignments.In other words, a batch of images will be of shape $(m, n_C, n_H, n_W)$ instead of $(m, n_H, n_W, n_C)$.Both of these conventions have a reasonable amount of traction among open-source implementations; there isn’t a uniform standard yet within the deep learning community.UpdatesIf you were working on the notebook before this update…The current notebook is version “3a”.You can find your original work saved in the notebook with the previous version name (“v3”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatestriplet_loss: Additional Hints added.verify: Hints added.who_is_it: corrected hints given in the comments.Spelling and formatting updates for easier reading.Load packagesLet’s load the required packages.12345678910111213141516171819202122232425from keras.models import Sequentialfrom keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenatefrom keras.models import Modelfrom keras.layers.normalization import BatchNormalizationfrom keras.layers.pooling import MaxPooling2D, AveragePooling2Dfrom keras.layers.merge import Concatenatefrom keras.layers.core import Lambda, Flatten, Densefrom keras.initializers import glorot_uniformfrom keras.engine.topology import Layerfrom keras import backend as KK.set_image_data_format('channels_first')import cv2import osimport numpy as npfrom numpy import genfromtxtimport pandas as pdimport tensorflow as tffrom fr_utils import *from inception_blocks_v2 import *%matplotlib inline%load_ext autoreload%autoreload 2np.set_printoptions(threshold=np.nan)0 - Naive Face VerificationIn Face Verification, you’re given two images and you have to determine if they are of the same person. The simplest way to do this is to compare the two images pixel-by-pixel. If the distance between the raw images are less than a chosen threshold, it may be the same person!Of course, this algorithm performs really poorly, since the pixel values change dramatically due to variations in lighting, orientation of the person’s face, even minor changes in head position, and so on.You’ll see that rather than using the raw image, you can learn an encoding, $f(img)$.By using an encoding for each image, an element-wise comparison produces a more accurate judgement as to whether two pictures are of the same person.1 - Encoding face images into a 128-dimensional vector1.1 - Using a ConvNet to compute encodingsThe FaceNet model takes a lot of data and a long time to train. So following common practice in applied deep learning, let’s load weights that someone else has already trained. The network architecture follows the Inception model from Szegedy et al.. We have provided an inception network implementation. You can look in the file inception_blocks_v2.py to see how it is implemented (do so by going to “File-&gt;Open…” at the top of the Jupyter notebook. This opens the file directory that contains the ‘.py’ file).The key things you need to know are:This network uses 96x96 dimensional RGB images as its input. Specifically, inputs a face image (or batch of $m$ face images) as a tensor of shape $(m, n_C, n_H, n_W) = (m, 3, 96, 96)$It outputs a matrix of shape $(m, 128)$ that encodes each input face image into a 128-dimensional vectorRun the cell below to create the model for face images.1FRmodel = faceRecoModel(input_shape=(3, 96, 96))12print("Total Params:", FRmodel.count_params())# Total Params: 3743280By using a 128-neuron fully connected layer as its last layer, the model ensures that the output is an encoding vector of size 128. You then use the encodings to compare two face images as follows:So, an encoding is a good one if:The encodings of two images of the same person are quite similar to each other.The encodings of two images of different persons are very different.The triplet loss function formalizes this, and tries to “push” the encodings of two images of the same person (Anchor and Positive) closer together, while “pulling” the encodings of two images of different persons (Anchor, Negative) further apart.1.2 - The Triplet LossFor an image $x$, we denote its encoding $f(x)$, where $f$ is the function computed by the neural network.Training will use triplets of images $(A, P, N)$:A is an “Anchor” image—a picture of a person.P is a “Positive” image—a picture of the same person as the Anchor image.N is a “Negative” image—a picture of a different person than the Anchor image.These triplets are picked from our training dataset. We will write $(A^{(i)}, P^{(i)}, N^{(i)})$ to denote the $i$-th training example.You’d like to make sure that an image $A^{(i)}$ of an individual is closer to the Positive $P^{(i)}$ than to the Negative image $N^{(i)}$) by at least a margin $\alpha$:\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 + \alpha < \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2You would thus like to minimize the following “triplet cost”:\mathcal{J} = \sum^{m}_{i=1} \large[ \small \underbrace{\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2}_\text{(1)} - \underbrace{\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2}_\text{(2)} + \alpha \large ] \small_+ \tag{3}Here, we are using the notation “$[z]_+$” to denote $max(z,0)$.Notes:The term (1) is the squared distance between the anchor “A” and the positive “P” for a given triplet; you want this to be small.The term (2) is the squared distance between the anchor “A” and the negative “N” for a given triplet, you want this to be relatively large. It has a minus sign preceding it because minimizing the negative of the term is the same as maximizing that term.$\alpha$ is called the margin. It is a hyperparameter that you pick manually. We will use $\alpha = 0.2$.Most implementations also rescale the encoding vectors to haven L2 norm equal to one (i.e., $\mid \mid f(img)\mid \mid_2$=1); you won’t have to worry about that in this assignment.Exercise: Implement the triplet loss as defined by formula (3). Here are the 4 steps:Compute the distance between the encodings of “anchor” and “positive”: $\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2$Compute the distance between the encodings of “anchor” and “negative”: $\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2$Compute the formula per training example: $ \mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2 + \alpha$Compute the full formula by taking the max with zero and summing over the training examples:\mathcal{J} = \sum^{m}_{i=1} \large[ \small \mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2+ \alpha \large ] \small_+ \tag{3}HintsUseful functions: tf.reduce_sum(), tf.square(), tf.subtract(), tf.add(), tf.maximum().For steps 1 and 2, you will sum over the entries of $\mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2$ and $\mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2$.For step 4 you will sum over the training examples.Additional HintsRecall that the square of the L2 norm is the sum of the squared differences: $||x - y||_{2}^{2} = \sum_{i=1}^{N}(x_{i} - y_{i})^{2}$Note that the anchor, positive and negative encodings are of shape (m,128), where m is the number of training examples and 128 is the number of elements used to encode a single example.For steps 1 and 2, you will maintain the number of m training examples and sum along the 128 values of each encoding.tf.reduce_sum has an axis parameter. This chooses along which axis the sums are applied.Note that one way to choose the last axis in a tensor is to use negative indexing (axis=-1).In step 4, when summing over training examples, the result will be a single scalar value.For tf.reduce_sum to sum across all axes, keep the default value axis=None.12345678910111213141516171819202122232425262728293031# GRADED FUNCTION: triplet_lossdef triplet_loss(y_true, y_pred, alpha = 0.2): """ Implementation of the triplet loss as defined by formula (3) Arguments: y_true -- true labels, required when you define a loss in Keras, you don't need it in this function. y_pred -- python list containing three objects: anchor -- the encodings for the anchor images, of shape (None, 128) positive -- the encodings for the positive images, of shape (None, 128) negative -- the encodings for the negative images, of shape (None, 128) Returns: loss -- real number, value of the loss """ anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2] ### START CODE HERE ### (≈ 4 lines) # Step 1: Compute the (encoding) distance between the anchor and the positive pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1) # Step 2: Compute the (encoding) distance between the anchor and the negative neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1) # Step 3: subtract the two previous distances and add alpha. basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha) # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples. loss = tf.reduce_sum(tf.maximum(basic_loss, 0.)) ### END CODE HERE ### return loss12345678910with tf.Session() as test: tf.set_random_seed(1) y_true = (None, None, None) y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1), tf.random_normal([3, 128], mean=1, stddev=1, seed = 1), tf.random_normal([3, 128], mean=3, stddev=4, seed = 1)) loss = triplet_loss(y_true, y_pred) print("loss = " + str(loss.eval()))# loss = 528.1432 - Loading the pre-trained modelFaceNet is trained by minimizing the triplet loss. But since training requires a lot of data and a lot of computation, we won’t train it from scratch here. Instead, we load a previously trained model. Load a model using the following cell; this might take a couple of minutes to run.12FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])load_weights_from_FaceNet(FRmodel)Here are some examples of distances between the encodings between three individuals:Let’s now use this model to perform face verification and face recognition!3 - Applying the modelYou are building a system for an office building where the building manager would like to offer facial recognition to allow the employees to enter the building.You’d like to build a Face verification system that gives access to the list of people who live or work there. To get admitted, each person has to swipe an ID card (identification card) to identify themselves at the entrance. The face recognition system then checks that they are who they claim to be.3.1 - Face VerificationLet’s build a database containing one encoding vector for each person who is allowed to enter the office. To generate the encoding we use img_to_encoding(image_path, model), which runs the forward propagation of the model on the specified image.Run the following code to build the database (represented as a python dictionary). This database maps each person’s name to a 128-dimensional encoding of their face.12345678910111213database = &#123;&#125;database["danielle"] = img_to_encoding("images/danielle.png", FRmodel)database["younes"] = img_to_encoding("images/younes.jpg", FRmodel)database["tian"] = img_to_encoding("images/tian.jpg", FRmodel)database["andrew"] = img_to_encoding("images/andrew.jpg", FRmodel)database["kian"] = img_to_encoding("images/kian.jpg", FRmodel)database["dan"] = img_to_encoding("images/dan.jpg", FRmodel)database["sebastiano"] = img_to_encoding("images/sebastiano.jpg", FRmodel)database["bertrand"] = img_to_encoding("images/bertrand.jpg", FRmodel)database["kevin"] = img_to_encoding("images/kevin.jpg", FRmodel)database["felix"] = img_to_encoding("images/felix.jpg", FRmodel)database["benoit"] = img_to_encoding("images/benoit.jpg", FRmodel)database["arnaud"] = img_to_encoding("images/arnaud.jpg", FRmodel)Now, when someone shows up at your front door and swipes their ID card (thus giving you their name), you can look up their encoding in the database, and use it to check if the person standing at the front door matches the name on the ID.Exercise: Implement the verify() function which checks if the front-door camera picture (image_path) is actually the person called “identity”. You will have to go through the following steps:Compute the encoding of the image from image_path.Compute the distance between this encoding and the encoding of the identity image stored in the database.Open the door if the distance is less than 0.7, else do not open it.As presented above, you should use the L2 distance np.linalg.norm.(Note: In this implementation, compare the L2 distance, not the square of the L2 distance, to the threshold 0.7.)Hintsidentity is a string that is also a key in the database dictionary.img_to_encoding has two parameters: the image_path and model.123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: verifydef verify(image_path, identity, database, model): """ Function that verifies if the person on the "image_path" image is "identity". Arguments: image_path -- path to an image identity -- string, name of the person you'd like to verify the identity. Has to be an employee who works in the office. database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors). model -- your Inception model instance in Keras Returns: dist -- distance between the image_path and the image of "identity" in the database. door_open -- True, if the door should open. False otherwise. """ ### START CODE HERE ### # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line) encoding = img_to_encoding(image_path, model) # Step 2: Compute distance with identity's image (≈ 1 line) dist = np.linalg.norm(encoding - database[identity]) # Step 3: Open the door if dist &lt; 0.7, else don't open (≈ 3 lines) if dist &lt; 0.7: print("It's " + str(identity) + ", welcome in!") door_open = True else: print("It's not " + str(identity) + ", please go away") door_open = False ### END CODE HERE ### return dist, door_openYounes is trying to enter the office and the camera takes a picture of him (“images/camera_0.jpg”). Let’s run your verification algorithm on this picture:1verify("images/camera_0.jpg", "younes", database, FRmodel)Benoit, who does not work in the office, stole Kian’s ID card and tried to enter the office. The camera took a picture of Benoit (“images/camera_2.jpg). Let’s run the verification algorithm to check if benoit can enter.1verify("images/camera_2.jpg", "kian", database, FRmodel)3.2 - Face RecognitionYour face verification system is mostly working well. But since Kian got his ID card stolen, when he came back to the office the next day and couldn’t get in!To solve this, you’d like to change your face verification system to a face recognition system. This way, no one has to carry an ID card anymore. An authorized person can just walk up to the building, and the door will unlock for them!You’ll implement a face recognition system that takes as input an image, and figures out if it is one of the authorized persons (and if so, who). Unlike the previous face verification system, we will no longer get a person’s name as one of the inputs.Exercise: Implement who_is_it(). You will have to go through the following steps:Compute the target encoding of the image from image_pathFind the encoding from the database that has smallest distance with the target encoding.Initialize the min_dist variable to a large enough number (100). It will help you keep track of what is the closest encoding to the input’s encoding.Loop over the database dictionary’s names and encodings. To loop use1for (name, db_enc) in database.items()Compute the L2 distance between the target “encoding” and the current “encoding” from the database.If this distance is less than the min_dist, then set min_dist to dist, and identity to name.123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: who_is_itdef who_is_it(image_path, database, model): """ Implements face recognition for the office by finding who is the person on the image_path image. Arguments: image_path -- path to an image database -- database containing image encodings along with the name of the person on the image model -- your Inception model instance in Keras Returns: min_dist -- the minimum distance between image_path encoding and the encodings from the database identity -- string, the name prediction for the person on image_path """ ### START CODE HERE ### ## Step 1: Compute the target "encoding" for the image. Use img_to_encoding() see example above. ## (≈ 1 line) encoding = img_to_encoding(image_path, model) ## Step 2: Find the closest encoding ## # Initialize "min_dist" to a large value, say 100 (≈1 line) min_dist = 100 # Loop over the database dictionary's names and encodings. for (name, db_enc) in database.items(): # Compute L2 distance between the target "encoding" and the current db_enc from the database. (≈ 1 line) dist = np.linalg.norm(encoding - db_enc) # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines) if dist &lt; min_dist: min_dist = dist identity = name ### END CODE HERE ### if min_dist &gt; 0.7: print("Not in the database.") else: print ("it's " + str(identity) + ", the distance is " + str(min_dist)) return min_dist, identityYounes is at the front-door and the camera takes a picture of him (“images/camera_0.jpg”). Let’s see if your who_it_is() algorithm identifies Younes.1who_is_it("images/camera_0.jpg", database, FRmodel)You can change “camera_0.jpg“ (picture of younes) to “camera_1.jpg“ (picture of bertrand) and see the result.Congratulations!Your face recognition system is working well! It only lets in authorized persons, and people don’t need to carry an ID card around anymore!You’ve now seen how a state-of-the-art face recognition system works.Ways to improve your facial recognition modelAlthough we won’t implement it here, here are some ways to further improve the algorithm:Put more images of each person (under different lighting conditions, taken on different days, etc.) into the database. Then given a new image, compare the new face to multiple pictures of the person. This would increase accuracy.Crop the images to just contain the face, and less of the “border” region around the face. This preprocessing removes some of the irrelevant pixels around the face, and also makes the algorithm more robust.Congrats on finishing this assignment!References:Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). FaceNet: A Unified Embedding for Face Recognition and ClusteringYaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, Lior Wolf (2014). DeepFace: Closing the gap to human-level performance in face verificationThe pretrained model we use is inspired by Victor Sy Wang’s implementation and was loaded using his code: https://github.com/iwantooxxoox/Keras-OpenFace.Our implementation also took a lot of inspiration from the official FaceNet github repository: https://github.com/davidsandberg/facenetDeep Learning &amp; Art: Neural Style TransferIn this assignment, you will learn about Neural Style Transfer. This algorithm was created by Gatys et al. (2015).In this assignment, you will:Implement the neural style transfer algorithmGenerate novel artistic images using your algorithmMost of the algorithms you’ve studied optimize a cost function to get a set of parameter values. In Neural Style Transfer, you’ll optimize a cost function to get pixel values!UpdatesIf you were working on the notebook before this update…The current notebook is version “3a”.You can find your original work saved in the notebook with the previous version name (“v2”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatesUse pprint.PrettyPrinter to format printing of the vgg model.computing content cost: clarified and reformatted instructions, fixed broken links, added additional hints for unrolling.style matrix: clarify two uses of variable “G” by using different notation for gram matrix.style cost: use distinct notation for gram matrix, added additional hints.Grammar and wording updates for clarity.model_nn: added hints.123456789101112import osimport sysimport scipy.ioimport scipy.miscimport matplotlib.pyplot as pltfrom matplotlib.pyplot import imshowfrom PIL import Imagefrom nst_utils import *import numpy as npimport tensorflow as tfimport pprint%matplotlib inline1 - Problem StatementNeural Style Transfer (NST) is one of the most fun techniques in deep learning. As seen below, it merges two images, namely: a “content” image (C) and a “style” image (S), to create a “generated” image (G).The generated image G combines the “content” of the image C with the “style” of image S.In this example, you are going to generate an image of the Louvre museum in Paris (content image C), mixed with a painting by Claude Monet, a leader of the impressionist movement (style image S).Let’s see how you can do this.2 - Transfer LearningNeural Style Transfer (NST) uses a previously trained convolutional network, and builds on top of that. The idea of using a network trained on a different task and applying it to a new task is called transfer learning.Following the original NST paper, we will use the VGG network. Specifically, we’ll use VGG-19, a 19-layer version of the VGG network. This model has already been trained on the very large ImageNet database, and thus has learned to recognize a variety of low level features (at the shallower layers) and high level features (at the deeper layers).Run the following code to load parameters from the VGG model. This may take a few seconds.123pp = pprint.PrettyPrinter(indent=4)model = load_vgg_model("pretrained-model/imagenet-vgg-verydeep-19.mat")pp.pprint(model)The model is stored in a python dictionary.The python dictionary contains key-value pairs for each layer.The ‘key’ is the variable name and the ‘value’ is a tensor for that layer.Assign input image to the model’s input layerTo run an image through this network, you just have to feed the image to the model. In TensorFlow, you can do so using the tf.assign function. In particular, you will use the assign function like this:1model["input"].assign(image)This assigns the image as an input to the model.Activate a layerAfter this, if you want to access the activations of a particular layer, say layer 4_2 when the network is run on this image, you would run a TensorFlow session on the correct tensor conv4_2, as follows:1sess.run(model["conv4_2"])3 - Neural Style Transfer (NST)We will build the Neural Style Transfer (NST) algorithm in three steps:Build the content cost function $J_{content}(C,G)$Build the style cost function $J_{style}(S,G)$Put it together to get $J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)$.3.1 - Computing the content costIn our running example, the content image C will be the picture of the Louvre Museum in Paris. Run the code below to see a picture of the Louvre.12content_image = scipy.misc.imread("images/louvre.jpg")imshow(content_image);The content image (C) shows the Louvre museum’s pyramid surrounded by old Paris buildings, against a sunny sky with a few clouds.3.1.1 - Make generated image G match the content of image CShallower versus deeper layersThe shallower layers of a ConvNet tend to detect lower-level features such as edges and simple textures.The deeper layers tend to detect higher-level features such as more complex textures as well as object classes.Choose a “middle” activation layer $a^{[l]}$We would like the “generated” image G to have similar content as the input image C. Suppose you have chosen some layer’s activations to represent the content of an image.In practice, you’ll get the most visually pleasing results if you choose a layer in the middle of the network—neither too shallow nor too deep.(After you have finished this exercise, feel free to come back and experiment with using different layers, to see how the results vary.)Forward propagate image “C”Set the image C as the input to the pretrained VGG network, and run forward propagation.Let $a^{(C)}$ be the hidden layer activations in the layer you had chosen. (In lecture, we had written this as $a^{l}$, but here we’ll drop the superscript $[l]$ to simplify the notation.) This will be an $n_H \times n_W \times n_C$ tensor.Forward propagate image “G”Repeat this process with the image G: Set G as the input, and run forward progation.Let $a^{(G)}$ be the corresponding hidden layer activation.Content Cost Function $J_{content}(C,G)$We will define the content cost function as:J_{content}(C,G) = \frac{1}{4 \times n_H \times n_W \times n_C}\sum _{ \text{all entries}} (a^{(C)} - a^{(G)})^2\tag{1}Here, $n_H, n_W$ and $n_C$ are the height, width and number of channels of the hidden layer you have chosen, and appear in a normalization term in the cost.For clarity, note that $a^{(C)}$ and $a^{(G)}$ are the 3D volumes corresponding to a hidden layer’s activations.In order to compute the cost $J_{content}(C,G)$, it might also be convenient to unroll these 3D volumes into a 2D matrix, as shown below.Technically this unrolling step isn’t needed to compute $J_{content}$, but it will be good practice for when you do need to carry out a similar operation later for computing the style cost $J_{style}$.Exercise: Compute the “content cost” using TensorFlow.Instructions: The 3 steps to implement this function are:Retrieve dimensions from a_G:To retrieve dimensions from a tensor X, use: X.get_shape().as_list()Unroll a_C and a_G as explained in the picture aboveYou’ll likey want to use these functions: tf.transpose and tf.reshape.Compute the content cost:You’ll likely want to use these functions: tf.reduce_sum, tf.square and tf.subtract.Additional Hints for “Unrolling”To unroll the tensor, we want the shape to change from $(m,n_H,n_W,n_C)$ to $(m, n_H \times n_W, n_C)$.tf.reshape(tensor, shape) takes a list of integers that represent the desired output shape.For the shape parameter, a -1 tells the function to choose the correct dimension size so that the output tensor still contains all the values of the original tensor.So tf.reshape(a_C, shape=[m, n_H * n_W, n_C]) gives the same result as tf.reshape(a_C, shape=[m, -1, n_C]).If you prefer to re-order the dimensions, you can use tf.transpose(tensor, perm), where perm is a list of integers containing the original index of the dimensions.For example, tf.transpose(a_C, perm=[0,3,1,2]) changes the dimensions from $(m, n_H, n_W, n_C)$ to $(m, n_C, n_H, n_W)$.There is more than one way to unroll the tensors.Notice that it’s not necessary to use tf.transpose to ‘unroll’ the tensors in this case but this is a useful function to practice and understand for other situations that you’ll encounter.123456789101112131415161718192021222324252627# GRADED FUNCTION: compute_content_costdef compute_content_cost(a_C, a_G): """ Computes the content cost Arguments: a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G Returns: J_content -- scalar that you compute using equation 1 above. """ ### START CODE HERE ### # Retrieve dimensions from a_G (≈1 line) m, n_H, n_W, n_C = a_G.get_shape().as_list() # Reshape a_C and a_G (≈2 lines) a_C_unrolled = tf.reshape(a_C, [n_H*n_W, n_C]) a_G_unrolled = tf.reshape(a_G, [n_H*n_W, n_C]) # compute the cost with tensorflow (≈1 line) J_content = 1./(4 * n_H * n_W * n_C)*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled, a_G_unrolled))) ### END CODE HERE ### return J_content123456789tf.reset_default_graph()with tf.Session() as test: tf.set_random_seed(1) a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4) a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4) J_content = compute_content_cost(a_C, a_G) print("J_content = " + str(J_content.eval()))# J_content = 6.76559What you should rememberThe content cost takes a hidden layer activation of the neural network, and measures how different $a^{(C)}$ and $a^{(G)}$ are.When we minimize the content cost later, this will help make sure $G$ has similar content as $C$.3.2 - Computing the style costFor our running example, we will use the following style image:12style_image = scipy.misc.imread("images/monet_800600.jpg")imshow(style_image);This was painted in the style of impressionism.Lets see how you can now define a “style” cost function $J_{style}(S,G)$.3.2.1 - Style matrixGram matrixThe style matrix is also called a “Gram matrix.”In linear algebra, the Gram matrix G of a set of vectors $(v_{1},\dots ,v_{n})$ is the matrix of dot products, whose entries are ${\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j}) }$.In other words, $G_{ij}$ compares how similar $v_i$ is to $v_j$: If they are highly similar, you would expect them to have a large dot product, and thus for $G_{ij}$ to be large.Two meanings of the variable $G$Note that there is an unfortunate collision in the variable names used here. We are following common terminology used in the literature.$G$ is used to denote the Style matrix (or Gram matrix)$G$ also denotes the generated image.For this assignment, we will use $G_{gram}$ to refer to the Gram matrix, and $G$ to denote the generated image.Compute $G_{gram}$In Neural Style Transfer (NST), you can compute the Style matrix by multiplying the “unrolled” filter matrix with its transpose:\mathbf{G}_{gram} = \mathbf{A}_{unrolled} \mathbf{A}_{unrolled}^T$G_{(gram)i,j}$: correlationThe result is a matrix of dimension $(n_C,n_C)$ where $n_C$ is the number of filters (channels). The value $G_{(gram)i,j}$ measures how similar the activations of filter $i$ are to the activations of filter $j$.$G_{(gram),i,i}$: prevalence of patterns or texturesThe diagonal elements $G_{(gram)ii}$ measure how “active” a filter $i$ is.For example, suppose filter $i$ is detecting vertical textures in the image. Then $G_{(gram)ii}$ measures how common vertical textures are in the image as a whole.If $G_{(gram)ii}$ is large, this means that the image has a lot of vertical texture.By capturing the prevalence of different types of features ($G_{(gram)ii}$), as well as how much different features occur together ($G_{(gram)ij}$), the Style matrix $G_{gram}$ measures the style of an image.12345678910111213141516# GRADED FUNCTION: gram_matrixdef gram_matrix(A): """ Argument: A -- matrix of shape (n_C, n_H*n_W) Returns: GA -- Gram matrix of A, of shape (n_C, n_C) """ ### START CODE HERE ### (≈1 line) GA = tf.matmul(A, tf.transpose(A)) ### END CODE HERE ### return GA12345678tf.reset_default_graph()with tf.Session() as test: tf.set_random_seed(1) A = tf.random_normal([3, 2*1], mean=1, stddev=4) GA = gram_matrix(A) print("GA = \n" + str(GA.eval()))3.2.2 - Style costYour goal will be to minimize the distance between the Gram matrix of the “style” image S and the gram matrix of the “generated” image G.For now, we are using only a single hidden layer $a^{[l]}$.The corresponding style cost for this layer is defined as:J_{style}^{[l]}(S,G) = \frac{1}{4 \times {n_C}^2 \times (n_H \times n_W)^2} \sum _{i=1}^{n_C}\sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2\tag{2}$G_{gram}^{(S)}$ Gram matrix of the “style” image.$G_{gram}^{(G)}$ Gram matrix of the “generated” image.Remember, this cost is computed using the hidden layer activations for a particular hidden layer in the network $a^{[l]}$Exercise: Compute the style cost for a single layer.Instructions: The 3 steps to implement this function are:Retrieve dimensions from the hidden layer activations a_G:To retrieve dimensions from a tensor X, use: X.get_shape().as_list()Unroll the hidden layer activations a_S and a_G into 2D matrices, as explained in the picture above (see the images in the sections “computing the content cost” and “style matrix”).You may use tf.transpose and tf.reshape.Compute the Style matrix of the images S and G. (Use the function you had previously written.)Compute the Style cost:You may find tf.reduce_sum, tf.square and tf.subtract useful.Additional HintsSince the activation dimensions are $(m, n_H, n_W, n_C)$ whereas the desired unrolled matrix shape is $(n_C, n_H*n_W)$, the order of the filter dimension $n_C$ is changed. So tf.transpose can be used to change the order of the filter dimension.for the product $\mathbf{G}_{gram} = \mathbf{A}_{} \mathbf{A}_{}^T$, you will also need to specify the perm parameter for the tf.transpose function.123456789101112131415161718192021222324252627282930# GRADED FUNCTION: compute_layer_style_costdef compute_layer_style_cost(a_S, a_G): """ Arguments: a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G Returns: J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2) """ ### START CODE HERE ### # Retrieve dimensions from a_G (≈1 line) m, n_H, n_W, n_C = a_G.get_shape().as_list() # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines) a_S = tf.transpose(tf.reshape(a_S, [n_H*n_W, n_C])) a_G = tf.transpose(tf.reshape(a_G, [n_H*n_W, n_C])) # Computing gram_matrices for both images S and G (≈2 lines) GS = gram_matrix(a_S) GG = gram_matrix(a_G) # Computing the loss (≈1 line) J_style_layer = 1./(4 * n_C * n_C * n_H * n_W * n_H * n_W) * tf.reduce_sum(tf.square(tf.subtract(GS, GG))) ### END CODE HERE ### return J_style_layer12345678910tf.reset_default_graph()with tf.Session() as test: tf.set_random_seed(1) a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4) a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4) J_style_layer = compute_layer_style_cost(a_S, a_G) print("J_style_layer = " + str(J_style_layer.eval()))# J_style_layer = 9.190283.2.3 Style WeightsSo far you have captured the style from only one layer.We’ll get better results if we “merge” style costs from several different layers.Each layer will be given weights ($\lambda^{[l]}$) that reflect how much each layer will contribute to the style.After completing this exercise, feel free to come back and experiment with different weights to see how it changes the generated image $G$.By default, we’ll give each layer equal weight, and the weights add up to 1. ($\sum_{l}^L\lambda^{[l]} = 1$)123456STYLE_LAYERS = [ ('conv1_1', 0.2), ('conv2_1', 0.2), ('conv3_1', 0.2), ('conv4_1', 0.2), ('conv5_1', 0.2)]You can combine the style costs for different layers as follows:J_{style}(S,G) = \sum_{l} \lambda^{[l]} J^{[l]}_{style}(S,G)where the values for $\lambda^{[l]}$ are given in STYLE_LAYERS.Exercise: compute style costWe’ve implemented a compute_style_cost(…) function.It calls your compute_layer_style_cost(...) several times, and weights their results using the values in STYLE_LAYERS.Please read over it to make sure you understand what it’s doing.Description of compute_style_costFor each layer:Select the activation (the output tensor) of the current layer.Get the style of the style image “S” from the current layer.Get the style of the generated image “G” from the current layer.Compute the “style cost” for the current layerAdd the weighted style cost to the overall style cost (J_style)Once you’re done with the loop:Return the overall style cost.12345678910111213141516171819202122232425262728293031323334353637def compute_style_cost(model, STYLE_LAYERS): """ Computes the overall style cost from several chosen layers Arguments: model -- our tensorflow model STYLE_LAYERS -- A python list containing: - the names of the layers we would like to extract style from - a coefficient for each of them Returns: J_style -- tensor representing a scalar value, style cost defined above by equation (2) """ # initialize the overall style cost J_style = 0 for layer_name, coeff in STYLE_LAYERS: # Select the output tensor of the currently selected layer out = model[layer_name] # Set a_S to be the hidden layer activation from the layer we have selected, by running the session on out a_S = sess.run(out) # Set a_G to be the hidden layer activation from same layer. Here, a_G references model[layer_name] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that # when we run the session, this will be the activations drawn from the appropriate layer, with G as input. a_G = out # Compute style_cost for the current layer J_style_layer = compute_layer_style_cost(a_S, a_G) # Add coeff * J_style_layer of this layer to overall style cost J_style += coeff * J_style_layer return J_styleNote: In the inner-loop of the for-loop above, a_G is a tensor and hasn’t been evaluated yet. It will be evaluated and updated at each iteration when we run the TensorFlow graph in model_nn() below.What you should rememberThe style of an image can be represented using the Gram matrix of a hidden layer’s activations.We get even better results by combining this representation from multiple different layers.This is in contrast to the content representation, where usually using just a single hidden layer is sufficient.Minimizing the style cost will cause the image $G$ to follow the style of the image $S$.3.3 - Defining the total cost to optimizeFinally, let’s create a cost function that minimizes both the style and the content cost. The formula is:J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)Exercise: Implement the total cost function which includes both the content cost and the style cost.123456789101112131415161718192021# GRADED FUNCTION: total_costdef total_cost(J_content, J_style, alpha = 10, beta = 40): """ Computes the total cost function Arguments: J_content -- content cost coded above J_style -- style cost coded above alpha -- hyperparameter weighting the importance of the content cost beta -- hyperparameter weighting the importance of the style cost Returns: J -- total cost as defined by the formula above. """ ### START CODE HERE ### (≈1 line) J = alpha * J_content + beta * J_style ### END CODE HERE ### return J12345678tf.reset_default_graph()with tf.Session() as test: np.random.seed(3) J_content = np.random.randn() J_style = np.random.randn() J = total_cost(J_content, J_style) print("J = " + str(J))What you should rememberThe total cost is a linear combination of the content cost $J_{content}(C,G)$ and the style cost $J_{style}(S,G)$.$\alpha$ and $\beta$ are hyperparameters that control the relative weighting between content and style.4 - Solving the optimization problemFinally, let’s put everything together to implement Neural Style Transfer!Here’s what the program will have to do:Create an Interactive SessionLoad the content imageLoad the style imageRandomly initialize the image to be generatedLoad the VGG19 modelBuild the TensorFlow graph:Run the content image through the VGG19 model and compute the content costRun the style image through the VGG19 model and compute the style costCompute the total costDefine the optimizer and the learning rateInitialize the TensorFlow graph and run it for a large number of iterations, updating the generated image at every step.Lets go through the individual steps in detail.Interactive SessionsYou’ve previously implemented the overall cost $J(G)$. We’ll now set up TensorFlow to optimize this with respect to $G$.To do so, your program has to reset the graph and use an “Interactive Session“.Unlike a regular session, the “Interactive Session” installs itself as the default session to build a graph.This allows you to run variables without constantly needing to refer to the session object (calling “sess.run()”), which simplifies the code.Start the interactive session.12345# Reset the graphtf.reset_default_graph()# Start interactive sessionsess = tf.InteractiveSession()Content imageLet’s load, reshape, and normalize our “content” image (the Louvre museum picture):12content_image = scipy.misc.imread("images/louvre_small.jpg")content_image = reshape_and_normalize_image(content_image)Style imageLet’s load, reshape and normalize our “style” image (Claude Monet’s painting):12style_image = scipy.misc.imread("images/monet.jpg")style_image = reshape_and_normalize_image(style_image)Generated image correlated with content imageNow, we initialize the “generated” image as a noisy image created from the content_image.The generated image is slightly correlated with the content image.By initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the “generated” image more rapidly match the content of the “content” image.Feel free to look in nst_utils.py to see the details of generate_noise_image(...); to do so, click “File—&gt;Open…” at the upper-left corner of this Jupyter notebook.12generated_image = generate_noise_image(content_image)imshow(generated_image[0]);Load pre-trained VGG19 modelNext, as explained in part (2), let’s load the VGG19 model.1model = load_vgg_model("pretrained-model/imagenet-vgg-verydeep-19.mat")Content CostTo get the program to compute the content cost, we will now assign a_C and a_G to be the appropriate hidden layer activations. We will use layer conv4_2 to compute the content cost. The code below does the following:Assign the content image to be the input to the VGG model.Set a_C to be the tensor giving the hidden layer activation for layer “conv4_2”.Set a_G to be the tensor giving the hidden layer activation for the same layer.Compute the content cost using a_C and a_G.Note: At this point, a_G is a tensor and hasn’t been evaluated. It will be evaluated and updated at each iteration when we run the Tensorflow graph in model_nn() below.12345678910111213141516# Assign the content image to be the input of the VGG model. sess.run(model['input'].assign(content_image))# Select the output tensor of layer conv4_2out = model['conv4_2']# Set a_C to be the hidden layer activation from the layer we have selecteda_C = sess.run(out)# Set a_G to be the hidden layer activation from same layer. Here, a_G references model['conv4_2'] # and isn't evaluated yet. Later in the code, we'll assign the image G as the model input, so that# when we run the session, this will be the activations drawn from the appropriate layer, with G as input.a_G = out# Compute the content costJ_content = compute_content_cost(a_C, a_G)Style cost12345# Assign the input of the model to be the "style" image sess.run(model['input'].assign(style_image))# Compute the style costJ_style = compute_style_cost(model, STYLE_LAYERS)Exercise: total costNow that you have J_content and J_style, compute the total cost J by calling total_cost().Use alpha = 10 and beta = 40.123### START CODE HERE ### (1 line)J = total_cost(J_content, J_style, 10, 40)### END CODE HERE ###OptimizerUse the Adam optimizer to minimize the total cost J.Use a learning rate of 2.0.Adam Optimizer documentation12345# define optimizer (1 line)optimizer = tf.train.AdamOptimizer(2.0)# define train_step (1 line)train_step = optimizer.minimize(J)Exercise: implement the modelImplement the model_nn() function.The function initializes the variables of the tensorflow graph,assigns the input image (initial generated image) as the input of the VGG19 modeland runs the train_step tensor (it was created in the code above this function) for a large number of steps.HintsTo initialize global variables, use this:1sess.run(tf.global_variables_initializer())Run sess.run() to evaluate a variable.assign can be used like this:1model["input"].assign(image)123456789101112131415161718192021222324252627282930313233343536373839def model_nn(sess, input_image, num_iterations = 200): # Initialize global variables (you need to run the session on the initializer) ### START CODE HERE ### (1 line) sess.run(tf.global_variables_initializer()) ### END CODE HERE ### # Run the noisy input image (initial generated image) through the model. Use assign(). ### START CODE HERE ### (1 line) sess.run(model["input"].assign(input_image)) ### END CODE HERE ### for i in range(num_iterations): # Run the session on the train_step to minimize the total cost ### START CODE HERE ### (1 line) sess.run(train_step) ### END CODE HERE ### # Compute the generated image by running the session on the current model['input'] ### START CODE HERE ### (1 line) generated_image = sess.run(model["input"]) ### END CODE HERE ### # Print every 20 iteration. if i%20 == 0: Jt, Jc, Js = sess.run([J, J_content, J_style]) print("Iteration " + str(i) + " :") print("total cost = " + str(Jt)) print("content cost = " + str(Jc)) print("style cost = " + str(Js)) # save current generated image in the "/output" directory save_image("output/" + str(i) + ".png", generated_image) # save last generated image save_image('output/generated_image.jpg', generated_image) return generated_imageRun the following cell to generate an artistic image. It should take about 3min on CPU for every 20 iterations but you start observing attractive results after ≈140 iterations. Neural Style Transfer is generally trained using GPUs.1model_nn(sess, generated_image)You’re done! After running this, in the upper bar of the notebook click on “File” and then “Open”. Go to the “/output” directory to see all the saved images. Open “generated_image” to see the generated image! :)You should see something the image presented below on the right:We didn’t want you to wait too long to see an initial result, and so had set the hyperparameters accordingly. To get the best looking results, running the optimization algorithm longer (and perhaps with a smaller learning rate) might work better. After completing and submitting this assignment, we encourage you to come back and play more with this notebook, and see if you can generate even better looking images.Here are few other examples:The beautiful ruins of the ancient city of Persepolis (Iran) with the style of Van Gogh (The Starry Night)The tomb of Cyrus the great in Pasargadae with the style of a Ceramic Kashi from Ispahan.A scientific study of a turbulent fluid with the style of a abstract blue fluid painting.5 - Test with your own image (Optional/Ungraded)Finally, you can also rerun the algorithm on your own images!To do so, go back to part 4 and change the content image and style image with your own pictures. In detail, here’s what you should do:Click on “File -&gt; Open” in the upper tab of the notebookGo to “/images” and upload your images (requirement: (WIDTH = 300, HEIGHT = 225)), rename them “my_content.png” and “my_style.png” for example.Change the code in part (3.4) from :12content_image = scipy.misc.imread("images/louvre.jpg")style_image = scipy.misc.imread("images/claude-monet.jpg")to:12content_image = scipy.misc.imread("images/my_content.jpg")style_image = scipy.misc.imread("images/my_style.jpg")Rerun the cells (you may need to restart the Kernel in the upper tab of the notebook).You can share your generated images with us on social media with the hashtag #deeplearniNgAI or by direct tagging!You can also tune your hyperparameters:Which layers are responsible for representing the style? STYLE_LAYERSHow many iterations do you want to run the algorithm? num_iterationsWhat is the relative weighting between content and style? alpha/beta6 - ConclusionGreat job on completing this assignment! You are now able to use Neural Style Transfer to generate artistic images. This is also your first time building a model in which the optimization algorithm updates the pixel values rather than the neural network’s parameters. Deep learning has many different types of models and this is only one of them!What you should rememberNeural Style Transfer is an algorithm that given a content image C and a style image S can generate an artistic imageIt uses representations (hidden layer activations) based on a pretrained ConvNet.The content cost function is computed using one hidden layer’s activations.The style cost function for one layer is computed using the Gram matrix of that layer’s activations. The overall style cost function is obtained using several hidden layers.Optimizing the total cost function results in synthesizing new images.Congratulations on finishing the course!This was the final programming exercise of this course. Congratulations—you’ve finished all the programming exercises of this course on Convolutional Networks! We hope to also see you in Course 5, on Sequence models!References:The Neural Style Transfer algorithm was due to Gatys et al. (2015). Harish Narayanan and Github user “log0” also have highly readable write-ups from which we drew inspiration. The pre-trained network used in this implementation is a VGG network, which is due to Simonyan and Zisserman (2015). Pre-trained weights were from the work of the MathConvNet team.Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic StyleHarish Narayanan, Convolutional neural networks for artistic style transfer.Log0, TensorFlow Implementation of “A Neural Algorithm of Artistic Style”.Karen Simonyan and Andrew Zisserman (2015). Very deep convolutional networks for large-scale image recognitionMatConvNet.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/specializations/deep-learninghttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Google深度学习框架-第10~12章]]></title>
    <url>%2F2020%2F01%2F24%2F%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6-%E7%AC%AC10-12%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[10.TensorFlow高层封装主要的高层封装有：TensorFlow-Slim，TFLearn、Keras和EstimatorTensorFlow-Slim123456789101112131415161718import tensorflow as tfimport tensorflow.contrib.slim as slimimport numpy as npfrom tensorflow.examples.tutorials.mnist import input_data# 通过TensorFlow-Slim来定义LeNet-5的网络结构。def lenet5(inputs): inputs = tf.reshape(inputs, [-1, 28, 28, 1]) # 定义一个卷积层 net = slim.conv2d(inputs, 32, [5, 5], padding='SAME', scope='layer1-conv') net = slim.max_pool2d(net, 2, stride=2, scope='layer2-max-pool') net = slim.conv2d(net, 64, [5, 5], padding='SAME', scope='layer3-conv') net = slim.max_pool2d(net, 2, stride=2, scope='layer4-max-pool') net = slim.flatten(net, scope='flatten') net = slim.fully_connected(net, 500, scope='layer5') net = slim.fully_connected(net, 10, scope='output') return net1234567891011121314151617def train(mnist): x = tf.placeholder(tf.float32, [None, 784], name='x-input') y_ = tf.placeholder(tf.float32, [None, 10], name='y-input') y = lenet5(x) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1)) loss = tf.reduce_mean(cross_entropy) train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss) with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(3000): xs, ys = mnist.train.next_batch(100) _, loss_value = sess.run([train_op, loss], feed_dict=&#123;x: xs, y_: ys&#125;) if i % 1000 == 0: print("After %d training step(s), loss on training batch is %g." % (i, loss_value))123456def main(argv=None): mnist = input_data.read_data_sets("../../datasets/MNIST_data", one_hot=True) train(mnist)if __name__ == '__main__': main()TF-LearnTF-Learn没有集成在TensorFlow的安装包中12345678910111213141516171819202122232425# 通过TFLearn的API定义卷机神经网络import tflearnfrom tflearn.layers.core import input_data, dropout, fully_connectedfrom tflearn.layers.conv import conv_2d, max_pool_2dfrom tflearn.layers.estimator import regression import tflearn.datasets.mnist as mnisttrainX, trainY, testX, testY = mnist.load_data( data_dir="../../datasets/MNIST_data", one_hot=True)# 将图像数据resize成卷积卷积神经网络输入的格式。trainX = trainX.reshape([-1, 28, 28, 1])testX = testX.reshape([-1, 28, 28, 1]) # 构建神经网络。net = input_data(shape=[None, 28, 28, 1], name='input')net = conv_2d(net, 32, 5, activation='relu')net = max_pool_2d(net, 2)net = conv_2d(net, 64, 5, activation='relu')net = max_pool_2d(net, 2)net = fully_connected(net, 500, activation='relu')net = fully_connected(net, 10, activation='softmax')# 定义学习任务。指定优化器为sgd，学习率为0.01，损失函数为交叉熵。net = regression(net, optimizer='sgd', learning_rate=0.01, loss='categorical_crossentropy')12345# 通过定义的网络结构训练模型，并在指定的验证数据上验证模型的效果。model = tflearn.DNN(net, tensorboard_verbose=0)model.fit(trainX, trainY, n_epoch=10, validation_set=([testX, testY]), show_metric=True)KerasCNN12345678910111213141516171819202122232425262728293031323334353637# 数据预处理import kerasfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2Dfrom keras import backend as K# from tensorflow import keras# from tensorflow.keras.datasets import mnist# from tensorflow.keras.models import Sequential# from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D# from tensorflow.keras import backend as Knum_classes = 10img_rows, img_cols = 28, 28 # 通过Keras封装好的API加载MNIST数据。其中trainX就是一个60000 * 28 * 28的数组，# trainY是每一张图片对应的数字。(trainX, trainY), (testX, testY) = mnist.load_data()# 根据对图像编码的格式要求来设置输入层的格式。if K.image_data_format() == 'channels_first': trainX = trainX.reshape(trainX.shape[0], 1, img_rows, img_cols) testX = testX.reshape(testX.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols)else: trainX = trainX.reshape(trainX.shape[0], img_rows, img_cols, 1) testX = testX.reshape(testX.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1) trainX = trainX.astype('float32')testX = testX.astype('float32')trainX /= 255.0testX /= 255.0 # 将标准答案转化为需要的格式（one-hot编码）。trainY = keras.utils.to_categorical(trainY, num_classes)testY = keras.utils.to_categorical(testY, num_classes)1234567891011121314# 使用Keras API定义模型。model = Sequential()model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(64, (5, 5), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Flatten())model.add(Dense(500, activation='relu'))model.add(Dense(num_classes, activation='softmax')) # 定义损失函数、优化函数和评测方法。model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), metrics=['accuracy'])123456789model.fit(trainX, trainY, batch_size=128, epochs=10, validation_data=(testX, testY)) # 在测试数据上计算准确率。score = model.evaluate(testX, testY)print('Test loss:', score[0])print('Test accuracy:', score[1])RNN123456789101112131415161718192021from keras.preprocessing import sequencefrom keras.models import Sequentialfrom keras.layers import Dense, Embeddingfrom keras.layers import LSTMfrom keras.datasets import imdbmax_features = 20000maxlen = 80 batch_size = 32# 加载数据并将单词转化为ID，max_features给出了最多使用的单词数。(trainX, trainY), (testX, testY) = imdb.load_data(num_words=max_features)print(len(trainX), 'train sequences')print(len(testX), 'test sequences')# 在自然语言中，每一段话的长度是不一样的，但循环神经网络的循环长度是固定的，# 所以这里需要先将所有段落统一成固定长度。trainX = sequence.pad_sequences(trainX, maxlen=maxlen)testX = sequence.pad_sequences(testX, maxlen=maxlen)print('trainX shape:', trainX.shape)print('testX shape:', testX.shape)12345678model = Sequential()model.add(Embedding(max_features, 128))model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))model.add(Dense(1, activation='sigmoid'))model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])12345678model.fit(trainX, trainY, batch_size=batch_size, epochs=10, validation_data=(testX, testY))score = model.evaluate(testX, testY, batch_size=batch_size)print('Test loss:', score[0])print('Test accuracy:', score[1])返回值123456789inputs = Input(shape=(784,))x = Dense(500, activation='relu')(inputs)predictions = Dense(10, activation='softmax')(x)model = Model(inputs=inputs, outputs=predictions)model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), metrics=['accuracy'])1234model.fit(trainX, trainY, batch_size=32, epochs=10, validation_data=(testX, testY))多输入输出12345678910111213141516171819# 定义两个输入。input1 = Input(shape=(784,), name = "input1")input2 = Input(shape=(10,), name = "input2")# 定义第一个输出。x = Dense(1, activation='relu')(input1)output1 = Dense(10, activation='softmax', name = "output1")(x)# 定义第二个输出。y = keras.layers.concatenate([x, input2])output2 = Dense(10, activation='softmax', name = "output2")(y)model = Model(inputs=[input1, input2], outputs=[output1, output2])# 定义损失函数、优化函数和评测方法。model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(), loss_weights = [1, 0.1], metrics=['accuracy'])1234model.fit([trainX, trainY], [trainY, trainY], batch_size=128, epochs=20, validation_data=([testX, testY], [testY, testY]))Keras和TensorFlow API联合12345678910111213141516import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist_data = input_data.read_data_sets('../../datasets/MNIST_data', one_hot=True)# 通过TensorFlow中的placeholder定义输入。x = tf.placeholder(tf.float32, shape=(None, 784))y_ = tf.placeholder(tf.float32, shape=(None, 10))net = tf.keras.layers.Dense(500, activation='relu')(x)y = tf.keras.layers.Dense(10, activation='softmax')(net)acc_value = tf.reduce_mean( tf.keras.metrics.categorical_accuracy(y_, y))loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_, y))train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)1234567891011with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(3000): xs, ys = mnist_data.train.next_batch(100) _, loss_value = sess.run([train_step, loss], feed_dict=&#123;x: xs, y_: ys&#125;) if i % 1000 == 0: print("After %d training step(s), loss on training batch is " "%g." % (i, loss_value)) print acc_value.eval(feed_dict=&#123;x: mnist_data.test.images, y_: mnist_data.test.labels&#125;)Estimator基本用法1234567891011121314151617import numpy as npimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datatf.logging.set_verbosity(tf.logging.INFO)mnist = input_data.read_data_sets("../../datasets/MNIST_data", one_hot=False)# 定义模型的输入。feature_columns = [tf.feature_column.numeric_column("image", shape=[784])]# 通过DNNClassifier定义模型。estimator = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[500], n_classes=10, optimizer=tf.train.AdamOptimizer(), model_dir="log")123456789# 训练模型train_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"image": mnist.train.images&#125;, y=mnist.train.labels.astype(np.int32), num_epochs=None, batch_size=128, shuffle=True)estimator.train(input_fn=train_input_fn, steps=10000)12345678910111213# 测试模型test_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"image": mnist.test.images&#125;, y=mnist.test.labels.astype(np.int32), num_epochs=1, batch_size=128, shuffle=False)test_results = estimator.evaluate(input_fn=test_input_fn)accuracy_score = test_results["accuracy"]print("\nTest accuracy: %g %%" % (accuracy_score*100))print(test_results)自定义模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import numpy as npimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datatf.logging.set_verbosity(tf.logging.INFO)def lenet(x, is_training): x = tf.reshape(x, shape=[-1, 28, 28, 1]) conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu) conv1 = tf.layers.max_pooling2d(conv1, 2, 2) conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu) conv2 = tf.layers.max_pooling2d(conv2, 2, 2) fc1 = tf.contrib.layers.flatten(conv2) fc1 = tf.layers.dense(fc1, 1024) fc1 = tf.layers.dropout(fc1, rate=0.4, training=is_training) return tf.layers.dense(fc1, 10)def model_fn(features, labels, mode, params): predict = lenet( features["image"], mode == tf.estimator.ModeKeys.TRAIN) if mode == tf.estimator.ModeKeys.PREDICT: return tf.estimator.EstimatorSpec( mode=mode, predictions=&#123;"result": tf.argmax(predict, 1)&#125;) loss = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits( logits=predict, labels=labels)) optimizer = tf.train.GradientDescentOptimizer( learning_rate=params["learning_rate"]) train_op = optimizer.minimize( loss=loss, global_step=tf.train.get_global_step()) eval_metric_ops = &#123; "accuracy": tf.metrics.accuracy( tf.argmax(predict, 1), labels) &#125; return tf.estimator.EstimatorSpec( mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)mnist = input_data.read_data_sets("../../datasets/MNIST_data", one_hot=False)model_params = &#123;"learning_rate": 0.01&#125;estimator = tf.estimator.Estimator(model_fn=model_fn, params=model_params) train_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"image": mnist.train.images&#125;, y=mnist.train.labels.astype(np.int32), num_epochs=None, batch_size=128, shuffle=True)estimator.train(input_fn=train_input_fn, steps=30000)12345678910test_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"image": mnist.test.images&#125;, y=mnist.test.labels.astype(np.int32), num_epochs=1, batch_size=128, shuffle=False)test_results = estimator.evaluate(input_fn=test_input_fn)accuracy_score = test_results["accuracy"]print("\nTest accuracy: %g %%" % (accuracy_score*100))12345678predict_input_fn = tf.estimator.inputs.numpy_input_fn( x=&#123;"image": mnist.test.images[:10]&#125;, num_epochs=1, shuffle=False)predictions = estimator.predict(input_fn=predict_input_fn)for i, p in enumerate(predictions): print("Prediction %s: %s" % (i + 1, p["result"]))使用数据集Dataset12345678910111213141516171819202122232425262728import tensorflow as tftf.logging.set_verbosity(tf.logging.INFO)def my_input_fn(file_path, perform_shuffle=False, repeat_count=1): def decode_csv(line): parsed_line = tf.decode_csv(line, [[0.], [0.], [0.], [0.], [0]]) return &#123;"x": parsed_line[:-1]&#125;, parsed_line[-1:] dataset = (tf.contrib.data.TextLineDataset(file_path) .skip(1) .map(decode_csv)) if perform_shuffle: dataset = dataset.shuffle(buffer_size=256) dataset = dataset.repeat(repeat_count) dataset = dataset.batch(32) iterator = dataset.make_one_shot_iterator() batch_features, batch_labels = iterator.get_next() return batch_features, batch_labelsfeature_columns = [tf.feature_column.numeric_column("x", shape=[4])]classifier = tf.estimator.DNNClassifier( feature_columns=feature_columns, hidden_units=[10, 10], n_classes=3)classifier.train( input_fn=lambda: my_input_fn("../../datasets/iris_training.csv", True, 100))1234# 测试模型test_results = classifier.evaluate( input_fn=lambda: my_input_fn("../../datasets/iris_test.csv", False, 1))print("\nTest accuracy: %g %%" % (test_results["accuracy"]*100))11.TensorBoard基本用法123456789import tensorflow as tf# 定义一个简单的计算图input1 = tf.constant([1.0, 2.0, 3.0], name="input1")input2 = tf.constant(tf.random_uniform([3]), name="input2")output = tf.add_n([input1, input2], name="add")writer = tf.summary.FileWriter("path/to/log", tf.get_default_graph())writer.close()12# 运行该命令，访问localhost:6006tensorboard --logdir=/path/to/log命名空间与TensorBoard图上节点12345678with tf.name_scope("input1"): input1 = tf.constant([1.0, 2.0, 3.0], name="input2")with tf.name_scope("input2"): input2 = tf.Variable(tf.random_uniform([3]), name="input2")output = tf.add_n([input1, input2], name="add")writer = tf.summary.FileWriter("log/simple_example.log", tf.get_default_graph())writer.close()]]></content>
      <categories>
        <category>实战Google深度学习框架笔记</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Google深度学习框架-第6~9章]]></title>
    <url>%2F2020%2F01%2F24%2F%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6-%E7%AC%AC6-9%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[6.2 CNN卷积层和池化层通过过滤器将一个2x2x3的节点矩阵变化成一个1x1x5的单位节点矩阵总共需要参数：2x2x3x5+5=64个使用$w_{(x,y,z)}^i$来表示对于输出单位节点矩阵中的第$i$个节点，则第$i$个节点的取值为：$g(i)=f(\sum \limits _{x=1}^2\sum \limits _{y=1}^2\sum \limits _{z=1}^3a_{(x,y,z)\times w_{x,y,z}^{i}+b^i})$$a$为过滤器，$f$为激活函数1234567891011import tensorflow as tfimport numpy as np# 输入矩阵M = np.array([ [[1],[-1],[0]], [[-1],[2],[1]], [[0],[2],[-2]] ])print("Matrix shape is: ", M.shape) # Matrix shape is: (3, 3, 1)12345# 定义卷积过滤器filter_weight = tf.get_variable('weights', [2, 2, 1, 1], initializer = tf.constant_initializer([ [1, -1], [0, 2]]))biases = tf.get_variable('biases', [1], initializer = tf.constant_initializer(1))12M = np.asarray(M, dtype='float32')M = M.reshape(1, 3, 3, 1)123456789101112# 计算矩阵通过卷积层过滤器和池化层过滤器计算后的结果x = tf.placeholder('float32', [1, None, None, 1])conv = tf.nn.conv2d(x, filter_weight, strides = [1, 2, 2, 1], padding = 'SAME')bias = tf.nn.bias_add(conv, biases)pool = tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')with tf.Session() as sess: tf.global_variables_initializer().run() convoluted_M = sess.run(bias,feed_dict=&#123;x:M&#125;) pooled_M = sess.run(pool,feed_dict=&#123;x:M&#125;) print("convoluted_M: \n", convoluted_M) print("pooled_M: \n", pooled_M)123456789101112convoluted_M: [[[[ 7.] [ 1.]] [[-1.] [-1.]]]]pooled_M: [[[[ 0.25] [ 0.5 ]] [[ 1. ] [-2. ]]]]6.4 经典卷积网络模型6.4.2 LeNet-5第一层的过滤器尺寸为5x5，深度为6，不使用全0填充，步长为1，有5x5x1x6+6=156个参数，下一层矩阵有28x28x6=4704个节点，故有4704x(25+1)=122304个连接。123456789101112131415# 设置神经网络的参数INPUT_NODE = 784OUTPUT_NODE = 10IMAGE_SIZE = 28NUM_CHANNELS = 1NUM_LABELS = 10CONV1_DEEP = 32CONV1_SIZE = 5CONV2_DEEP = 64CONV2_SIZE = 5FC_SIZE = 51212345678910111213141516171819202122232425262728293031323334353637383940414243def inference(input_tensor, train, regularizer): with tf.variable_scope('layer1-conv1'): conv1_weights = tf.get_variable( "weight", [CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP], initializer=tf.truncated_normal_initializer(stddev=0.1)) conv1_biases = tf.get_variable("bias", [CONV1_DEEP], initializer=tf.constant_initializer(0.0)) conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding='SAME') relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases)) with tf.name_scope("layer2-pool1"): pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding="SAME") with tf.variable_scope("layer3-conv2"): conv2_weights = tf.get_variable( "weight", [CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP], initializer=tf.truncated_normal_initializer(stddev=0.1)) conv2_biases = tf.get_variable("bias", [CONV2_DEEP], initializer=tf.constant_initializer(0.0)) conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding='SAME') relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases)) with tf.name_scope("layer4-pool2"): pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') pool_shape = pool2.get_shape().as_list() nodes = pool_shape[1] * pool_shape[2] * pool_shape[3] reshaped = tf.reshape(pool2, [pool_shape[0], nodes]) with tf.variable_scope('layer5-fc1'): fc1_weights = tf.get_variable("weight", [nodes, FC_SIZE], initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer != None: tf.add_to_collection('losses', regularizer(fc1_weights)) fc1_biases = tf.get_variable("bias", [FC_SIZE], initializer=tf.constant_initializer(0.1)) fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases) if train: fc1 = tf.nn.dropout(fc1, 0.5) with tf.variable_scope('layer6-fc2'): fc2_weights = tf.get_variable("weight", [FC_SIZE, NUM_LABELS], initializer=tf.truncated_normal_initializer(stddev=0.1)) if regularizer != None: tf.add_to_collection('losses', regularizer(fc2_weights)) fc2_biases = tf.get_variable("bias", [NUM_LABELS], initializer=tf.constant_initializer(0.1)) logit = tf.matmul(fc1, fc2_weights) + fc2_biases return logit训练12345import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataimport LeNet5_inferneceimport osimport numpy as np123456BATCH_SIZE = 100LEARNING_RATE_BASE = 0.01LEARNING_RATE_DECAY = 0.99REGULARIZATION_RATE = 0.0001TRAINING_STEPS = 6000MOVING_AVERAGE_DECAY = 0.991234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 定义训练过程def train(mnist): # 定义输出为4维矩阵的placeholder x = tf.placeholder(tf.float32, [ BATCH_SIZE, LeNet5_infernece.IMAGE_SIZE, LeNet5_infernece.IMAGE_SIZE, LeNet5_infernece.NUM_CHANNELS], name='x-input') y_ = tf.placeholder(tf.float32, [None, LeNet5_infernece.OUTPUT_NODE], name='y-input') regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE) y = LeNet5_infernece.inference(x,False,regularizer) global_step = tf.Variable(0, trainable=False) # 定义损失函数、学习率、滑动平均操作以及训练过程。 variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step) variables_averages_op = variable_averages.apply(tf.trainable_variables()) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1)) cross_entropy_mean = tf.reduce_mean(cross_entropy) loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses')) learning_rate = tf.train.exponential_decay( LEARNING_RATE_BASE, global_step, mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY, staircase=True) train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step) with tf.control_dependencies([train_step, variables_averages_op]): train_op = tf.no_op(name='train') # 初始化TensorFlow持久化类。 saver = tf.train.Saver() with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(TRAINING_STEPS): xs, ys = mnist.train.next_batch(BATCH_SIZE) reshaped_xs = np.reshape(xs, ( BATCH_SIZE, LeNet5_infernece.IMAGE_SIZE, LeNet5_infernece.IMAGE_SIZE, LeNet5_infernece.NUM_CHANNELS)) _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict=&#123;x: reshaped_xs, y_: ys&#125;) if i % 1000 == 0: print("After %d training step(s), loss on training batch is %g." % (step, loss_value))1234567# 主程序入口def main(argv=None): mnist = input_data.read_data_sets("../../../datasets/MNIST_data", one_hot=True) train(mnist)if __name__ == '__main__': main()一般图片分类问题的卷积神经网络架构：输入层$\rightarrow $(卷积层+ $\rightarrow $ 池化层?)$\rightarrow $全连接层+6.4.2 Inception-v3使用slim库6.5 迁移学习1234567891011121314151617# 下载数据集# wget http://download.tensorflow.org/example_images/flower_photos.tgzimport globimport os.pathimport numpy as npimport tensorflow as tffrom tensorflow.python.platform import gfile# 原始输入数据的目录，这个目录下有5个子目录，每个子目录底下保存这属于该# 类别的所有图片。INPUT_DATA = '../../datasets/flower_photos'# 输出文件地址。我们将整理后的图片数据通过numpy的格式保存。OUTPUT_FILE = '../../datasets/flower_processed_data.npy'# 测试数据和验证数据比例。VALIDATION_PERCENTAGE = 10TEST_PERCENTAGE = 10123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 读取数据并将数据分割成训练数据、验证数据和测试数据。def create_image_lists(sess, testing_percentage, validation_percentage): sub_dirs = [x[0] for x in os.walk(INPUT_DATA)] is_root_dir = True # 初始化各个数据集。 training_images = [] training_labels = [] testing_images = [] testing_labels = [] validation_images = [] validation_labels = [] current_label = 0 # 读取所有的子目录。 for sub_dir in sub_dirs: if is_root_dir: is_root_dir = False continue # 获取一个子目录中所有的图片文件。 extensions = ['jpg', 'jpeg', 'JPG', 'JPEG'] file_list = [] dir_name = os.path.basename(sub_dir) for extension in extensions: file_glob = os.path.join(INPUT_DATA, dir_name, '*.' + extension) file_list.extend(glob.glob(file_glob)) if not file_list: continue print("processing:", dir_name) i = 0 # 处理图片数据。 for file_name in file_list: i += 1 # 读取并解析图片，将图片转化为299*299以方便inception-v3模型来处理。 image_raw_data = gfile.FastGFile(file_name, 'rb').read() image = tf.image.decode_jpeg(image_raw_data) if image.dtype != tf.float32: image = tf.image.convert_image_dtype(image, dtype=tf.float32) image = tf.image.resize_images(image, [299, 299]) image_value = sess.run(image) # 随机划分数据聚。 chance = np.random.randint(100) if chance &lt; validation_percentage: validation_images.append(image_value) validation_labels.append(current_label) elif chance &lt; (testing_percentage + validation_percentage): testing_images.append(image_value) testing_labels.append(current_label) else: training_images.append(image_value) training_labels.append(current_label) if i % 200 == 0: print(i, "images processed.") current_label += 1 # 将训练数据随机打乱以获得更好的训练效果。 state = np.random.get_state() np.random.shuffle(training_images) np.random.set_state(state) np.random.shuffle(training_labels) return np.asarray([training_images, training_labels, validation_images, validation_labels, testing_images, testing_labels])12345# 运行数据处理过程with tf.Session() as sess: processed_data = create_image_lists(sess, TEST_PERCENTAGE, VALIDATION_PERCENTAGE) # 通过numpy格式保存处理后的数据。 np.save(OUTPUT_FILE, processed_data)12345678910111213141516171819202122232425262728import globimport os.pathimport numpy as npimport tensorflow as tffrom tensorflow.python.platform import gfileimport tensorflow.contrib.slim as slim# 加载通过TensorFlow-Slim定义好的inception_v3模型。import tensorflow.contrib.slim.python.slim.nets.inception_v3 as inception_v3# 处理好之后的数据文件。INPUT_DATA = &apos;../../datasets/flower_processed_data.npy&apos;# 保存训练好的模型的路径。TRAIN_FILE = &apos;train_dir/model&apos;# 谷歌提供的训练好的模型文件地址。因为GitHub无法保存大于100M的文件，所以# 在运行时需要先自行从Google下载inception_v3.ckpt文件。CKPT_FILE = &apos;../../datasets/inception_v3.ckpt&apos;# 定义训练中使用的参数。LEARNING_RATE = 0.0001STEPS = 300BATCH = 32N_CLASSES = 5# 不需要从谷歌训练好的模型中加载的参数。CHECKPOINT_EXCLUDE_SCOPES = &apos;InceptionV3/Logits,InceptionV3/AuxLogits&apos;# 需要训练的网络层参数明层，在fine-tuning的过程中就是最后的全联接层。TRAINABLE_SCOPES=&apos;InceptionV3/Logits,InceptionV3/AuxLogit&apos;123456789101112131415# 获取所有需要从谷歌训练好的模型中加载的参数def get_tuned_variables(): exclusions = [scope.strip() for scope in CHECKPOINT_EXCLUDE_SCOPES.split(',')] variables_to_restore = [] # 枚举inception-v3模型中所有的参数，然后判断是否需要从加载列表中移除。 for var in slim.get_model_variables(): excluded = False for exclusion in exclusions: if var.op.name.startswith(exclusion): excluded = True break if not excluded: variables_to_restore.append(var) return variables_to_restore12345678910# 获取所有需要训练的变量列表def get_trainable_variables(): scopes = [scope.strip() for scope in TRAINABLE_SCOPES.split(',')] variables_to_train = [] # 枚举所有需要训练的参数前缀，并通过这些前缀找到所有需要训练的参数。 for scope in scopes: variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope) variables_to_train.extend(variables) return variables_to_train12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485def main(): # 加载预处理好的数据。 processed_data = np.load(INPUT_DATA) training_images = processed_data[0] n_training_example = len(training_images) training_labels = processed_data[1] validation_images = processed_data[2] validation_labels = processed_data[3] testing_images = processed_data[4] testing_labels = processed_data[5] print(&quot;%d training examples, %d validation examples and %d testing examples.&quot; % ( n_training_example, len(validation_labels), len(testing_labels))) # 定义inception-v3的输入，images为输入图片，labels为每一张图片对应的标签。 images = tf.placeholder(tf.float32, [None, 299, 299, 3], name=&apos;input_images&apos;) labels = tf.placeholder(tf.int64, [None], name=&apos;labels&apos;) # 定义inception-v3模型。因为谷歌给出的只有模型参数取值，所以这里 # 需要在这个代码中定义inception-v3的模型结构。虽然理论上需要区分训练和 # 测试中使用到的模型，也就是说在测试时应该使用is_training=False，但是 # 因为预先训练好的inception-v3模型中使用的batch normalization参数与 # 新的数据会有出入，所以这里直接使用同一个模型来做测试。 with slim.arg_scope(inception_v3.inception_v3_arg_scope()): logits, _ = inception_v3.inception_v3( images, num_classes=N_CLASSES, is_training=True) trainable_variables = get_trainable_variables() # 定义损失函数和训练过程。 tf.losses.softmax_cross_entropy( tf.one_hot(labels, N_CLASSES), logits, weights=1.0) total_loss = tf.losses.get_total_loss() train_step = tf.train.RMSPropOptimizer(LEARNING_RATE).minimize(total_loss) # 计算正确率。 with tf.name_scope(&apos;evaluation&apos;): correct_prediction = tf.equal(tf.argmax(logits, 1), labels) evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 定义加载Google训练好的Inception-v3模型的Saver。 load_fn = slim.assign_from_checkpoint_fn( CKPT_FILE, get_tuned_variables(), ignore_missing_vars=True) # 定义保存新模型的Saver。 saver = tf.train.Saver() with tf.Session() as sess: # 初始化没有加载进来的变量。 init = tf.global_variables_initializer() sess.run(init) # 加载谷歌已经训练好的模型。 print(&apos;Loading tuned variables from %s&apos; % CKPT_FILE) load_fn(sess) start = 0 end = BATCH for i in range(STEPS): _, loss = sess.run([train_step, total_loss], feed_dict=&#123; images: training_images[start:end], labels: training_labels[start:end]&#125;) if i % 30 == 0 or i + 1 == STEPS: saver.save(sess, TRAIN_FILE, global_step=i) validation_accuracy = sess.run(evaluation_step, feed_dict=&#123; images: validation_images, labels: validation_labels&#125;) print(&apos;Step %d: Training loss is %.1f Validation accuracy = %.1f%%&apos; % ( i, loss, validation_accuracy * 100.0)) start = end if start == n_training_example: start = 0 end = start + BATCH if end &gt; n_training_example: end = n_training_example # 在最后的测试数据上测试正确率。 test_accuracy = sess.run(evaluation_step, feed_dict=&#123; images: testing_images, labels: testing_labels&#125;) print(&apos;Final test accuracy = %.1f%%&apos; % (test_accuracy * 100))7.1 TFRecordTFRecord文件中的数据都是通过tf.train.Example Protocol Buffer的格式存储的。123import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataimport numpy as np1234567891011121314151617181920212223242526272829303132333435363738394041424344# 定义函数转化变量类型。def _int64_feature(value): return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))def _bytes_feature(value): return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))# 将数据转化为tf.train.Example格式。def _make_example(pixels, label, image): image_raw = image.tostring() example = tf.train.Example(features=tf.train.Features(feature=&#123; 'pixels': _int64_feature(pixels), 'label': _int64_feature(np.argmax(label)), 'image_raw': _bytes_feature(image_raw) &#125;)) return example# 读取mnist训练数据。mnist = input_data.read_data_sets("../../datasets/MNIST_data",dtype=tf.uint8, one_hot=True)images = mnist.train.imageslabels = mnist.train.labelspixels = images.shape[1]num_examples = mnist.train.num_examples# 输出包含训练数据的TFRecord文件。with tf.python_io.TFRecordWriter("output.tfrecords") as writer: for index in range(num_examples): example = _make_example(pixels, labels[index], images[index]) writer.write(example.SerializeToString())print("TFRecord训练文件已保存。")# 读取mnist测试数据。images_test = mnist.test.imageslabels_test = mnist.test.labelspixels_test = images_test.shape[1] # 784num_examples_test = mnist.test.num_examples# 输出包含测试数据的TFRecord文件。with tf.python_io.TFRecordWriter("output_test.tfrecords") as writer: for index in range(num_examples_test): example = _make_example( pixels_test, labels_test[index], images_test[index]) writer.write(example.SerializeToString())print("TFRecord测试文件已保存。")1234567891011121314151617181920212223242526# 读取文件。reader = tf.TFRecordReader()filename_queue = tf.train.string_input_producer(["output.tfrecords"])_,serialized_example = reader.read(filename_queue)# 解析读取的样例。features = tf.parse_single_example( serialized_example, features=&#123; 'pixels':tf.FixedLenFeature([],tf.int64), 'label':tf.FixedLenFeature([],tf.int64), 'image_raw':tf.FixedLenFeature([],tf.string) &#125;)images = tf.decode_raw(features['image_raw'],tf.uint8)labels = tf.cast(features['label'],tf.int32)pixels = tf.cast(features['pixels'],tf.int32)sess = tf.Session()# 启动多线程处理输入数据。coord = tf.train.Coordinator()threads = tf.train.start_queue_runners(sess=sess,coord=coord)for i in range(10): image, label, pixel = sess.run([images, labels, pixels])7.2 图像数据处理7.2.1 TensorFlow图像处理函数123import matplotlib.pyplot as pltimport tensorflow as tf import numpy as np123456789image_raw_data = tf.gfile.FastGFile("../../datasets/cat.jpg",'rb').read()with tf.Session() as sess: img_data = tf.image.decode_jpeg(image_raw_data) # 输出解码之后的三维矩阵。 print(img_data.eval()) img_data.set_shape([1797, 2673, 3]) print(img_data.get_shape())1234# 打印图片with tf.Session() as sess: plt.imshow(img_data.eval()) plt.show()123456789# 大小调整with tf.Session() as sess: # 如果直接以0-255范围的整数数据输入resize_images，那么输出将是0-255之间的实数， # 不利于后续处理。本书建议在调整图片大小前，先将图片转为0-1范围的实数。 image_float = tf.image.convert_image_dtype(img_data, tf.float32) resized = tf.image.resize_images(image_float, [300, 300], method=0) plt.imshow(resized.eval()) plt.show()12345678# 裁剪和填充图片with tf.Session() as sess: croped = tf.image.resize_image_with_crop_or_pad(img_data, 1000, 1000) padded = tf.image.resize_image_with_crop_or_pad(img_data, 3000, 3000) plt.imshow(croped.eval()) plt.show() plt.imshow(padded.eval()) plt.show()12# 截取中间50%的图片central_cropped = tf.image.central_crop(img_data, 0.5)12345678910111213141516# 翻转图片with tf.Session() as sess: # 上下翻转 #flipped1 = tf.image.flip_up_down(img_data) # 左右翻转 #flipped2 = tf.image.flip_left_right(img_data) #对角线翻转 transposed = tf.image.transpose_image(img_data) plt.imshow(transposed.eval()) plt.show() # 以一定概率上下翻转图片。 #flipped = tf.image.random_flip_up_down(img_data) # 以一定概率左右翻转图片。 #flipped = tf.image.random_flip_left_right(img_data)123456789101112131415161718192021222324252627# 图片色彩调整with tf.Session() as sess: # 在进行一系列图片调整前，先将图片转换为实数形式，有利于保持计算精度。 image_float = tf.image.convert_image_dtype(img_data, tf.float32) # 将图片的亮度-0.5。 #adjusted = tf.image.adjust_brightness(image_float, -0.5) # 将图片的亮度+0.5 #adjusted = tf.image.adjust_brightness(image_float, 0.5) # 在[-max_delta, max_delta)的范围随机调整图片的亮度。 adjusted = tf.image.random_brightness(image_float, max_delta=0.5) # 将图片的对比度-5 #adjusted = tf.image.adjust_contrast(image_float, -5) # 将图片的对比度+5 #adjusted = tf.image.adjust_contrast(image_float, 5) # 在[lower, upper]的范围随机调整图的对比度。 #adjusted = tf.image.random_contrast(image_float, lower, upper) # 在最终输出前，将实数取值截取到0-1范围内。 adjusted = tf.clip_by_value(adjusted, 0.0, 1.0) plt.imshow(adjusted.eval()) plt.show()123456789101112131415161718192021222324252627# 添加色相和饱和度with tf.Session() as sess: # 在进行一系列图片调整前，先将图片转换为实数形式，有利于保持计算精度。 image_float = tf.image.convert_image_dtype(img_data, tf.float32) adjusted = tf.image.adjust_hue(image_float, 0.1) #adjusted = tf.image.adjust_hue(image_float, 0.3) #adjusted = tf.image.adjust_hue(image_float, 0.6) #adjusted = tf.image.adjust_hue(image_float, 0.9) # 在[-max_delta, max_delta]的范围随机调整图片的色相。max_delta的取值在[0, 0.5]之间。 #adjusted = tf.image.random_hue(image_float, max_delta) # 将图片的饱和度-5。 #adjusted = tf.image.adjust_saturation(image_float, -5) # 将图片的饱和度+5。 #adjusted = tf.image.adjust_saturation(image_float, 5) # 在[lower, upper]的范围随机调整图的饱和度。 #adjusted = tf.image.random_saturation(image_float, lower, upper) # 将代表一张图片的三维矩阵中的数字均值变为0，方差变为1。 #adjusted = tf.image.per_image_whitening(image_float) # 在最终输出前，将实数取值截取到0-1范围内。 adjusted = tf.clip_by_value(adjusted, 0.0, 1.0) plt.imshow(adjusted.eval()) plt.show()1234567891011121314151617181920212223# 添加标注框并裁减with tf.Session() as sess: boxes = tf.constant([[[0.05, 0.05, 0.9, 0.7], [0.35, 0.47, 0.5, 0.56]]]) # sample_distorted_bounding_box要求输入图片必须是实数类型。 image_float = tf.image.convert_image_dtype(img_data, tf.float32) begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box( tf.shape(image_float), bounding_boxes=boxes, min_object_covered=0.4) # 截取后的图片 distorted_image = tf.slice(image_float, begin, size) plt.imshow(distorted_image.eval()) plt.show() # 在原图上用标注框画出截取的范围。由于原图的分辨率较大（2673x1797)，生成的标注框 # 在Jupyter Notebook上通常因边框过细而无法分辨，这里为了演示方便先缩小分辨率。 image_small = tf.image.resize_images(image_float, [180, 267], method=0) batchced_img = tf.expand_dims(image_small, 0) image_with_box = tf.image.draw_bounding_boxes(batchced_img, bbox_for_draw) print(bbox_for_draw.eval()) plt.imshow(image_with_box[0].eval()) plt.show()7.3 多线程输入数据处理框架7.3.1 队列与多线程12345678910q = tf.FIFOQueue(2, "int32") # 2为队列大小init = q.enqueue_many(([0, 10],)) # 初始化队列x = q.dequeue()y = x + 1q_inc = q.enqueue([y]) # +1后的数据放入队列with tf.Session() as sess: init.run() for _ in range(5): v, _ = sess.run([x, q_inc]) print(v)123import numpy as npimport threadingimport time12345678910# 每隔1秒判断是否需要停止并打印自己的IDdef MyLoop(coord, worker_id): while not coord.should_stop(): if np.random.rand()&lt;0.1: print("Stoping from id: %d\n" % worker_id) # 停止所有进程 coord.request_stop() else: print("Working on id: %d\n" % worker_id) time.sleep(1)12345# 创建、启动并退出线程coord = tf.train.Coordinator()threads = [threading.Thread(target=MyLoop, args=(coord, i, )) for i in range(5)]for t in threads:t.start()coord.join(threads)12345678910111213141516# 多线程queue = tf.FIFOQueue(100,"float")# 定义队列入队操作enqueue_op = queue.enqueue([tf.random_normal([1])])qr = tf.train.QueueRunner(queue, [enqueue_op] * 5)tf.train.add_queue_runner(qr)# 定义队列出队操作out_tensor = queue.dequeue()# 启动with tf.Session() as sess: coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(sess=sess, coord=coord) for _ in range(3): print(sess.run(out_tensor)[0]) coord.request_stop() coord.join(threads)7.3.2 输入文件队列12345678910111213141516171819# 生成文件存储样例数据# 创建TFRecord文件的辅助函数def _int64_feature(value): return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))num_shards = 2 # 写入文件数instances_per_shard = 2 # 每个文件数据数for i in range(num_shards): filename = ('data.tfrecords-%.5d-of-%.5d' % (i, num_shards)) # 将Example结构写入TFRecord文件。 writer = tf.python_io.TFRecordWriter(filename) for j in range(instances_per_shard): # Example结构仅包含当前样例属于第几个文件以及是当前文件的第几个样本。 example = tf.train.Example(features=tf.train.Features(feature=&#123; 'i': _int64_feature(i), 'j': _int64_feature(j)&#125;)) writer.write(example.SerializeToString()) writer.close()1234567891011121314151617181920212223# 读取文件files = tf.train.match_filenames_once("data.tfrecords-*")filename_queue = tf.train.string_input_producer(files, shuffle=False) reader = tf.TFRecordReader()_, serialized_example = reader.read(filename_queue)features = tf.parse_single_example( serialized_example, features=&#123; 'i': tf.FixedLenFeature([], tf.int64), 'j': tf.FixedLenFeature([], tf.int64), &#125;)with tf.Session() as sess: sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()]) print(sess.run(files)) coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(sess=sess, coord=coord) for i in range(6): print(sess.run([features['i'], features['j']])) coord.request_stop() coord.join(threads)在不打乱文件列表的情况下，会依次读取输出样例数据的每一个样例，当所有样例读取完毕，程序会重头开始，如果限制$num_epochs$为1，程序将报错。7.3.3 组合训练数据12345678910111213141516171819example, label = features['i'], features['j']# 一个batch中样例的个数batch_size = 2capacity = 1000 + 3 * batch_sizeexample_batch, label_batch = tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)with tf.Session() as sess: tf.global_variables_initializer().run() tf.local_variables_initializer().run() coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(sess=sess, coord=coord) for i in range(3): cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch]) print(cur_example_batch, cur_label_batch) coord.request_stop() coord.join(threads)# tf.train.shuffle_batch7.3.4 输入数据处理框架123# 创建文件列表，通过文件列表创建输入文件队列files = tf.train.match_filenames_once("output.tfrecords")filename_queue = tf.train.string_input_producer(files, shuffle=False)1234567891011121314151617181920# 解析TFRecord文件里的数据# 读取文件。reader = tf.TFRecordReader()_,serialized_example = reader.read(filename_queue)# 解析读取的样例。features = tf.parse_single_example( serialized_example, features=&#123; 'image_raw':tf.FixedLenFeature([],tf.string), 'pixels':tf.FixedLenFeature([],tf.int64), 'label':tf.FixedLenFeature([],tf.int64) &#125;)decoded_images = tf.decode_raw(features['image_raw'],tf.uint8)retyped_images = tf.cast(decoded_images, tf.float32)labels = tf.cast(features['label'],tf.int32)#pixels = tf.cast(features['pixels'],tf.int32)images = tf.reshape(retyped_images, [784])123456789# 将文件以100个为一组打包min_after_dequeue = 10000batch_size = 100capacity = min_after_dequeue + 3 * batch_sizeimage_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue)1234# 训练模型def inference(input_tensor, weights1, biases1, weights2, biases2): layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1) return tf.matmul(layer1, weights2) + biases2123456789101112131415161718192021222324252627282930313233343536373839404142# 模型相关的参数INPUT_NODE = 784OUTPUT_NODE = 10LAYER1_NODE = 500REGULARAZTION_RATE = 0.0001 TRAINING_STEPS = 5000 weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))y = inference(image_batch, weights1, biases1, weights2, biases2) # 计算交叉熵及其平均值cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=label_batch)cross_entropy_mean = tf.reduce_mean(cross_entropy) # 损失函数的计算regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)regularaztion = regularizer(weights1) + regularizer(weights2)loss = cross_entropy_mean + regularaztion# 优化损失函数train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss) # 初始化会话，并开始训练过程。with tf.Session() as sess: # tf.global_variables_initializer().run() sess.run((tf.global_variables_initializer(), tf.local_variables_initializer())) coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(sess=sess, coord=coord) # 循环的训练神经网络。 for i in range(TRAINING_STEPS): if i % 1000 == 0: print("After %d training step(s), loss is %g " % (i, sess.run(loss))) sess.run(train_step) coord.request_stop() coord.join(threads)7.4数据集12import tempfileimport tensorflow as tf12345678910111213input_data = [1, 2, 3, 5, 8]dataset = tf.data.Dataset.from_tensor_slices(input_data)# 定义迭代器用于遍历数据集iterator = dataset.make_one_shot_iterator()# get_next() 返回代表一个输入数据的张量。x = iterator.get_next()y = x * xwith tf.Session() as sess: for i in range(len(input_data)): print(sess.run(y))12345678910111213141516171819202122# 读取文本文件里的数据# 创建文本文件作为本例的输入。with open("./test1.txt", "w") as file: file.write("File1, line1.\n") file.write("File1, line2.\n")with open("./test2.txt", "w") as file: file.write("File2, line1.\n") file.write("File2, line2.\n")# 从文本文件创建数据集。这里可以提供多个文件。input_files = ["./test1.txt", "./test2.txt"]dataset = tf.data.TextLineDataset(input_files)# 定义迭代器。iterator = dataset.make_one_shot_iterator()# 这里get_next()返回一个字符串类型的张量，代表文件中的一行。x = iterator.get_next() with tf.Session() as sess: for i in range(4): print(sess.run(x))1234567891011121314151617181920212223242526272829303132333435# 解析TFRecord文件里的数据# 解析一个TFRecord的方法。def parser(record): features = tf.parse_single_example( record, features=&#123; 'image_raw':tf.FixedLenFeature([],tf.string), 'pixels':tf.FixedLenFeature([],tf.int64), 'label':tf.FixedLenFeature([],tf.int64) &#125;) decoded_images = tf.decode_raw(features['image_raw'],tf.uint8) retyped_images = tf.cast(decoded_images, tf.float32) images = tf.reshape(retyped_images, [784]) labels = tf.cast(features['label'],tf.int32) #pixels = tf.cast(features['pixels'],tf.int32) return images, labels# 从TFRecord文件创建数据集。这里可以提供多个文件。input_files = ["output.tfrecords"]dataset = tf.data.TFRecordDataset(input_files)# map()函数表示对数据集中的每一条数据进行调用解析方法。dataset = dataset.map(parser)# 定义遍历数据集的迭代器。iterator = dataset.make_one_shot_iterator()# 读取数据，可用于进一步计算image, label = iterator.get_next()with tf.Session() as sess: for i in range(10): x, y = sess.run([image, label]) print(y)因为使用了$make_one_shot_iterator$，如果需要用$placeholder$来初始化数据集，则需要$initializable_iterator$12345678910111213141516171819# 从TFRecord文件创建数据集，具体文件路径是一个placeholder，稍后再提供具体路径。input_files = tf.placeholder(tf.string)dataset = tf.data.TFRecordDataset(input_files)dataset = dataset.map(parser)# 定义遍历dataset的initializable_iterator。iterator = dataset.make_initializable_iterator()image, label = iterator.get_next()with tf.Session() as sess: # 首先初始化iterator，并给出input_files的值。 sess.run(iterator.initializer, feed_dict=&#123;input_files: ["output.tfrecords"]&#125;) # 遍历所有数据一个epoch。当遍历结束时，程序会抛出OutOfRangeError。 while True: try: x, y = sess.run([image, label]) except tf.errors.OutOfRangeError: break8.1 RNN1import numpy as np1234567X = [1,2]state = [0.0, 0.0]w_cell_state = np.asarray([[0.1, 0.2], [0.3, 0.4]])w_cell_input = np.asarray([0.5, 0.6])b_cell = np.asarray([0.1, -0.1])w_output = np.asarray([[1.0], [2.0]])b_output = 0.11234567for i in range(len(X)): before_activation = np.dot(state, w_cell_state) + X[i] * w_cell_input + b_cell state = np.tanh(before_activation) final_output = np.dot(state, w_output) + b_output print("before activation: ", before_activation) print("state: ", state) print("output: ", final_output)全连接层神经网络的输入大小为n+x8.2 LSTM参考：https://www.cnblogs.com/zuotongbin/p/10698843.html123import numpy as npimport tensorflow as tfimport matplotlib.pyplot as plt12345678HIDDEN_SIZE = 30 # LSTM中隐藏节点的个数。NUM_LAYERS = 2 # LSTM的层数。TIMESTEPS = 10 # 循环神经网络的训练序列长度。TRAINING_STEPS = 10000 # 训练轮数。BATCH_SIZE = 32 # batch大小。TRAINING_EXAMPLES = 10000 # 训练数据个数。TESTING_EXAMPLES = 1000 # 测试数据个数。SAMPLE_GAP = 0.01 # 采样间隔。123456789101112131415161718# 产生正弦数据def generate_data(seq): X = [] y = [] # 序列的第i项和后面的TIMESTEPS-1项合在一起作为输入；第i + TIMESTEPS项作为输 # 出。即用sin函数前面的TIMESTEPS个点的信息，预测第i + TIMESTEPS个点的函数值。 for i in range(len(seq) - TIMESTEPS): X.append([seq[i: i + TIMESTEPS]]) y.append([seq[i + TIMESTEPS]]) return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32) # 用正弦函数生成训练和测试数据集合。test_start = (TRAINING_EXAMPLES + TIMESTEPS) * SAMPLE_GAPtest_end = test_start + (TESTING_EXAMPLES + TIMESTEPS) * SAMPLE_GAPtrain_X, train_y = generate_data(np.sin(np.linspace( 0, test_start, TRAINING_EXAMPLES + TIMESTEPS, dtype=np.float32)))test_X, test_y = generate_data(np.sin(np.linspace( test_start, test_end, TESTING_EXAMPLES + TIMESTEPS, dtype=np.float32)))123456789101112131415161718192021222324252627def lstm_model(X, y, is_training): # 使用多层的LSTM结构。 cell = tf.nn.rnn_cell.MultiRNNCell([ tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) for _ in range(NUM_LAYERS)]) # 使用TensorFlow接口将多层的LSTM结构连接成RNN网络并计算其前向传播结果。 outputs, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32) output = outputs[:, -1, :] # 对LSTM网络的输出再做加一层全链接层并计算损失。注意这里默认的损失为平均 # 平方差损失函数。 predictions = tf.contrib.layers.fully_connected( output, 1, activation_fn=None) # 只在训练时计算损失函数和优化步骤。测试时直接返回预测结果。 if not is_training: return predictions, None, None # 计算损失函数。 loss = tf.losses.mean_squared_error(labels=y, predictions=predictions) # 创建模型优化器并得到优化步骤。 train_op = tf.contrib.layers.optimize_loss( loss, tf.train.get_global_step(), optimizer="Adagrad", learning_rate=0.1) return predictions, loss, train_op123456789101112131415161718192021222324252627282930def run_eval(sess, test_X, test_y): # 将测试数据以数据集的方式提供给计算图。 ds = tf.data.Dataset.from_tensor_slices((test_X, test_y)) ds = ds.batch(1) X, y = ds.make_one_shot_iterator().get_next() # 调用模型得到计算结果。这里不需要输入真实的y值。 with tf.variable_scope("model", reuse=True): prediction, _, _ = lstm_model(X, [0.0], False) # 将预测结果存入一个数组。 predictions = [] labels = [] for i in range(TESTING_EXAMPLES): p, l = sess.run([prediction, y]) predictions.append(p) labels.append(l) # 计算rmse作为评价指标。 predictions = np.array(predictions).squeeze() labels = np.array(labels).squeeze() rmse = np.sqrt(((predictions - labels) ** 2).mean(axis=0)) print("Root Mean Square Error is: %f" % rmse) #对预测的sin函数曲线进行绘图。 plt.figure() plt.plot(predictions, label='predictions') plt.plot(labels, label='real_sin') plt.legend() plt.show()12345678910111213141516171819202122232425# 将训练数据以数据集的方式提供给计算图。ds = tf.data.Dataset.from_tensor_slices((train_X, train_y))ds = ds.repeat().shuffle(1000).batch(BATCH_SIZE)X, y = ds.make_one_shot_iterator().get_next()# 定义模型，得到预测结果、损失函数，和训练操作。with tf.variable_scope("model"): _, loss, train_op = lstm_model(X, y, True) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 测试在训练之前的模型效果。 print("Evaluate model before training.") run_eval(sess, test_X, test_y) # 训练模型。 for i in range(TRAINING_STEPS): _, l = sess.run([train_op, loss]) if i % 1000 == 0: print("train step: " + str(i) + ", loss: " + str(l)) # 使用训练好的模型对测试数据进行预测。 print("Evaluate model after training.") run_eval(sess, test_X, test_y)9.1 语言模型的背景知识将句子看成单词序列，$S=(w_1,w_2,…,w_m)$,其中$m$为句子长度则该句子的概率可以表示为：$p(S)=p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)…$，所需$V^m$个参数，$V$为词汇量。$n-gram$模型：$p(S)=\prod _i ^m p(w_i|w_{i-n+1},…,w_{i-1})$语言模型的评价方法$perplexity(S)= \sqrt[m]{\frac{1}{p(w_1,w_2,w_3,…,w_m)}} $对数形式：$log(perplexity(S))=-\frac{1}{m}\sum \limits _{i=1} ^m log(w_i|w_1,…,w_{i-1})$log perplexity在数学上可以看作真实分布与预测分布之间的交叉熵$H(u,v)$1import tensorflow as tf12345678910111213141516# 假设词汇表的大小为3， 语料包含两个单词"2 0"word_labels = tf.constant([2, 0])# 假设模型对两个单词预测时，产生的logit分别是[2.0, -1.0, 3.0]和[1.0, 0.0, -0.5]predict_logits = tf.constant([[2.0, -1.0, 3.0], [1.0, 0.0, -0.5]])# 使用sparse_softmax_cross_entropy_with_logits计算交叉熵。loss = tf.nn.sparse_softmax_cross_entropy_with_logits( labels=word_labels, logits=predict_logits)# 运行程序，计算loss的结果是[0.32656264, 0.46436879], 这对应两个预测的# perplexity损失。with tf.Session() as sess: print(sess.run(loss))# [0.32656264 0.4643688 ]123456789101112131415161718# softmax_cross_entropy_with_logits与上面的函数相似，但是需要将预测目标以# softmax_cross_entropy_with_logits_v2# 概率分布的形式给出。word_prob_distribution = tf.constant([[0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])loss = tf.nn.softmax_cross_entropy_with_logits( labels=word_prob_distribution, logits=predict_logits)# 运行结果与上面相同：[ 0.32656264, 0.46436879]with tf.Session() as sess: print(sess.run(loss))# label smoothing：将正确数据的概率设为一个比1.0略小的值，将错误数据的概率# 设为比0.0略大的值，这样可以避免模型与数据过拟合，在某些时候可以提高训练效果。word_prob_smooth = tf.constant([[0.01, 0.01, 0.98], [0.98, 0.01, 0.01]])loss = tf.nn.softmax_cross_entropy_with_logits_v2( labels=word_prob_smooth, logits=predict_logits)# 运行结果：[ 0.37656265, 0.48936883]with tf.Session() as sess: print(sess.run(loss))9.2 神经语言模型PTB数据集文本数据预处理—生产词汇表123import codecsimport collectionsfrom operator import itemgetter1234567891011121314# 设置参数MODE = "PTB" # 将MODE设置为"PTB", "TRANSLATE_EN", "TRANSLATE_ZH"之一。if MODE == "PTB": # PTB数据处理 RAW_DATA = "../../datasets/PTB_data/ptb.train.txt" # 训练集数据文件 VOCAB_OUTPUT = "ptb.vocab" # 输出的词汇表文件elif MODE == "TRANSLATE_ZH": # 翻译语料的中文部分 RAW_DATA = "../../datasets/TED_data/train.txt.zh" VOCAB_OUTPUT = "zh.vocab" VOCAB_SIZE = 4000elif MODE == "TRANSLATE_EN": # 翻译语料的英文部分 RAW_DATA = "../../datasets/TED_data/train.txt.en" VOCAB_OUTPUT = "en.vocab" VOCAB_SIZE = 100001234567891011# 对单词按词频排序counter = collections.Counter()with codecs.open(RAW_DATA, "r", "utf-8") as f: for line in f: for word in line.strip().split(): counter[word] += 1# 按词频顺序对单词进行排序。sorted_word_to_cnt = sorted( counter.items(), key=itemgetter(1), reverse=True)sorted_words = [x[0] for x in sorted_word_to_cnt]12345678910# 插入特殊符号if MODE == "PTB": # 稍后我们需要在文本换行处加入句子结束符"&lt;eos&gt;"，这里预先将其加入词汇表。 sorted_words = ["&lt;eos&gt;"] + sorted_wordselif MODE in ["TRANSLATE_EN", "TRANSLATE_ZH"]: # 在9.3.2小节处理机器翻译数据时，除了"&lt;eos&gt;"以外，还需要将"&lt;unk&gt;"和句子起始符 # "&lt;sos&gt;"加入词汇表，并从词汇表中删除低频词汇。 sorted_words = ["&lt;unk&gt;", "&lt;sos&gt;", "&lt;eos&gt;"] + sorted_words if len(sorted_words) &gt; VOCAB_SIZE: sorted_words = sorted_words[:VOCAB_SIZE]1234# 保存词汇表文件with codecs.open(VOCAB_OUTPUT, 'w', 'utf-8') as file_output: for word in sorted_words: file_output.write(word + "\n")文本数据预处理—生产训练文件12345678# 读取词汇表，并建立词汇到单词编号的映射。with codecs.open(VOCAB, "r", "utf-8") as f_vocab: vocab = [w.strip() for w in f_vocab.readlines()]word_to_id = &#123;k: v for (k, v) in zip(vocab, range(len(vocab)))&#125;# 如果出现了不在词汇表内的低频词，则替换为"unk"。def get_id(word): return word_to_id[word] if word in word_to_id else word_to_id["&lt;unk&gt;"]12345678910# 对数据进行替换并保存结果。fin = codecs.open(RAW_DATA, "r", "utf-8")fout = codecs.open(OUTPUT_DATA, 'w', 'utf-8')for line in fin: words = line.strip().split() + ["&lt;eos&gt;"] # 读取单词并添加&lt;eos&gt;结束符 # 将每个单词替换为词汇表中的编号 out_line = ' '.join([str(get_id(w)) for w in words]) + '\n' fout.write(out_line)fin.close()fout.close()PTB数据的batching方法123456789101112131415161718192021222324252627# 从文件中读取数据，并返回包含单词编号的数组。def read_data(file_path): with open(file_path, "r") as fin: # 将整个文档读进一个长字符串。 id_string = ' '.join([line.strip() for line in fin.readlines()]) id_list = [int(w) for w in id_string.split()] # 将读取的单词编号转为整数 return id_listdef make_batches(id_list, batch_size, num_step): # 计算总的batch数量。每个batch包含的单词数量是batch_size * num_step。 num_batches = (len(id_list) - 1) // (batch_size * num_step) # 如9-4图所示，将数据整理成一个维度为[batch_size, num_batches * num_step] # 的二维数组。 data = np.array(id_list[: num_batches * batch_size * num_step]) data = np.reshape(data, [batch_size, num_batches * num_step]) # 沿着第二个维度将数据切分成num_batches个batch，存入一个数组。 data_batches = np.split(data, num_batches, axis=1) # 重复上述操作，但是每个位置向右移动一位。这里得到的是RNN每一步输出所需要预测的 # 下一个单词。 label = np.array(id_list[1 : num_batches * batch_size * num_step + 1]) label = np.reshape(label, [batch_size, num_batches * num_step]) label_batches = np.split(label, num_batches, axis=1) # 返回一个长度为num_batches的数组，其中每一项包括一个data矩阵和一个label矩阵。 return list(zip(data_batches, label_batches))基于RNN的神经语言模型双层LSTM1234567891011121314151617# 设置参数TRAIN_DATA = "ptb.train" # 训练数据路径。EVAL_DATA = "ptb.valid" # 验证数据路径。TEST_DATA = "ptb.test" # 测试数据路径。HIDDEN_SIZE = 300 # 隐藏层规模。NUM_LAYERS = 2 # 深层循环神经网络中LSTM结构的层数。VOCAB_SIZE = 10000 # 词典规模。TRAIN_BATCH_SIZE = 20 # 训练数据batch的大小。TRAIN_NUM_STEP = 35 # 训练数据截断长度。EVAL_BATCH_SIZE = 1 # 测试数据batch的大小。EVAL_NUM_STEP = 1 # 测试数据截断长度。NUM_EPOCH = 5 # 使用训练数据的轮数。LSTM_KEEP_PROB = 0.9 # LSTM节点不被dropout的概率。EMBEDDING_KEEP_PROB = 0.9 # 词向量不被dropout的概率。MAX_GRAD_NORM = 5 # 用于控制梯度膨胀的梯度大小上限。SHARE_EMB_AND_SOFTMAX = True # 在Softmax层和词向量层之间共享参数。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# 通过一个PTBModel类来描述模型，这样方便维护循环神经网络中的状态。class PTBModel(object): def __init__(self, is_training, batch_size, num_steps): # 记录使用的batch大小和截断长度。 self.batch_size = batch_size self.num_steps = num_steps # 定义每一步的输入和预期输出。两者的维度都是[batch_size, num_steps]。 self.input_data = tf.placeholder(tf.int32, [batch_size, num_steps]) self.targets = tf.placeholder(tf.int32, [batch_size, num_steps]) # 定义使用LSTM结构为循环体结构且使用dropout的深层循环神经网络。 dropout_keep_prob = LSTM_KEEP_PROB if is_training else 1.0 lstm_cells = [ tf.nn.rnn_cell.DropoutWrapper( tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE), output_keep_prob=dropout_keep_prob) for _ in range(NUM_LAYERS)] cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells) # 初始化最初的状态，即全零的向量。这个量只在每个epoch初始化第一个batch # 时使用。 self.initial_state = cell.zero_state(batch_size, tf.float32) # 定义单词的词向量矩阵。 embedding = tf.get_variable("embedding", [VOCAB_SIZE, HIDDEN_SIZE]) # 将输入单词转化为词向量。 inputs = tf.nn.embedding_lookup(embedding, self.input_data) # 只在训练时使用dropout。 if is_training: inputs = tf.nn.dropout(inputs, EMBEDDING_KEEP_PROB) # 定义输出列表。在这里先将不同时刻LSTM结构的输出收集起来，再一起提供给 # softmax层。 outputs = [] state = self.initial_state with tf.variable_scope("RNN"): for time_step in range(num_steps): if time_step &gt; 0: tf.get_variable_scope().reuse_variables() cell_output, state = cell(inputs[:, time_step, :], state) outputs.append(cell_output) # 把输出队列展开成[batch, hidden_size*num_steps]的形状，然后再 # reshape成[batch*numsteps, hidden_size]的形状。 output = tf.reshape(tf.concat(outputs, 1), [-1, HIDDEN_SIZE]) # Softmax层：将RNN在每个位置上的输出转化为各个单词的logits。 if SHARE_EMB_AND_SOFTMAX: weight = tf.transpose(embedding) else: weight = tf.get_variable("weight", [HIDDEN_SIZE, VOCAB_SIZE]) bias = tf.get_variable("bias", [VOCAB_SIZE]) logits = tf.matmul(output, weight) + bias # 定义交叉熵损失函数和平均损失。 loss = tf.nn.sparse_softmax_cross_entropy_with_logits( labels=tf.reshape(self.targets, [-1]), logits=logits) self.cost = tf.reduce_sum(loss) / batch_size self.final_state = state # 只在训练模型时定义反向传播操作。 if not is_training: return trainable_variables = tf.trainable_variables() # 控制梯度大小，定义优化方法和训练步骤。 grads, _ = tf.clip_by_global_norm( tf.gradients(self.cost, trainable_variables), MAX_GRAD_NORM) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0) self.train_op = optimizer.apply_gradients( zip(grads, trainable_variables))12345678910111213141516171819202122232425# 使用给定的模型model在数据data上运行train_op并返回在全部数据上的perplexity值。def run_epoch(session, model, batches, train_op, output_log, step): # 计算平均perplexity的辅助变量。 total_costs = 0.0 iters = 0 state = session.run(model.initial_state) # 训练一个epoch。 for x, y in batches: # 在当前batch上运行train_op并计算损失值。交叉熵损失函数计算的就是下一个单 # 词为给定单词的概率。 cost, state, _ = session.run( [model.cost, model.final_state, train_op], &#123;model.input_data: x, model.targets: y, model.initial_state: state&#125;) total_costs += cost iters += model.num_steps # 只有在训练时输出日志。 if output_log and step % 100 == 0: print("After %d steps, perplexity is %.3f" % ( step, np.exp(total_costs / iters))) step += 1 # 返回给定模型在给定数据上的perplexity值。 return step, np.exp(total_costs / iters)123456789101112131415161718192021222324252627282930313233343536373839404142# 主函数def main(): # 定义初始化函数。 initializer = tf.random_uniform_initializer(-0.05, 0.05) # 定义训练用的循环神经网络模型。 with tf.variable_scope("language_model", reuse=None, initializer=initializer): train_model = PTBModel(True, TRAIN_BATCH_SIZE, TRAIN_NUM_STEP) # 定义测试用的循环神经网络模型。它与train_model共用参数，但是没有dropout。 with tf.variable_scope("language_model", reuse=True, initializer=initializer): eval_model = PTBModel(False, EVAL_BATCH_SIZE, EVAL_NUM_STEP) # 训练模型。 with tf.Session() as session: tf.global_variables_initializer().run() train_batches = make_batches( read_data(TRAIN_DATA), TRAIN_BATCH_SIZE, TRAIN_NUM_STEP) eval_batches = make_batches( read_data(EVAL_DATA), EVAL_BATCH_SIZE, EVAL_NUM_STEP) test_batches = make_batches( read_data(TEST_DATA), EVAL_BATCH_SIZE, EVAL_NUM_STEP) step = 0 for i in range(NUM_EPOCH): print("In iteration: %d" % (i + 1)) step, train_pplx = run_epoch(session, train_model, train_batches, train_model.train_op, True, step) print("Epoch: %d Train Perplexity: %.3f" % (i + 1, train_pplx)) _, eval_pplx = run_epoch(session, eval_model, eval_batches, tf.no_op(), False, 0) print("Epoch: %d Eval Perplexity: %.3f" % (i + 1, eval_pplx)) _, test_pplx = run_epoch(session, eval_model, test_batches, tf.no_op(), False, 0) print("Test Perplexity: %.3f" % test_pplx)if __name__ == "__main__": main()9.3 神经网络机器翻译Seq2Seq模型也称为encoder-decoder模型训练1234567891011121314151617# 假设输入数据已经用9.2.1小节中的方法转换成了单词编号的格式。SRC_TRAIN_DATA = "./train.en" # 源语言输入文件。TRG_TRAIN_DATA = "./train.zh" # 目标语言输入文件。CHECKPOINT_PATH = "./seq2seq_ckpt" # checkpoint保存路径。 HIDDEN_SIZE = 1024 # LSTM的隐藏层规模。NUM_LAYERS = 2 # 深层循环神经网络中LSTM结构的层数。SRC_VOCAB_SIZE = 10000 # 源语言词汇表大小。TRG_VOCAB_SIZE = 4000 # 目标语言词汇表大小。BATCH_SIZE = 100 # 训练数据batch的大小。NUM_EPOCH = 5 # 使用训练数据的轮数。KEEP_PROB = 0.8 # 节点不被dropout的概率。MAX_GRAD_NORM = 5 # 用于控制梯度膨胀的梯度大小上限。SHARE_EMB_AND_SOFTMAX = True # 在Softmax层和词向量层之间共享参数。MAX_LEN = 50 # 限定句子的最大单词数量。SOS_ID = 1 # 目标语言词汇表中&lt;sos&gt;的ID。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 使用Dataset从一个文件中读取一个语言的数据。# 数据的格式为每行一句话，单词已经转化为单词编号。def MakeDataset(file_path): dataset = tf.data.TextLineDataset(file_path) # 根据空格将单词编号切分开并放入一个一维向量。 dataset = dataset.map(lambda string: tf.string_split([string]).values) # 将字符串形式的单词编号转化为整数。 dataset = dataset.map( lambda string: tf.string_to_number(string, tf.int32)) # 统计每个句子的单词数量，并与句子内容一起放入Dataset中。 dataset = dataset.map(lambda x: (x, tf.size(x))) return dataset# 从源语言文件src_path和目标语言文件trg_path中分别读取数据，并进行填充和# batching操作。def MakeSrcTrgDataset(src_path, trg_path, batch_size): # 首先分别读取源语言数据和目标语言数据。 src_data = MakeDataset(src_path) trg_data = MakeDataset(trg_path) # 通过zip操作将两个Dataset合并为一个Dataset。现在每个Dataset中每一项数据ds # 由4个张量组成： # ds[0][0]是源句子 # ds[0][1]是源句子长度 # ds[1][0]是目标句子 # ds[1][1]是目标句子长度 dataset = tf.data.Dataset.zip((src_data, trg_data)) # 删除内容为空（只包含&lt;EOS&gt;）的句子和长度过长的句子。 def FilterLength(src_tuple, trg_tuple): ((src_input, src_len), (trg_label, trg_len)) = (src_tuple, trg_tuple) src_len_ok = tf.logical_and( tf.greater(src_len, 1), tf.less_equal(src_len, MAX_LEN)) trg_len_ok = tf.logical_and( tf.greater(trg_len, 1), tf.less_equal(trg_len, MAX_LEN)) return tf.logical_and(src_len_ok, trg_len_ok) dataset = dataset.filter(FilterLength) # 从图9-5可知，解码器需要两种格式的目标句子： # 1.解码器的输入(trg_input)，形式如同"&lt;sos&gt; X Y Z" # 2.解码器的目标输出(trg_label)，形式如同"X Y Z &lt;eos&gt;" # 上面从文件中读到的目标句子是"X Y Z &lt;eos&gt;"的形式，我们需要从中生成"&lt;sos&gt; X Y Z" # 形式并加入到Dataset中。 def MakeTrgInput(src_tuple, trg_tuple): ((src_input, src_len), (trg_label, trg_len)) = (src_tuple, trg_tuple) trg_input = tf.concat([[SOS_ID], trg_label[:-1]], axis=0) return ((src_input, src_len), (trg_input, trg_label, trg_len)) dataset = dataset.map(MakeTrgInput) # 随机打乱训练数据。 dataset = dataset.shuffle(10000) # 规定填充后输出的数据维度。 padded_shapes = ( (tf.TensorShape([None]), # 源句子是长度未知的向量 tf.TensorShape([])), # 源句子长度是单个数字 (tf.TensorShape([None]), # 目标句子（解码器输入）是长度未知的向量 tf.TensorShape([None]), # 目标句子（解码器目标输出）是长度未知的向量 tf.TensorShape([]))) # 目标句子长度是单个数字 # 调用padded_batch方法进行batching操作。 batched_dataset = dataset.padded_batch(batch_size, padded_shapes) return batched_dataset1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# 定义NMTModel类来描述模型。class NMTModel(object): # 在模型的初始化函数中定义模型要用到的变量。 def __init__(self): # 定义编码器和解码器所使用的LSTM结构。 self.enc_cell = tf.nn.rnn_cell.MultiRNNCell( [tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) for _ in range(NUM_LAYERS)]) self.dec_cell = tf.nn.rnn_cell.MultiRNNCell( [tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) for _ in range(NUM_LAYERS)]) # 为源语言和目标语言分别定义词向量。 self.src_embedding = tf.get_variable( "src_emb", [SRC_VOCAB_SIZE, HIDDEN_SIZE]) self.trg_embedding = tf.get_variable( "trg_emb", [TRG_VOCAB_SIZE, HIDDEN_SIZE]) # 定义softmax层的变量 if SHARE_EMB_AND_SOFTMAX: self.softmax_weight = tf.transpose(self.trg_embedding) else: self.softmax_weight = tf.get_variable( "weight", [HIDDEN_SIZE, TRG_VOCAB_SIZE]) self.softmax_bias = tf.get_variable( "softmax_bias", [TRG_VOCAB_SIZE]) # 在forward函数中定义模型的前向计算图。 # src_input, src_size, trg_input, trg_label, trg_size分别是上面 # MakeSrcTrgDataset函数产生的五种张量。 def forward(self, src_input, src_size, trg_input, trg_label, trg_size): batch_size = tf.shape(src_input)[0] # 将输入和输出单词编号转为词向量。 src_emb = tf.nn.embedding_lookup(self.src_embedding, src_input) trg_emb = tf.nn.embedding_lookup(self.trg_embedding, trg_input) # 在词向量上进行dropout。 src_emb = tf.nn.dropout(src_emb, KEEP_PROB) trg_emb = tf.nn.dropout(trg_emb, KEEP_PROB) # 使用dynamic_rnn构造编码器。 # 编码器读取源句子每个位置的词向量，输出最后一步的隐藏状态enc_state。 # 因为编码器是一个双层LSTM，因此enc_state是一个包含两个LSTMStateTuple类 # 张量的tuple，每个LSTMStateTuple对应编码器中的一层。 # enc_outputs是顶层LSTM在每一步的输出，它的维度是[batch_size, # max_time, HIDDEN_SIZE]。Seq2Seq模型中不需要用到enc_outputs，而 # 后面介绍的attention模型会用到它。 with tf.variable_scope("encoder"): enc_outputs, enc_state = tf.nn.dynamic_rnn( self.enc_cell, src_emb, src_size, dtype=tf.float32) # 使用dyanmic_rnn构造解码器。 # 解码器读取目标句子每个位置的词向量，输出的dec_outputs为每一步 # 顶层LSTM的输出。dec_outputs的维度是 [batch_size, max_time, # HIDDEN_SIZE]。 # initial_state=enc_state表示用编码器的输出来初始化第一步的隐藏状态。 with tf.variable_scope("decoder"): dec_outputs, _ = tf.nn.dynamic_rnn( self.dec_cell, trg_emb, trg_size, initial_state=enc_state) # 计算解码器每一步的log perplexity。这一步与语言模型代码相同。 output = tf.reshape(dec_outputs, [-1, HIDDEN_SIZE]) logits = tf.matmul(output, self.softmax_weight) + self.softmax_bias loss = tf.nn.sparse_softmax_cross_entropy_with_logits( labels=tf.reshape(trg_label, [-1]), logits=logits) # 在计算平均损失时，需要将填充位置的权重设置为0，以避免无效位置的预测干扰 # 模型的训练。 label_weights = tf.sequence_mask( trg_size, maxlen=tf.shape(trg_label)[1], dtype=tf.float32) label_weights = tf.reshape(label_weights, [-1]) cost = tf.reduce_sum(loss * label_weights) cost_per_token = cost / tf.reduce_sum(label_weights) # 定义反向传播操作。反向操作的实现与语言模型代码相同。 trainable_variables = tf.trainable_variables() # 控制梯度大小，定义优化方法和训练步骤。 grads = tf.gradients(cost / tf.to_float(batch_size), trainable_variables) grads, _ = tf.clip_by_global_norm(grads, MAX_GRAD_NORM) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0) train_op = optimizer.apply_gradients( zip(grads, trainable_variables)) return cost_per_token, train_op123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 使用给定的模型model上训练一个epoch，并返回全局步数。# 每训练200步便保存一个checkpoint。def run_epoch(session, cost_op, train_op, saver, step): # 训练一个epoch。 # 重复训练步骤直至遍历完Dataset中所有数据。 while True: try: # 运行train_op并计算损失值。训练数据在main()函数中以Dataset方式提供。 cost, _ = session.run([cost_op, train_op]) if step % 10 == 0: print("After %d steps, per token cost is %.3f" % (step, cost)) # 每200步保存一个checkpoint。 if step % 200 == 0: saver.save(session, CHECKPOINT_PATH, global_step=step) step += 1 except tf.errors.OutOfRangeError: break return stepdef main(): # 定义初始化函数。 initializer = tf.random_uniform_initializer(-0.05, 0.05) # 定义训练用的循环神经网络模型。 with tf.variable_scope("nmt_model", reuse=None, initializer=initializer): train_model = NMTModel() # 定义输入数据。 data = MakeSrcTrgDataset(SRC_TRAIN_DATA, TRG_TRAIN_DATA, BATCH_SIZE) iterator = data.make_initializable_iterator() (src, src_size), (trg_input, trg_label, trg_size) = iterator.get_next() # 定义前向计算图。输入数据以张量形式提供给forward函数。 cost_op, train_op = train_model.forward(src, src_size, trg_input, trg_label, trg_size) # 训练模型。 saver = tf.train.Saver() step = 0 with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(NUM_EPOCH): print("In iteration: %d" % (i + 1)) sess.run(iterator.initializer) step = run_epoch(sess, cost_op, train_op, saver, step)if __name__ == "__main__": main()测试123import tensorflow as tfimport codecsimport sys123456789101112131415161718# 读取checkpoint的路径。9000表示是训练程序在第9000步保存的checkpoint。CHECKPOINT_PATH = "./seq2seq_ckpt-9000"# 模型参数。必须与训练时的模型参数保持一致。HIDDEN_SIZE = 1024 # LSTM的隐藏层规模。NUM_LAYERS = 2 # 深层循环神经网络中LSTM结构的层数。SRC_VOCAB_SIZE = 10000 # 源语言词汇表大小。TRG_VOCAB_SIZE = 4000 # 目标语言词汇表大小。SHARE_EMB_AND_SOFTMAX = True # 在Softmax层和词向量层之间共享参数。# 词汇表文件SRC_VOCAB = "./en.vocab"TRG_VOCAB = "./zh.vocab"# 词汇表中&lt;sos&gt;和&lt;eos&gt;的ID。在解码过程中需要用&lt;sos&gt;作为第一步的输入，并将检查# 是否是&lt;eos&gt;，因此需要知道这两个符号的ID。SOS_ID = 1EOS_ID = 2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081# 定义NMTModel类来描述模型。class NMTModel(object): # 在模型的初始化函数中定义模型要用到的变量。 def __init__(self): # 定义编码器和解码器所使用的LSTM结构。 self.enc_cell = tf.nn.rnn_cell.MultiRNNCell( [tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) for _ in range(NUM_LAYERS)]) self.dec_cell = tf.nn.rnn_cell.MultiRNNCell( [tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE) for _ in range(NUM_LAYERS)]) # 为源语言和目标语言分别定义词向量。 self.src_embedding = tf.get_variable( "src_emb", [SRC_VOCAB_SIZE, HIDDEN_SIZE]) self.trg_embedding = tf.get_variable( "trg_emb", [TRG_VOCAB_SIZE, HIDDEN_SIZE]) # 定义softmax层的变量 if SHARE_EMB_AND_SOFTMAX: self.softmax_weight = tf.transpose(self.trg_embedding) else: self.softmax_weight = tf.get_variable( "weight", [HIDDEN_SIZE, TRG_VOCAB_SIZE]) self.softmax_bias = tf.get_variable( "softmax_bias", [TRG_VOCAB_SIZE]) def inference(self, src_input): # 虽然输入只有一个句子，但因为dynamic_rnn要求输入是batch的形式，因此这里 # 将输入句子整理为大小为1的batch。 src_size = tf.convert_to_tensor([len(src_input)], dtype=tf.int32) src_input = tf.convert_to_tensor([src_input], dtype=tf.int32) src_emb = tf.nn.embedding_lookup(self.src_embedding, src_input) # 使用dynamic_rnn构造编码器。这一步与训练时相同。 with tf.variable_scope("encoder"): enc_outputs, enc_state = tf.nn.dynamic_rnn( self.enc_cell, src_emb, src_size, dtype=tf.float32) # 设置解码的最大步数。这是为了避免在极端情况出现无限循环的问题。 MAX_DEC_LEN=100 with tf.variable_scope("decoder/rnn/multi_rnn_cell"): # 使用一个变长的TensorArray来存储生成的句子。 init_array = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True, clear_after_read=False) # 填入第一个单词&lt;sos&gt;作为解码器的输入。 init_array = init_array.write(0, SOS_ID) # 构建初始的循环状态。循环状态包含循环神经网络的隐藏状态，保存生成句子的 # TensorArray，以及记录解码步数的一个整数step。 init_loop_var = (enc_state, init_array, 0) # tf.while_loop的循环条件： # 循环直到解码器输出&lt;eos&gt;，或者达到最大步数为止。 def continue_loop_condition(state, trg_ids, step): return tf.reduce_all(tf.logical_and( tf.not_equal(trg_ids.read(step), EOS_ID), tf.less(step, MAX_DEC_LEN-1))) def loop_body(state, trg_ids, step): # 读取最后一步输出的单词，并读取其词向量。 trg_input = [trg_ids.read(step)] trg_emb = tf.nn.embedding_lookup(self.trg_embedding, trg_input) # 这里不使用dynamic_rnn，而是直接调用dec_cell向前计算一步。 dec_outputs, next_state = self.dec_cell.call( state=state, inputs=trg_emb) # 计算每个可能的输出单词对应的logit，并选取logit值最大的单词作为 # 这一步的而输出。 output = tf.reshape(dec_outputs, [-1, HIDDEN_SIZE]) logits = (tf.matmul(output, self.softmax_weight) + self.softmax_bias) next_id = tf.argmax(logits, axis=1, output_type=tf.int32) # 将这一步输出的单词写入循环状态的trg_ids中。 trg_ids = trg_ids.write(step+1, next_id[0]) return next_state, trg_ids, step+1 # 执行tf.while_loop，返回最终状态。 state, trg_ids, step = tf.while_loop( continue_loop_condition, loop_body, init_loop_var) return trg_ids.stack()123456789101112131415161718192021222324252627282930313233343536373839# 翻译一个测试句子def main(): # 定义训练用的循环神经网络模型。 with tf.variable_scope("nmt_model", reuse=None): model = NMTModel() # 定义个测试句子。 test_en_text = "This is a test . &lt;eos&gt;" print(test_en_text) # 根据英文词汇表，将测试句子转为单词ID。 with codecs.open(SRC_VOCAB, "r", "utf-8") as f_vocab: src_vocab = [w.strip() for w in f_vocab.readlines()] src_id_dict = dict((src_vocab[x], x) for x in range(len(src_vocab))) test_en_ids = [(src_id_dict[token] if token in src_id_dict else src_id_dict['&lt;unk&gt;']) for token in test_en_text.split()] print(test_en_ids) # 建立解码所需的计算图。 output_op = model.inference(test_en_ids) sess = tf.Session() saver = tf.train.Saver() saver.restore(sess, CHECKPOINT_PATH) # 读取翻译结果。 output_ids = sess.run(output_op) print(output_ids) # 根据中文词汇表，将翻译结果转换为中文文字。 with codecs.open(TRG_VOCAB, "r", "utf-8") as f_vocab: trg_vocab = [w.strip() for w in f_vocab.readlines()] output_text = ''.join([trg_vocab[x] for x in output_ids]) # 输出翻译结果。 print(output_text.encode('utf8').decode(sys.stdout.encoding)) sess.close()if __name__ == "__main__": main()注意力机制]]></content>
      <categories>
        <category>实战Google深度学习框架笔记</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Google深度学习框架-第3~5章]]></title>
    <url>%2F2020%2F01%2F08%2F%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6-%E7%AC%AC3-5%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[3.1计算图定义两个不同的图1234567891011121314151617181920212223import tensorflow as tfg1 = tf.Graph()with g1.as_default(): # 在计算图g1中定义变量“v” v = tf.get_variable("v", [1], initializer = tf.zeros_initializer()) # 设置初始值为0g2 = tf.Graph()with g2.as_default(): v = tf.get_variable("v", [1], initializer = tf.ones_initializer()) # 设置初始值为1 with tf.Session(graph = g1) as sess: tf.global_variables_initializer().run() with tf.variable_scope("", reuse=True): print(sess.run(tf.get_variable("v")))with tf.Session(graph = g2) as sess: tf.global_variables_initializer().run() with tf.variable_scope("", reuse=True): print(sess.run(tf.get_variable("v"))) # [0.]# [1.]计算图不仅仅可以用来隔离张量和计算，也提供了管理张量和计算张量的机制。tf.Graph.device ：指定运行计算的设备123456789101112g = tf.Graph()with g.as_default(): a = tf.constant(1.0, name="a") b = tf.constant(2.0, name="b")with g.device('/gpu:0'): result = a + b with tf.Session(graph = g) as sess: tf.global_variables_initializer().run() print(sess.run(result))3.2~3.3张量和会话张量（tensor）只是对运算结果的引用。123456789101112import tensorflow as tfa = tf.constant([1.0, 2.0], name="a")b = tf.constant([2.0, 3.0], name="b")result = a + b# Tensor("add:0", shape=(2,), dtype=float32)# 张量的三个属性：name、shape、typeprint(result)# 使用tf.InteractiveSession构建会话sess = tf.InteractiveSession ()print(result.eval())sess.close()通过ConfigProto配置会话123config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)sess1 = tf.InteractiveSession(config=config)sess2 = tf.Session(config=config)3.4简易神经网络1234567891011121314151617181920212223import tensorflow as tf# 声明变量、设置x常量w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))x = tf.constant([[0.7, 0.9]]) # [1, 2]a = tf.matmul(x, w1) # [1, 3]y = tf.matmul(a, w2)# sess = tf.Session()# sess.run(w1.initializer) # sess.run(w2.initializer) # print(sess.run(y)) # sess.close()with tf.Session() as sess: # sess.run(w1.initializer) # sess.run(w2.initializer) tf.global_variables_initializer().run() # print(sess.run(y)) print(sess.run(y, feed_dict=&#123;x: [[0.7,0.9]]&#125;)) # [[3.957578]]完整例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546import tensorflow as tffrom numpy.random import RandomStatebatch_size = 8w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))x = tf.placeholder(tf.float32, shape=(None, 2), name="x-input")y_= tf.placeholder(tf.float32, shape=(None, 1), name='y-input')# 前向传播a = tf.matmul(x, w1)y = tf.matmul(a, w2)y = tf.sigmoid(y)cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)# 生成模拟数据集rdm = RandomState(1)X = rdm.rand(128,2)Y = [[int(x1+x2 &lt; 1)] for (x1, x2) in X]with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) # 输出目前（未经训练）的参数取值。 print(sess.run(w1)) print(sess.run(w2)) print("\n") # 训练模型。 STEPS = 5000 for i in range(STEPS): start = (i*batch_size) % 128 end = (i*batch_size) % 128 + batch_size sess.run([train_step, y, y_], feed_dict=&#123;x: X[start:end], y_: Y[start:end]&#125;) if i % 1000 == 0: total_cross_entropy = sess.run(cross_entropy, feed_dict=&#123;x: X, y_: Y&#125;) print("After %d training step(s), cross entropy on all data is %g" % (i, total_cross_entropy)) # 输出训练后的参数取值。 print("\n") print(sess.run(w1)) print(sess.run(w2))4.1激活函数激活函数可以实现去线性化。4.2损失函数交叉熵：$H(p,q)=-\sum \limits_x p(x)log\;q(x)$12cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)) + (1 - y_) * tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))1cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)$MSE(y,y’)=\frac{\sum \limits _{i=1}^n (y_i-y_i’)^2}{n}$1loss = tf.losses.mean_squared_error(y, y_)4.4神经网络优化4.4.1学习率指数衰减的学习率1LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True)4.4.2正则化4.4.1学习率12345678910111213141516171819202122232425# 生成模拟数据集import tensorflow as tfimport matplotlib.pyplot as pltimport numpy as npdata = []label = []np.random.seed(0)# 以原点为圆心，半径为1的圆把散点划分成红蓝两部分，并加入随机噪音。for i in range(150): x1 = np.random.uniform(-1,1) x2 = np.random.uniform(0,2) if x1**2 + x2**2 &lt;= 1: data.append([np.random.normal(x1, 0.1),np.random.normal(x2,0.1)]) label.append(0) else: data.append([np.random.normal(x1, 0.1), np.random.normal(x2, 0.1)]) label.append(1) data = np.hstack(data).reshape(-1,2)label = np.hstack(label).reshape(-1, 1)plt.scatter(data[:,0], data[:,1], c=np.squeeze(label), cmap="RdBu", vmin=-.2, vmax=1.2, edgecolor="white")plt.show()12345# 定义一个获取权重，并自动加入正则项到损失的函数def get_weight(shape, lambda1): var = tf.Variable(tf.random_normal(shape), dtype=tf.float32) tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(var)) return var1234567891011121314151617181920212223242526x = tf.placeholder(tf.float32, shape=(None, 2))y_ = tf.placeholder(tf.float32, shape=(None, 1))sample_size = len(data)# 每层节点的个数layer_dimension = [2,10,5,3,1]n_layers = len(layer_dimension)cur_layer = xin_dimension = layer_dimension[0]# 循环生成网络结构for i in range(1, n_layers): out_dimension = layer_dimension[i] weight = get_weight([in_dimension, out_dimension], 0.003) bias = tf.Variable(tf.constant(0.1, shape=[out_dimension])) cur_layer = tf.nn.elu(tf.matmul(cur_layer, weight) + bias) in_dimension = layer_dimension[i]y= cur_layer# 损失函数的定义。mse_loss = tf.reduce_sum(tf.pow(y_ - y, 2)) / sample_sizetf.add_to_collection('losses', mse_loss)loss = tf.add_n(tf.get_collection('losses'))123456789101112131415161718192021# 定义训练的目标函数mse_loss，训练次数及训练模型train_op = tf.train.AdamOptimizer(0.001).minimize(mse_loss)TRAINING_STEPS = 40000with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(TRAINING_STEPS): sess.run(train_op, feed_dict=&#123;x: data, y_: label&#125;) if i % 2000 == 0: print("After %d steps, mse_loss: %f" % (i,sess.run(mse_loss, feed_dict=&#123;x: data, y_: label&#125;))) # 画出训练后的分割曲线 xx, yy = np.mgrid[-1.2:1.2:.01, -0.2:2.2:.01] grid = np.c_[xx.ravel(), yy.ravel()] probs = sess.run(y, feed_dict=&#123;x:grid&#125;) probs = probs.reshape(xx.shape)plt.scatter(data[:,0], data[:,1], c=np.squeeze(label), cmap="RdBu", vmin=-.2, vmax=1.2, edgecolor="white")plt.contour(xx, yy, probs, levels=[.5], cmap="Greys", vmin=0, vmax=.1)plt.show()123456789101112131415161718192021# 定义训练的目标函数loss，训练次数及训练模型train_op = tf.train.AdamOptimizer(0.001).minimize(loss)TRAINING_STEPS = 40000with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(TRAINING_STEPS): sess.run(train_op, feed_dict=&#123;x: data, y_: label&#125;) if i % 2000 == 0: print("After %d steps, loss: %f" % (i, sess.run(loss, feed_dict=&#123;x: data, y_: label&#125;))) # 画出训练后的分割曲线 xx, yy = np.mgrid[-1:1:.01, 0:2:.01] grid = np.c_[xx.ravel(), yy.ravel()] probs = sess.run(y, feed_dict=&#123;x:grid&#125;) probs = probs.reshape(xx.shape)plt.scatter(data[:,0], data[:,1], c=np.squeeze(label), cmap="RdBu", vmin=-.2, vmax=1.2, edgecolor="white")plt.contour(xx, yy, probs, levels=[.5], cmap="Greys", vmin=0, vmax=.1)plt.show()4.4.3滑动平均模型影子变量$shadow_variable = decay\times shadow_variable + (1-decay)\times shadow_variable$1ema = tf.train.ExponentialMovingAverage(0.99, step)ExponentialMovingAverage还提供了num_updates$decay = min\{decay,\frac{1+num_updates}{10+num_updates}\}$12345678910111213141516171819202122232425262728293031323334353637import tensorflow as tfv1 = tf.Variable(0, dtype=tf.float32)step = tf.Variable(0, trainable=False)ema = tf.train.ExponentialMovingAverage(0.99, step)maintain_averages_op = ema.apply([v1]) with tf.Session() as sess: # 初始化 init_op = tf.global_variables_initializer() sess.run(init_op) # [0.0, 0.0] print(sess.run([v1, ema.average(v1)])) # 更新变量v1的取值 sess.run(tf.assign(v1, 5)) sess.run(maintain_averages_op) # [5.0, 4.5] # decay = min&#123;0.99, (1+step)/(10+step) = 0.1&#125; = 0.1 # 0.1x0 + 0.9x5 = 4.5 print(sess.run([v1, ema.average(v1)])) # 更新step和v1的取值 sess.run(tf.assign(step, 10000)) sess.run(tf.assign(v1, 10)) sess.run(maintain_averages_op) # [10.0, 4.555] # decay = min&#123;0.99, (1+step)/(10+step) ~ 0.999&#125; = 0.99 # 0.99x4.5 + 0.01x10 = 4.555 print(sess.run([v1, ema.average(v1)])) # 更新一次v1的滑动平均值 sess.run(maintain_averages_op) # [10.0, 4.60945] # 0.99x4.555 + 0.01x10 = 4.60945 print(sess.run([v1, ema.average(v1)]))5.1MNIST123456# 读取数据集from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("../../datasets/MNIST_data/", one_hot=True)# import tensorflow as tf# mnist = tf.keras.datasets.mnist# (X_train, y_train), (X_test, y_test) = mnist.load_data()123456print("Training data size: ", mnist.train.num_examples)print("Validating data size: ", mnist.validation.num_examples)print("Testing data size: ", mnist.test.num_examples)# Training data size: 55000# Validating data size: 5000# Testing data size: 1000012print("Example training data: ", mnist.train.images[0]) print("Example training data label: ", mnist.train.labels[0])1234567# 使用mnist.train.next_batch来实现随机梯度下降batch_size = 100xs, ys = mnist.train.next_batch(batch_size) # 从train的集合中选取batch_size个训练数据。print("X shape:", xs.shape) print("Y shape:", ys.shape)# X shape: (100, 784)# Y shape: (100, 10)训练神经网络123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataINPUT_NODE = 784 # 输入节点OUTPUT_NODE = 10 # 输出节点LAYER1_NODE = 500 # 隐藏层数 BATCH_SIZE = 100 # 每次batch打包的样本个数 # 模型相关的参数LEARNING_RATE_BASE = 0.8 LEARNING_RATE_DECAY = 0.99 REGULARAZTION_RATE = 0.0001 TRAINING_STEPS = 5000 MOVING_AVERAGE_DECAY = 0.99 # 定义辅助函数def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2): # 不使用滑动平均类 if avg_class == None: layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1) return tf.matmul(layer1, weights2) + biases2 else: # 使用滑动平均类 layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1)) return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2) # 定义训练过程def train(mnist): x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input') y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input') # 生成隐藏层的参数。 weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1)) biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE])) # 生成输出层的参数。 weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1)) biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE])) # 计算不含滑动平均类的前向传播结果 y = inference(x, None, weights1, biases1, weights2, biases2) # 定义训练轮数及相关的滑动平均类 global_step = tf.Variable(0, trainable=False) variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step) variables_averages_op = variable_averages.apply(tf.trainable_variables()) average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2) # 计算交叉熵及其平均值 cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1)) cross_entropy_mean = tf.reduce_mean(cross_entropy) # 损失函数的计算 regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE) regularaztion = regularizer(weights1) + regularizer(weights2) loss = cross_entropy_mean + regularaztion # 设置指数衰减的学习率。 learning_rate = tf.train.exponential_decay( LEARNING_RATE_BASE, global_step, mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY, staircase=True) # 优化损失函数 train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step) # 反向传播更新参数和更新每一个参数的滑动平均值 with tf.control_dependencies([train_step, variables_averages_op]): train_op = tf.no_op(name='train') # 计算正确率 correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 初始化会话，并开始训练过程。 with tf.Session() as sess: tf.global_variables_initializer().run() validate_feed = &#123;x: mnist.validation.images, y_: mnist.validation.labels&#125; test_feed = &#123;x: mnist.test.images, y_: mnist.test.labels&#125; # 循环的训练神经网络。 for i in range(TRAINING_STEPS): if i % 1000 == 0: validate_acc = sess.run(accuracy, feed_dict=validate_feed) print("After %d training step(s), validation accuracy using average model is %g " % (i, validate_acc)) xs,ys=mnist.train.next_batch(BATCH_SIZE) sess.run(train_op,feed_dict=&#123;x:xs,y_:ys&#125;) test_acc=sess.run(accuracy,feed_dict=test_feed) print(("After %d training step(s), test accuracy using average model is %g" %(TRAINING_STEPS, test_acc))) def main(argv=None): mnist = input_data.read_data_sets("../../../datasets/MNIST_data", one_hot=True) train(mnist)if __name__=='__main__': main()变量管理1234567891011121314import tensorflow as tfwith tf.variable_scope("foo"): v = tf.get_variable("v", [1], initializer=tf.constant_initializer(1.0)) #with tf.variable_scope("foo"): # v = tf.get_variable("v", [1]) with tf.variable_scope("foo", reuse=True): v1 = tf.get_variable("v", [1])print(v == v1) # True#with tf.variable_scope("bar", reuse=True): # v = tf.get_variable("v", [1])1234567891011121314151617181920# 通过variable_scope来管理变量v1 = tf.get_variable("v", [1])print(v1.name)with tf.variable_scope("foo",reuse=True): v2 = tf.get_variable("v", [1]) print(v2.name)with tf.variable_scope("foo"): with tf.variable_scope("bar"): v3 = tf.get_variable("v", [1]) print(v3.name) v4 = tf.get_variable("v1", [1])print(v4.name)# v:0# foo/v:0# foo/bar/v:0# v1:0模型持久化1234567891011# 保存计算两个变量和的模型v1 = tf.Variable(tf.random_normal([1], stddev=1, seed=1))v2 = tf.Variable(tf.random_normal([1], stddev=1, seed=1))result = v1 + v2init_op = tf.global_variables_initializer()saver = tf.train.Saver()with tf.Session() as sess: sess.run(init_op) saver.save(sess, "Saved_model/model.ckpt")1234# 加载保存了两个变量和的模型with tf.Session() as sess: saver.restore(sess, "Saved_model/model.ckpt") print(sess.run(result))1234# 变量重命名v1 = tf.Variable(tf.constant(1.0, shape=[1]), name = "other-v1")v2 = tf.Variable(tf.constant(2.0, shape=[1]), name = "other-v2")saver = tf.train.Saver(&#123;"v1": v1, "v2": v2&#125;)滑动平均类的保存variables_to_restore()pb文件保存]]></content>
      <categories>
        <category>实战Google深度学习框架笔记</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（4-3）]]></title>
    <url>%2F2020%2F01%2F06%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%884-3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目标检测（Object detection）3.1 目标定位（Object localization）定义：图片分类定位分类符号表示：这有四个分类，神经网络输出的是这四个数字和一个分类标签，或分类标签出现的概率。目标标签$y$的定义如下：$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$它是一个向量，第一个组件$p_{c}$表示是否含有对象，如果对象属于前三类（行人、汽车、摩托车），则$p_{c}= 1$，如果是背景，则图片中没有要检测的对象，则$p_{c} =0$。当$y_1=1$时：$L\left(\hat{y},y \right) = \left( \hat{y_1} - y_{1} \right)^{2} + \left(\hat{y_2} - y_{2}\right)^{2} + \ldots\left( \hat{y_8} - y_{8}\right)^{2}$当$y_1=0$时：$L\left(\hat{y},y \right) = \left( \hat{y_1} - y_{1} \right)^{2} $实际应用中，可以使用更好的方式是：不对$c_{1}$、$c_{2}$、$c_{3}$和softmax激活函数应用对数损失函数，并输出其中一个元素值对边界框坐标应用平方差或类似方法对$P_c$应用逻辑回归函数，甚至采用平方预测误差3.2 特征点检测（Landmark detection）假设你正在构建一个人脸识别应用，出于某种原因，你希望算法可以给出眼角的具体位置。眼角坐标为$(x,y)$，你可以让神经网络的最后一层多输出两个数字$l_{x}$和$l_{y}$，作为眼角的坐标值。除了眼角的四个坐标值，也可以设定特征点的个数，假设脸部有64个特征点。具体做法是，准备一个卷积网络和一些特征集，将人脸图片输入卷积网络，输出1或0，1表示有人脸，0表示没有人脸，然后输出（$l_{1x}$，$l_{1y}$）……直到（$l_{64x}$，$l_{64y}$）。这里我用$l$代表一个特征，这里有129个输出单元，其中1表示图片中有人脸，因为有64个特征，64×2=128，所以最终输出128+1=129个单元，由此实现对图片的人脸检测和定位。3.3 目标检测（Object detection）构建一个汽车检测算法：创建一个标签训练集使用适当剪切的图片，汽车居于中间位置，并基本占据整张图片训练卷积网络，用于实现滑动窗口目标检测滑动窗口目标检测首先选定一个特定大小的窗口，将窗口内的图片输入到模型中进行预测；以固定步幅滑动该窗口，遍历图像的每个区域，对窗内的各个小图不断输入模型进行预测；继续选取一个更大的窗口，再次遍历图像的每个区域，对区域内是否有车进行预测；遍历整个图像，可以保证在每个位置都能检测到是否有车。滑动窗口目标检测算法也有很明显的缺点，就是计算成本，因为你在图片中剪切出太多小方块，卷积网络要一个个地处理。如果你选用的步幅很大，显然会减少输入卷积网络的窗口个数，但是粗糙间隔尺寸可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积网络的小窗口会特别多，这意味着超高的计算成本。3.4 滑动窗口的卷积实现（Convolutional implementation of sliding windows）通过卷积实现滑动窗口对象检测算法假设向滑动窗口卷积网络输入14×14×3的图片。假设输入给卷积网络的图片大小是14×14×3，测试集图片是16×16×3，现在给这个输入图片加上黄色条块，在最初的滑动窗口算法中，你会把这片蓝色区域输入卷积网络（红色笔标记）生成0或1分类。接着滑动窗口，步幅为2个像素。结果发现，这4次卷积操作中很多计算都是重复的。所以执行滑动窗口的卷积时使得卷积网络在这4次前向传播过程中共享很多计算，尤其是在这一步操作中（编号1），卷积网络运行同样的参数，使得相同的5×5×16过滤器进行卷积操作，得到12×12×16的输出层。最终，在输出层这4个子方块中，每个小方块代表之前不同的滑动窗口的输出。所以该卷积操作的原理是我们不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公共区域可以共享很多计算。不过这种算法仍然存在一个缺点，就是边界框的位置可能不够准确。3.5 Bounding Box预测（Bounding box predictions）YOLO算法：比如你的输入图像是100×100的，然后在图像上放一个网格。基本思路是使用图像分类和定位算法，将算法应用到9个格子上。对于9个格子中的每一个指定一个标签$y$，$y$是8维的，$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$，$p_{c}$等于0或1取决于这个绿色格子中是否有图像。然后$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$作用就是，如果那个格子里有对象，那么就给出边界框坐标。所以对于这里9个格子中任何一个，你都会得到一个8维输出向量，因为这里是3×3的网格，所以有9个格子，总的输出尺寸是3×3×8，所以目标输出是3×3×8。将对象分配到一个格子的过程是：观察对象的中点，将该对象分配到其中点所在的格子中，（即使对象横跨多个格子，也只分配到中点所在的格子中，其他格子记为无该对象，即标记为“0”）；YOLO显式地输出边界框，使得其可以具有任意宽高比，并且能输出更精确的坐标，不受滑动窗口算法滑动步幅大小的限制；YOLO是一次卷积实现，并不是在n×n网格上进行n2次运算，而是单次卷积实现，算法实现效率高，运行速度快，可以实现实时识别。Specify the bounding boxes：在YOLO算法中，对于这个方框（编号1所示），我们约定左上这个点是$(0,0)$，然后右下这个点是$(1,1)$,要指定橙色中点的位置，$b_{x}$大概是0.4，因为它的位置大概是水平长度的0.4，然后$b_{y}$大概是0.3，然后边界框的高度用格子总体宽度的比例表示，所以这个红框的宽度可能是蓝线（编号2所示的蓝线）的90%，所以$b_{h}$是0.9，它的高度也许是格子总体高度的一半，这样的话$b_{w}$就是0.5。换句话说，$b_{x}$、$b_{y}$、$b_{h}$和$b_{w}$单位是相对于格子尺寸的比例，所以$b_{x}$和$b_{y}$必须在0和1之间，因为从定义上看，橙色点位于对象分配到格子的范围内，如果它不在0和1之间，如果它在方块外，那么这个对象就应该分配到另一个格子上。这个值（$b_{h}$和$b_{w}$）可能会大于1，特别是如果有一辆汽车的边界框是这样的（编号3所示），那么边界框的宽度和高度有可能大于1。3.6 交并比（Intersection over union）一般约定，在计算机检测任务中，如果$loU≥0.5$，就说检测正确，如果预测器和实际边界框完美重叠，loU就是1，因为交集就等于并集。3.7 非极大值抑制（Non-max suppression）非极大值抑制这个方法可以确保你的算法对每个对象只检测一次。假设你需要在这张图片里检测行人和汽车，你可能会在上面放个19×19网格，理论上这辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以理论上应该只有一个格子做出有车的预测。最可靠的检测，就用高亮标记，然后非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。非最大值意味着你只输出概率最大的分类结果，但抑制很接近，但不是最大的其他预测结果，所以这方法叫做非极大值抑制。3.8 Anchor Boxes使用Anchor box 可以同时检测出多个对象。难点问题：如果我们使用了两个Anchor box，但是同一个格子中却有三个对象的情况，此时只能用一些额外的手段来处理；同一个格子中存在两个对象，但它们的Anchor box 形状相同，此时也需要引入一些专门处理该情况的手段。Anchor box 的选择：一般人工指定Anchor box 的形状，选择5~10个以覆盖到多种不同的形状，可以涵盖我们想要检测的对象的形状；高级方法：K-means 算法：将不同对象形状进行聚类，用聚类后的结果来选择一组最具代表性的Anchor box，以此来代表我们想要检测对象的形状。3.9 YOLO 算法（Putting it together: YOLO algorithm）运行非最大值抑制（NMS）：假设使用了2个Anchor box，那么对于每一个网格，我们都会得到预测输出的2个bounding boxes，其中一个$P_c$比较高；3.10 候选区域（选修）（Region proposals (Optional)）滑动窗法的缺点：在显然没有任何对象的区域浪费时间所以这里这个矩形区域（编号1）基本是空的，显然没有什么需要分类的东西。也许算法会在这个矩形上（编号2）运行。R-CNN选出候选区域的方法是运行图像分割算法，分割的结果是下边的图像。Car detection with YOLOAutonomous driving - Car detectionWelcome to your week 3 programming assignment. You will learn about object detection using the very powerful YOLO model. Many of the ideas in this notebook are described in the two YOLO papers: Redmon et al., 2016 and Redmon and Farhadi, 2016.You will learn to:Use object detection on a car detection datasetDeal with bounding boxesUpdatesIf you were working on the notebook before this update…The current notebook is version “3a”.You can find your original work saved in the notebook with the previous version name (“v3”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatesClarified “YOLO” instructions preceding the code.Added details about anchor boxes.Added explanation of how score is calculated.yolo_filter_boxes: added additional hints. Clarify syntax for argmax and max.iou: clarify instructions for finding the intersection.iou: give variable names for all 8 box vertices, for clarity. Adds width and height variables for clarity.iou: add test cases to check handling of non-intersecting boxes, intersection at vertices, or intersection at edges.yolo_non_max_suppression: clarify syntax for tf.image.non_max_suppression and keras.gather.“convert output of the model to usable bounding box tensors”: Provides a link to the definition of yolo_head.predict: hint on calling sess.run.Spelling, grammar, wording and formatting updates to improve clarity.Import librariesRun the following cell to load the packages and dependencies that you will find useful as you build the object detector!1234567891011121314151617import argparseimport osimport matplotlib.pyplot as pltfrom matplotlib.pyplot import imshowimport scipy.ioimport scipy.miscimport numpy as npimport pandas as pdimport PILimport tensorflow as tffrom keras import backend as Kfrom keras.layers import Input, Lambda, Conv2Dfrom keras.models import load_model, Modelfrom yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxesfrom yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body%matplotlib inlineImportant Note: As you can see, we import Keras’s backend as K. This means that to use a Keras function in this notebook, you will need to write: K.function(...).1 - Problem StatementYou are working on a self-driving car. As a critical component of this project, you’d like to first build a car detection system. To collect data, you’ve mounted a camera to the hood (meaning the front) of the car, which takes pictures of the road ahead every few seconds while you drive around.You’ve gathered all these images into a folder and have labelled them by drawing bounding boxes around every car you found. Here’s an example of what your bounding boxes look like.If you have 80 classes that you want the object detector to recognize, you can represent the class label $c$ either as an integer from 1 to 80, or as an 80-dimensional vector (with 80 numbers) one component of which is 1 and the rest of which are 0. The video lectures had used the latter representation; in this notebook, we will use both representations, depending on which is more convenient for a particular step.In this exercise, you will learn how “You Only Look Once” (YOLO) performs object detection, and then apply it to car detection. Because the YOLO model is very computationally expensive to train, we will load pre-trained weights for you to use.2 - YOLO“You Only Look Once” (YOLO) is a popular algorithm because it achieves high accuracy while also being able to run in real-time. This algorithm “only looks once” at the image in the sense that it requires only one forward propagation pass through the network to make predictions. After non-max suppression, it then outputs recognized objects together with the bounding boxes.2.1 - Model detailsInputs and outputsThe input is a batch of images, and each image has the shape (m, 608, 608, 3)The output is a list of bounding boxes along with the recognized classes. Each bounding box is represented by 6 numbers $(p_c, b_x, b_y, b_h, b_w, c)$ as explained above. If you expand $c$ into an 80-dimensional vector, each bounding box is then represented by 85 numbers.Anchor BoxesAnchor boxes are chosen by exploring the training data to choose reasonable height/width ratios that represent the different classes. For this assignment, 5 anchor boxes were chosen for you (to cover the 80 classes), and stored in the file ‘./model_data/yolo_anchors.txt’The dimension for anchor boxes is the second to last dimension in the encoding: $(m, n_H,n_W,anchors,classes)$.The YOLO architecture is: IMAGE (m, 608, 608, 3) -&gt; DEEP CNN -&gt; ENCODING (m, 19, 19, 5, 85).EncodingLet’s look in greater detail at what this encoding represents.If the center/midpoint of an object falls into a grid cell, that grid cell is responsible for detecting that object.Since we are using 5 anchor boxes, each of the 19 x19 cells thus encodes information about 5 boxes. Anchor boxes are defined only by their width and height.For simplicity, we will flatten the last two last dimensions of the shape (19, 19, 5, 85) encoding. So the output of the Deep CNN is (19, 19, 425).Class scoreNow, for each box (of each cell) we will compute the following element-wise product and extract a probability that the box contains a certain class.The class score is $score_{c,i} = p_{c} \times c_{i}$: the probability that there is an object $p_{c}$ times the probability that the object is a certain class $c_{i}$.Example of figure 4In figure 4, let’s say for box 1 (cell 1), the probability that an object exists is $p_{1}=0.60$. So there’s a 60% chance that an object exists in box 1 (cell 1).The probability that the object is the class “category 3 (a car)” is $c_{3}=0.73$.The score for box 1 and for category “3” is $score_{1,3}=0.60 \times 0.73 = 0.44$.Let’s say we calculate the score for all 80 classes in box 1, and find that the score for the car class (class 3) is the maximum. So we’ll assign the score 0.44 and class “3” to this box “1”.Visualizing classesHere’s one way to visualize what YOLO is predicting on an image:For each of the 19x19 grid cells, find the maximum of the probability scores (taking a max across the 80 classes, one maximum for each of the 5 anchor boxes).Color that grid cell according to what object that grid cell considers the most likely.Doing this results in this picture:Note that this visualization isn’t a core part of the YOLO algorithm itself for making predictions; it’s just a nice way of visualizing an intermediate result of the algorithm.Visualizing bounding boxesAnother way to visualize YOLO’s output is to plot the bounding boxes that it outputs. Doing that results in a visualization like this:Non-Max suppressionIn the figure above, we plotted only boxes for which the model had assigned a high probability, but this is still too many boxes. You’d like to reduce the algorithm’s output to a much smaller number of detected objects.To do so, you’ll use non-max suppression. Specifically, you’ll carry out these steps:Get rid of boxes with a low score (meaning, the box is not very confident about detecting a class; either due to the low probability of any object, or low probability of this particular class).Select only one box when several boxes overlap with each other and detect the same object.2.2 - Filtering with a threshold on class scoresYou are going to first apply a filter by thresholding. You would like to get rid of any box for which the class “score” is less than a chosen threshold.The model gives you a total of 19x19x5x85 numbers, with each box described by 85 numbers. It is convenient to rearrange the (19,19,5,85) (or (19,19,425)) dimensional tensor into the following variables:box_confidence: tensor of shape $(19 \times 19, 5, 1)$ containing $p_c$ (confidence probability that there’s some object) for each of the 5 boxes predicted in each of the 19x19 cells.boxes: tensor of shape $(19 \times 19, 5, 4)$ containing the midpoint and dimensions $(b_x, b_y, b_h, b_w)$ for each of the 5 boxes in each cell.box_class_probs: tensor of shape $(19 \times 19, 5, 80)$ containing the “class probabilities” $(c_1, c_2, … c_{80})$ for each of the 80 classes for each of the 5 boxes per cell.Exercise: Implement yolo_filter_boxes().Compute box scores by doing the elementwise product as described in Figure 4 ($p \times c$).The following code may help you choose the right operator:123a = np.random.randn(19*19, 5, 1)b = np.random.randn(19*19, 5, 80)c = a * b # shape of c will be (19*19, 5, 80)This is an example of broadcasting (multiplying vectors of different sizes).For each box, find:the index of the class with the maximum box scorethe corresponding box scoreUseful referencesKeras argmaxKeras maxAdditional Hints * For the `axis` parameter of `argmax` and `max`, if you want to select the **last** axis, one way to do so is to set `axis=-1`. This is similar to Python array indexing, where you can select the last position of an array using `arrayname[-1]`. * Applying `max` normally collapses the axis for which the maximum is applied. `keepdims=False` is the default option, and allows that dimension to be removed. We don&#39;t need to keep the last dimension after applying the maximum here. * Even though the documentation shows `keras.backend.argmax`, use `keras.argmax`. Similarly, use `keras.max`. Create a mask by using a threshold. As a reminder: ([0.9, 0.3, 0.4, 0.5, 0.1] &lt; 0.4) returns: [False, True, False, False, True]. The mask should be True for the boxes you want to keep.Use TensorFlow to apply the mask to box_class_scores, boxes and box_classes to filter out the boxes we don’t want. You should be left with just the subset of boxes you want to keep.Useful reference:boolean maskAdditional Hints:For the tf.boolean_mask, we can keep the default axis=None.Reminder: to call a Keras function, you should use K.function(...).123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: yolo_filter_boxesdef yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6): """Filters YOLO boxes by thresholding on object and class confidence. Arguments: box_confidence -- tensor of shape (19, 19, 5, 1) boxes -- tensor of shape (19, 19, 5, 4) box_class_probs -- tensor of shape (19, 19, 5, 80) threshold -- real value, if [ highest class probability score &lt; threshold], then get rid of the corresponding box Returns: scores -- tensor of shape (None,), containing the class probability score for selected boxes boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes Note: "None" is here because you don't know the exact number of selected boxes, as it depends on the threshold. For example, the actual output size of scores would be (10,) if there are 10 boxes. """ # Step 1: Compute box scores ### START CODE HERE ### (≈ 1 line) box_scores = box_confidence * box_class_probs # (19*19, 5, 80) ### END CODE HERE ### # Step 2: Find the box_classes using the max box_scores, keep track of the corresponding score ### START CODE HERE ### (≈ 2 lines) box_classes = K.argmax(box_scores, axis=-1) box_class_scores = K.max(box_scores, axis=-1, keepdims=False) ### END CODE HERE ### # Step 3: Create a filtering mask based on "box_class_scores" by using "threshold". The mask should have the # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability &gt;= threshold) ### START CODE HERE ### (≈ 1 line) filtering_mask = box_class_scores &gt;= threshold ### END CODE HERE ### # Step 4: Apply the mask to box_class_scores, boxes and box_classes ### START CODE HERE ### (≈ 3 lines) scores = tf.boolean_mask(box_class_scores, filtering_mask) boxes = tf.boolean_mask(boxes, filtering_mask) classes = tf.boolean_mask(box_classes, filtering_mask) ### END CODE HERE ### return scores, boxes, classes1234567891011with tf.Session() as test_a: box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1) boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1) box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1) scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5) print("scores[2] = " + str(scores[2].eval())) print("boxes[2] = " + str(boxes[2].eval())) print("classes[2] = " + str(classes[2].eval())) print("scores.shape = " + str(scores.shape)) print("boxes.shape = " + str(boxes.shape)) print("classes.shape = " + str(classes.shape))Note In the test for yolo_filter_boxes, we’re using random numbers to test the function. In real data, the box_class_probs would contain non-zero values between 0 and 1 for the probabilities. The box coordinates in boxes would also be chosen so that lengths and heights are non-negative.2.3 - Non-max suppressionEven after filtering by thresholding over the class scores, you still end up with a lot of overlapping boxes. A second filter for selecting the right boxes is called non-maximum suppression (NMS).Exercise: Implement iou(). Some hints:In this code, we use the convention that (0,0) is the top-left corner of an image, (1,0) is the upper-right corner, and (1,1) is the lower-right corner. In other words, the (0,0) origin starts at the top left corner of the image. As x increases, we move to the right. As y increases, we move down.For this exercise, we define a box using its two corners: upper left $(x_1, y_1)$ and lower right $(x_2,y_2)$, instead of using the midpoint, height and width. (This makes it a bit easier to calculate the intersection).To calculate the area of a rectangle, multiply its height $(y_2 - y_1)$ by its width $(x_2 - x_1)$. (Since $(x_1,y_1)$ is the top left and $x_2,y_2$ are the bottom right, these differences should be non-negative.To find the intersection of the two boxes $(xi_{1}, yi_{1}, xi_{2}, yi_{2})$:Feel free to draw some examples on paper to clarify this conceptually.The top left corner of the intersection $(xi_{1}, yi_{1})$ is found by comparing the top left corners $(x_1, y_1)$ of the two boxes and finding a vertex that has an x-coordinate that is closer to the right, and y-coordinate that is closer to the bottom.The bottom right corner of the intersection $(xi_{2}, yi_{2})$ is found by comparing the bottom right corners $(x_2,y_2)$ of the two boxes and finding a vertex whose x-coordinate is closer to the left, and the y-coordinate that is closer to the top.The two boxes may have no intersection. You can detect this if the intersection coordinates you calculate end up being the top right and/or bottom left corners of an intersection box. Another way to think of this is if you calculate the height $(y_2 - y_1)$ or width $(x_2 - x_1)$ and find that at least one of these lengths is negative, then there is no intersection (intersection area is zero).The two boxes may intersect at the edges or vertices, in which case the intersection area is still zero. This happens when either the height or width (or both) of the calculated intersection is zero.Additional Hintsxi1 = maximum of the x1 coordinates of the two boxesyi1 = maximum of the y1 coordinates of the two boxesxi2 = minimum of the x2 coordinates of the two boxesyi2 = minimum of the y2 coordinates of the two boxesinter_area = You can use max(height, 0) and max(width, 0)123456789101112131415161718192021222324252627282930313233343536373839# GRADED FUNCTION: ioudef iou(box1, box2): """Implement the intersection over union (IoU) between box1 and box2 Arguments: box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2) box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2) """ # Assign variable names to coordinates for clarity (box1_x1, box1_y1, box1_x2, box1_y2) = box1 (box2_x1, box2_y1, box2_x2, box2_y2) = box2 # Calculate the (yi1, xi1, yi2, xi2) coordinates of the intersection of box1 and box2. Calculate its Area. ### START CODE HERE ### (≈ 7 lines) xi1 = max(box1[0], box2[0]) yi1 = max(box1[1], box2[1]) xi2 = min(box1[2], box2[2]) yi2 = min(box1[3], box2[3]) inter_width = max(xi2 - xi1,0) inter_height = max(yi2 - yi1,0) inter_area = inter_width * inter_height ### END CODE HERE ### # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B) ### START CODE HERE ### (≈ 3 lines) box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1]) box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1]) union_area = box1_area + box2_area - inter_area # print(inter_area) ### END CODE HERE ### # compute the IoU ### START CODE HERE ### (≈ 1 line) iou = inter_area / union_area ### END CODE HERE ### return iou12345678910111213141516171819## Test case 1: boxes intersectbox1 = (2, 1, 4, 3)box2 = (1, 2, 3, 4) print("iou for intersecting boxes = " + str(iou(box1, box2)))## Test case 2: boxes do not intersectbox1 = (1,2,3,4)box2 = (5,6,7,8)print("iou for non-intersecting boxes = " + str(iou(box1,box2)))## Test case 3: boxes intersect at vertices onlybox1 = (1,1,2,2)box2 = (2,2,3,3)print("iou for boxes that only touch at vertices = " + str(iou(box1,box2)))## Test case 4: boxes intersect at edge onlybox1 = (1,1,3,3)box2 = (2,3,3,4)print("iou for boxes that only touch at edges = " + str(iou(box1,box2)))YOLO non-max suppressionYou are now ready to implement non-max suppression. The key steps are:Select the box that has the highest score.Compute the overlap of this box with all other boxes, and remove boxes that overlap significantly (iou &gt;= iou_threshold).Go back to step 1 and iterate until there are no more boxes with a lower score than the currently selected box.This will remove all boxes that have a large overlap with the selected boxes. Only the “best” boxes remain.Exercise: Implement yolo_non_max_suppression() using TensorFlow. TensorFlow has two built-in functions that are used to implement non-max suppression (so you don’t actually need to use your iou() implementation):Reference documentationtf.image.non_max_suppression()1234567tf.image.non_max_suppression( boxes, scores, max_output_size, iou_threshold=0.5, name=None)Note that in the version of tensorflow used here, there is no parameter score_threshold (it’s shown in the documentation for the latest version) so trying to set this value will result in an error message: got an unexpected keyword argument ‘score_threshold.K.gather()Even though the documentation shows tf.keras.backend.gather(), you can use keras.gather().1234keras.gather( reference, indices)1234567891011121314151617181920212223242526272829303132333435363738# GRADED FUNCTION: yolo_non_max_suppressiondef yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5): """ Applies Non-max suppression (NMS) to set of boxes Arguments: scores -- tensor of shape (None,), output of yolo_filter_boxes() boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later) classes -- tensor of shape (None,), output of yolo_filter_boxes() max_boxes -- integer, maximum number of predicted boxes you'd like iou_threshold -- real value, "intersection over union" threshold used for NMS filtering Returns: scores -- tensor of shape (, None), predicted score for each box boxes -- tensor of shape (4, None), predicted box coordinates classes -- tensor of shape (, None), predicted class for each box Note: The "None" dimension of the output tensors has obviously to be less than max_boxes. Note also that this function will transpose the shapes of scores, boxes, classes. This is made for convenience. """ max_boxes_tensor = K.variable(max_boxes, dtype='int32') # tensor to be used in tf.image.non_max_suppression() K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep ### START CODE HERE ### (≈ 1 line) nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes, iou_threshold, name=None) ### END CODE HERE ### # Use K.gather() to select only nms_indices from scores, boxes and classes ### START CODE HERE ### (≈ 3 lines) scores = K.gather(scores, nms_indices) boxes = K.gather(boxes, nms_indices) classes = K.gather(classes, nms_indices) ### END CODE HERE ### return scores, boxes, classes1234567891011with tf.Session() as test_b: scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1) boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1) classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1) scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes) print("scores[2] = " + str(scores[2].eval())) print("boxes[2] = " + str(boxes[2].eval())) print("classes[2] = " + str(classes[2].eval())) print("scores.shape = " + str(scores.eval().shape)) print("boxes.shape = " + str(boxes.eval().shape)) print("classes.shape = " + str(classes.eval().shape))2.4 Wrapping up the filteringIt’s time to implement a function taking the output of the deep CNN (the 19x19x5x85 dimensional encoding) and filtering through all the boxes using the functions you’ve just implemented.Exercise: Implement yolo_eval() which takes the output of the YOLO encoding and filters the boxes using score threshold and NMS. There’s just one last implementational detail you have to know. There’re a few ways of representing boxes, such as via their corners or via their midpoint and height/width. YOLO converts between a few such formats at different times, using the following functions (which we have provided):1boxes = yolo_boxes_to_corners(box_xy, box_wh)which converts the yolo box coordinates (x,y,w,h) to box corners’ coordinates (x1, y1, x2, y2) to fit the input of yolo_filter_boxes1boxes = scale_boxes(boxes, image_shape)YOLO’s network was trained to run on 608x608 images. If you are testing this data on a different size image—for example, the car detection dataset had 720x1280 images—this step rescales the boxes so that they can be plotted on top of the original 720x1280 image.Don’t worry about these two functions; we’ll show you where they need to be called.1234567891011121314151617181920212223242526272829303132333435363738394041424344# GRADED FUNCTION: yolo_evaldef yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5): """ Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes. Arguments: yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors: box_confidence: tensor of shape (None, 19, 19, 5, 1) box_xy: tensor of shape (None, 19, 19, 5, 2) box_wh: tensor of shape (None, 19, 19, 5, 2) box_class_probs: tensor of shape (None, 19, 19, 5, 80) image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype) max_boxes -- integer, maximum number of predicted boxes you'd like score_threshold -- real value, if [ highest class probability score &lt; threshold], then get rid of the corresponding box iou_threshold -- real value, "intersection over union" threshold used for NMS filtering Returns: scores -- tensor of shape (None, ), predicted score for each box boxes -- tensor of shape (None, 4), predicted box coordinates classes -- tensor of shape (None,), predicted class for each box """ ### START CODE HERE ### # Retrieve outputs of the YOLO model (≈1 line) box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs # Convert boxes to be ready for filtering functions (convert boxes box_xy and box_wh to corner coordinates) boxes = yolo_boxes_to_corners(box_xy, box_wh) # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line) scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold) # Scale boxes back to original image shape. boxes = scale_boxes(boxes, image_shape) # Use one of the functions you've implemented to perform Non-max suppression with # maximum number of boxes set to max_boxes and a threshold of iou_threshold (≈1 line) scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold) ### END CODE HERE ### return scores, boxes, classes123456789101112with tf.Session() as test_b: yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1), tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1), tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1), tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)) scores, boxes, classes = yolo_eval(yolo_outputs) print("scores[2] = " + str(scores[2].eval())) print("boxes[2] = " + str(boxes[2].eval())) print("classes[2] = " + str(classes[2].eval())) print("scores.shape = " + str(scores.eval().shape)) print("boxes.shape = " + str(boxes.eval().shape)) print("classes.shape = " + str(classes.eval().shape))Summary for YOLO:Input image (608, 608, 3)The input image goes through a CNN, resulting in a (19,19,5,85) dimensional output.After flattening the last two dimensions, the output is a volume of shape (19, 19, 425):Each cell in a 19x19 grid over the input image gives 425 numbers.425 = 5 x 85 because each cell contains predictions for 5 boxes, corresponding to 5 anchor boxes, as seen in lecture.85 = 5 + 80 where 5 is because $(p_c, b_x, b_y, b_h, b_w)$ has 5 numbers, and 80 is the number of classes we’d like to detectYou then select only few boxes based on:Score-thresholding: throw away boxes that have detected a class with a score less than the thresholdNon-max suppression: Compute the Intersection over Union and avoid selecting overlapping boxesThis gives you YOLO’s final output.3 - Test YOLO pre-trained model on imagesIn this part, you are going to use a pre-trained model and test it on the car detection dataset. We’ll need a session to execute the computation graph and evaluate the tensors.1sess = K.get_session()3.1 - Defining classes, anchors and image shape.Recall that we are trying to detect 80 classes, and are using 5 anchor boxes.We have gathered the information on the 80 classes and 5 boxes in two files “coco_classes.txt” and “yolo_anchors.txt”.We’ll read class names and anchors from text files.The car detection dataset has 720x1280 images, which we’ve pre-processed into 608x608 images.123class_names = read_classes("model_data/coco_classes.txt")anchors = read_anchors("model_data/yolo_anchors.txt")image_shape = (720., 1280.)3.2 - Loading a pre-trained modelTraining a YOLO model takes a very long time and requires a fairly large dataset of labelled bounding boxes for a large range of target classes.You are going to load an existing pre-trained Keras YOLO model stored in “yolo.h5”.These weights come from the official YOLO website, and were converted using a function written by Allan Zelener. References are at the end of this notebook. Technically, these are the parameters from the “YOLOv2” model, but we will simply refer to it as “YOLO” in this notebook.Run the cell below to load the model from this file.1yolo_model = load_model("model_data/yolo.h5")This loads the weights of a trained YOLO model. Here’s a summary of the layers your model contains.1yolo_model.summary()Note: On some computers, you may see a warning message from Keras. Don’t worry about it if you do—it is fine.Reminder: this model converts a preprocessed batch of input images (shape: (m, 608, 608, 3)) into a tensor of shape (m, 19, 19, 5, 85) as explained in Figure (2).3.3 - Convert output of the model to usable bounding box tensorsThe output of yolo_model is a (m, 19, 19, 5, 85) tensor that needs to pass through non-trivial processing and conversion. The following cell does that for you.If you are curious about how yolo_head is implemented, you can find the function definition in the file ‘keras_yolo.py’. The file is located in your workspace in this path ‘yad2k/models/keras_yolo.py’.1yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))You added yolo_outputs to your graph. This set of 4 tensors is ready to be used as input by your yolo_eval function.3.4 - Filtering boxesyolo_outputs gave you all the predicted boxes of yolo_model in the correct format. You’re now ready to perform filtering and select only the best boxes. Let’s now call yolo_eval, which you had previously implemented, to do this.1scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)3.5 - Run the graph on an imageLet the fun begin. You have created a graph that can be summarized as follows:yolo_model.input is given to yolo_model. The model is used to compute the output yolo_model.outputyolo_model.output is processed by yolo_head. It gives you yolo_outputsyolo_outputs goes through a filtering function, yolo_eval. It outputs your predictions: scores, boxes, classesExercise: Implement predict() which runs the graph to test YOLO on an image.You will need to run a TensorFlow session, to have it compute scores, boxes, classes.The code below also uses the following function:1image, image_data = preprocess_image("images/" + image_file, model_image_size = (608, 608))which outputs:image: a python (PIL) representation of your image used for drawing boxes. You won’t need to use it.image_data: a numpy-array representing the image. This will be the input to the CNN.Important note: when a model uses BatchNorm (as is the case in YOLO), you will need to pass an additional placeholder in the feed_dict {K.learning_phase(): 0}.Hint: Using the TensorFlow Session objectRecall that above, we called K.get_Session() and saved the Session object in sess.To evaluate a list of tensors, we call sess.run() like this:1234sess.run(fetches=[tensor1,tensor2,tensor3], feed_dict=&#123;yolo_model.input: the_input_variable, K.learning_phase():0 &#125;Notice that the variables scores, boxes, classes are not passed into the predict function, but these are global variables that you will use within the predict function.1234567891011121314151617181920212223242526272829303132333435363738def predict(sess, image_file): """ Runs the graph stored in "sess" to predict boxes for "image_file". Prints and plots the predictions. Arguments: sess -- your tensorflow/Keras session containing the YOLO graph image_file -- name of an image stored in the "images" folder. Returns: out_scores -- tensor of shape (None, ), scores of the predicted boxes out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes out_classes -- tensor of shape (None, ), class index of the predicted boxes Note: "None" actually represents the number of predicted boxes, it varies between 0 and max_boxes. """ # Preprocess your image image, image_data = preprocess_image("images/" + image_file, model_image_size = (608, 608)) # Run the session with the correct tensors and choose the correct placeholders in the feed_dict. # You'll need to use feed_dict=&#123;yolo_model.input: ... , K.learning_phase(): 0&#125;) ### START CODE HERE ### (≈ 1 line) out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict = &#123;yolo_model.input:image_data, K.learning_phase(): 0&#125;) ### END CODE HERE ### # Print predictions info print('Found &#123;&#125; boxes for &#123;&#125;'.format(len(out_boxes), image_file)) # Generate colors for drawing bounding boxes. colors = generate_colors(class_names) # Draw bounding boxes on the image file draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors) # Save the predicted bounding box on the image image.save(os.path.join("out", image_file), quality=90) # Display the results in the notebook output_image = scipy.misc.imread(os.path.join("out", image_file)) imshow(output_image) return out_scores, out_boxes, out_classesRun the following cell on the “test.jpg” image to verify that your function is correct.1out_scores, out_boxes, out_classes = predict(sess, "test.jpg")The model you’ve just run is actually able to detect 80 different classes listed in “coco_classes.txt”. To test the model on your own images:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Write your image&#39;s name in the cell above code 4. Run the code and see the output of the algorithm! If you were to run your session in a for loop over all your images. Here’s what you would get:What you should remember:YOLO is a state-of-the-art object detection model that is fast and accurateIt runs an input image through a CNN which outputs a 19x19x5x85 dimensional volume.The encoding can be seen as a grid where each of the 19x19 cells contains information about 5 boxes.You filter through all the boxes using non-max suppression. Specifically:Score thresholding on the probability of detecting a class to keep only accurate (high probability) boxesIntersection over Union (IoU) thresholding to eliminate overlapping boxesBecause training a YOLO model from randomly initialized weights is non-trivial and requires a large dataset as well as lot of computation, we used previously trained model parameters in this exercise. If you wish, you can also try fine-tuning the YOLO model with your own dataset, though this would be a fairly non-trivial exercise.References: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener’s GitHub repository. The pre-trained weights used in this exercise came from the official YOLO website.Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015)Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016)Allan Zelener - YAD2K: Yet Another Darknet 2 KerasThe official YOLO website (https://pjreddie.com/darknet/yolo/)Car detection dataset:The Drive.ai Sample Dataset (provided by drive.ai) is licensed under a Creative Commons Attribution 4.0 International License. We are grateful to Brody Huval, Chih Hu and Rahul Patel for providing this data.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/specializations/deep-learninghttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（4-2）]]></title>
    <url>%2F2020%2F01%2F04%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%884-2%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深度卷积网络：实例探究（Deep convolutional models: case studies）2.1 为什么要进行实例探究？（Why look at case studies?）2.2 经典网络（Classic networks）几个经典的神经网络结构，分别是LeNet-5、AlexNet和VGGNet。LeNet-5LeNet-5是针对灰度图片训练的，所以图片的大小只有32×32×1。在LetNet中，存在的经典模式：随着网络的深度增加，图像的大小在缩小，与此同时，通道的数量却在增加；每个卷积层后面接一个池化层。AlexNet在写这篇论文的时候，GPU的处理速度还比较慢，所以AlexNet采用了非常复杂的方法在两个GPU上进行训练。大致原理是，这些层分别拆分到两个不同的GPU上，同时还专门有一个方法用于两个GPU进行交流。经典的AlexNet结构还有另一种类型的层，叫作“局部响应归一化层”（Local Response Normalization），即LRN层。VGGNetVGG-16的这个数字16，就是指在这个网络中包含16个卷积层和全连接层。确实是个很大的网络，总共包含约1.38亿个参数。2.3 残差网络(ResNets)（Residual Networks (ResNets)）非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。跳跃连接（Skip connection），它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。信息流从$a^{\left\lbrack l \right\rbrack}$到$a^{\left\lbrack l + 2 \right\rbrack}$需要经过以上所有步骤，即这组网络层的主路径。在残差网络中有一点变化，我们将$a^{[l]}$直接向后，拷贝到神经网络的深层，在ReLU非线性激活函数前加上$a^{[l]}$，这是一条捷径。$a^{[l]}$的信息直接到达神经网络的深层，不再沿着主路径传递，这就意味着最后这个等式($a^{\left\lbrack l + 2 \right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack})$)去掉了，取而代之的是另一个ReLU非线性函数，仍然对$z^{\left\lbrack l + 2 \right\rbrack}$进行$g$函数处理，但这次要加上$a^{[l]}$，即：$\ a^{\left\lbrack l + 2 \right\rbrack} = g\left(z^{\left\lbrack l + 2 \right\rbrack} + a^{[l]}\right)$，也就是加上的这个$a^{[l]}$产生了一个残差块。普通网络（Plain network）ResNet在没有残差的普通神经网络中，训练的误差实际上是随着网络层数的加深，先减小再增加；在有残差的ResNet中，即使网络再深，训练误差都会随着网络层数的加深逐渐减小。ResNet对于中间的激活函数来说，有助于能够达到更深的网络，解决梯度消失和梯度爆炸的问题。2.4 残差网络为什么有用？（Why ResNets work?）假设有一个大型神经网络，其输入为$X$，输出激活值$a^{[l]}$。假如你想增加这个神经网络的深度，那么用Big NN表示，输出为$ a^{\left\lbrack l\right\rbrack}$。再给这个网络额外添加两层，依次添加两层，最后输出为$a^{\left\lbrack l + 2 \right\rbrack}$，可以把这两层看作一个ResNets块，即具有捷径连接的残差块。假设在整个网络中使用ReLU激活函数，所以激活值都大于等于0，包括输入$X$的非零异常值。因为ReLU激活函数输出的数字要么是0，要么是正数。则有$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$。展开这个表达式$a^{\left\lbrack l + 2 \right\rbrack} = g(W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$，其中$z^{\left\lbrack l + 2 \right\rbrack} = W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2\right\rbrack}$。如果使用L2正则化或权重衰减，它会压缩$W^{\left\lbrack l + 2\right\rbrack}$的值，如果对$b$应用权重衰减也可达到同样的效果。假设$W^{\left\lbrack l + 2 \right\rbrack} = 0$，$b^{\left\lbrack l + 2 \right\rbrack} = 0$，这几项就没有了，最后$ a^{\left\lbrack l + 2 \right\rbrack} = \ g\left( a^{[l]} \right) = a^{\left\lbrack l\right\rbrack}$结果表明，残差块学习这个恒等式函数并不难，跳跃连接使我们很容易得出$ a^{\left\lbrack l + 2 \right\rbrack} = a^{\left\lbrack l\right\rbrack}$。这意味着，即使给神经网络增加了这两层，它的效率也并不逊色于更简单的神经网络，因为学习恒等函数对它来说很简单。尽管它多了两层，也只把$a^{[l]}$的值赋值给$a^{\left\lbrack l + 2 \right\rbrack}$。所以给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现。另外，之所以能实现跳跃连接是因为same卷积保留了维度，所以很容易得出这个捷径连接，并输出这两个相同维度的向量。ResNets类似于其它很多网络，也会有很多卷积层，其中偶尔会有池化层或类池化层的层。普通网络和ResNets网络常用的结构是：卷积层-卷积层-卷积层-池化层-卷积层-卷积层-卷积层-池化层……依此重复。直到最后，有一个通过softmax进行预测的全连接层。2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）对于二维，用1×1的过滤器进行卷积，似乎用处不大，只是对输入矩阵乘以某个数字。对于三维，1×1×32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字（输入图片中左下角位置32个通道中的数字），即相同高度和宽度上某一切片上的32个数字，这32个数字具有不同通道，乘以32个权重（将过滤器中的32个数理解为权重），然后应用ReLU非线性函数，在这里输出相应的结果。所以1×1卷积可以从根本上理解为对这32个不同的位置都应用一个全连接层，全连接层的作用是输入32个数字（过滤器数量标记为$n_{C}^{\left\lbrack l + 1\right\rbrack}$，在这36个单元上重复此过程）,输出结果是6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算。1x1卷积应用：维度压缩：使用目标维度的1×1的卷积核个数。增加非线性：保持与原维度相同的1×1的卷积核个数。2.6 谷歌 Inception 网络简介（Inception network motivation）构建卷积层时，Inception网络的作用就是代替你来决定过滤器类型，或者确定是否需要创建卷积层或池化层。在上面的Inception结构中，应用了不同的卷积核，以及带padding的池化层。在保持输入图片大小不变的情况下，通过不同运算结果的叠加，增加了通道的数量。计算成本对于1×1大小卷积核用作过渡的计算成本，也将下面的中间的层叫做“bottleneck layer”：所以1×1卷积核作为“bottleneck layer”的过渡层能够有效减小卷积神经网的计算成本。事实证明，只要合理地设置“bottleneck layer”，既可以显著减小上层的规模，同时又能降低计算成本，从而不会影响网络的性能。2.7 Inception 网络（Inception network）2.8 使用开源的实现方案（Using open-source implementations）ResNets实现的GitHub地址https://github.com/KaimingHe/deep-residual-networks2.9 迁移学习（Transfer Learning）假如说你要建立一个猫咪检测器，然而你的训练集很小。此时从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。例如ImageNet数据集，它有1000个不同的类别，因此这个网络会有一个Softmax单元，它可以输出1000个可能类别之一。可以去掉这个Softmax层，创建你自己的Softmax单元。对于使用的框架，它也许会有trainableParameter=0这样的参数，对于这些前面的层，你可能会设置这个参数。为了不训练这些权重，有时也会有freeze=1这样的参数。不同的深度学习编程框架有不同的方式，允许你指定是否训练特定层的权重。在这个例子中，你只需要训练softmax层的权重，把前面这些层的权重都冻结。如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这所有的权重当作初始化，然后训练整个网络。如果这是一个1000节点的softmax，而你只有三个输出，你需要你自己的softmax输出层来输出你要的标签。2.10 数据增强（Data augmentation）镜像翻转（Mirroring）随机剪裁（Random Cropping）色彩转换（Color shifting）：为图片的RGB三个色彩通道进行增减值，如（R：+20，G：-20，B：+20）；PCA颜色增强：对图片的主色的变化较大，图片的次色变化较小，使总体的颜色保持一致。2.11 计算机视觉现状（The state of computer vision）Keras tutorial - Emotion Detection in Images of FacesWelcome to the first assignment of week 2. In this assignment, you will:Learn to use Keras, a high-level neural networks API (programming framework), written in Python and capable of running on top of several lower-level frameworks including TensorFlow and CNTK.See how you can in a couple of hours build a deep learning algorithm.Why are we using Keras?Keras was developed to enable deep learning engineers to build and experiment with different models very quickly.Just as TensorFlow is a higher-level framework than Python, Keras is an even higher-level framework and provides additional abstractions.Being able to go from idea to result with the least possible delay is key to finding good models.However, Keras is more restrictive than the lower-level frameworks, so there are some very complex models that you would still implement in TensorFlow rather than in Keras.That being said, Keras will work fine for many common models.UpdatesIf you were working on the notebook before this update…The current notebook is version “v2a”.You can find your original work saved in the notebook with the previous version name (“v2”).To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatesChanged back-story of model to “emotion detection” from “happy house.”Cleaned/organized wording of instructions and commentary.Added instructions on how to set input_shapeAdded explanation of “objects as functions” syntax.Clarified explanation of variable naming convention.Added hints for steps 1,2,3,4123456789101112131415161718192021import numpy as npfrom keras import layersfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2Dfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2Dfrom keras.models import Modelfrom keras.preprocessing import imagefrom keras.utils import layer_utilsfrom keras.utils.data_utils import get_filefrom keras.applications.imagenet_utils import preprocess_inputimport pydotfrom IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotfrom keras.utils import plot_modelfrom kt_utils import *import keras.backend as KK.set_image_data_format('channels_last')import matplotlib.pyplot as pltfrom matplotlib.pyplot import imshow%matplotlib inlineNote: As you can see, we’ve imported a lot of functions from Keras. You can use them by calling them directly in your code. Ex: X = Input(...) or X = ZeroPadding2D(...).In other words, unlike TensorFlow, you don’t have to create the graph and then make a separate sess.run() call to evaluate those variables.1 - Emotion TrackingA nearby community health clinic is helping the local residents monitor their mental health.As part of their study, they are asking volunteers to record their emotions throughout the day.To help the participants more easily track their emotions, you are asked to create an app that will classify their emotions based on some pictures that the volunteers will take of their facial expressions.As a proof-of-concept, you first train your model to detect if someone’s emotion is classified as “happy” or “not happy.”To build and train this model, you have gathered pictures of some volunteers in a nearby neighborhood. The dataset is labeled.Run the following code to normalize the dataset and learn about its shapes.12345678910111213141516X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()# Normalize image vectorsX_train = X_train_orig/255.X_test = X_test_orig/255.# ReshapeY_train = Y_train_orig.TY_test = Y_test_orig.Tprint ("number of training examples = " + str(X_train.shape[0]))print ("number of test examples = " + str(X_test.shape[0]))print ("X_train shape: " + str(X_train.shape))print ("Y_train shape: " + str(Y_train.shape))print ("X_test shape: " + str(X_test.shape))print ("Y_test shape: " + str(Y_test.shape))123456number of training examples = 600number of test examples = 150X_train shape: (600, 64, 64, 3)Y_train shape: (600, 1)X_test shape: (150, 64, 64, 3)Y_test shape: (150, 1)2 - Building a model in KerasKeras is very good for rapid prototyping. In just a short time you will be able to build a model that achieves outstanding results.Here is an example of a model in Keras:12345678910111213141516171819202122232425262728293031def model(input_shape): """ input_shape: The height, width and channels as a tuple. Note that this does not include the 'batch' as a dimension. If you have a batch like 'X_train', then you can provide the input_shape using X_train.shape[1:] """ # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image! X_input = Input(input_shape) # Zero-Padding: pads the border of X_input with zeroes X = ZeroPadding2D((3, 3))(X_input) # CONV -&gt; BN -&gt; RELU Block applied to X X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X) X = BatchNormalization(axis = 3, name = 'bn0')(X) X = Activation('relu')(X) # MAXPOOL X = MaxPooling2D((2, 2), name='max_pool')(X) # FLATTEN X (means convert it to a vector) + FULLYCONNECTED X = Flatten()(X) X = Dense(1, activation='sigmoid', name='fc')(X) # Create model. This creates your Keras model instance, you'll use this instance to train/test the model. model = Model(inputs = X_input, outputs = X, name='HappyModel') return modelVariable naming conventionNote that Keras uses a different convention with variable names than we’ve previously used with numpy and TensorFlow.Instead of creating unique variable names for each step and each layer, such as123X = ...Z1 = ...A1 = ...Keras re-uses and overwrites the same variable at each step:123X = ...X = ...X = ...The exception is X_input, which we kept separate since it’s needed later.Objects as functionsNotice how there are two pairs of parentheses in each statement. For example:1X = ZeroPadding2D((3, 3))(X_input)The first is a constructor call which creates an object (ZeroPadding2D).In Python, objects can be called as functions. Search for ‘python object as function and you can read this blog post Python Pandemonium. See the section titled “Objects as functions.”The single line is equivalent to this:12ZP = ZeroPadding2D((3, 3)) # ZP is an object that can be called as a functionX = ZP(X_input)Exercise: Implement a HappyModel().This assignment is more open-ended than most.Start by implementing a model using the architecture we suggest, and run through the rest of this assignment using that as your initial model. * Later, come back and try out other model architectures.For example, you might take inspiration from the model above, but then vary the network architecture and hyperparameters however you wish.You can also use other functions such as AveragePooling2D(), GlobalMaxPooling2D(), Dropout().Note: Be careful with your data’s shapes. Use what you’ve learned in the videos to make sure your convolutional, pooling and fully-connected layers are adapted to the volumes you’re applying it to.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# GRADED FUNCTION: HappyModeldef HappyModel(input_shape): """ Implementation of the HappyModel. Arguments: input_shape -- shape of the images of the dataset (height, width, channels) as a tuple. Note that this does not include the 'batch' as a dimension. If you have a batch like 'X_train', then you can provide the input_shape using X_train.shape[1:] Returns: model -- a Model() instance in Keras """ ### START CODE HERE ### # Feel free to use the suggested outline in the text above to get started, and run through the whole # exercise (including the later portions of this notebook) once. The come back also try out other # network architectures as well. # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image! X_input = Input(input_shape) # Zero-Padding: pads the border of X_input with zeroes X = ZeroPadding2D((3, 3))(X_input) #(?, 70, 70, 3) # CONV -&gt; BN -&gt; RELU Block applied to X X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X) #(?, 64, 64, 32) X = BatchNormalization(axis = 3, name = 'bn0')(X) X = Activation('relu')(X) # MAXPOOL X = MaxPooling2D((2, 2), name='max_pool')(X) #(?, 32, 32, 32) # FLATTEN X (means convert it to a vector) + FULLYCONNECTED X = Flatten()(X) X = Dense(1, activation='sigmoid', name='fc')(X) # Create model. This creates your Keras model instance, you'll use this instance to train/test the model. model = Model(inputs = X_input, outputs = X, name='HappyModel') return model ### END CODE HERE ### return modelYou have now built a function to describe your model. To train and test this model, there are four steps in Keras:Create the model by calling the function aboveCompile the model by calling model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;])Train the model on train data by calling model.fit(x = ..., y = ..., epochs = ..., batch_size = ...)Test the model on test data by calling model.evaluate(x = ..., y = ...)If you want to know more about model.compile(), model.fit(), model.evaluate() and their arguments, refer to the official Keras documentation.Step 1: create the model.Hint:The input_shape parameter is a tuple (height, width, channels). It excludes the batch number.Try X_train.shape[1:] as the input_shape.123### START CODE HERE ### (1 line)happyModel = HappyModel(X_train.shape[1:])### END CODE HERE ###Step 2: compile the modelHint:Optimizers you can try include &#39;adam&#39;, &#39;sgd&#39; or others. See the documentation for optimizersThe “happiness detection” is a binary classification problem. The loss function that you can use is &#39;binary_cross_entropy&#39;. Note that &#39;categorical_cross_entropy&#39; won’t work with your data set as its formatted, because the data is an array of 0 or 1 rather than two arrays (one for each category). Documentation for losses123### START CODE HERE ### (1 line)happyModel.compile(optimizer = "Adam", loss = "binary_crossentropy", metrics = ["accuracy"])### END CODE HERE ###Step 3: train the modelHint:Use the &#39;X_train&#39;, &#39;Y_train&#39; variables. Use integers for the epochs and batch_sizeNote: If you run fit() again, the model will continue to train with the parameters it has already learned instead of reinitializing them.123### START CODE HERE ### (1 line)happyModel.fit(x = X_train, y = Y_train, epochs = 10, batch_size = 32)### END CODE HERE ###Step 4: evaluate modelHint:Use the &#39;X_test&#39; and &#39;Y_test&#39; variables to evaluate the model’s performance.123456### START CODE HERE ### (1 line)preds = happyModel.evaluate(X_test, Y_test)### END CODE HERE ###print()print ("Loss = " + str(preds[0]))print ("Test Accuracy = " + str(preds[1]))Expected performanceIf your happyModel() function worked, its accuracy should be better than random guessing (50% accuracy).To give you a point of comparison, our model gets around 95% test accuracy in 40 epochs (and 99% train accuracy) with a mini batch size of 16 and “adam” optimizer.Tips for improving your modelIf you have not yet achieved a very good accuracy (&gt;= 80%), here are some things tips:Use blocks of CONV-&gt;BATCHNORM-&gt;RELU such as:123X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv0')(X)X = BatchNormalization(axis = 3, name = 'bn0')(X)X = Activation('relu')(X)until your height and width dimensions are quite low and your number of channels quite large (≈32 for example).You can then flatten the volume and use a fully-connected layer.Use MAXPOOL after such blocks. It will help you lower the dimension in height and width.Change your optimizer. We find ‘adam’ works well.If you get memory issues, lower your batch_size (e.g. 12 )Run more epochs until you see the train accuracy no longer improves.Note: If you perform hyperparameter tuning on your model, the test set actually becomes a dev set, and your model might end up overfitting to the test (dev) set. Normally, you’ll want separate dev and test sets. The dev set is used for parameter tuning, and the test set is used once to estimate the model’s performance in production.3 - ConclusionCongratulations, you have created a proof of concept for “happiness detection”!Key Points to rememberKeras is a tool we recommend for rapid prototyping. It allows you to quickly try out different model architectures.Remember The four steps in Keras:CreateCompileFit/TrainEvaluate/Test4 - Test with your own image (Optional)Congratulations on finishing this assignment. You can now take a picture of your face and see if it can classify whether your expression is “happy” or “not happy”. To do that:Click on “File” in the upper bar of this notebook, then click “Open” to go on your Coursera Hub.Add your image to this Jupyter Notebook’s directory, in the “images” folderWrite your image’s name in the following codeRun the code and check if the algorithm is right (0 is not happy, 1 is happy)!The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try!1234567891011### START CODE HERE ###img_path = 'images/my_image.jpg'### END CODE HERE ###img = image.load_img(img_path, target_size=(64, 64))imshow(img)x = image.img_to_array(img)x = np.expand_dims(x, axis=0)x = preprocess_input(x)print(happyModel.predict(x))5 - Other useful functions in Keras (Optional)Two other basic features of Keras that you’ll find useful are:model.summary(): prints the details of your layers in a table with the sizes of its inputs/outputsplot_model(): plots your graph in a nice layout. You can even save it as “.png” using SVG() if you’d like to share it on social media ;). It is saved in “File” then “Open…” in the upper bar of the notebook.Run the following code.1happyModel.summary()12plot_model(happyModel, to_file='HappyModel.png')SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))Residual NetworksWelcome to the second assignment of this week! You will learn how to build very deep convolutional networks, using Residual Networks (ResNets). In theory, very deep networks can represent very complex functions; but in practice, they are hard to train. Residual Networks, introduced by He et al., allow you to train much deeper networks than were previously practically feasible.In this assignment, you will:Implement the basic building blocks of ResNets.Put together these building blocks to implement and train a state-of-the-art neural network for image classification.UpdatesIf you were working on the notebook before this update…The current notebook is version “2a”.You can find your original work saved in the notebook with the previous version name (“v2”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatesFor testing on an image, replaced preprocess_input(x) with x=x/255.0 to normalize the input image in the same way that the model’s training data was normalized.Refers to “shallower” layers as those layers closer to the input, and “deeper” layers as those closer to the output (Using “shallower” layers instead of “lower” or “earlier”).Added/updated instructions.This assignment will be done in Keras.Before jumping into the problem, let’s run the cell below to load the required packages.123456789101112131415161718192021import numpy as npfrom keras import layersfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2Dfrom keras.models import Model, load_modelfrom keras.preprocessing import imagefrom keras.utils import layer_utilsfrom keras.utils.data_utils import get_filefrom keras.applications.imagenet_utils import preprocess_inputimport pydotfrom IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotfrom keras.utils import plot_modelfrom resnets_utils import *from keras.initializers import glorot_uniformimport scipy.miscfrom matplotlib.pyplot import imshow%matplotlib inlineimport keras.backend as KK.set_image_data_format('channels_last')K.set_learning_phase(1)1 - The problem of very deep neural networksLast week, you built your first convolutional neural network. In recent years, neural networks have become deeper, with state-of-the-art networks going from just a few layers (e.g., AlexNet) to over a hundred layers.The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the shallower layers, closer to the input) to very complex features (at the deeper layers, closer to the output).However, using a deeper network doesn’t always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and “explode” to take very large values).During training, you might therefore see the magnitude (or norm) of the gradient for the shallower layers decrease to zero very rapidly as training proceeds:You are now going to solve this problem by building a Residual Network!2 - Building a Residual NetworkIn ResNets, a “shortcut” or a “skip connection” allows the model to skip layers:The image on the left shows the “main path” through the network. The image on the right adds a shortcut to the main path. By stacking these ResNet blocks on top of each other, you can form a very deep network.We also saw in lecture that having ResNet blocks with the shortcut also makes it very easy for one of the blocks to learn an identity function. This means that you can stack on additional ResNet blocks with little risk of harming training set performance.(There is also some evidence that the ease of learning an identity function accounts for ResNets’ remarkable performance even more so than skip connections helping with vanishing gradients).Two main types of blocks are used in a ResNet, depending mainly on whether the input/output dimensions are same or different. You are going to implement both of them: the “identity block” and the “convolutional block.”2.1 - The identity blockThe identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$) has the same dimension as the output activation (say $a^{[l+2]}$). To flesh out the different steps of what happens in a ResNet’s identity block, here is an alternative diagram showing the individual steps:The upper path is the “shortcut path.” The lower path is the “main path.” In this diagram, we have also made explicit the CONV2D and ReLU steps in each layer. To speed up training we have also added a BatchNorm step. Don’t worry about this being complicated to implement—you’ll see that BatchNorm is just one line of code in Keras!In this exercise, you’ll actually implement a slightly more powerful version of this identity block, in which the skip connection “skips over” 3 hidden layers rather than 2 layers. It looks like this:Here are the individual steps.First component of main path:The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and its name should be conv_name_base + &#39;2a&#39;. Use 0 as the seed for the random initialization.The first BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2a&#39;.Then apply the ReLU activation function. This has no name and no hyperparameters.Second component of main path:The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is “same” and its name should be conv_name_base + &#39;2b&#39;. Use 0 as the seed for the random initialization.The second BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2b&#39;.Then apply the ReLU activation function. This has no name and no hyperparameters.Third component of main path:The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and its name should be conv_name_base + &#39;2c&#39;. Use 0 as the seed for the random initialization.The third BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2c&#39;.Note that there is no ReLU activation function in this component.Final step:The X_shortcut and the output from the 3rd layer X are added together.Hint: The syntax will look something like Add()([var1,var2])Then apply the ReLU activation function. This has no name and no hyperparameters.Exercise: Implement the ResNet identity block. We have implemented the first component of the main path. Please read this carefully to make sure you understand what it is doing. You should implement the rest.To implement the Conv2D step: Conv2DTo implement BatchNorm: BatchNormalization (axis: Integer, the axis that should be normalized (typically the ‘channels’ axis))For the activation, use: Activation(&#39;relu&#39;)(X)To add the value passed forward by the shortcut: Add1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# GRADED FUNCTION: identity_blockdef identity_block(X, f, filters, stage, block): """ Implementation of the identity block as defined in Figure 4 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network Returns: X -- output of the identity block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value. You'll need this later to add back to the main path. X_shortcut = X # First component of main path X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (≈3 lines) X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X) X = Activation('relu')(X) # Third component of main path (≈2 lines) X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X) # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines) X = Add()([X, X_shortcut]) X = Activation('relu')(X) ### END CODE HERE ### return X1234567891011tf.reset_default_graph()with tf.Session() as test: np.random.seed(1) A_prev = tf.placeholder("float", [3, 4, 4, 6]) X = np.random.randn(3, 4, 4, 6) A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') test.run(tf.global_variables_initializer()) out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): 0&#125;) print("out = " + str(out[0][1][1][0]))# out = [ 0.94822985 0. 1.16101444 2.747859 0. 1.36677003]2.2 - The convolutional blockThe ResNet “convolutional block” is the second block type. You can use this type of block when the input and output dimensions don’t match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path:The CONV2D layer in the shortcut path is used to resize the input $x$ to a different dimension, so that the dimensions match up in the final addition needed to add the shortcut value back to the main path. (This plays a similar role as the matrix $W_s$ discussed in lecture.)For example, to reduce the activation dimensions’s height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2.The CONV2D layer on the shortcut path does not use any non-linear activation function. Its main role is to just apply a (learned) linear function that reduces the dimension of the input, so that the dimensions match up for the later addition step.The details of the convolutional block are as follows.First component of main path:The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is “valid” and its name should be conv_name_base + &#39;2a&#39;. Use 0 as the glorot_uniform seed.The first BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2a&#39;.Then apply the ReLU activation function. This has no name and no hyperparameters.Second component of main path:The second CONV2D has $F_2$ filters of shape (f,f) and a stride of (1,1). Its padding is “same” and it’s name should be conv_name_base + &#39;2b&#39;. Use 0 as the glorot_uniform seed.The second BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2b&#39;.Then apply the ReLU activation function. This has no name and no hyperparameters.Third component of main path:The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is “valid” and it’s name should be conv_name_base + &#39;2c&#39;. Use 0 as the glorot_uniform seed.The third BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;2c&#39;. Note that there is no ReLU activation function in this component.Shortcut path:The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is “valid” and its name should be conv_name_base + &#39;1&#39;. Use 0 as the glorot_uniform seed.The BatchNorm is normalizing the ‘channels’ axis. Its name should be bn_name_base + &#39;1&#39;.Final step:The shortcut and the main path values are added together.Then apply the ReLU activation function. This has no name and no hyperparameters.Exercise: Implement the convolutional block. We have implemented the first component of the main path; you should implement the rest. As before, always use 0 as the seed for the random initialization, to ensure consistency with our grader.Conv2DBatchNormalization (axis: Integer, the axis that should be normalized (typically the features axis))For the activation, use: Activation(&#39;relu&#39;)(X)Add123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# GRADED FUNCTION: convolutional_blockdef convolutional_block(X, f, filters, stage, block, s = 2): """ Implementation of the convolutional block as defined in Figure 4 Arguments: X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev) f -- integer, specifying the shape of the middle CONV's window for the main path filters -- python list of integers, defining the number of filters in the CONV layers of the main path stage -- integer, used to name the layers, depending on their position in the network block -- string/character, used to name the layers, depending on their position in the network s -- Integer, specifying the stride to be used Returns: X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C) """ # defining name basis conv_name_base = 'res' + str(stage) + block + '_branch' bn_name_base = 'bn' + str(stage) + block + '_branch' # Retrieve Filters F1, F2, F3 = filters # Save the input value X_shortcut = X ##### MAIN PATH ##### # First component of main path X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X) X = Activation('relu')(X) ### START CODE HERE ### # Second component of main path (≈3 lines) X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b', padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X) X = Activation('relu')(X) # Third component of main path (≈2 lines) X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X) ##### SHORTCUT PATH #### (≈2 lines) X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut) X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut) # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines) X = Add()([X, X_shortcut]) X = Activation('relu')(X) ### END CODE HERE ### return X12345678910tf.reset_default_graph()with tf.Session() as test: np.random.seed(1) A_prev = tf.placeholder("float", [3, 4, 4, 6]) X = np.random.randn(3, 4, 4, 6) A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a') test.run(tf.global_variables_initializer()) out = test.run([A], feed_dict=&#123;A_prev: X, K.learning_phase(): 0&#125;) print("out = " + str(out[0][1][1][0]))3 - Building your first ResNet model (50 layers)You now have the necessary blocks to build a very deep ResNet. The following figure describes in detail the architecture of this neural network. “ID BLOCK” in the diagram stands for “Identity block,” and “ID BLOCK x3” means you should stack 3 identity blocks together.The details of this ResNet-50 model are:Zero-padding pads the input with a pad of (3,3)Stage 1:The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is “conv1”.BatchNorm is applied to the ‘channels’ axis of the input.MaxPooling uses a (3,3) window and a (2,2) stride.Stage 2:The convolutional block uses three sets of filters of size [64,64,256], “f” is 3, “s” is 1 and the block is “a”.The 2 identity blocks use three sets of filters of size [64,64,256], “f” is 3 and the blocks are “b” and “c”.Stage 3:The convolutional block uses three sets of filters of size [128,128,512], “f” is 3, “s” is 2 and the block is “a”.The 3 identity blocks use three sets of filters of size [128,128,512], “f” is 3 and the blocks are “b”, “c” and “d”.Stage 4:The convolutional block uses three sets of filters of size [256, 256, 1024], “f” is 3, “s” is 2 and the block is “a”.The 5 identity blocks use three sets of filters of size [256, 256, 1024], “f” is 3 and the blocks are “b”, “c”, “d”, “e” and “f”.Stage 5:The convolutional block uses three sets of filters of size [512, 512, 2048], “f” is 3, “s” is 2 and the block is “a”.The 2 identity blocks use three sets of filters of size [512, 512, 2048], “f” is 3 and the blocks are “b” and “c”.The 2D Average Pooling uses a window of shape (2,2) and its name is “avg_pool”.The ‘flatten’ layer doesn’t have any hyperparameters or name.The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation. Its name should be &#39;fc&#39; + str(classes).Exercise: Implement the ResNet with 50 layers described in the figure above. We have implemented Stages 1 and 2. Please implement the rest. (The syntax for implementing Stages 3-5 should be quite similar to that of Stage 2.) Make sure you follow the naming convention in the text above.You’ll need to use this function:Average pooling see referenceHere are some other functions we used in the code below:Conv2D: See referenceBatchNorm: See reference (axis: Integer, the axis that should be normalized (typically the features axis))Zero padding: See referenceMax pooling: See referenceFully connected layer: See referenceAddition: See reference123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# GRADED FUNCTION: ResNet50def ResNet50(input_shape = (64, 64, 3), classes = 6): """ Implementation of the popular ResNet50 the following architecture: CONV2D -&gt; BATCHNORM -&gt; RELU -&gt; MAXPOOL -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; CONVBLOCK -&gt; IDBLOCK*3 -&gt; CONVBLOCK -&gt; IDBLOCK*5 -&gt; CONVBLOCK -&gt; IDBLOCK*2 -&gt; AVGPOOL -&gt; TOPLAYER Arguments: input_shape -- shape of the images of the dataset classes -- integer, number of classes Returns: model -- a Model() instance in Keras """ # Define the input as a tensor with shape input_shape X_input = Input(input_shape) # Zero-Padding X = ZeroPadding2D((3, 3))(X_input) # Stage 1 X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X) X = BatchNormalization(axis = 3, name = 'bn_conv1')(X) X = Activation('relu')(X) X = MaxPooling2D((3, 3), strides=(2, 2))(X) # Stage 2 X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1) X = identity_block(X, 3, [64, 64, 256], stage=2, block='b') X = identity_block(X, 3, [64, 64, 256], stage=2, block='c') ### START CODE HERE ### # Stage 3 (≈4 lines) X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2) X = identity_block(X, 3, [128, 128, 512], stage=3, block='b') X = identity_block(X, 3, [128, 128, 512], stage=3, block='c') X = identity_block(X, 3, [128, 128, 512], stage=3, block='d') # Stage 4 (≈6 lines) X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2) X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e') X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f') # Stage 5 (≈3 lines) X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2) X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b') X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c') # AVGPOOL (≈1 line). Use "X = AveragePooling2D(...)(X)" X = AveragePooling2D((2, 2), name='avg_pool')(X) ### END CODE HERE ### # output layer X = Flatten()(X) X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X) # Create model model = Model(inputs = X_input, outputs = X, name='ResNet50') return modelRun the following code to build the model’s graph. If your implementation is not correct you will know it by checking your accuracy when running model.fit(...) below.1model = ResNet50(input_shape = (64, 64, 3), classes = 6)As seen in the Keras Tutorial Notebook, prior training a model, you need to configure the learning process by compiling the model.1model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])The model is now ready to be trained. The only thing you need is a dataset.Let’s load the SIGNS Dataset.12345678910111213141516X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()# Normalize image vectorsX_train = X_train_orig/255.X_test = X_test_orig/255.# Convert training and test labels to one hot matricesY_train = convert_to_one_hot(Y_train_orig, 6).TY_test = convert_to_one_hot(Y_test_orig, 6).Tprint ("number of training examples = " + str(X_train.shape[0]))print ("number of test examples = " + str(X_test.shape[0]))print ("X_train shape: " + str(X_train.shape))print ("Y_train shape: " + str(Y_train.shape))print ("X_test shape: " + str(X_test.shape))print ("Y_test shape: " + str(Y_test.shape))123456number of training examples = 1080number of test examples = 120X_train shape: (1080, 64, 64, 3)Y_train shape: (1080, 6)X_test shape: (120, 64, 64, 3)Y_test shape: (120, 6)Run the following cell to train your model on 2 epochs with a batch size of 32. On a CPU it should take you around 5min per epoch.1model.fit(X_train, Y_train, epochs = 2, batch_size = 32)Let’s see how this model (trained on only two epochs) performs on the test set.123preds = model.evaluate(X_test, Y_test)print ("Loss = " + str(preds[0]))print ("Test Accuracy = " + str(preds[1]))For the purpose of this assignment, we’ve asked you to train the model for just two epochs. You can see that it achieves poor performances. Please go ahead and submit your assignment; to check correctness, the online grader will run your code only for a small number of epochs as well.After you have finished this official (graded) part of this assignment, you can also optionally train the ResNet for more iterations, if you want. We get a lot better performance when we train for ~20 epochs, but this will take more than an hour when training on a CPU.Using a GPU, we’ve trained our own ResNet50 model’s weights on the SIGNS dataset. You can load and run our trained model on the test set in the cells below. It may take ≈1min to load the model.1model = load_model('ResNet50.h5')123preds = model.evaluate(X_test, Y_test)print ("Loss = " + str(preds[0]))print ("Test Accuracy = " + str(preds[1]))ResNet50 is a powerful model for image classification when it is trained for an adequate number of iterations. We hope you can use what you’ve learnt and apply it to your own classification problem to perform state-of-the-art accuracy.Congratulations on finishing this assignment! You’ve now implemented a state-of-the-art image classification system!4 - Test on your own image (Optional/Ungraded)If you wish, you can also take a picture of your own hand and see the output of the model. To do this:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Write your image&#39;s name in the following code 4. Run the code and check if the algorithm is right! 12345678910img_path = 'images/my_image.jpg'img = image.load_img(img_path, target_size=(64, 64))x = image.img_to_array(img)x = np.expand_dims(x, axis=0)x = x/255.0print('Input image shape:', x.shape)my_image = scipy.misc.imread(img_path)imshow(my_image)print("class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = ")print(model.predict(x))You can also print a summary of your model by running the following code.1model.summary()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377____________________________________________________________________________________________________Layer (type) Output Shape Param # Connected to ====================================================================================================input_1 (InputLayer) (None, 64, 64, 3) 0 ____________________________________________________________________________________________________zero_padding2d_1 (ZeroPadding2D) (None, 70, 70, 3) 0 input_1[0][0] ____________________________________________________________________________________________________conv1 (Conv2D) (None, 32, 32, 64) 9472 zero_padding2d_1[0][0] ____________________________________________________________________________________________________bn_conv1 (BatchNormalization) (None, 32, 32, 64) 256 conv1[0][0] ____________________________________________________________________________________________________activation_4 (Activation) (None, 32, 32, 64) 0 bn_conv1[0][0] ____________________________________________________________________________________________________max_pooling2d_1 (MaxPooling2D) (None, 15, 15, 64) 0 activation_4[0][0] ____________________________________________________________________________________________________res2a_branch2a (Conv2D) (None, 15, 15, 64) 4160 max_pooling2d_1[0][0] ____________________________________________________________________________________________________bn2a_branch2a (BatchNormalizatio (None, 15, 15, 64) 256 res2a_branch2a[0][0] ____________________________________________________________________________________________________activation_5 (Activation) (None, 15, 15, 64) 0 bn2a_branch2a[0][0] ____________________________________________________________________________________________________res2a_branch2b (Conv2D) (None, 15, 15, 64) 36928 activation_5[0][0] ____________________________________________________________________________________________________bn2a_branch2b (BatchNormalizatio (None, 15, 15, 64) 256 res2a_branch2b[0][0] ____________________________________________________________________________________________________activation_6 (Activation) (None, 15, 15, 64) 0 bn2a_branch2b[0][0] ____________________________________________________________________________________________________res2a_branch2c (Conv2D) (None, 15, 15, 256) 16640 activation_6[0][0] ____________________________________________________________________________________________________res2a_branch1 (Conv2D) (None, 15, 15, 256) 16640 max_pooling2d_1[0][0] ____________________________________________________________________________________________________bn2a_branch2c (BatchNormalizatio (None, 15, 15, 256) 1024 res2a_branch2c[0][0] ____________________________________________________________________________________________________bn2a_branch1 (BatchNormalization (None, 15, 15, 256) 1024 res2a_branch1[0][0] ____________________________________________________________________________________________________add_2 (Add) (None, 15, 15, 256) 0 bn2a_branch2c[0][0] bn2a_branch1[0][0] ____________________________________________________________________________________________________activation_7 (Activation) (None, 15, 15, 256) 0 add_2[0][0] ____________________________________________________________________________________________________res2b_branch2a (Conv2D) (None, 15, 15, 64) 16448 activation_7[0][0] ____________________________________________________________________________________________________bn2b_branch2a (BatchNormalizatio (None, 15, 15, 64) 256 res2b_branch2a[0][0] ____________________________________________________________________________________________________activation_8 (Activation) (None, 15, 15, 64) 0 bn2b_branch2a[0][0] ____________________________________________________________________________________________________res2b_branch2b (Conv2D) (None, 15, 15, 64) 36928 activation_8[0][0] ____________________________________________________________________________________________________bn2b_branch2b (BatchNormalizatio (None, 15, 15, 64) 256 res2b_branch2b[0][0] ____________________________________________________________________________________________________activation_9 (Activation) (None, 15, 15, 64) 0 bn2b_branch2b[0][0] ____________________________________________________________________________________________________res2b_branch2c (Conv2D) (None, 15, 15, 256) 16640 activation_9[0][0] ____________________________________________________________________________________________________bn2b_branch2c (BatchNormalizatio (None, 15, 15, 256) 1024 res2b_branch2c[0][0] ____________________________________________________________________________________________________add_3 (Add) (None, 15, 15, 256) 0 bn2b_branch2c[0][0] activation_7[0][0] ____________________________________________________________________________________________________activation_10 (Activation) (None, 15, 15, 256) 0 add_3[0][0] ____________________________________________________________________________________________________res2c_branch2a (Conv2D) (None, 15, 15, 64) 16448 activation_10[0][0] ____________________________________________________________________________________________________bn2c_branch2a (BatchNormalizatio (None, 15, 15, 64) 256 res2c_branch2a[0][0] ____________________________________________________________________________________________________activation_11 (Activation) (None, 15, 15, 64) 0 bn2c_branch2a[0][0] ____________________________________________________________________________________________________res2c_branch2b (Conv2D) (None, 15, 15, 64) 36928 activation_11[0][0] ____________________________________________________________________________________________________bn2c_branch2b (BatchNormalizatio (None, 15, 15, 64) 256 res2c_branch2b[0][0] ____________________________________________________________________________________________________activation_12 (Activation) (None, 15, 15, 64) 0 bn2c_branch2b[0][0] ____________________________________________________________________________________________________res2c_branch2c (Conv2D) (None, 15, 15, 256) 16640 activation_12[0][0] ____________________________________________________________________________________________________bn2c_branch2c (BatchNormalizatio (None, 15, 15, 256) 1024 res2c_branch2c[0][0] ____________________________________________________________________________________________________add_4 (Add) (None, 15, 15, 256) 0 bn2c_branch2c[0][0] activation_10[0][0] ____________________________________________________________________________________________________activation_13 (Activation) (None, 15, 15, 256) 0 add_4[0][0] ____________________________________________________________________________________________________res3a_branch2a (Conv2D) (None, 8, 8, 128) 32896 activation_13[0][0] ____________________________________________________________________________________________________bn3a_branch2a (BatchNormalizatio (None, 8, 8, 128) 512 res3a_branch2a[0][0] ____________________________________________________________________________________________________activation_14 (Activation) (None, 8, 8, 128) 0 bn3a_branch2a[0][0] ____________________________________________________________________________________________________res3a_branch2b (Conv2D) (None, 8, 8, 128) 147584 activation_14[0][0] ____________________________________________________________________________________________________bn3a_branch2b (BatchNormalizatio (None, 8, 8, 128) 512 res3a_branch2b[0][0] ____________________________________________________________________________________________________activation_15 (Activation) (None, 8, 8, 128) 0 bn3a_branch2b[0][0] ____________________________________________________________________________________________________res3a_branch2c (Conv2D) (None, 8, 8, 512) 66048 activation_15[0][0] ____________________________________________________________________________________________________res3a_branch1 (Conv2D) (None, 8, 8, 512) 131584 activation_13[0][0] ____________________________________________________________________________________________________bn3a_branch2c (BatchNormalizatio (None, 8, 8, 512) 2048 res3a_branch2c[0][0] ____________________________________________________________________________________________________bn3a_branch1 (BatchNormalization (None, 8, 8, 512) 2048 res3a_branch1[0][0] ____________________________________________________________________________________________________add_5 (Add) (None, 8, 8, 512) 0 bn3a_branch2c[0][0] bn3a_branch1[0][0] ____________________________________________________________________________________________________activation_16 (Activation) (None, 8, 8, 512) 0 add_5[0][0] ____________________________________________________________________________________________________res3b_branch2a (Conv2D) (None, 8, 8, 128) 65664 activation_16[0][0] ____________________________________________________________________________________________________bn3b_branch2a (BatchNormalizatio (None, 8, 8, 128) 512 res3b_branch2a[0][0] ____________________________________________________________________________________________________activation_17 (Activation) (None, 8, 8, 128) 0 bn3b_branch2a[0][0] ____________________________________________________________________________________________________res3b_branch2b (Conv2D) (None, 8, 8, 128) 147584 activation_17[0][0] ____________________________________________________________________________________________________bn3b_branch2b (BatchNormalizatio (None, 8, 8, 128) 512 res3b_branch2b[0][0] ____________________________________________________________________________________________________activation_18 (Activation) (None, 8, 8, 128) 0 bn3b_branch2b[0][0] ____________________________________________________________________________________________________res3b_branch2c (Conv2D) (None, 8, 8, 512) 66048 activation_18[0][0] ____________________________________________________________________________________________________bn3b_branch2c (BatchNormalizatio (None, 8, 8, 512) 2048 res3b_branch2c[0][0] ____________________________________________________________________________________________________add_6 (Add) (None, 8, 8, 512) 0 bn3b_branch2c[0][0] activation_16[0][0] ____________________________________________________________________________________________________activation_19 (Activation) (None, 8, 8, 512) 0 add_6[0][0] ____________________________________________________________________________________________________res3c_branch2a (Conv2D) (None, 8, 8, 128) 65664 activation_19[0][0] ____________________________________________________________________________________________________bn3c_branch2a (BatchNormalizatio (None, 8, 8, 128) 512 res3c_branch2a[0][0] ____________________________________________________________________________________________________activation_20 (Activation) (None, 8, 8, 128) 0 bn3c_branch2a[0][0] ____________________________________________________________________________________________________res3c_branch2b (Conv2D) (None, 8, 8, 128) 147584 activation_20[0][0] ____________________________________________________________________________________________________bn3c_branch2b (BatchNormalizatio (None, 8, 8, 128) 512 res3c_branch2b[0][0] ____________________________________________________________________________________________________activation_21 (Activation) (None, 8, 8, 128) 0 bn3c_branch2b[0][0] ____________________________________________________________________________________________________res3c_branch2c (Conv2D) (None, 8, 8, 512) 66048 activation_21[0][0] ____________________________________________________________________________________________________bn3c_branch2c (BatchNormalizatio (None, 8, 8, 512) 2048 res3c_branch2c[0][0] ____________________________________________________________________________________________________add_7 (Add) (None, 8, 8, 512) 0 bn3c_branch2c[0][0] activation_19[0][0] ____________________________________________________________________________________________________activation_22 (Activation) (None, 8, 8, 512) 0 add_7[0][0] ____________________________________________________________________________________________________res3d_branch2a (Conv2D) (None, 8, 8, 128) 65664 activation_22[0][0] ____________________________________________________________________________________________________bn3d_branch2a (BatchNormalizatio (None, 8, 8, 128) 512 res3d_branch2a[0][0] ____________________________________________________________________________________________________activation_23 (Activation) (None, 8, 8, 128) 0 bn3d_branch2a[0][0] ____________________________________________________________________________________________________res3d_branch2b (Conv2D) (None, 8, 8, 128) 147584 activation_23[0][0] ____________________________________________________________________________________________________bn3d_branch2b (BatchNormalizatio (None, 8, 8, 128) 512 res3d_branch2b[0][0] ____________________________________________________________________________________________________activation_24 (Activation) (None, 8, 8, 128) 0 bn3d_branch2b[0][0] ____________________________________________________________________________________________________res3d_branch2c (Conv2D) (None, 8, 8, 512) 66048 activation_24[0][0] ____________________________________________________________________________________________________bn3d_branch2c (BatchNormalizatio (None, 8, 8, 512) 2048 res3d_branch2c[0][0] ____________________________________________________________________________________________________add_8 (Add) (None, 8, 8, 512) 0 bn3d_branch2c[0][0] activation_22[0][0] ____________________________________________________________________________________________________activation_25 (Activation) (None, 8, 8, 512) 0 add_8[0][0] ____________________________________________________________________________________________________res4a_branch2a (Conv2D) (None, 4, 4, 256) 131328 activation_25[0][0] ____________________________________________________________________________________________________bn4a_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4a_branch2a[0][0] ____________________________________________________________________________________________________activation_26 (Activation) (None, 4, 4, 256) 0 bn4a_branch2a[0][0] ____________________________________________________________________________________________________res4a_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_26[0][0] ____________________________________________________________________________________________________bn4a_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4a_branch2b[0][0] ____________________________________________________________________________________________________activation_27 (Activation) (None, 4, 4, 256) 0 bn4a_branch2b[0][0] ____________________________________________________________________________________________________res4a_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_27[0][0] ____________________________________________________________________________________________________res4a_branch1 (Conv2D) (None, 4, 4, 1024) 525312 activation_25[0][0] ____________________________________________________________________________________________________bn4a_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4a_branch2c[0][0] ____________________________________________________________________________________________________bn4a_branch1 (BatchNormalization (None, 4, 4, 1024) 4096 res4a_branch1[0][0] ____________________________________________________________________________________________________add_9 (Add) (None, 4, 4, 1024) 0 bn4a_branch2c[0][0] bn4a_branch1[0][0] ____________________________________________________________________________________________________activation_28 (Activation) (None, 4, 4, 1024) 0 add_9[0][0] ____________________________________________________________________________________________________res4b_branch2a (Conv2D) (None, 4, 4, 256) 262400 activation_28[0][0] ____________________________________________________________________________________________________bn4b_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4b_branch2a[0][0] ____________________________________________________________________________________________________activation_29 (Activation) (None, 4, 4, 256) 0 bn4b_branch2a[0][0] ____________________________________________________________________________________________________res4b_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_29[0][0] ____________________________________________________________________________________________________bn4b_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4b_branch2b[0][0] ____________________________________________________________________________________________________activation_30 (Activation) (None, 4, 4, 256) 0 bn4b_branch2b[0][0] ____________________________________________________________________________________________________res4b_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_30[0][0] ____________________________________________________________________________________________________bn4b_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4b_branch2c[0][0] ____________________________________________________________________________________________________add_10 (Add) (None, 4, 4, 1024) 0 bn4b_branch2c[0][0] activation_28[0][0] ____________________________________________________________________________________________________activation_31 (Activation) (None, 4, 4, 1024) 0 add_10[0][0] ____________________________________________________________________________________________________res4c_branch2a (Conv2D) (None, 4, 4, 256) 262400 activation_31[0][0] ____________________________________________________________________________________________________bn4c_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4c_branch2a[0][0] ____________________________________________________________________________________________________activation_32 (Activation) (None, 4, 4, 256) 0 bn4c_branch2a[0][0] ____________________________________________________________________________________________________res4c_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_32[0][0] ____________________________________________________________________________________________________bn4c_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4c_branch2b[0][0] ____________________________________________________________________________________________________activation_33 (Activation) (None, 4, 4, 256) 0 bn4c_branch2b[0][0] ____________________________________________________________________________________________________res4c_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_33[0][0] ____________________________________________________________________________________________________bn4c_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4c_branch2c[0][0] ____________________________________________________________________________________________________add_11 (Add) (None, 4, 4, 1024) 0 bn4c_branch2c[0][0] activation_31[0][0] ____________________________________________________________________________________________________activation_34 (Activation) (None, 4, 4, 1024) 0 add_11[0][0] ____________________________________________________________________________________________________res4d_branch2a (Conv2D) (None, 4, 4, 256) 262400 activation_34[0][0] ____________________________________________________________________________________________________bn4d_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4d_branch2a[0][0] ____________________________________________________________________________________________________activation_35 (Activation) (None, 4, 4, 256) 0 bn4d_branch2a[0][0] ____________________________________________________________________________________________________res4d_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_35[0][0] ____________________________________________________________________________________________________bn4d_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4d_branch2b[0][0] ____________________________________________________________________________________________________activation_36 (Activation) (None, 4, 4, 256) 0 bn4d_branch2b[0][0] ____________________________________________________________________________________________________res4d_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_36[0][0] ____________________________________________________________________________________________________bn4d_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4d_branch2c[0][0] ____________________________________________________________________________________________________add_12 (Add) (None, 4, 4, 1024) 0 bn4d_branch2c[0][0] activation_34[0][0] ____________________________________________________________________________________________________activation_37 (Activation) (None, 4, 4, 1024) 0 add_12[0][0] ____________________________________________________________________________________________________res4e_branch2a (Conv2D) (None, 4, 4, 256) 262400 activation_37[0][0] ____________________________________________________________________________________________________bn4e_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4e_branch2a[0][0] ____________________________________________________________________________________________________activation_38 (Activation) (None, 4, 4, 256) 0 bn4e_branch2a[0][0] ____________________________________________________________________________________________________res4e_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_38[0][0] ____________________________________________________________________________________________________bn4e_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4e_branch2b[0][0] ____________________________________________________________________________________________________activation_39 (Activation) (None, 4, 4, 256) 0 bn4e_branch2b[0][0] ____________________________________________________________________________________________________res4e_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_39[0][0] ____________________________________________________________________________________________________bn4e_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4e_branch2c[0][0] ____________________________________________________________________________________________________add_13 (Add) (None, 4, 4, 1024) 0 bn4e_branch2c[0][0] activation_37[0][0] ____________________________________________________________________________________________________activation_40 (Activation) (None, 4, 4, 1024) 0 add_13[0][0] ____________________________________________________________________________________________________res4f_branch2a (Conv2D) (None, 4, 4, 256) 262400 activation_40[0][0] ____________________________________________________________________________________________________bn4f_branch2a (BatchNormalizatio (None, 4, 4, 256) 1024 res4f_branch2a[0][0] ____________________________________________________________________________________________________activation_41 (Activation) (None, 4, 4, 256) 0 bn4f_branch2a[0][0] ____________________________________________________________________________________________________res4f_branch2b (Conv2D) (None, 4, 4, 256) 590080 activation_41[0][0] ____________________________________________________________________________________________________bn4f_branch2b (BatchNormalizatio (None, 4, 4, 256) 1024 res4f_branch2b[0][0] ____________________________________________________________________________________________________activation_42 (Activation) (None, 4, 4, 256) 0 bn4f_branch2b[0][0] ____________________________________________________________________________________________________res4f_branch2c (Conv2D) (None, 4, 4, 1024) 263168 activation_42[0][0] ____________________________________________________________________________________________________bn4f_branch2c (BatchNormalizatio (None, 4, 4, 1024) 4096 res4f_branch2c[0][0] ____________________________________________________________________________________________________add_14 (Add) (None, 4, 4, 1024) 0 bn4f_branch2c[0][0] activation_40[0][0] ____________________________________________________________________________________________________activation_43 (Activation) (None, 4, 4, 1024) 0 add_14[0][0] ____________________________________________________________________________________________________res5a_branch2a (Conv2D) (None, 2, 2, 512) 524800 activation_43[0][0] ____________________________________________________________________________________________________bn5a_branch2a (BatchNormalizatio (None, 2, 2, 512) 2048 res5a_branch2a[0][0] ____________________________________________________________________________________________________activation_44 (Activation) (None, 2, 2, 512) 0 bn5a_branch2a[0][0] ____________________________________________________________________________________________________res5a_branch2b (Conv2D) (None, 2, 2, 512) 2359808 activation_44[0][0] ____________________________________________________________________________________________________bn5a_branch2b (BatchNormalizatio (None, 2, 2, 512) 2048 res5a_branch2b[0][0] ____________________________________________________________________________________________________activation_45 (Activation) (None, 2, 2, 512) 0 bn5a_branch2b[0][0] ____________________________________________________________________________________________________res5a_branch2c (Conv2D) (None, 2, 2, 2048) 1050624 activation_45[0][0] ____________________________________________________________________________________________________res5a_branch1 (Conv2D) (None, 2, 2, 2048) 2099200 activation_43[0][0] ____________________________________________________________________________________________________bn5a_branch2c (BatchNormalizatio (None, 2, 2, 2048) 8192 res5a_branch2c[0][0] ____________________________________________________________________________________________________bn5a_branch1 (BatchNormalization (None, 2, 2, 2048) 8192 res5a_branch1[0][0] ____________________________________________________________________________________________________add_15 (Add) (None, 2, 2, 2048) 0 bn5a_branch2c[0][0] bn5a_branch1[0][0] ____________________________________________________________________________________________________activation_46 (Activation) (None, 2, 2, 2048) 0 add_15[0][0] ____________________________________________________________________________________________________res5b_branch2a (Conv2D) (None, 2, 2, 512) 1049088 activation_46[0][0] ____________________________________________________________________________________________________bn5b_branch2a (BatchNormalizatio (None, 2, 2, 512) 2048 res5b_branch2a[0][0] ____________________________________________________________________________________________________activation_47 (Activation) (None, 2, 2, 512) 0 bn5b_branch2a[0][0] ____________________________________________________________________________________________________res5b_branch2b (Conv2D) (None, 2, 2, 512) 2359808 activation_47[0][0] ____________________________________________________________________________________________________bn5b_branch2b (BatchNormalizatio (None, 2, 2, 512) 2048 res5b_branch2b[0][0] ____________________________________________________________________________________________________activation_48 (Activation) (None, 2, 2, 512) 0 bn5b_branch2b[0][0] ____________________________________________________________________________________________________res5b_branch2c (Conv2D) (None, 2, 2, 2048) 1050624 activation_48[0][0] ____________________________________________________________________________________________________bn5b_branch2c (BatchNormalizatio (None, 2, 2, 2048) 8192 res5b_branch2c[0][0] ____________________________________________________________________________________________________add_16 (Add) (None, 2, 2, 2048) 0 bn5b_branch2c[0][0] activation_46[0][0] ____________________________________________________________________________________________________activation_49 (Activation) (None, 2, 2, 2048) 0 add_16[0][0] ____________________________________________________________________________________________________res5c_branch2a (Conv2D) (None, 2, 2, 512) 1049088 activation_49[0][0] ____________________________________________________________________________________________________bn5c_branch2a (BatchNormalizatio (None, 2, 2, 512) 2048 res5c_branch2a[0][0] ____________________________________________________________________________________________________activation_50 (Activation) (None, 2, 2, 512) 0 bn5c_branch2a[0][0] ____________________________________________________________________________________________________res5c_branch2b (Conv2D) (None, 2, 2, 512) 2359808 activation_50[0][0] ____________________________________________________________________________________________________bn5c_branch2b (BatchNormalizatio (None, 2, 2, 512) 2048 res5c_branch2b[0][0] ____________________________________________________________________________________________________activation_51 (Activation) (None, 2, 2, 512) 0 bn5c_branch2b[0][0] ____________________________________________________________________________________________________res5c_branch2c (Conv2D) (None, 2, 2, 2048) 1050624 activation_51[0][0] ____________________________________________________________________________________________________bn5c_branch2c (BatchNormalizatio (None, 2, 2, 2048) 8192 res5c_branch2c[0][0] ____________________________________________________________________________________________________add_17 (Add) (None, 2, 2, 2048) 0 bn5c_branch2c[0][0] activation_49[0][0] ____________________________________________________________________________________________________activation_52 (Activation) (None, 2, 2, 2048) 0 add_17[0][0] ____________________________________________________________________________________________________avg_pool (AveragePooling2D) (None, 1, 1, 2048) 0 activation_52[0][0] ____________________________________________________________________________________________________flatten_1 (Flatten) (None, 2048) 0 avg_pool[0][0] ____________________________________________________________________________________________________fc6 (Dense) (None, 6) 12294 flatten_1[0][0] ====================================================================================================Total params: 23,600,006Trainable params: 23,546,886Non-trainable params: 53,120____________________________________________________________________________________________________Finally, run the code below to visualize your ResNet50. You can also download a .png picture of your model by going to “File -&gt; Open…-&gt; model.png”.12plot_model(model, to_file='model.png')SVG(model_to_dot(model).create(prog='dot', format='svg'))What you should rememberVery deep “plain” networks don’t work in practice because they are hard to train due to vanishing gradients.The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function.There are two main types of blocks: The identity block and the convolutional block.Very deep Residual Networks are built by stacking these blocks together.ReferencesThis notebook presents the ResNet algorithm due to He et al. (2015). The implementation here also took significant inspiration and follows the structure given in the GitHub repository of Francois Chollet:Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - Deep Residual Learning for Image Recognition (2015)Francois Chollet’s GitHub repository: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/specializations/deep-learninghttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（4-1）]]></title>
    <url>%2F2019%2F11%2F22%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%884-1%EF%BC%89%2F</url>
    <content type="text"><![CDATA[卷积神经网络（Foundations of Convolutional Neural Networks）1.1 计算机视觉（Computer vision）1.2 边缘检测示例（Edge detection example）卷积运算是卷积神经网络最基本的组成部分。给了这样一张图片，让电脑去搞清楚这张照片里有什么物体，你可能做的第一件事是检测图片中的垂直边缘。比如说，在这张图片中的栏杆就对应垂直线，与此同时，这些行人的轮廓线某种程度上也是垂线，这些线是垂直边缘检测器的输出。同样，你可能也想检测水平边缘，比如说这些栏杆就是很明显的水平线，它们也能被检测到，结果在这。所以如何在图像中检测这些边缘？垂直边缘检测一个6×6的灰度图像，6×6×1的矩阵。为了检测图像中的垂直边缘，可以构造一个3×3矩阵（称为过滤器，有时候也称作“核”）。然后对这个6×6的图像进行卷积运算，卷积运算用“$*$”来表示，用3×3的过滤器对其进行卷积。这个卷积运算的输出将会是一个4×4（6-3+1）的矩阵，你可以将它看成一个4×4的图像。计算过程：$\begin{bmatrix} 3 \times 1 &amp; 0 \times 0 &amp; 1 \times \left(1 \right) \\ 1 \times 1 &amp; 5 \times 0 &amp; 8 \times \left( - 1 \right) \\ 2 \times1 &amp; 7 \times 0 &amp; 2 \times \left( - 1 \right) \\ \end{bmatrix} = \begin{bmatrix}3 &amp; 0 &amp; - 1 \\ 1 &amp; 0 &amp; - 8 \\ 2 &amp; 0 &amp; - 2 \\\end{bmatrix}$，然后将该矩阵每个元素相加得到最左上角的元素，即$3+1+2+0+0 +0+(-1)+(-8) +(-2)=-5$。为什么这个可以做垂直边缘检测呢？在这个例子中，在输出图像中间的亮处，表示在图像中间有一个特别明显的垂直边缘。从垂直边缘检测中可以得到的启发是，因为我们使用3×3的矩阵（过滤器），所以垂直边缘是一个3×3的区域，左边是明亮的像素，中间的并不需要考虑，右边是深色像素。在这个6×6图像的中间部分，明亮的像素在左边，深色的像素在右边，就被视为一个垂直边缘，卷积运算提供了一个方便的方法来发现图像中的垂直边缘。1.3 更多边缘检测内容（More edge detection）现在这幅图有什么变化呢？它的颜色被翻转了，变成了左边比较暗，而右边比较亮。现在亮度为10的点跑到了右边，为0的点则跑到了左边。如果你用它与相同的过滤器进行卷积，最后得到的图中间会是-30，而不是30。如果你将矩阵转换为图片，就会是该矩阵下面图片的样子。现在中间的过渡部分被翻转了，之前的30翻转成了-30，表明是由暗向亮过渡，而不是由亮向暗过渡。水平边缘检测更复杂的例子这里的30（右边矩阵中绿色方框标记元素）代表了左边这块3×3的区域（左边矩阵绿色方框标记部分），这块区域确实是上边比较亮，而下边比较暗的，所以它在这里发现了一条正边缘。而这里的-30（右边矩阵中紫色方框标记元素）又代表了左边另一块区域（左边矩阵紫色方框标记部分），这块区域确实是底部比较亮，而上边则比较暗，所以在这里它是一条负边。我们现在所使用的都是相对很小的图片，仅有6×6。但这些中间的数值，比如说这个10（右边矩阵中黄色方框标记元素）代表的是左边这块区域（左边6×6矩阵中黄色方框标记的部分）。这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一起得到了一个中间值。但假如这个一个非常大的1000×1000的类似这样棋盘风格的大图，就不会出现这些亮度为10的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。其他过滤器$\begin{bmatrix}1 &amp; 0 &amp; - 1 \\ 2 &amp; 0 &amp; - 2 \\ 1 &amp; 0 &amp; - 1 \\\end{bmatrix}$叫做Sobel的过滤器，它的优点在于增加了中间一行元素的权重，这使得结果的鲁棒性会更高一些。$\begin{bmatrix} 3&amp; 0 &amp; - 3 \\ 10 &amp; 0 &amp; - 10 \\ 3 &amp; 0 &amp; - 3 \\\end{bmatrix}$叫做Scharr过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果你将其翻转90度，你就能得到对应水平边缘检测。把这9个数字当成参数的过滤器，通过反向传播，可以学习这种$\begin{bmatrix}1 &amp; 0 &amp; - 1 \\ 1 &amp; 0 &amp; - 1 \\ 1 &amp; 0 &amp; - 1 \\\end{bmatrix}$的过滤器，或者Sobel过滤器和Scharr过滤器。1.4 Padding用一个3×3的过滤器卷积一个6×6的图像，最后会得到一个4×4的输出。这样的话会有两个缺点：1.每次做卷积操作，你的图像就会缩小2.角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息解决方法：沿着图像边缘填充像素至于选择填充多少像素，通常有两个选择，分别叫做Valid卷积和Same卷积。Valid卷积意味着不填充，这样的话，如果你有一个$n×n$的图像，用一个$f×f$的过滤器卷积，它将会给你一个$(n-f+1)×(n-f+1)$维的输出。Same卷积，那意味你填充后，你的输出大小和输入大小是一样的。$p=(f-1)/2$计算机视觉中，$f$通常是奇数，甚至可能都是这样。可能原因：1.如果$f$是一个偶数，那么你只能使用一些不对称填充。只有$f$是奇数的情况下，Same卷积才会有自然的填充，我们可以以同样的数量填充四周，而不是左边填充多一点，右边填充少一点，这样不对称的填充。2.当你有一个奇数维过滤器，比如3×3或者5×5的，它就有一个中心点。1.5 卷积步长（Strided convolutions）用3×3的矩阵卷积一个7×7的矩阵，得到一个3×3的输出。输入和输出的维度是由下面的公式决定的。如果你用一个$f×f$的过滤器卷积一个$n×n$的图像，你的padding为$p$，步幅为$s$，在这个例子中$s=2$，你会得到一个输出，因为现在你不是一次移动一个步子，而是一次移动$s$个步子，输出于是变为$\frac{n+2p - f}{s} + 1 \times \frac{n+2p - f}{s} + 1$互相关和卷积在深度学习中，我们称为的卷积运算实则没有卷积核变换为镜像的这一步操作，因为在权重学习的角度，变换是没有必要的。深度学习的卷积操作在数学上准确度来说称为互相关（cross-correlation）。1.6 三维卷积（Convolutions over volumes）这个过滤器是3×3×3的，如果你想检测图像红色通道的边缘，那么你可以将第一个过滤器设为$\begin{bmatrix}1 &amp; 0 &amp; - 1 \\ 1 &amp; 0 &amp; - 1 \\ 1 &amp; 0 &amp; - 1 \\\end{bmatrix}$，和之前一样，而绿色通道全为0，$\begin{bmatrix} 0&amp; 0 &amp; 0 \\ 0 &amp;0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\\end{bmatrix}$，蓝色也全为0。如果你把这三个堆叠在一起形成一个3×3×3的过滤器，那么这就是一个检测垂直边界的过滤器，但只对红色通道有用。如果你有一个$n \times n \times n_{c}$（通道数）的输入图像，这里的$n_{c}$就是通道数目，然后卷积上一个$f×f×n_{c}$，然后你就得到了$（n-f+1）×（n-f+1）×n_{c^{‘}}$，这里$n_{c^{‘}}$其实就是下一层的通道数。1.7 单层卷积网络（One layer of a convolutional network）和普通的神经网络单层前向传播的过程类似，卷积神经网络也是一个先由输入和权重及偏置做线性运算，然后得到的结果输入一个激活函数中，得到最终的输出：z^{[1]}=w^{[1]}a^{[0]}+b^{[1]}\\a^{[1]}=g(z^{[1]})不同点是在卷积神经网络中，权重和输入进行的是卷积运算。在一个卷积层中，如果我们有10个 3×3×3 大小的卷积核，那么加上每个卷积核对应的偏置，则对于一个卷积层，我们共有的参数个数为 ：$(3\times3\times3+1)\times10 = 280$不论输入图片有多大，参数始终都是280个。用这10个过滤器来提取特征，如垂直边缘，水平边缘和其它特征。即使这些图片很大，参数却很少，这就是卷积神经网络的一个特征，叫作“避免过拟合”。卷积层的各种标记的总结：用$f^{[l]}$表示过滤器大小，上标$\lbrack l\rbrack$表示$l$层中过滤器大小为$f×f$。用$p^{[l]}$来标记padding的数量，用$s^{[l]}$标记步幅。图片大小为$n_{H}^{\left\lbrack l - 1 \right\rbrack} \times n_{W}^{\left\lbrack l - 1 \right\rbrack} \times n_{c}^{\left\lbrack l - 1\right\rbrack}$，$l$层的输入就是上一层的输出，因此上标要用$\lbrack l - 1\rbrack$。权重为$f^{[l]}\times f^{[l]}\times n^{[l-1]}_{C}\times n^{[l]}_{C}$$n_{H}^{[l]} = \lfloor\frac{n_{H}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]}}{s^{[l]}} +1\rfloor$，$n_{W}^{[l]} = \lfloor\frac{n_{W}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]}}{s^{[l]}} +1\rfloor$。1.8 简单卷积网络示例（A simple convolution network example）假如有大小是39×39×3的图片，用于辨别图片中有没有猫，用0或1表示。假设第一层我们用一个3×3的过滤器来提取特征，那么$f^{[1]} = 3$，因为过滤器时3×3的矩阵。$s^{[1]} = 1$，$p^{[1]} =0$，所以高度和宽度使用valid卷积。如果有10个过滤器，神经网络下一层的激活值为37×37×10。假设还有另外一个卷积层，采用过滤器是5×5的矩阵，即$f^{\left\lbrack 2 \right\rbrack} = 5$步幅为2，即$s^{\left\lbrack 2 \right\rbrack} = 2$。padding为0，即$p^{\left\lbrack 2 \right\rbrack} = 0$，且有20个过滤器。所以其输出结果为17×17×20。构建最后一个卷积层，假设过滤器还是5×5，步幅为2，即$f^{\left\lbrack 2 \right\rbrack} = 5$，$s^{\left\lbrack 3 \right\rbrack} = 2$，假设使用了40个过滤器。padding为0，最后结果为7×7×40。为图片提取了7×7×40个特征后进行平滑处理，然后把这个长向量填充到softmax回归函数中。一个典型的卷积神经网络通常有三层，一个是卷积层（COV），一个是池化层(POOL)，最后一个是全连接层（FC）。1.9 池化层（Pooling layers）执行最大池化的树池是一个2×2矩阵。执行过程非常简单，把4×4的输入拆分成不同的区域，我把这个区域用不同颜色来标记。对于2×2的输出，输出的每个元素都是其对应颜色区域中的最大元素值。这是一个2×2矩阵，即$f=2$，步幅是2，即$s=2$。最大池化的输入就是$n_{H} \times n_{W} \times n_{c}$，假设没有padding，则输出$\lfloor\frac{n_{H} - f}{s} +1\rfloor \times \lfloor\frac{n_{w} - f}{s} + 1\rfloor \times n_{c}$。输入通道与输出通道个数相同，因为我们对每个通道都做了池化。需要注意的一点是，池化过程中没有需要学习的参数。执行反向传播时，反向传播没有参数适用于最大池化。只有这些设置过的超参数，可能是手动设置的，也可能是通过交叉验证设置的。1.10 卷积神经网络示例（Convolutional neural network example）有一张大小为32×32×3的输入图片，用于手写体数字识别。第一层使用过滤器大小为5×5，步幅是1，padding是0，过滤器个数为6，那么输出为28×28×6。将这层标记为CONV1，它用了6个过滤器，增加了偏差，应用了非线性函数，可能是ReLU非线性函数，最后输出CONV1的结果。然后构建一个池化层，选择用最大池化，参数$f=2$，$s=2$，因此，28×28变成了14×14，通道数量保持不变，所以最终输出为14×14×6，将该输出标记为POOL1。一类卷积是一个卷积层和一个池化层一起作为一层，这就是神经网络的Layer1。另一类卷积是把卷积层作为一层，而池化层单独作为一层。人们在计算神经网络有多少层时，通常只统计具有权重和参数的层。因为池化层没有权重和参数，只有一些超参数。这里，我们把CONV1和POOL1共同作为一个卷积，并标记为Layer1。再为它构建一个卷积层，过滤器大小为5×5，步幅为1，使用用16个过滤器，最后输出一个10×10×16的矩阵，标记为CONV2。然后做最大池化，超参数$f=2$，$s=2$。你大概可以猜出结果，$f=2$，$s=2$，高度和宽度会减半，最后输出为5×5×16，标记为POOL2，这就是神经网络的第二个卷积层，即Layer2。5×5×16矩阵包含400个元素，现在将POOL2平整化为一个大小为400的一维向量，然后利用这400个单元构建下一层。下一层含有120个单元，这是第一个全连接层，标记为FC3。然后我们对这个120个单元再添加一个全连接层，这层更小，假设它含有84个单元，标记为FC4。最后，用这84个单元填充一个softmax单元。如果我们想通过手写数字识别来识别手写0-9这10个数字，这个softmax就会有10个输出。池化层和最大池化层没有参数；卷积层的参数相对较少，全连接层有着大量参数。1.11 为什么使用卷积？（Why convolutions?）和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接，举例说明一下。卷积神经网络仅有$6×(5×5+1)=156$个参数，而普通的全连接网络有$3072×4704≈14M$个参数。卷积网络映射这么少参数有两个原因：参数共享： 一个特征检测器（filter）对图片的一部分有用的同时也有可能对图片的另外一部分有用。连接的稀疏性：在每一层中，每个输出值只取决于少量的输入。训练卷积神经网络$x$表示一张图片，$\hat{y}$是二进制标记或某个重要标记。我们选定了一个卷积神经网络，输入图片，增加卷积层和池化层，然后添加全连接层，最后输出一个softmax，即$\hat{y}$。卷积层和全连接层有不同的参数$w$和偏差$b$。$\text{Cost}\ J = \frac{1}{m}\sum\limits_{i = 1}^{m}{L(\hat{y}^{(i)},y^{(i)})}$Part 1：Convolutional Model: step by stepWelcome to Course 4’s first assignment! In this assignment, you will implement convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and (optionally) backward propagation.Notation:Superscript $[l]$ denotes an object of the $l^{th}$ layer.Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.Superscript $(i)$ denotes an object from the $i^{th}$ example.Example: $x^{(i)}$ is the $i^{th}$ training example input.Subscript $i$ denotes the $i^{th}$ entry of a vector.Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.$n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$.$n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$.We assume that you are already familiar with numpy and/or have completed the previous courses of the specialization. Let’s get started!UpdatesIf you were working on the notebook before this update…The current notebook is version “v2a”.You can find your original work saved in the notebook with the previous version name (“v2”)To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of updatesclarified example used for padding function. Updated starter code for padding function.conv_forward has additional hints to help students if they’re stuck.conv_forward places code for vert_start and vert_end within the for h in range(...) loop; to avoid redundant calculations. Similarly updated horiz_start and horiz_end. Thanks to our mentor Kevin Brown for pointing this out.conv_forward breaks down the Z[i, h, w, c] single line calculation into 3 lines, for clarity.conv_forward test case checks that students don’t accidentally use n_H_prev instead of n_H, use n_W_prev instead of n_W, and don’t accidentally swap n_H with n_Wpool_forward properly nests calculations of vert_start, vert_end, horiz_start, and horiz_end to avoid redundant calculations.pool_forward has two new test cases that check for a correct implementation of stride (the height and width of the previous layer’s activations should be large enough relative to the filter dimensions so that a stride can take place).conv_backward: initialize Z and cache variables within unit test, to make it independent of unit testing that occurs in the conv_forward section of the assignment.Many thanks to our course mentor, Paul Mielke, for proposing these test cases.1 - PackagesLet’s first import all the packages that you will need during this assignment.numpy is the fundamental package for scientific computing with Python.matplotlib is a library to plot graphs in Python.np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.12345678910111213import numpy as npimport h5pyimport matplotlib.pyplot as plt%matplotlib inlineplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'%load_ext autoreload%autoreload 2np.random.seed(1)2 - Outline of the AssignmentYou will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:Convolution functions, including:Zero PaddingConvolve windowConvolution forwardConvolution backward (optional)Pooling functions, including:Pooling forwardCreate maskDistribute valuePooling backward (optional)This notebook will ask you to implement these functions from scratch in numpy. In the next notebook, you will use the TensorFlow equivalents of these functions to build the following model:Note that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation.3 - Convolutional Neural NetworksAlthough programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below.In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself.3.1 - Zero-PaddingZero-padding adds zeros around the border of an image:The main benefits of padding are the following:It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the “same” convolution, in which the height/width is exactly preserved after one layer.It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.Exercise: Implement the following function, which pads all the images of a batch of examples X with zeros. Use np.pad. Note if you want to pad the array “a” of shape $(5,5,5,5,5)$ with pad = 1 for the 2nd dimension, pad = 3 for the 4th dimension and pad = 0 for the rest, you would do:1a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))1234567891011121314151617181920# GRADED FUNCTION: zero_paddef zero_pad(X, pad): """ Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, as illustrated in Figure 1. Argument: X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images pad -- integer, amount of padding around each image on vertical and horizontal dimensions Returns: X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C) """ ### START CODE HERE ### (≈ 1 line) X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant') ### END CODE HERE ### return X_pad12345678910111213np.random.seed(1)x = np.random.randn(4, 3, 3, 2)x_pad = zero_pad(x, 2)print ("x.shape =\n", x.shape)print ("x_pad.shape =\n", x_pad.shape)print ("x[1,1] =\n", x[1,1])print ("x_pad[1,1] =\n", x_pad[1,1])fig, axarr = plt.subplots(1, 2)axarr[0].set_title('x')axarr[0].imshow(x[0,:,:,0])axarr[1].set_title('x_pad')axarr[1].imshow(x_pad[0,:,:,0])3.2 - Single step of convolutionIn this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which:Takes an input volumeApplies a filter at every position of the inputOutputs another volume (usually of different size)In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output.Later in this notebook, you’ll apply this function to multiple positions of the input to implement the full convolutional operation.Exercise: Implement conv_single_step(). Hint.Note: The variable b will be passed in as a numpy array. If we add a scalar (a float or integer) to a numpy array, the result is a numpy array. In the special case when a numpy array contains a single value, we can cast it as a float to convert it to a scalar.1234567891011121314151617181920212223242526# GRADED FUNCTION: conv_single_stepdef conv_single_step(a_slice_prev, W, b): """ Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation of the previous layer. Arguments: a_slice_prev -- slice of input data of shape (f, f, n_C_prev) W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev) b -- Bias parameters contained in a window - matrix of shape (1, 1, 1) Returns: Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data """ ### START CODE HERE ### (≈ 2 lines of code) # Element-wise product between a_slice_prev and W. Do not add the bias yet. s = a_slice_prev * W # Sum over all entries of the volume s. Z = np.sum(s) # Add bias b to Z. Cast b to a float() so that Z results in a scalar value. Z = Z + b ### END CODE HERE ### return Z12345678np.random.seed(1)a_slice_prev = np.random.randn(4, 4, 3)W = np.random.randn(4, 4, 3)b = np.random.randn(1, 1, 1)Z = conv_single_step(a_slice_prev, W, b)print("Z =", Z)# Z = [[[-6.99908945]]]3.3 - Convolutional Neural Networks - Forward passIn the forward pass, you will take many filters and convolve them on the input. Each ‘convolution’ gives you a 2D matrix output. You will then stack these outputs to get a 3D volume:Exercise:Implement the function below to convolve the filters W on an input activation A_prev.This function takes the following inputs:A_prev, the activations output by the previous layer (for a batch of m inputs);Weights are denoted by W. The filter window size is f by f.The bias vector is b, where each filter has its own (single) bias.Finally you also have access to the hyperparameters dictionary which contains the stride and the padding.Hint:To select a 2x2 slice at the upper left corner of a matrix “a_prev” (shape (5,5,3)), you would do:1a_slice_prev = a_prev[0:2,0:2,:]Notice how this gives a 3D slice that has height 2, width 2, and depth 3. Depth is the number of channels.This will be useful when you will define a_slice_prev below, using the start/end indexes you will define.To define a_slice you will need to first define its corners vert_start, vert_end, horiz_start and horiz_end. This figure may be helpful for you to find out how each of the corner can be defined using h, w, f and s in the code below.Reminder:The formulas relating the output shape of the convolution to the input shape is:n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1n_C = \text{number of filters used in the convolution}For this exercise, we won’t worry about vectorization, and will just implement everything with for-loops.Additional Hints if you’re stuckYou will want to use array slicing (e.g.varname[0:1,:,3:5]) for the following variables:a_prev_pad ,W, bCopy the starter code of the function and run it outside of the defined function, in separate cells.Check that the subset of each array is the size and dimension that you’re expecting.To decide how to get the vert_start, vert_end; horiz_start, horiz_end, remember that these are indices of the previous layer.Draw an example of a previous padded layer (8 x 8, for instance), and the current (output layer) (2 x 2, for instance).The output layer’s indices are denoted by h and w.Make sure that a_slice_prev has a height, width and depth.Remember that a_prev_pad is a subset of A_prev_pad.Think about which one should be used within the for loops.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# GRADED FUNCTION: conv_forwarddef conv_forward(A_prev, W, b, hparameters): """ Implements the forward propagation for a convolution function Arguments: A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev) W -- Weights, numpy array of shape (f, f, n_C_prev, n_C) b -- Biases, numpy array of shape (1, 1, 1, n_C) hparameters -- python dictionary containing "stride" and "pad" Returns: Z -- conv output, numpy array of shape (m, n_H, n_W, n_C) cache -- cache of values needed for the conv_backward() function """ ### START CODE HERE ### # Retrieve dimensions from A_prev's shape (≈1 line) (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape # Retrieve dimensions from W's shape (≈1 line) (f, f, n_C_prev, n_C) = W.shape # Retrieve information from "hparameters" (≈2 lines) stride = hparameters["stride"] pad = hparameters["pad"] # Compute the dimensions of the CONV output volume using the formula given above. # Hint: use int() to apply the 'floor' operation. (≈2 lines) n_H = int((n_H_prev - f + 2 * pad) / stride + 1) n_W = int((n_W_prev - f + 2 * pad) / stride + 1) # Initialize the output volume Z with zeros. (≈1 line) Z = np.zeros((m, n_H, n_W, n_C)) # Create A_prev_pad by padding A_prev A_prev_pad = zero_pad(A_prev, pad) for i in range(m): # loop over the batch of training examples a_prev_pad = A_prev_pad[i, :, :, :] # Select ith training example's padded activation for h in range(n_H): # loop over vertical axis of the output volume # Find the vertical start and end of the current "slice" (≈2 lines) vert_start = stride * h vert_end = vert_start + f for w in range(n_W): # loop over horizontal axis of the output volume # Find the horizontal start and end of the current "slice" (≈2 lines) horiz_start = stride * w horiz_end = horiz_start + f for c in range(n_C): # loop over channels (= #filters) of the output volume # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line) a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line) weights = W[:, :, :, c] biases = b[:, :, :, c] Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases) ### END CODE HERE ### # Making sure your output shape is correct assert(Z.shape == (m, n_H, n_W, n_C)) # Save information in "cache" for the backprop cache = (A_prev, W, b, hparameters) return Z, cache123456789101112np.random.seed(1)A_prev = np.random.randn(10,5,7,4)W = np.random.randn(3,3,4,8)b = np.random.randn(1,1,1,8)hparameters = &#123;"pad" : 1, "stride": 2&#125;Z, cache_conv = conv_forward(A_prev, W, b, hparameters)print("Z's mean =\n", np.mean(Z))print("Z[3,2,1] =\n", Z[3,2,1])print("cache_conv[0][1][2][3] =\n", cache_conv[0][1][2][3])# (3,3,4)*W[:,:,:,0].shapeFinally, CONV layer should also contain an activation, in which case we would add the following line of code:1234# Convolve the window to get back one output neuronZ[i, h, w, c] = ...# Apply activationA[i, h, w, c] = activation(Z[i, h, w, c])You don’t need to do it here.4 - Pooling layerThe pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are:Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the $f \times f$ window you would compute a max or average over.4.1 - Forward PoolingNow, you are going to implement MAX-POOL and AVG-POOL, in the same function.Exercise: Implement the forward pass of the pooling layer. Follow the hints in the comments below.Reminder:As there’s no padding, the formulas binding the output shape of the pooling to the input shape is:n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1n_C = n_{C_{prev}}1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# GRADED FUNCTION: pool_forwarddef pool_forward(A_prev, hparameters, mode = "max"): """ Implements the forward pass of the pooling layer Arguments: A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev) hparameters -- python dictionary containing "f" and "stride" mode -- the pooling mode you would like to use, defined as a string ("max" or "average") Returns: A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C) cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters """ # Retrieve dimensions from the input shape (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape # Retrieve hyperparameters from "hparameters" f = hparameters["f"] stride = hparameters["stride"] # Define the dimensions of the output n_H = int(1 + (n_H_prev - f) / stride) n_W = int(1 + (n_W_prev - f) / stride) n_C = n_C_prev # Initialize output matrix A A = np.zeros((m, n_H, n_W, n_C)) ### START CODE HERE ### for i in range(m): # loop over the training examples for h in range(n_H): # loop on the vertical axis of the output volume # Find the vertical start and end of the current "slice" (≈2 lines) vert_start = h * stride vert_end = vert_start + f for w in range(n_W): # loop on the horizontal axis of the output volume # Find the vertical start and end of the current "slice" (≈2 lines) horiz_start = w * stride horiz_end = horiz_start + f for c in range (n_C): # loop over the channels of the output volume # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line) a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] # Compute the pooling operation on the slice. # Use an if statement to differentiate the modes. # Use np.max and np.mean. if mode == "max": A[i, h, w, c] = np.max(a_prev_slice) elif mode == "average": A[i, h, w, c] = np.mean(a_prev_slice) ### END CODE HERE ### # Store the input and hparameters in "cache" for pool_backward() cache = (A_prev, hparameters) # Making sure your output shape is correct assert(A.shape == (m, n_H, n_W, n_C)) return A, cache1234567891011121314# Case 1: stride of 1np.random.seed(1)A_prev = np.random.randn(2, 5, 5, 3)hparameters = &#123;"stride" : 1, "f": 3&#125;A, cache = pool_forward(A_prev, hparameters)print("mode = max")print("A.shape = " + str(A.shape))print("A =\n", A)print()A, cache = pool_forward(A_prev, hparameters, mode = "average")print("mode = average")print("A.shape = " + str(A.shape))print("A =\n", A)123456789101112131415# Case 2: stride of 2np.random.seed(1)A_prev = np.random.randn(2, 5, 5, 3)hparameters = &#123;"stride" : 2, "f": 3&#125;A, cache = pool_forward(A_prev, hparameters)print("mode = max")print("A.shape = " + str(A.shape))print("A =\n", A)print()A, cache = pool_forward(A_prev, hparameters, mode = "average")print("mode = average")print("A.shape = " + str(A.shape))print("A =\n", A)Congratulations! You have now implemented the forward passes of all the layers of a convolutional network.The remainder of this notebook is optional, and will not be graded.5 - Backpropagation in convolutional neural networks (OPTIONAL / UNGRADED)In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers don’t need to bother with the details of the backward pass. The backward pass for convolutional networks is complicated. If you wish, you can work through this optional portion of the notebook to get a sense of what backprop in a convolutional network looks like.When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in convolutional neural networks you can calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are not trivial and we did not derive them in lecture, but we will briefly present them below.5.1 - Convolutional layer backward passLet’s start by implementing the backward pass for a CONV layer.5.1.1 - Computing dA:This is the formula for computing $dA$ with respect to the cost for a certain filter $W_c$ and a given training example:dA += \sum _{h=0} ^{n_H} \sum_{w=0} ^{n_W} W_c \times dZ_{hw} \tag{1}Where $W_c$ is a filter and $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). Note that at each time, we multiply the the same filter $W_c$ by a different dZ when updating dA. We do so mainly because when computing the forward propagation, each filter is dotted and summed by a different a_slice. Therefore when computing the backprop for dA, we are just adding the gradients of all the a_slices.In code, inside the appropriate for-loops, this formula translates into:1da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]5.1.2 - Computing dW:This is the formula for computing $dW_c$ ($dW_c$ is the derivative of one filter) with respect to the loss:dW_c += \sum _{h=0} ^{n_H} \sum_{w=0} ^ {n_W} a_{slice} \times dZ_{hw} \tag{2}Where $a_{slice}$ corresponds to the slice which was used to generate the activation $Z_{ij}$. Hence, this ends up giving us the gradient for $W$ with respect to that slice. Since it is the same $W$, we will just add up all such gradients to get $dW$.In code, inside the appropriate for-loops, this formula translates into:1dW[:,:,:,c] += a_slice * dZ[i, h, w, c]5.1.3 - Computing db:This is the formula for computing $db$ with respect to the cost for a certain filter $W_c$:db = \sum_h \sum_w dZ_{hw} \tag{3}As you have previously seen in basic neural networks, db is computed by summing $dZ$. In this case, you are just summing over all the gradients of the conv output (Z) with respect to the cost.In code, inside the appropriate for-loops, this formula translates into:1db[:,:,:,c] += dZ[i, h, w, c]Exercise: Implement the conv_backward function below. You should sum over all the training examples, filters, heights, and widths. You should then compute the derivatives using formulas 1, 2 and 3 above.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475def conv_backward(dZ, cache): """ Implement the backward propagation for a convolution function Arguments: dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C) cache -- cache of values needed for the conv_backward(), output of conv_forward() Returns: dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev), numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev) dW -- gradient of the cost with respect to the weights of the conv layer (W) numpy array of shape (f, f, n_C_prev, n_C) db -- gradient of the cost with respect to the biases of the conv layer (b) numpy array of shape (1, 1, 1, n_C) """ ### START CODE HERE ### # Retrieve information from "cache" (A_prev, W, b, hparameters) = cache # Retrieve dimensions from A_prev's shape (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape # Retrieve dimensions from W's shape (f, f, n_C_prev, n_C) = W.shape # Retrieve information from "hparameters" stride = hparameters['stride'] pad = hparameters['pad'] # Retrieve dimensions from dZ's shape (m, n_H, n_W, n_C) = dZ.shape # Initialize dA_prev, dW, db with the correct shapes dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev)) dW = np.zeros((f, f, n_C_prev, n_C)) db = np.zeros((1, 1, 1, n_C)) # Pad A_prev and dA_prev A_prev_pad = zero_pad(A_prev, pad) dA_prev_pad = zero_pad(dA_prev, pad) for i in range(m): # loop over the training examples # select ith training example from A_prev_pad and dA_prev_pad a_prev_pad = A_prev_pad[i, :, :, :] da_prev_pad = dA_prev_pad[i, :, :, :] for h in range(n_H): # loop over vertical axis of the output volume for w in range(n_W): # loop over horizontal axis of the output volume for c in range(n_C): # loop over the channels of the output volume # Find the corners of the current "slice" vert_start = h * stride vert_end = vert_start + f horiz_start = w * stride horiz_end = horiz_start + f # Use the corners to define the slice from a_prev_pad a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] # Update gradients for the window and the filter's parameters using the code formulas given above da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c] dW[:,:,:,c] += a_slice * dZ[i, h, w, c] db[:,:,:,c] += dZ[i, h, w, c] # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :]) dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :] ### END CODE HERE ### # Making sure your output shape is correct assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev)) return dA_prev, dW, db123456789101112131415# We'll run conv_forward to initialize the 'Z' and 'cache_conv",# which we'll use to test the conv_backward functionnp.random.seed(1)A_prev = np.random.randn(10,4,4,3)W = np.random.randn(2,2,3,8)b = np.random.randn(1,1,1,8)hparameters = &#123;"pad" : 2, "stride": 2&#125;Z, cache_conv = conv_forward(A_prev, W, b, hparameters)# Test conv_backwarddA, dW, db = conv_backward(Z, cache_conv)print("dA_mean =", np.mean(dA))print("dW_mean =", np.mean(dW))print("db_mean =", np.mean(db))5.2 Pooling layer - backward passNext, let’s implement the backward pass for the pooling layer, starting with the MAX-POOL layer. Even though a pooling layer has no parameters for backprop to update, you still need to backpropagation the gradient through the pooling layer in order to compute gradients for layers that came before the pooling layer.5.2.1 Max pooling - backward passBefore jumping into the backpropagation of the pooling layer, you are going to build a helper function called create_mask_from_window() which does the following:X = \begin{bmatrix} 1 && 3 \\ 4 && 2 \end{bmatrix} \quad \rightarrow \quad M =\begin{bmatrix} 0 && 0 \\ 1 && 0 \end{bmatrix}\tag{4}As you can see, this function creates a “mask” matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You’ll see later that the backward pass for average pooling will be similar to this but using a different mask.Exercise: Implement create_mask_from_window(). This function will be helpful for pooling backward.Hints:np.max() may be helpful. It computes the maximum of an array.If you have a matrix X and a scalar x: A = (X == x) will return a matrix A of the same size as X such that:12A[i,j] = True if X[i,j] = xA[i,j] = False if X[i,j] != xHere, you don’t need to consider cases where there are several maxima in a matrix.12345678910111213141516def create_mask_from_window(x): """ Creates a mask from an input matrix x, to identify the max entry of x. Arguments: x -- Array of shape (f, f) Returns: mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x. """ ### START CODE HERE ### (≈1 line) mask = (x == np.max(x)) ### END CODE HERE ### return mask12345np.random.seed(1)x = np.random.randn(2,3)mask = create_mask_from_window(x)print('x = ', x)print("mask = ", mask)Why do we keep track of the position of the max? It’s because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will “propagate” the gradient back to this particular input value that had influenced the cost.5.2.2 - Average pooling - backward passIn max pooling, for each input window, all the “influence” on the output came from a single input value—the max. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you’ll use for the backward pass will look like:dZ = 1 \quad \rightarrow \quad dZ =\begin{bmatrix} 1/4 && 1/4 \\ 1/4 && 1/4 \end{bmatrix}\tag{5}This implies that each position in the $dZ$ matrix contributes equally to output because in the forward pass, we took an average.Exercise: Implement the function below to equally distribute a value dz through a matrix of dimension shape. Hint123456789101112131415161718192021222324def distribute_value(dz, shape): """ Distributes the input value in the matrix of dimension shape Arguments: dz -- input scalar shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz Returns: a -- Array of size (n_H, n_W) for which we distributed the value of dz """ ### START CODE HERE ### # Retrieve dimensions from shape (≈1 line) (n_H, n_W) = shape # Compute the value to distribute on the matrix (≈1 line) average = dz / (n_H * n_W) # Create a matrix where every entry is the "average" value (≈1 line) a = average * np.ones(shape) ### END CODE HERE ### return a12a = distribute_value(2, (2,2))print('distributed value =', a)5.2.3 Putting it together: Pooling backwardYou now have everything you need to compute backward propagation on a pooling layer.Exercise: Implement the pool_backward function in both modes (&quot;max&quot; and &quot;average&quot;). You will once again use 4 for-loops (iterating over training examples, height, width, and channels). You should use an if/elif statement to see if the mode is equal to &#39;max&#39; or &#39;average&#39;. If it is equal to ‘average’ you should use the distribute_value() function you implemented above to create a matrix of the same shape as a_slice. Otherwise, the mode is equal to ‘max‘, and you will create a mask with create_mask_from_window() and multiply it by the corresponding value of dA.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970def pool_backward(dA, cache, mode = "max"): """ Implements the backward pass of the pooling layer Arguments: dA -- gradient of cost with respect to the output of the pooling layer, same shape as A cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters mode -- the pooling mode you would like to use, defined as a string ("max" or "average") Returns: dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev """ ### START CODE HERE ### # Retrieve information from cache (≈1 line) (A_prev, hparameters) = cache # Retrieve hyperparameters from "hparameters" (≈2 lines) stride = hparameters['stride'] f = hparameters['f'] # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines) m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape m, n_H, n_W, n_C = dA.shape # Initialize dA_prev with zeros (≈1 line) dA_prev = np.zeros(np.shape(A_prev)) for i in range(m): # loop over the training examples # select training example from A_prev (≈1 line) a_prev = A_prev[i, :, :, :] for h in range(n_H): # loop on the vertical axis for w in range(n_W): # loop on the horizontal axis for c in range(n_C): # loop over the channels (depth) # Find the corners of the current "slice" (≈4 lines) vert_start = h * stride vert_end = vert_start + f horiz_start = w * stride horiz_end = horiz_start + f # Compute the backward propagation in both modes. if mode == "max": # Use the corners and "c" to define the current slice from a_prev (≈1 line) a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c] # Create the mask from a_prev_slice (≈1 line) mask = create_mask_from_window(a_prev_slice) # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line) dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask, dA[i, h, w, c]) elif mode == "average": # Get the value a from dA (≈1 line) da = dA[i, h, w, c] # Define the shape of the filter as fxf (≈1 line) shape = (f, f) # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line) dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape) ### END CODE ### # Making sure your output shape is correct assert(dA_prev.shape == A_prev.shape) return dA_prev123456789101112131415np.random.seed(1)A_prev = np.random.randn(5, 5, 3, 2)hparameters = &#123;"stride" : 1, "f": 2&#125;A, cache = pool_forward(A_prev, hparameters)dA = np.random.randn(5, 4, 2, 2)dA_prev = pool_backward(dA, cache, mode = "max")print("mode = max")print('mean of dA = ', np.mean(dA))print('dA_prev[1,1] = ', dA_prev[1,1]) print()dA_prev = pool_backward(dA, cache, mode = "average")print("mode = average")print('mean of dA = ', np.mean(dA))print('dA_prev[1,1] = ', dA_prev[1,1])Congratulations !Congratulations on completing this assignment. You now understand how convolutional neural networks work. You have implemented all the building blocks of a neural network. In the next assignment you will implement a ConvNet using TensorFlow.Part 2：Convolutional Neural Networks: ApplicationWelcome to Course 4’s second assignment! In this notebook, you will:Implement helper functions that you will use when implementing a TensorFlow modelImplement a fully functioning ConvNet using TensorFlowAfter this assignment you will be able to:Build and train a ConvNet in TensorFlow for a classification problemWe assume here that you are already familiar with TensorFlow. If you are not, please refer the TensorFlow Tutorial of the third week of Course 2 (“Improving deep neural networks“).Updates to AssignmentIf you were working on a previous versionThe current notebook filename is version “1a”.You can find your work in the file directory as version “1”.To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.List of Updatesinitialize_parameters: added details about tf.get_variable, eval. Clarified test case.Added explanations for the kernel (filter) stride values, max pooling, and flatten functions.Added details about softmax cross entropy with logits.Added instructions for creating the Adam Optimizer.Added explanation of how to evaluate tensors (optimizer and cost).forward_propagation: clarified instructions, use “F” to store “flatten” layer.Updated print statements and ‘expected output’ for easier visual comparisons.Many thanks to Kevin P. Brown (mentor for the deep learning specialization) for his suggestions on the assignments in this course!1.0 - TensorFlow modelIn the previous assignment, you built helper functions using numpy to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call.As usual, we will start by loading in the packages.12345678910111213import mathimport numpy as npimport h5pyimport matplotlib.pyplot as pltimport scipyfrom PIL import Imagefrom scipy import ndimageimport tensorflow as tffrom tensorflow.python.framework import opsfrom cnn_utils import *%matplotlib inlinenp.random.seed(1)Run the next cell to load the “SIGNS” dataset you are going to use.12# Loading the data (signs)X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of index below and re-run to see different examples.1234# Example of a pictureindex = 6plt.imshow(X_train_orig[index])print ("y = " + str(np.squeeze(Y_train_orig[:, index])))In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.To get started, let’s examine the shapes of your data.1234567891011X_train = X_train_orig/255.X_test = X_test_orig/255.Y_train = convert_to_one_hot(Y_train_orig, 6).TY_test = convert_to_one_hot(Y_test_orig, 6).Tprint ("number of training examples = " + str(X_train.shape[0]))print ("number of test examples = " + str(X_test.shape[0]))print ("X_train shape: " + str(X_train.shape))print ("Y_train shape: " + str(Y_train.shape))print ("X_test shape: " + str(X_test.shape))print ("Y_test shape: " + str(Y_test.shape))conv_layers = &#123;&#125;1.1 - Create placeholdersTensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.Exercise: Implement the function below to create placeholders for the input image X and the output Y. You should not define the number of training examples for the moment. To do so, you could use “None” as the batch size, it will give you the flexibility to choose it later. Hence X should be of dimension [None, n_H0, n_W0, n_C0] and Y should be of dimension [None, n_y]. Hint: search for the tf.placeholder documentation”.1234567891011121314151617181920212223# GRADED FUNCTION: create_placeholdersdef create_placeholders(n_H0, n_W0, n_C0, n_y): """ Creates the placeholders for the tensorflow session. Arguments: n_H0 -- scalar, height of an input image n_W0 -- scalar, width of an input image n_C0 -- scalar, number of channels of the input n_y -- scalar, number of classes Returns: X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float" Y -- placeholder for the input labels, of shape [None, n_y] and dtype "float" """ ### START CODE HERE ### (≈2 lines) X = tf.placeholder(tf.float32, shape=[None, n_H0, n_W0, n_C0]) Y = tf.placeholder(tf.float32, shape=[None, n_y]) ### END CODE HERE ### return X, Y123X, Y = create_placeholders(64, 64, 3, 6)print ("X = " + str(X))print ("Y = " + str(Y))1.2 - Initialize parametersYou will initialize weights/filters $W1$ and $W2$ using tf.contrib.layers.xavier_initializer(seed = 0). You don’t need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.Exercise: Implement initialize_parameters(). The dimensions for each group of filters are provided below. Reminder - to initialize a parameter $W$ of shape [1,2,3,4] in Tensorflow, use:1W = tf.get_variable("W", [1,2,3,4], initializer = ...)tf.get_variable()Search for the tf.get_variable documentation. Notice that the documentation says:1Gets an existing variable with these parameters or create a new one.So we can use this function to create a tensorflow variable with the specified name, but if the variables already exist, it will get the existing variable with that same name.123456789101112131415161718192021222324# GRADED FUNCTION: initialize_parametersdef initialize_parameters(): """ Initializes weight parameters to build a neural network with tensorflow. The shapes are: W1 : [4, 4, 3, 8] W2 : [2, 2, 8, 16] Note that we will hard code the shape values in the function to make the grading simpler. Normally, functions should take values as inputs rather than hard coding. Returns: parameters -- a dictionary of tensors containing W1, W2 """ tf.set_random_seed(1) # so that your "random" numbers match ours ### START CODE HERE ### (approx. 2 lines of code) W1 = tf.get_variable("W1", [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed=0)) W2 = tf.get_variable("W2", [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0)) ### END CODE HERE ### parameters = &#123;"W1": W1, "W2": W2&#125; return parameters12345678910tf.reset_default_graph()with tf.Session() as sess_test: parameters = initialize_parameters() init = tf.global_variables_initializer() sess_test.run(init) print("W1[1,1,1] = \n" + str(parameters["W1"].eval()[1,1,1])) print("W1.shape: " + str(parameters["W1"].shape)) print("\n") print("W2[1,1,1] = \n" + str(parameters["W2"].eval()[1,1,1])) print("W2.shape: " + str(parameters["W2"].shape))1.3 - Forward propagationIn TensorFlow, there are built-in functions that implement the convolution steps for you.tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = ‘SAME’): given an input $X$ and a group of filters $W$, this function convolves $W$’s filters on X. The third parameter ([1,s,s,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). Normally, you’ll choose a stride of 1 for the number of examples (the first value) and for the channels (the fourth value), which is why we wrote the value as [1,s,s,1]. You can read the full documentation on conv2d.tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = ‘SAME’): given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window. For max pooling, we usually operate on a single example at a time and a single channel at a time. So the first and fourth value in [1,f,f,1] are both 1. You can read the full documentation on max_pool.tf.nn.relu(Z): computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on relu.tf.contrib.layers.flatten(P): given a tensor “P”, this function takes each training (or test) example in the batch and flattens it into a 1D vector.If a tensor P has the shape (m,h,w,c), where m is the number of examples (the batch size), it returns a flattened tensor with shape (batch_size, k), where $k=h \times w \times c$. “k” equals the product of all the dimension sizes other than the first dimension.For example, given a tensor with dimensions [100,2,3,4], it flattens the tensor to be of shape [100, 24], where 24 = 2 3 4. You can read the full documentation on flatten.tf.contrib.layers.fully_connected(F, num_outputs): given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on full_connected.In the last function above (tf.contrib.layers.fully_connected), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.Window, kernel, filterThe words “window”, “kernel”, and “filter” are used to refer to the same thing. This is why the parameter ksize refers to “kernel size”, and we use (f,f) to refer to the filter size. Both “kernel” and “filter” refer to the “window.”123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: forward_propagationdef forward_propagation(X, parameters): """ Implements the forward propagation for the model: CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED Note that for simplicity and grading purposes, we'll hard-code some values such as the stride and kernel (filter) sizes. Normally, functions should take these values as function parameters. Arguments: X -- input dataset placeholder, of shape (input size, number of examples) parameters -- python dictionary containing your parameters "W1", "W2" the shapes are given in initialize_parameters Returns: Z3 -- the output of the last LINEAR unit """ # Retrieve the parameters from the dictionary "parameters" W1 = parameters['W1'] W2 = parameters['W2'] ### START CODE HERE ### # CONV2D: stride of 1, padding 'SAME' Z1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME') # RELU A1 = tf.nn.relu(Z1) # MAXPOOL: window 8x8, stride 8, padding 'SAME' P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding='SAME') # CONV2D: filters W2, stride 1, padding 'SAME' Z2 = tf.nn.conv2d(P1, W2, strides=[1,1,1,1], padding='SAME') # RELU A2 = tf.nn.relu(Z2) # MAXPOOL: window 4x4, stride 4, padding 'SAME' P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding='SAME') # FLATTEN F = tf.contrib.layers.flatten(P2) # FULLY-CONNECTED without non-linear activation function (not not call softmax). # 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" Z3 = tf.contrib.layers.fully_connected(F, 6, activation_fn=None) ### END CODE HERE ### return Z31234567891011tf.reset_default_graph()with tf.Session() as sess: np.random.seed(1) X, Y = create_placeholders(64, 64, 3, 6) parameters = initialize_parameters() Z3 = forward_propagation(X, parameters) init = tf.global_variables_initializer() sess.run(init) a = sess.run(Z3, &#123;X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)&#125;) print("Z3 = \n" + str(a))1.4 - Compute costImplement the compute cost function below. Remember that the cost function helps the neural network see how much the model’s predictions differ from the correct labels. By adjusting the weights of the network to reduce the cost, the neural network can improve its predictions.You might find these two functions helpful:tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y): computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation softmax_cross_entropy_with_logits.tf.reduce_mean: computes the mean of elements across dimensions of a tensor. Use this to calculate the sum of the losses over all the examples to get the overall cost. You can check the full documentation reduce_mean.Details on softmax_cross_entropy_with_logits (optional reading)Softmax is used to format outputs so that they can be used for classification. It assigns a value between 0 and 1 for each category, where the sum of all prediction values (across all possible categories) equals 1.Cross Entropy is compares the model’s predicted classifications with the actual labels and results in a numerical value representing the “loss” of the model’s predictions.“Logits” are the result of multiplying the weights and adding the biases. Logits are passed through an activation function (such as a relu), and the result is called the “activation.”The function is named softmax_cross_entropy_with_logits takes logits as input (and not activations); then uses the model to predict using softmax, and then compares the predictions with the true labels using cross entropy. These are done with a single function to optimize the calculations.Exercise: Compute the cost below using the function above.12345678910111213141516171819# GRADED FUNCTION: compute_cost def compute_cost(Z3, Y): """ Computes the cost Arguments: Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6) Y -- "true" labels vector placeholder, same shape as Z3 Returns: cost - Tensor of the cost function """ ### START CODE HERE ### (1 line of code) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y)) ### END CODE HERE ### return cost12345678910111213tf.reset_default_graph()with tf.Session() as sess: np.random.seed(1) X, Y = create_placeholders(64, 64, 3, 6) parameters = initialize_parameters() Z3 = forward_propagation(X, parameters) cost = compute_cost(Z3, Y) init = tf.global_variables_initializer() sess.run(init) a = sess.run(cost, &#123;X: np.random.randn(4,64,64,3), Y: np.random.randn(4,6)&#125;) print("cost = " + str(a))# cost = 2.910341.5 ModelFinally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset.Exercise: Complete the function below.The model below should:create placeholdersinitialize parametersforward propagatecompute the costcreate an optimizerFinally you will create a session and run a for loop for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function. Hint for initializing the variablesAdam OptimizerYou can use tf.train.AdamOptimizer(learning_rate = ...) to create the optimizer. The optimizer has a minimize(loss=...) function that you’ll call to set the cost function that the optimizer will minimize.For details, check out the documentation for Adam OptimizerRandom mini batchesIf you took course 2 of the deep learning specialization, you implemented random_mini_batches() in the “Optimization” programming assignment. This function returns a list of mini-batches. It is already implemented in the cnn_utils.py file and imported here, so you can call it like this:1minibatches = random_mini_batches(X, Y, mini_batch_size = 64, seed = 0)(You will want to choose the correct variable names when you use it in your code).Evaluating the optimizer and costWithin a loop, for each mini-batch, you’ll use the tf.Session object (named sess) to feed a mini-batch of inputs and labels into the neural network and evaluate the tensors for the optimizer as well as the cost. Remember that we built a graph data structure and need to feed it inputs and labels and use sess.run() in order to get values for the optimizer and cost.You’ll use this kind of syntax:12345output_for_var1, output_for_var2 = sess.run( fetches=[var1, var2], feed_dict=&#123;var_inputs: the_batch_of_inputs, var_labels: the_batch_of_labels&#125; )Notice that sess.run takes its first argument fetches as a list of objects that you want it to evaluate (in this case, we want to evaluate the optimizer and the cost).It also takes a dictionary for the feed_dict parameter.The keys are the tf.placeholder variables that we created in the create_placeholders function above.The values are the variables holding the actual numpy arrays for each mini-batch.The sess.run outputs a tuple of the evaluated tensors, in the same order as the list given to fetches.For more information on how to use sess.run, see the documentation tf.Sesssion#run documentation.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116# GRADED FUNCTION: modeldef model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epochs = 100, minibatch_size = 64, print_cost = True): """ Implements a three-layer ConvNet in Tensorflow: CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED Arguments: X_train -- training set, of shape (None, 64, 64, 3) Y_train -- test set, of shape (None, n_y = 6) X_test -- training set, of shape (None, 64, 64, 3) Y_test -- test set, of shape (None, n_y = 6) learning_rate -- learning rate of the optimization num_epochs -- number of epochs of the optimization loop minibatch_size -- size of a minibatch print_cost -- True to print the cost every 100 epochs Returns: train_accuracy -- real number, accuracy on the train set (X_train) test_accuracy -- real number, testing accuracy on the test set (X_test) parameters -- parameters learnt by the model. They can then be used to predict. """ ops.reset_default_graph() # to be able to rerun the model without overwriting tf variables tf.set_random_seed(1) # to keep results consistent (tensorflow seed) seed = 3 # to keep results consistent (numpy seed) (m, n_H0, n_W0, n_C0) = X_train.shape n_y = Y_train.shape[1] costs = [] # To keep track of the cost # Create Placeholders of the correct shape ### START CODE HERE ### (1 line) X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y) ### END CODE HERE ### # Initialize parameters ### START CODE HERE ### (1 line) parameters = initialize_parameters() ### END CODE HERE ### # Forward propagation: Build the forward propagation in the tensorflow graph ### START CODE HERE ### (1 line) Z3 = forward_propagation(X, parameters) ### END CODE HERE ### # Cost function: Add cost function to tensorflow graph ### START CODE HERE ### (1 line) cost = compute_cost(Z3, Y) ### END CODE HERE ### # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost. ### START CODE HERE ### (1 line) optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost) ### END CODE HERE ### # Initialize all the variables globally init = tf.global_variables_initializer() # Start the session to compute the tensorflow graph with tf.Session() as sess: # Run the initialization sess.run(init) # Do the training loop for epoch in range(num_epochs): minibatch_cost = 0. num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set seed = seed + 1 minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed) for minibatch in minibatches: # Select a minibatch (minibatch_X, minibatch_Y) = minibatch """ # IMPORTANT: The line that runs the graph on a minibatch. # Run the session to execute the optimizer and the cost. # The feedict should contain a minibatch for (X,Y). """ ### START CODE HERE ### (1 line) _ , temp_cost = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;) ### END CODE HERE ### minibatch_cost += temp_cost / num_minibatches # Print the cost every epoch if print_cost == True and epoch % 5 == 0: print ("Cost after epoch %i: %f" % (epoch, minibatch_cost)) if print_cost == True and epoch % 1 == 0: costs.append(minibatch_cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per tens)') plt.title("Learning rate =" + str(learning_rate)) plt.show() # Calculate the correct predictions predict_op = tf.argmax(Z3, 1) correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1)) # Calculate accuracy on the test set accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) print(accuracy) train_accuracy = accuracy.eval(&#123;X: X_train, Y: Y_train&#125;) test_accuracy = accuracy.eval(&#123;X: X_test, Y: Y_test&#125;) print("Train Accuracy:", train_accuracy) print("Test Accuracy:", test_accuracy) return train_accuracy, test_accuracy, parametersRun the following cell to train your model for 100 epochs. Check if your cost after epoch 0 and 5 matches our output. If not, stop the cell and go back to your code!1_, _, parameters = model(X_train, Y_train, X_test, Y_test)Congratulations! You have finished the assignment and built a model that recognizes SIGN language with almost 80% accuracy on the test set. If you wish, feel free to play around with this dataset further. You can actually improve its accuracy by spending more time tuning the hyperparameters, or using regularization (as this model clearly has a high variance).Once again, here’s a thumbs up for your work!1234fname = "images/thumbs_up.jpg"image = np.array(ndimage.imread(fname, flatten=False))my_image = scipy.misc.imresize(image, size=(64,64))plt.imshow(my_image)参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/specializations/deep-learninghttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（3-2）]]></title>
    <url>%2F2019%2F11%2F22%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%883-2%EF%BC%89%2F</url>
    <content type="text"><![CDATA[机器学习策略（2）(ML Strategy (2))2.1 进行误差分析（Carrying out error analysis）假设你正在调试猫分类器，然后你取得了90%准确率，相当于10%错误，在你的开发集上做到这样。同时注意到算法将一些狗分类为猫，你可以针对狗，收集更多的狗图，或者设计一些只处理狗的算法功能之类的，为了让你的猫分类器在狗图上做的更好，让算法不再将狗分类成猫，然而可能几个月的尝试都改进不了什么。收集错误样例：假设你的100个错误标记样本中只有5%是狗，那么你也只能修正这100个错误中的5个，错误率相对下降了5%（总体下降了0.5%，100的错误样本，错误率为10%，则样本为1000）。可以提升的上限 称为性能上限。并行分析：建立这样一个表格，同时对样例进行标注，最后分析性能上限。2.2 清除标注错误的数据（Cleaning up Incorrectly labeled data）你的监督学习问题的数据由输入$x$和输出标签 $y$ 构成，如果你观察一下你的数据，并发现有些输出标签 $y$ 是错的。你的数据有些标签是错的，是否值得花时间去修正这些标签呢？如果做标记的人一直把如例子中的白色的狗标记成猫，那那就成问题了。因为你的分类器学习之后，会把所有白色的狗都分类为猫。但随机错误或近似随机错误，对于大多数深度学习算法来说不成问题。dev、test中错误标记的情况：如果在开发集和测试集中出现了错误标记的问题，我们可以在误差分析的过程中，增加错误标记这一原因，再对错误的数据进行分析，得出修正这些标记错误的价值。2.3 快速搭建你的第一个系统，并进行迭代（Build your first system quickly, then iterate）尽快建立你的第一个系统原型，然后快速迭代。比如一个新的语音识别系统，你可以走很多方向，优先考虑很多事情。建立这个初始系统的所有意义在于，它可以是一个快速和粗糙的实现（quick and dirty implementation），让你确定偏差方差的范围，可以知道下一步应该优先做什么，让你能够进行错误分析，可以观察一些错误，然后想出所有能走的方向，哪些是实际上最有希望的方向。2.4 使用来自不同分布的数据，进行训练和测试（Training and testing on different distributions）假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。现在你有两个数据来源，一个是你真正关心的数据分布，来自应用上传的数据。方法一：将两组数据合并到一起，总共得到21万张图片样本。将这些样本随机分配到训练、开发、测试集中。好处：三个集合中的数据均来自于同一分布；坏处：我们设立开发集的目的是瞄准目标，而现在我们的目标绝大部分是为了去优化网上获取的高清晰度的照片，而不是我们真正的目标。这个方法不是一个好的方法。方法二：训练集均是来自网上下载的20万张高清图片，当然也可以加上5000张手机非高清图片；对于开发和测试集都是手机非高清图片。好处：开发集全部来自手机图片，瞄准目标；坏处：训练集和开发、测试集来自不同的分布。从长期来看，这样的分布能够给我们带来更好的系统性能。2.5 数据分布不匹配时，偏差与方差的分析（Bias and Variance with mismatched data distributions）估计学习算法的偏差和方差真的可以帮你确定接下来应该优先做的方向，但是，当你的训练集来自和开发集、测试集不同分布时，分析偏差和方差的方式可能不一样。如果我们的训练集和开发、测试集来自相同的分布，那么我们可以说模型存在很大的方差问题。但如果数据来自不同的分布，那么我们就不能下这样的定论了。 可能因为训练集很容易识别，因为训练集都是高分辨率图片，很清晰的图像，但开发集要难以识别得多。我们要做的是随机打散训练集，然后分出一部分训练集作为训练-开发集（training-dev），就像开发集和测试集来自同一分布，训练集、训练-开发集也来自同一分布。但不同的地方是，现在你只在训练集训练你的神经网络，你不会让神经网络在训练-开发集上跑后向传播。为了进行误差分析，你应该做的是看看分类器在训练集上的误差，训练-开发集上的误差，还有开发集上的误差。比如说这个样本中，训练误差是1%，我们说训练-开发集上的误差是9%，然后开发集误差是10%，和以前一样。你就可以从这里得到结论，当你从训练数据变到训练-开发集数据时，错误率真的上升了很多。而训练数据和训练-开发数据的差异在于，你的神经网络能看到第一部分数据并直接在上面做了训练，但没有在训练-开发集上直接训练，这就告诉你，算法存在方差问题，因为训练-开发集的错误率是在和训练集来自同一分布的数据中测得的。所以你知道，尽管你的神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集里，它无法很好地泛化推广到来自同一分布，但以前没见过的数据中，所以在这个样本中我们确实有一个方差问题。一个不同的样本，假设训练误差为1%，训练-开发误差为1.5%，但当你开始处理开发集时，错误率上升到10%。现在你的方差问题就很小了，因为当你从见过的训练数据转到训练-开发集数据，神经网络还没有看到的数据，错误率只上升了一点点。但当你转到开发集时，错误率就大大上升了，所以这是数据不匹配的问题。因为你的学习算法没有直接在训练-开发集或者开发集训练过，但是这两个数据集来自不同的分布。但不管算法在学习什么，它在训练-开发集上做的很好，但开发集上做的不好，所以总之你的算法擅长处理和你关心的数据不同的分布，我们称之为数据不匹配的问题。训练误差是10%，训练-开发误差是11%，开发误差为12%，人类水平对贝叶斯错误率的估计大概是0%，如果你得到了这种等级的表现，那就真的存在偏差问题了。存在可避免偏差问题，因为算法做的比人类水平差很多，所以这里的偏差真的很高。通过：Human level、Training set error、Training-dev set error、Dev error、Test error 之间误差的大小，可以分别得知我们的模型，需要依次在：可避免的偏差、方差、数据分布不匹配、开发集的或拟合程度，这些方面做改进。2.6 处理数据不匹配问题（Addressing data mismatch）2.7 迁移学习（Transfer learning）假设你已经训练好一个图像识别神经网络，所以你首先用一个神经网络，并在$(x,y)$对上训练，其中$x$是图像，$y$是某些对象，图像是猫、狗、鸟或其他东西。如果你把这个神经网络拿来，然后让它适应或者说迁移，在不同任务中学到的知识，比如放射科诊断，就是说阅读$X$射线扫描图。你可以做的是把神经网络最后的输出层拿走，就把它删掉，还有进入到最后一层的权重删掉，然后为最后一层重新赋予随机权重，然后让它在放射诊断数据上训练。你有足够多的数据，你可以重新训练神经网络中剩下的所有层。经验规则是，如果你有一个小数据集，就只训练输出层前的最后一层，或者也许是最后一两层。但是如果你有很多数据，那么也许你可以重新训练网络中的所有参数。如果你重新训练神经网络中的所有参数，那么这个在图像识别数据的初期训练阶段，有时称为预训练（pre-training），因为你在用图像识别数据去预先初始化，或者预训练神经网络的权重。然后，如果你以后更新所有权重，然后在放射科数据上训练，有时这个过程叫微调（fine tuning）。2.8 多任务学习（Multi-task learning）在迁移学习中，你的步骤是串行的，你从任务$A$里学习只是然后迁移到任务$B$。在多任务学习中，你是同时开始学习的，试图让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。我们来看一个例子，假设你在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志，还有交通灯各种其他东西。比如在左边这个例子中，图像里有个停车标志，然后图像中有辆车，但没有行人，也没有交通灯。如果这是输入图像$x^{(i)}$，那么这里不再是一个标签 $y^{(i)}$，而是有4个标签。在这个例子中，没有行人，有一辆车，有一个停车标志，没有交通灯。然后如果你尝试检测其他物体，也许 $y^{(i)}$的维数会更高，现在我们就先用4个吧，所以 $y^{(i)}$是个4×1向量。如果你从整体来看这个训练集标签和以前类似，我们将训练集的标签水平堆叠起来，像这样$y^{(1)}$一直到$y^{(m)}$：Y = \begin{bmatrix} | & | & | & \ldots & | \\ y^{(1)} & y^{(2)} & y^{(3)} & \ldots & y^{(m)} \\ | & | & | & \ldots & | \\ \end{bmatrix}不过现在$y^{(i)}$是4×1向量，所以这些都是竖向的列向量，所以这个矩阵$Y$现在变成$4×m$矩阵。而之前，当$y$是单实数时，这就是$1×m$矩阵。要训练这个神经网络，你现在需要定义神经网络的损失函数，对于一个输出$\hat y$，是个4维向量，对于整个训练集的平均损失：$\frac{1}{m}\sum \limits _{i = 1}^{m}{\sum \limits_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}}$$\sum \limits_{j = 1}^{4}{L(\hat y_{j}^{(i)},y_{j}^{(i)})}$这些单个预测的损失，所以这就是对四个分量的求和，行人、车、停车标志、交通灯，而这个标志L指的是logistic损失，我们就这么写：$L(\hat y_{j}^{(i)},y_{j}^{(i)}) = - y_{j}^{(i)}\log\hat y_{j}^{(i)} - (1 - y_{j}^{(i)})log(1 - \hat y_{j}^{(i)})$整个训练集的平均损失和之前分类猫的例子主要区别在于，现在你要对$j=1$到4求和，这与softmax回归的主要区别在于，与softmax回归不同，softmax将单个标签分配给单个样本。另一个细节，到目前为止，我是这么描述算法的，好像每张图都有全部标签。事实证明，多任务学习也可以处理图像只有部分物体被标记的情况。所以第一个训练样本，我们说有人，给数据贴标签的人告诉你里面有一个行人，没有车，但他们没有标记是否有停车标志，或者是否有交通灯。也许第二个例子中，有行人，有车。但是，当标记人看着那张图片时，他们没有加标签，没有标记是否有停车标志，是否有交通灯等等。也许有些样本都有标记，但也许有些样本他们只标记了有没有车，然后还有一些是问号。2.9 什么是端到端的深度学习？（What is end-to-end deep learning?）简而言之，以前有一些数据处理系统或者学习系统，它们需要多个阶段的处理。那么端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它。所以和这种有很多阶段的流水线相比，端到端深度学习做的是，你训练一个巨大的神经网络，输入就是一段音频，输出直接是听写文本。2.10 是否要使用端到端的深度学习？（Whether to use end-to-end learning?）假设你正在搭建一个机器学习系统，你要决定是否使用端对端方法，我们来看看端到端深度学习的一些优缺点，这样你就可以根据一些准则，判断你的应用程序是否有希望使用端到端方法。参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/learn/machine-learning-projectshttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2019%2F11%2F05%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[修改用户名和邮箱123git config --global user.name xxxgit config --global user.email xxx# --global为全局参数初始化仓库并提交1git init1234git add READMEgit status #查看状态git commit# git commit -m 'xxxx'123git branch #查看分支# git checkout -b xxx 切换分支，-b为创建git push origin master获取仓库1git push origin xxx版本回退1234git log –pretty=oneline # –pretty=oneline 输出到一行git reset --hard HEAD^ #HEAD~1# git reset --hard 版本号参考资料http://www.imooc.com/article/20411/https://git-scm.com/book/zh/v1/]]></content>
      <tags>
        <tag>开发者工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（3-1）]]></title>
    <url>%2F2019%2F10%2F25%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%883-1%EF%BC%89%2F</url>
    <content type="text"><![CDATA[机器学习（ML）策略（1）1.1 为什么是ML策略？（Why ML Strategy?）1.2 正交化（Orthogonalization）1.3 单一数字评估指标（Single number evaluation metric）查准率 $P=\frac{TP}{TP+FP}$查全率$R=\frac{TP}{TP+FN}$$F_1$分数：$\frac{2}{\frac{1}{P} + \frac{1}{R}}$1.4 满足和优化指标（Satisficing and optimizing metrics）通过定义优化和满足指标去选择“最好的”分类器。顾及多个指标，比如说，有一个优化指标，想尽可能优化的，然后还有一个或多个满足指标，需要满足的。1.5 训练/开发/测试集划分（Train/dev/test distributions）设立开发集和测试集时，要选择这样的开发集和测试集，能够反映你未来会得到的数据，认为很重要的数据，必须得到好结果的数据，特别是，这里的开发集和测试集可能来自同一个分布。所以不管你未来会得到什么样的数据，一旦你的算法效果不错，要尝试收集类似的数据，而且，不管那些数据是什么，都要随机分配到开发集和测试集上。因为这样，你才能将瞄准想要的目标，让你的团队高效迭代来逼近同一个目标，希望最好是同一个目标。1.6 开发集和测试集的大小（Size of dev and test sets）样本较少：70/30或60/20/20样本较多：98%作为训练集，1%开发集，1%测试集1.7 什么时候该改变开发/测试集和指标？（When to change dev/test sets and metrics）假设有两个猫的图片的分类器：算法$A$由于某些原因，把很多色情图像分类成猫了。如果你部署算法$A$，那么用户就会看到更多猫图，因为它识别猫的错误率只有3%，但它同时也会给用户推送一些色情图像，这是你的公司完全不能接受的，你的用户也完全不能接受。相比之下，算法$B$有5％的错误率，这样分类器就得到较少的图像，但它不会推送色情图像。所以从你们公司的角度来看，以及从用户接受的角度来看，算法$B$实际上是一个更好的算法，因为它不让任何色情图像通过。假设开始我们的评估指标如下：$Error = \dfrac{1}{m_{dev}}\sum\limits_{i=1}^{m_{dev}}I\{y^{(i)}_{pred}\neq y^{(i)}\}$$m_$是你的开发集例子数，用$y_^{(i)}$表示预测值，其值为0或1，$I$这符号表示一个函数，统计出里面这个表达式为真的样本数，所以这个公式就统计了分类错误的样本。其中一个修改评估指标的方法是，这里（$\frac{1}{m_}$与$\sum_{i =1}^{m_}{I\{ y_^{(i)} \neq y^{(i)}\}}$之间）加个权重项，即：$Error = \frac{1}{m_}\sum \limits_{i = 1}^{m_}{w^{(i)}I\{ y_^{(i)} \neq y^{(i)}\}}$我们将这个称为$w^{\left( i \right)}$，其中如果图片$x^{(i)}$不是色情图片，则$w^{\left( i \right)} = 1$。如果$x^{(i)}$是色情图片，$w^{(i)}$可能就是10甚至100，这样你赋予了色情图片更大的权重，让算法将色情图分类为猫图时，错误率这个项快速变大。如果你希望得到归一化常数，在技术上，就是$w^{(i)}$对所有$i$求和，这样错误率仍然在0和1之间，即：$Error = \frac{1}{\sum\limits_{}^{}w^{(i)}}\sum_{i = 1}^{m_}{w^{(i)}I\{ y_^{(i)} \neq y^{(i)}\}}$假设你的两个猫分类器$A$和$B$，分别有用开发集评估得到3%的错误率和5%的错误率。或者甚至用在网上下载的图片构成的测试集上，这些是高质量，取景框很专业的图像。但也许你在部署算法产品时，你发现算法$B$看起来表现更好，即使它在开发集上表现不错，你发现你一直在用从网上下载的高质量图片训练，但当你部署到手机应用时，算法作用到用户上传的图片时，那些图片取景不专业，没有把猫完整拍下来，或者猫的表情很古怪，也许图像很模糊，当你实际测试算法时，你发现算法$B$表现其实更好。1.8 为什么是人的表现？（Why human-level performance?）贝叶斯最优错误率有时写作Bayesian，即省略optimal，就是从$x$到$y$映射的理论最优函数，永远不会被超越。1.9 可避免偏差（Avoidable bias）使用猫分类器来做例子，比如人类具有近乎完美的准确度，所以人类水平的错误是1%。在这种情况下，如果您的学习算法达到8%的训练错误率和10%的开发错误率，那么你也许想在训练集上得到更好的结果。所以事实上，你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。如果误差与人的误差接近则，减少开发集误差和测试集误差之间的差距1.10 理解人的表现（Understanding human-level performance）对人类水平误差有一个大概的估计，可以让我们去估计贝叶斯误差，这样可以让我们更快的做出决定：减少偏差还是减少方差。而这个决策技巧通常都很有效果，直到系统的性能开始超越人类，那么我们对贝叶斯误差的估计就不再准确了，再从减少偏差和减少方差方面提升系统性能就会比较困难了。1.11 超过人的表现（Surpassing human- level performance）1.12 改善你的模型的表现（Improving your model performance）参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/learn/machine-learning-projectshttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow基础教程]]></title>
    <url>%2F2019%2F10%2F14%2FTensorflow%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Tensorflow搭建自己的神经网络代码莫烦Python——https://github.com/MorvanZhou/tutorials/tree/master/tensorflowTUT例子2123456789101112131415161718192021222324import tensorflow as tfimport numpy as np# 创建数据x_data = np.random.rand(100).astype(np.float32)y_data = x_data * 0.1 + 0.3Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))biases = tf.Variable(tf.zeros([1]))y = Weights * x_data + biasesloss = tf.reduce_mean(tf.square(y - y_data))optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss)with tf.Session() as sess: # 使用变量一定要执行 init = tf.global_variables_initializer() sess.run(init) for step in range(201): sess.run(train) if step % 20 == 0: print(step, sess.run(Weights), sess.run(biases))123456# tensorflow的启动（启动默认图）sess = tf.Session()sess.close()# 指定GPUwith tf.Session() as sess: with tf.device("/gpu:1"):1234567891011121314#交互式使用 # 进入一个交互式 TensorFlow 会话.import tensorflow as tfsess = tf.InteractiveSession()x = tf.Variable([1.0, 2.0])a = tf.constant([3.0, 3.0])# 使用初始化器 initializer op 的 run() 方法初始化 'x'x.initializer.run()sub = tf.subtract(x, a)print(sub.eval())# ==&gt; [-2. -1.]Variable变量123456789101112131415import tensorflow as tfstate = tf.Variable(0, name="counter")# print(state.name)one = tf.constant(1)new_value = tf.add(state, one)update = tf.assign(state, new_value)with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for _ in range(3): sess.run(update) print(sess.run(new_value))placeholder传入值123456789import tensorflow as tfinput1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.multiply(input1, input2)with tf.Session() as sess: print(sess.run(output, feed_dict=&#123;input1: [7.], input2: [2.]&#125;))例子3添加层建造神经网络结果可视化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltdef add_layer(inputs, in_size, out_size, activation_function=None): # add one more layer and return the output of this layer Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs# Make up some real datax_data = np.linspace(-1, 1, 300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise# define placeholder for inputs to networkxs = tf.placeholder(tf.float32, [None, 1])ys = tf.placeholder(tf.float32, [None, 1])# add hidden layerl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)# add output layerprediction = add_layer(l1, 10, 1, activation_function=None)# the error between prediciton and real dataloss = tf.reduce_mean( tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)# important step# tf.initialize_all_variables() no long valid from# 2017-03-02 if using tensorflow &gt;= 0.12# if int((tf.__version__).split('.')[1]) &lt; 12 and int(# (tf.__version__).split('.')[0]) &lt; 1:# init = tf.initialize_all_variables()# else:# init = tf.global_variables_initializer()# sess = tf.Session()# sess.run(init)with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) # plot the real data fig = plt.figure() ax = fig.add_subplot(1, 1, 1) ax.scatter(x_data, y_data) plt.ion() plt.show() for i in range(1000): # training sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: # to visualize the result and improvement try: # 删除上一条线 ax.lines.remove(lines[0]) except Exception: pass prediction_value = sess.run(prediction, feed_dict=&#123;xs: x_data&#125;) # plot the prediction lines = ax.plot(x_data, prediction_value, 'r-', lw=5) plt.pause(0.1)加速神经网络训练除了随机梯度初始化（SGD），在深度学习中还有很多其他的方法可以对网络进行优化减少网络收敛时间除了学习率（learning rate）还有更多其他的参数比SGD到达更高的分类准确率学习率12# SGDW += -lr * dW123# Adagradcache += (dW ** 2)W += -lr * dW / (np.sqrt(cache) + eps)123# RMSprop（decay_rate通常为0.9）cache = decay_rate * cache + (1 - decay_rate) * (dW ** 2)W += -lr * dW / (np.sqrt(cache) + eps)1234# Adamm = beta1 * m + (1 - beta1) * dWv = beta2 * v + (1 - beta2) * (dW ** 2)x += -lr * m / (np.sqrt(v) + eps)Tensorboard12345678910111213141516171819202122232425262728293031323334353637383940414243444546from __future__ import print_functionimport tensorflow as tfdef add_layer(inputs, in_size, out_size, activation_function=None): # add one more layer and return the output of this layer with tf.name_scope('layer'): with tf.name_scope('weights'): Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W') with tf.name_scope('biases'): biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b') with tf.name_scope('Wx_plus_b'): Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) return outputs# define placeholder for inputs to networkwith tf.name_scope('inputs'): xs = tf.placeholder(tf.float32, [None, 1], name='x_input') ys = tf.placeholder(tf.float32, [None, 1], name='y_input')# add hidden layerl1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)# add output layerprediction = add_layer(l1, 10, 1, activation_function=None)# the error between prediciton and real datawith tf.name_scope('loss'): loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))with tf.name_scope('train'): train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)sess = tf.Session()with tf.Session() as sess: writer = tf.summary.FileWriter("logs/", sess.graph) init = tf.global_variables_initializer() sess.run(init) # 命令行运行tensorboard --logdir="logs/" # 访问http://localhost:60061234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465from __future__ import print_functionimport tensorflow as tfimport numpy as npdef add_layer(inputs, in_size, out_size, n_layer, activation_function=None): # add one more layer and return the output of this layer layer_name = 'layer%s' % n_layer with tf.name_scope(layer_name): with tf.name_scope('weights'): Weights = tf.Variable( tf.random_normal([in_size, out_size]), name='W') tf.summary.histogram(layer_name + '/weights', Weights) with tf.name_scope('biases'): biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b') tf.summary.histogram(layer_name + '/biases', biases) with tf.name_scope('Wx_plus_b'): Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) tf.summary.histogram(layer_name + '/outputs', outputs) return outputs# Make up some real datax_data = np.linspace(-1, 1, 300)[:, np.newaxis]noise = np.random.normal(0, 0.05, x_data.shape)y_data = np.square(x_data) - 0.5 + noise# define placeholder for inputs to networkwith tf.name_scope('inputs'): xs = tf.placeholder(tf.float32, [None, 1], name='x_input') ys = tf.placeholder(tf.float32, [None, 1], name='y_input')# add hidden layerl1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)# add output layerprediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)# the error between prediciton and real datawith tf.name_scope('loss'): loss = tf.reduce_mean( tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1])) tf.summary.scalar('loss', loss)with tf.name_scope('train'): train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)with tf.Session() as sess: merged = tf.summary.merge_all() writer = tf.summary.FileWriter("logs/", sess.graph) init = tf.global_variables_initializer() sess.run(init) for i in range(1000): sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;) if i % 50 == 0: result = sess.run(merged, feed_dict=&#123;xs: x_data, ys: y_data&#125;) writer.add_summary(result, i) # 命令行运行tensorboard --logdir="logs/" # 访问http://localhost:6006 # event查看：tf.summary.scalar('loss', loss) # histogram查看：tf.summary.histogram(layer_name + '/outputs', outputs) # 显示不正确先删除上一次文件Classification分类学习123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# number 1 to 10 data# 数据集下载网址：http://yann.lecun.com/exdb/mnist/mnist = input_data.read_data_sets('MNIST_data', one_hot=True)def add_layer(inputs, in_size, out_size, activation_function=None): # biases和Weights并不是纯随机数，一定的初始值跟有利于寻找到最优解 biases = tf.Variable(tf.zeros([1, out_size]) + 0.03) Weights = tf.Variable( tf.random_normal([in_size, out_size], mean=0, stddev=0.3)) Wx_plus_b = tf.matmul(inputs, Weights) + biases if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) return outputsdef compute_accuracy(v_xs, v_ys): global prediction y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs&#125;) correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys&#125;) return resultxs = tf.placeholder(tf.float32, [None, 784]) # 28x28ys = tf.placeholder(tf.float32, [None, 10])# 输出层prediction = add_layer(xs, 784, 10, activation_function=tf.nn.softmax)# 误差loss# 交叉熵# reduction_indices指定处理纬度cross_entropy = tf.reduce_mean( -tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict=&#123;xs: batch_xs, ys: batch_ys&#125;) if i % 50 == 0: print(compute_accuracy(mnist.test.images, mnist.test.labels))过拟合防止过拟合的方法：正则化，参数范数惩罚数据增强提前终止参数绑定与参数共享bagging和其他集成方法Dropout辅助分类节点(auxiliary classifiers)Batch NormalizationDropoutKeras实现的源码1234567891011121314151617181920212223242526272829303132def dropout(x, level, noise_shape=None, seed=None): """Sets entries in `x` to zero at random, while scaling the entire tensor. # Arguments x: tensor level: fraction of the entries in the tensor that will be set to 0. noise_shape: shape for randomly generated keep/drop flags, must be broadcastable to the shape of `x` seed: random seed to ensure determinism. """ # 随机失活概率level if level &lt; 0. or level &gt;= 1: raise ValueError('Dropout level must be in interval [0, 1[.') if seed is None: seed = np.random.randint(1, 10e6) if isinstance(noise_shape, list): noise_shape = tuple(noise_shape) rng = RandomStreams(seed=seed) retain_prob = 1. - level if noise_shape is None: random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype) else: random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype) random_tensor = T.patternbroadcast(random_tensor, [dim == 1 for dim in noise_shape]) # 弥补参数期望 x *= random_tensor x /= retain_probreturn x相关文章：https://blog.csdn.net/program_developer/article/details/80737724Dropout解决过拟合1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import tensorflow as tffrom sklearn.datasets import load_digitsfrom sklearn.model_selection import train_test_split# 标签二值化from sklearn.preprocessing import LabelBinarizer# load data# 较小的数据集：1797个8x8像素图片# MINIST：60,000个28x28像素图片digits = load_digits()X = digits.datay = digits.targety = LabelBinarizer().fit_transform(y)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)def add_layer(inputs, in_size, out_size, layer_name, activation_function=None): # add one more layer and return the output of this layer Weights = tf.Variable(tf.random_normal([in_size, out_size])) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, ) Wx_plus_b = tf.matmul(inputs, Weights) + biases # here to dropout Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob) if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b, ) tf.summary.histogram(layer_name + '/outputs', outputs) return outputs# define placeholder for inputs to networkkeep_prob = tf.placeholder(tf.float32)xs = tf.placeholder(tf.float32, [None, 64]) # 8x8ys = tf.placeholder(tf.float32, [None, 10])# add output layerl1 = add_layer(xs, 64, 50, 'l1', activation_function=tf.nn.tanh)prediction = add_layer(l1, 50, 10, 'l2', activation_function=tf.nn.softmax)# the loss between prediction and real datacross_entropy = tf.reduce_mean( -tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) # losstf.summary.scalar('loss', cross_entropy)train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)with tf.Session() as sess: merged = tf.summary.merge_all() # summary writer goes in here train_writer = tf.summary.FileWriter("logs/train", sess.graph) test_writer = tf.summary.FileWriter("logs/test", sess.graph) init = tf.global_variables_initializer() sess.run(init) for i in range(500): # here to determine the keeping probability sess.run( train_step, feed_dict=&#123; xs: X_train, ys: y_train, keep_prob: 0.5 &#125;) if i % 50 == 0: # record loss train_result = sess.run( merged, feed_dict=&#123; xs: X_train, ys: y_train, keep_prob: 1 &#125;) test_result = sess.run( merged, feed_dict=&#123; xs: X_test, ys: y_test, keep_prob: 1 &#125;) train_writer.add_summary(train_result, i) test_writer.add_summary(test_result, i)CNN（Convolutional Neural Network）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596from __future__ import print_functionimport tensorflow as tffrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets# number 1 to 10 datamnist = read_data_sets('MNIST_data', one_hot=True)def compute_accuracy(v_xs, v_ys): global prediction y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs, keep_prob: 1&#125;) correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys, keep_prob: 1&#125;) return resultdef weight_variable(shape): # 截断正态分布随机数 initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)def conv2d(x, W): # stride [1, x_movement, y_movement, 1] # Must have strides[0] = strides[3] = 1 return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): # stride [1, x_movement, y_movement, 1] # strides [batch, height, width, channels] return tf.nn.max_pool( x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')# define placeholder for inputs to networkxs = tf.placeholder(tf.float32, [None, 784]) / 255. # 28x28ys = tf.placeholder(tf.float32, [None, 10])keep_prob = tf.placeholder(tf.float32)x_image = tf.reshape(xs, [-1, 28, 28, 1])# print(x_image.shape) # [n_samples, 28,28,1]## conv1 layer ### 32个5*5*1的卷积核W_conv1 = weight_variable([5, 5, 1, 32]) # patch 5x5, in size 1, out size 32b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu( conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32h_pool1 = max_pool_2x2(h_conv1) # output size 14x14x32## conv2 layer ##W_conv2 = weight_variable([5, 5, 32, 64]) # patch 5x5, in size 32, out size 64b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu( conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64h_pool2 = max_pool_2x2(h_conv2) # output size 7x7x64## fc1 layer ##W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])# [n_samples, 7, 7, 64] -&gt;&gt; [n_samples, 7*7*64]h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)h_fc1_drop = tf.nn.dropout(h_fc1, rate = 1 - keep_prob)## fc2 layer ##W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)# the error between prediction and real datacross_entropy = tf.reduce_mean( -tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) # losstrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) # 1000次时就有97%的正确率 for i in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run( train_step, feed_dict=&#123; xs: batch_xs, ys: batch_ys, keep_prob: 0.5 &#125;) if i % 50 == 0: print( compute_accuracy(mnist.test.images[:1000], mnist.test.labels[:1000]))RNN（Recurrent Neural Network ）分类例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120import tensorflow as tffrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets# set random seed for comparing the two result calculationstf.set_random_seed(1)# this is datamnist = read_data_sets('MNIST_data', one_hot=True)# hyperparameterslr = 0.001training_iters = 100000batch_size = 128n_inputs = 28 # MNIST data input (img shape: 28*28)n_steps = 28 # time steps, img shape: 28*28 = n_inputs*n_steps# 每次放一行数据进去n_hidden_units = 128 # neurons in hidden layern_classes = 10 # MNIST classes (0-9 digits)# tf Graph inputx = tf.placeholder(tf.float32, [None, n_steps, n_inputs])y = tf.placeholder(tf.float32, [None, n_classes])# Define weightsweights = &#123; # (28, 128) 'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])), # (128, 10) 'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))&#125;biases = &#123; # (128, ) 'in': tf.Variable(tf.constant(0.1, shape=[ n_hidden_units, ])), # (10, ) 'out': tf.Variable(tf.constant(0.1, shape=[ n_classes, ]))&#125;def RNN(X, weights, biases): # hidden layer for input to cell ######################################## # transpose the inputs shape from # X ==&gt; (128 batch * 28 steps, 28 inputs) X = tf.reshape(X, [-1, n_inputs]) # into hidden # X_in = (128 batch * 28 steps, 128 hidden) X_in = tf.matmul(X, weights['in']) + biases['in'] # X_in ==&gt; (128 batch, 28 steps, 128 hidden) X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units]) # cell cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units) # lstm cell is divided into two parts (c_state, h_state) # 全零初始化init_state init_state = cell.zero_state(batch_size, dtype=tf.float32) # You have 2 options for following step. # 1: tf.nn.rnn(cell, inputs); # 2: tf.nn.dynamic_rnn(cell, inputs). # If use option 1, you have to modified the shape of X_in, go and check out this: # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py # In here, we go for option 2. # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in. # Make sure the time_major is changed accordingly. # outputs = [batch_size, timestep_size, hidden_size] outputs, final_state = tf.nn.dynamic_rnn( cell, X_in, initial_state=init_state, time_major=False) # hidden layer for output as the final results ############################################# # final_state = [c_state, h_state] # results = tf.matmul(final_state[1], weights['out']) + biases['out'] # # or # unpack to list [(batch, outputs)..] * steps # tf.transpose： [0,1,2] 的维度 -&gt; [1, 0, 2] # [batch_size, timestep_size, hidden_size] -&gt; [, batch_size, ] # tf.unstack：解包为[batch,hidden]下标为timestep # outputs[-1]为最后一次 outputs = tf.unstack(tf.transpose(outputs, [1, 0, 2])) results = tf.matmul(outputs[-1], weights['out']) + biases['out'] # shape = (128, 10) return resultspred = RNN(x, weights, biases)cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))train_op = tf.train.AdamOptimizer(lr).minimize(cost)correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) step = 0 while step * batch_size &lt; training_iters: batch_xs, batch_ys = mnist.train.next_batch(batch_size) batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs]) sess.run([train_op], feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;) if step % 20 == 0: print(sess.run(accuracy, feed_dict=&#123; x: batch_xs, y: batch_ys, &#125;)) step += 1回归例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltBATCH_START = 0TIME_STEPS = 20BATCH_SIZE = 50INPUT_SIZE = 1OUTPUT_SIZE = 1CELL_SIZE = 10LR = 0.006def get_batch(): global BATCH_START, TIME_STEPS # xs shape (50batch, 20steps) xs = np.arange(BATCH_START, BATCH_START + TIME_STEPS * BATCH_SIZE).reshape( (BATCH_SIZE, TIME_STEPS)) / (10 * np.pi) seq = np.sin(xs) res = np.cos(xs) BATCH_START += TIME_STEPS # plt.plot(xs[0, :], res[0, :], 'r', xs[0, :], seq[0, :], 'b--') # plt.show() # returned seq, res and xs: shape (batch, step, input) return [seq[:, :, np.newaxis], res[:, :, np.newaxis], xs]class LSTMRNN(object): def __init__(self, n_steps, input_size, output_size, cell_size, batch_size): self.n_steps = n_steps self.input_size = input_size self.output_size = output_size self.cell_size = cell_size self.batch_size = batch_size with tf.name_scope('inputs'): self.xs = tf.placeholder( tf.float32, [None, n_steps, input_size], name='xs') self.ys = tf.placeholder( tf.float32, [None, n_steps, output_size], name='ys') with tf.variable_scope('in_hidden'): self.add_input_layer() with tf.variable_scope('LSTM_cell'): self.add_cell() with tf.variable_scope('out_hidden'): self.add_output_layer() with tf.name_scope('cost'): self.compute_cost() with tf.name_scope('train'): self.train_op = tf.train.AdamOptimizer(LR).minimize(self.cost) def add_input_layer(self, ): l_in_x = tf.reshape( self.xs, [-1, self.input_size], name='2_2D') # (batch*n_step, in_size) # Ws (in_size, cell_size) Ws_in = self._weight_variable([self.input_size, self.cell_size]) # bs (cell_size, ) bs_in = self._bias_variable([ self.cell_size, ]) # l_in_y = (batch * n_steps, cell_size) with tf.name_scope('Wx_plus_b'): l_in_y = tf.matmul(l_in_x, Ws_in) + bs_in # reshape l_in_y ==&gt; (batch, n_steps, cell_size) self.l_in_y = tf.reshape( l_in_y, [-1, self.n_steps, self.cell_size], name='2_3D') def add_cell(self): lstm_cell = tf.contrib.rnn.BasicLSTMCell( self.cell_size, forget_bias=1.0, state_is_tuple=True) with tf.name_scope('initial_state'): self.cell_init_state = lstm_cell.zero_state( self.batch_size, dtype=tf.float32) self.cell_outputs, self.cell_final_state = tf.nn.dynamic_rnn( lstm_cell, self.l_in_y, initial_state=self.cell_init_state, time_major=False) def add_output_layer(self): # shape = (batch * steps, cell_size) l_out_x = tf.reshape( self.cell_outputs, [-1, self.cell_size], name='2_2D') Ws_out = self._weight_variable([self.cell_size, self.output_size]) bs_out = self._bias_variable([ self.output_size, ]) # shape = (batch * steps, output_size) with tf.name_scope('Wx_plus_b'): self.pred = tf.matmul(l_out_x, Ws_out) + bs_out def compute_cost(self): losses = tf.contrib.legacy_seq2seq.sequence_loss_by_example( [tf.reshape(self.pred, [-1], name='reshape_pred')], [tf.reshape(self.ys, [-1], name='reshape_target')], [tf.ones([self.batch_size * self.n_steps], dtype=tf.float32)], average_across_timesteps=True, softmax_loss_function=self.ms_error, name='losses') with tf.name_scope('average_cost'): self.cost = tf.div( tf.reduce_sum(losses, name='losses_sum'), self.batch_size, name='average_cost') tf.summary.scalar('cost', self.cost) @staticmethod def ms_error(labels, logits): return tf.square(tf.subtract(labels, logits)) def _weight_variable(self, shape, name='weights'): initializer = tf.random_normal_initializer( mean=0., stddev=1., ) return tf.get_variable(shape=shape, initializer=initializer, name=name) def _bias_variable(self, shape, name='biases'): initializer = tf.constant_initializer(0.1) return tf.get_variable(name=name, shape=shape, initializer=initializer)if __name__ == '__main__': model = LSTMRNN(TIME_STEPS, INPUT_SIZE, OUTPUT_SIZE, CELL_SIZE, BATCH_SIZE) with tf.Session() as sess: merged = tf.summary.merge_all() writer = tf.summary.FileWriter("logs", sess.graph) init = tf.global_variables_initializer() sess.run(init) # relocate to the local dir and run this line to view it on Chrome (http://0.0.0.0:6006/): # $ tensorboard --logdir='logs' plt.ion() plt.show() for i in range(200): seq, res, xs = get_batch() if i == 0: feed_dict = &#123; model.xs: seq, model.ys: res, # create initial state &#125; else: feed_dict = &#123; model.xs: seq, model.ys: res, model.cell_init_state: state # use last state as the initial state for this run &#125; _, cost, state, pred = sess.run( [model.train_op, model.cost, model.cell_final_state, model.pred], feed_dict=feed_dict) # plotting plt.plot(xs[0, :], res[0].flatten(), 'r', xs[0, :], pred.flatten()[:TIME_STEPS], 'b--') plt.ylim((-1.2, 1.2)) plt.draw() plt.pause(0.3) if i % 20 == 0: print('cost: ', round(cost, 4)) result = sess.run(merged, feed_dict) writer.add_summary(result, i)Autoencoder123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170from __future__ import division, print_function, absolute_importimport tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt# Import MNIST datafrom tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_setsmnist = read_data_sets('MNIST_data', one_hot=True)# Visualize decoder setting# Parameterslearning_rate = 0.01training_epochs = 5batch_size = 256display_step = 1examples_to_show = 10# Network Parametersn_input = 784 # MNIST data input (img shape: 28*28)# tf Graph input (only pictures)X = tf.placeholder("float", [None, n_input])# hidden layer settingsn_hidden_1 = 256 # 1st layer num featuresn_hidden_2 = 128 # 2nd layer num featuresweights = &#123; 'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])), 'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), 'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])), 'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),&#125;biases = &#123; 'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])), 'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])), 'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])), 'decoder_b2': tf.Variable(tf.random_normal([n_input])),&#125;# Building the encoderdef encoder(x): # Encoder Hidden layer with sigmoid activation #1 layer_1 = tf.nn.sigmoid( tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1'])) # Decoder Hidden layer with sigmoid activation #2 layer_2 = tf.nn.sigmoid( tf.add( tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2'])) return layer_2# Building the decoderdef decoder(x): # Encoder Hidden layer with sigmoid activation #1 layer_1 = tf.nn.sigmoid( tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1'])) # Decoder Hidden layer with sigmoid activation #2 layer_2 = tf.nn.sigmoid( tf.add( tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2'])) return layer_2"""# Visualize encoder setting# Parameterslearning_rate = 0.01 # 0.01 this learning rate will be better! Testedtraining_epochs = 10batch_size = 256display_step = 1# Network Parametersn_input = 784 # MNIST data input (img shape: 28*28)# tf Graph input (only pictures)X = tf.placeholder("float", [None, n_input])# hidden layer settingsn_hidden_1 = 128n_hidden_2 = 64n_hidden_3 = 10n_hidden_4 = 2weights = &#123; 'encoder_h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],)), 'encoder_h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],)), 'encoder_h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3],)), 'encoder_h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4],)), 'decoder_h1': tf.Variable(tf.truncated_normal([n_hidden_4, n_hidden_3],)), 'decoder_h2': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_2],)), 'decoder_h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_1],)), 'decoder_h4': tf.Variable(tf.truncated_normal([n_hidden_1, n_input],)),&#125;biases = &#123; 'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])), 'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])), 'encoder_b3': tf.Variable(tf.random_normal([n_hidden_3])), 'encoder_b4': tf.Variable(tf.random_normal([n_hidden_4])), 'decoder_b1': tf.Variable(tf.random_normal([n_hidden_3])), 'decoder_b2': tf.Variable(tf.random_normal([n_hidden_2])), 'decoder_b3': tf.Variable(tf.random_normal([n_hidden_1])), 'decoder_b4': tf.Variable(tf.random_normal([n_input])),&#125;def encoder(x): layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1'])) layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2'])) layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['encoder_h3']), biases['encoder_b3'])) layer_4 = tf.add(tf.matmul(layer_3, weights['encoder_h4']), biases['encoder_b4']) return layer_4def decoder(x): layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1'])) layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2'])) layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['decoder_h3']), biases['decoder_b3'])) layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, weights['decoder_h4']), biases['decoder_b4'])) return layer_4"""# Construct modelencoder_op = encoder(X)decoder_op = decoder(encoder_op)# Predictiony_pred = decoder_op# Targets (Labels) are the input data.y_true = X# Define loss and optimizer, minimize the squared errorcost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)# Launch the graphwith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) total_batch = int(mnist.train.num_examples / batch_size) # Training cycle for epoch in range(training_epochs): # Loop over all batches for i in range(total_batch): batch_xs, batch_ys = mnist.train.next_batch( batch_size) # max(x) = 1, min(x) = 0 # Run optimization op (backprop) and cost op (to get loss value) _, c = sess.run([optimizer, cost], feed_dict=&#123;X: batch_xs&#125;) # Display logs per epoch step if epoch % display_step == 0: print("Epoch:", '%04d' % (epoch + 1), "cost=", "&#123;:.9f&#125;".format(c)) print("Optimization Finished!") # # Applying encode and decode over test set encode_decode = sess.run( y_pred, feed_dict=&#123;X: mnist.test.images[:examples_to_show]&#125;) # Compare original images with their reconstructions f, a = plt.subplots(2, 10, figsize=(10, 2)) for i in range(examples_to_show): a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28))) a[1][i].imshow(np.reshape(encode_decode[i], (28, 28))) plt.show() # encoder_result = sess.run(encoder_op, feed_dict=&#123;X: mnist.test.images&#125;) # plt.scatter(encoder_result[:, 0], encoder_result[:, 1], c=mnist.test.labels) # plt.colorbar()# plt.show()name_scope/variable_scope12345678910111213141516171819202122232425262728293031323334353637383940414243from __future__ import print_functionimport tensorflow as tfwith tf.name_scope("a_name_scope"): initializer = tf.constant_initializer(value=1) var1 = tf.get_variable( name='var1', shape=[1], dtype=tf.float32, initializer=initializer) var2 = tf.Variable(name='var2', initial_value=[2], dtype=tf.float32) var21 = tf.Variable(name='var2', initial_value=[2.1], dtype=tf.float32) var22 = tf.Variable(name='var2', initial_value=[2.2], dtype=tf.float32)with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) print(var1.name) # var1:0 print(sess.run(var1)) # [ 1.] print(var2.name) # a_name_scope/var2:0 print(sess.run(var2)) # [ 2.] print(var21.name) # a_name_scope/var2_1:0 print(sess.run(var21)) # [ 2.0999999] print(var22.name) # a_name_scope/var2_2:0 print(sess.run(var22)) # [ 2.20000005]with tf.variable_scope("a_variable_scope") as scope: initializer = tf.constant_initializer(value=3) var3 = tf.get_variable( name='var3', shape=[1], dtype=tf.float32, initializer=initializer) var4 = tf.Variable(name='var4', initial_value=[4], dtype=tf.float32) var4_reuse = tf.Variable(name='var4', initial_value=[4], dtype=tf.float32) scope.reuse_variables() var3_reuse = tf.get_variable(name='var3', )with tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) print(var3.name) # a_variable_scope/var3:0 print(sess.run(var3)) # [ 3.] print(var4.name) # a_variable_scope/var4:0 print(sess.run(var4)) # [ 4.] print(var4_reuse.name) # a_variable_scope/var4_1:0 print(sess.run(var4_reuse)) # [ 4.] print(var3_reuse.name) # a_variable_scope/var3:0 print(sess.run(var3_reuse)) # [ 3.]123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112from __future__ import print_functionimport tensorflow as tfclass TrainConfig: batch_size = 20 time_steps = 20 input_size = 10 output_size = 2 cell_size = 11 learning_rate = 0.01class TestConfig(TrainConfig): time_steps = 1class RNN(object): def __init__(self, config): self._batch_size = config.batch_size self._time_steps = config.time_steps self._input_size = config.input_size self._output_size = config.output_size self._cell_size = config.cell_size self._lr = config.learning_rate self._built_RNN() def _built_RNN(self): with tf.variable_scope('inputs'): self._xs = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._input_size], name='xs') self._ys = tf.placeholder(tf.float32, [self._batch_size, self._time_steps, self._output_size], name='ys') with tf.name_scope('RNN'): with tf.variable_scope('input_layer'): l_in_x = tf.reshape(self._xs, [-1, self._input_size], name='2_2D') # (batch*n_step, in_size) # Ws (in_size, cell_size) Wi = self._weight_variable([self._input_size, self._cell_size]) print(Wi.name) # bs (cell_size, ) bi = self._bias_variable([self._cell_size, ]) # l_in_y = (batch * n_steps, cell_size) with tf.name_scope('Wx_plus_b'): l_in_y = tf.matmul(l_in_x, Wi) + bi l_in_y = tf.reshape(l_in_y, [-1, self._time_steps, self._cell_size], name='2_3D') with tf.variable_scope('cell'): cell = tf.contrib.rnn.BasicLSTMCell(self._cell_size) with tf.name_scope('initial_state'): self._cell_initial_state = cell.zero_state(self._batch_size, dtype=tf.float32) self.cell_outputs = [] cell_state = self._cell_initial_state for t in range(self._time_steps): if t &gt; 0: tf.get_variable_scope().reuse_variables() cell_output, cell_state = cell(l_in_y[:, t, :], cell_state) self.cell_outputs.append(cell_output) self._cell_final_state = cell_state with tf.variable_scope('output_layer'): # cell_outputs_reshaped (BATCH*TIME_STEP, CELL_SIZE) cell_outputs_reshaped = tf.reshape(tf.concat(self.cell_outputs, 1), [-1, self._cell_size]) Wo = self._weight_variable((self._cell_size, self._output_size)) bo = self._bias_variable((self._output_size,)) product = tf.matmul(cell_outputs_reshaped, Wo) + bo # _pred shape (batch*time_step, output_size) self._pred = tf.nn.relu(product) # for displacement with tf.name_scope('cost'): _pred = tf.reshape(self._pred, [self._batch_size, self._time_steps, self._output_size]) mse = self.ms_error(_pred, self._ys) mse_ave_across_batch = tf.reduce_mean(mse, 0) mse_sum_across_time = tf.reduce_sum(mse_ave_across_batch, 0) self._cost = mse_sum_across_time self._cost_ave_time = self._cost / self._time_steps with tf.variable_scope('trian'): self._lr = tf.convert_to_tensor(self._lr) self.train_op = tf.train.AdamOptimizer(self._lr).minimize(self._cost) @staticmethod def ms_error(y_target, y_pre): return tf.square(tf.subtract(y_target, y_pre)) @staticmethod def _weight_variable(shape, name='weights'): initializer = tf.random_normal_initializer(mean=0., stddev=0.5, ) return tf.get_variable(shape=shape, initializer=initializer, name=name) @staticmethod def _bias_variable(shape, name='biases'): initializer = tf.constant_initializer(0.1) return tf.get_variable(name=name, shape=shape, initializer=initializer)if __name__ == '__main__': train_config = TrainConfig() test_config = TestConfig() # the wrong method to reuse parameters in train rnn # 不同变量 # with tf.variable_scope('train_rnn'): # train_rnn1 = RNN(train_config) # with tf.variable_scope('test_rnn'): # test_rnn1 = RNN(test_config) # the right method to reuse parameters in train rnn with tf.variable_scope('rnn') as scope: sess = tf.Session() train_rnn2 = RNN(train_config) scope.reuse_variables() test_rnn2 = RNN(test_config) init = tf.global_variables_initializer() sess.run(init)Batch Normalization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltACTIVATION = tf.nn.reluN_LAYERS = 7N_HIDDEN_UNITS = 30def fix_seed(seed=1): # reproducible np.random.seed(seed) tf.set_random_seed(seed)def plot_his(inputs, inputs_norm): # plot histogram for the inputs of every layer for j, all_inputs in enumerate([inputs, inputs_norm]): for i, input in enumerate(all_inputs): plt.subplot(2, len(all_inputs), j*len(all_inputs)+(i+1)) plt.cla() if i == 0: the_range = (-7, 10) else: the_range = (-1, 1) plt.hist(input.ravel(), bins=15, range=the_range, color='#FF5733') plt.yticks(()) if j == 1: plt.xticks(the_range) else: plt.xticks(()) ax = plt.gca() ax.spines['right'].set_color('none') ax.spines['top'].set_color('none') plt.title("%s normalizing" % ("Without" if j == 0 else "With")) plt.draw() plt.pause(0.01)def built_net(xs, ys, norm): def add_layer(inputs, in_size, out_size, activation_function=None, norm=False): # weights and biases (bad initialization for this case) Weights = tf.Variable(tf.random_normal([in_size, out_size], mean=0., stddev=1.)) biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) # fully connected product Wx_plus_b = tf.matmul(inputs, Weights) + biases # normalize fully connected product if norm: # Batch Normalize fc_mean, fc_var = tf.nn.moments( Wx_plus_b, axes=[0], # the dimension you wanna normalize, here [0] for batch # for image, you wanna do [0, 1, 2] for [batch, height, width] but not channel ) scale = tf.Variable(tf.ones([out_size])) shift = tf.Variable(tf.zeros([out_size])) epsilon = 0.001 # apply moving average for mean and var when train on batch ema = tf.train.ExponentialMovingAverage(decay=0.5) def mean_var_with_update(): ema_apply_op = ema.apply([fc_mean, fc_var]) with tf.control_dependencies([ema_apply_op]): return tf.identity(fc_mean), tf.identity(fc_var) mean, var = mean_var_with_update() Wx_plus_b = tf.nn.batch_normalization(Wx_plus_b, mean, var, shift, scale, epsilon) # similar with this two steps: # Wx_plus_b = (Wx_plus_b - fc_mean) / tf.sqrt(fc_var + 0.001) # Wx_plus_b = Wx_plus_b * scale + shift # activation if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) return outputs fix_seed(1) if norm: # BN for the first input fc_mean, fc_var = tf.nn.moments( xs, axes=[0], ) scale = tf.Variable(tf.ones([1])) shift = tf.Variable(tf.zeros([1])) epsilon = 0.001 # apply moving average for mean and var when train on batch ema = tf.train.ExponentialMovingAverage(decay=0.5) def mean_var_with_update(): ema_apply_op = ema.apply([fc_mean, fc_var]) with tf.control_dependencies([ema_apply_op]): return tf.identity(fc_mean), tf.identity(fc_var) mean, var = mean_var_with_update() xs = tf.nn.batch_normalization(xs, mean, var, shift, scale, epsilon) # record inputs for every layer layers_inputs = [xs] # build hidden layers for l_n in range(N_LAYERS): layer_input = layers_inputs[l_n] in_size = layers_inputs[l_n].get_shape()[1].value output = add_layer( layer_input, # input in_size, # input size N_HIDDEN_UNITS, # output size ACTIVATION, # activation function norm, # normalize before activation ) layers_inputs.append(output) # add output for next run # build output layer prediction = add_layer(layers_inputs[-1], 30, 1, activation_function=None) cost = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1])) train_op = tf.train.GradientDescentOptimizer(0.001).minimize(cost) return [train_op, cost, layers_inputs]# make up datafix_seed(1)x_data = np.linspace(-7, 10, 2500)[:, np.newaxis]np.random.shuffle(x_data)noise = np.random.normal(0, 8, x_data.shape)y_data = np.square(x_data) - 5 + noise# plot input dataplt.scatter(x_data, y_data)plt.show()xs = tf.placeholder(tf.float32, [None, 1]) # [num_samples, num_features]ys = tf.placeholder(tf.float32, [None, 1])train_op, cost, layers_inputs = built_net(xs, ys, norm=False) # without BNtrain_op_norm, cost_norm, layers_inputs_norm = built_net(xs, ys, norm=True) # with BNwith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) # record cost cost_his = [] cost_his_norm = [] record_step = 5 plt.ion() plt.figure(figsize=(7, 3)) for i in range(250): if i % 50 == 0: # plot histogram all_inputs, all_inputs_norm = sess.run([layers_inputs, layers_inputs_norm], feed_dict=&#123;xs: x_data, ys: y_data&#125;) plot_his(all_inputs, all_inputs_norm) # train on batch sess.run([train_op, train_op_norm], feed_dict=&#123;xs: x_data[i*10:i*10+10], ys: y_data[i*10:i*10+10]&#125;) if i % record_step == 0: # record cost cost_his.append(sess.run(cost, feed_dict=&#123;xs: x_data, ys: y_data&#125;)) cost_his_norm.append(sess.run(cost_norm, feed_dict=&#123;xs: x_data, ys: y_data&#125;)) # plt.ioff() # plt.figure() # plt.plot(np.arange(len(cost_his))*record_step, np.array(cost_his), label='no BN') # no norm # plt.plot(np.arange(len(cost_his))*record_step, np.array(cost_his_norm), label='BN') # norm # plt.legend() # plt.show()参考资料Tensorflow中文社区教程——http://www.tensorfly.cn/莫烦Python——https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（2-3）]]></title>
    <url>%2F2019%2F10%2F14%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%882-3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[改善深层神经网络： 超参数调试、Batch正则化和程序框架（Hyperparameter tuning）3.1 调试处理（Tuning process）在机器学习领域，超参数比较少的情况下，利用网格中取样点来调试超参数；但在深度学习领域，超参数较多的情况下，不是设置规则的网格点，而是随机选择点进行调试。这样做是因为在我们处理问题的时候，是无法知道哪个超参数是更重要的，所以随机的方式去测试超参数点的性能，更为合理，这样可以探究更超参数的潜在价值。3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺。均匀随机：假设你在搜索超参数$a$（学习速率），假设你怀疑其值最小是0.0001或最大是1。如果你画一条从0.0001到1的数轴，沿其随机均匀取值，那90%的数值将会落在0.1到1之间，结果就是，在0.1到1之间，应用了90%的资源，而在0.0001到0.1之间，只有10%的搜索资源，这看上去不太对。反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在0.0001到0.001之间，就会有更多的搜索资源可用，还有在0.001到0.01之间等等。在Python中，你可以这样做，使r=-4*np.random.rand()，然后$a$随机取值，$ a =10^{r}$，所以，第一行可以得出$r \in [ 4,0]$，那么$a \in[10^{-4},10^{0}]$，所以最左边的数字是$10^{-4}$，最右边是$10^{0}$。3.3 超参数调试的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）3.4 归一化网络的激活函数（Normalizing activations in a network）Batch Norm 的实现以神经网络中某一隐藏层的中间值为例： $z^{(1)},z^{(2)},\ldots,z^{(m)}$$\mu = \dfrac{1}{m}\sum\limits_{i}z^{(i)} \\ \sigma^{2}=\dfrac{1}{m}\sum\limits_{i}(z^{(i)}-\mu)^{2} \\z^{(i)}_{\rm norm} = \dfrac{z^{(i)}-\mu}{\sqrt{\sigma^{2}+\varepsilon}}$为了使数值稳定，通常将$\varepsilon$作为分母，以防$σ=0$的情况。把这些$z$值标准化，化为含平均值0和标准单位方差，所以$z$的每一个分量都含有平均值0和方差1，但我们不想让隐藏单元总是含有平均值0和方差1，也许隐藏单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为${\tilde{z}}^{(i)}$，${\tilde{z}}^{(i)}= \gamma z_{\text{norm}}^{(i)} +\beta$，这里$\gamma$和$\beta$是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，比如Momentum或者Nesterov，Adam，你会更新$\gamma$和$\beta$，正如更新神经网络的权重一样。3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）假设你在使用mini-batch梯度下降法，你运行$t=1$到batch数量的for循环，你会在mini-batch $X^{\left\{ t\right\}}$上应用正向prop，每个隐藏层都应用正向prop，用Batch归一化代替$z^{[l]}$为${\tilde{z}}^{[l]}$。接下来，它确保在这个mini-batch中，$z$值有归一化的均值和方差，归一化均值和方差后是${\tilde{z}}^{[l]}$，然后，你用反向prop计算$dw^{[l]}$和$db^{[l]}$，及所有l层所有的参数，$d{\beta}^{[l]}$和$d\gamma^{[l]}$。尽管严格来说，因为你要去掉$b$，这部分其实已经去掉了。最后，你更新这些参数：$w^{[l]} = w^{[l]} -\text{αd}w^{[l]}$，和以前一样，${\beta}^{[l]} = {\beta}^{[l]} - {αd}{\beta}^{[l]}$，对于$\gamma$也是如此$\gamma^{[l]} = \gamma^{[l]} -{αd}\gamma^{[l]}$。3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）一个原因是，你已经看到如何归一化输入特征值$x$，使其均值为0，方差1，它又是怎样加速学习的，有一些从0到1而不是从1到1000的特征值，通过归一化所有的输入特征值$x$，以获得类似范围的值，可以加速学习。所以Batch归一化起的作用的原因，直观的一点就是，它在做类似的工作，但不仅仅对于这里的输入值，还有隐藏单元的值。Batch归一化有效的第二个原因是，它可以使权重比你的网络更滞后或更深层，比如，第10层的权重更能经受得住变化，相比于神经网络中前层的权重，比如第1层。如果图像中，你的训练集是这个样子的，你的正面例子在这儿，反面例子在那儿（左图），但你试图把它们都统一于一个数据集，也许正面例子在这，反面例子在那儿（右图）。你也许无法期待，在左边训练得很好的模块，同样在右边也运行得很好，即使存在运行都很好的同一个函数，但你不会希望你的学习算法去发现绿色的决策边界，如果只看左边数据的话。Covariate shift此网络已经学习了参数$w^{[3]}$和$b^{[3]}$，从第三隐藏层的角度来看，它从前层中取得一些值，接着它需要做些什么，使希望输出值$\hat y$接近真实值$y$。Batch归一化做的，是它减少了这些隐藏值分布变化的数量，它们被同样的均值和方差所限制。Batch归一化还有一个作用，它有轻微的正则化效果。在mini-batch计算中，由均值和方差缩放的，因为在mini-batch上计算的均值和方差，而不是在整个数据集上，均值和方差有一些小的噪声。所以和dropout相似，它往每个隐藏层的激活值上增加了噪音，dropout有增加噪音的方式，它使一个隐藏的单元，以一定的概率乘以0，以一定的概率乘以1，所以你的dropout含几重噪音，因为它乘以0或1。对比而言，Batch归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。这里的均值和标准差的估计值也是有噪音的，所以类似于dropout，Batch归一化有轻微的正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似于dropout，它给隐藏层增加了噪音，因此有轻微的正则化效果。因为添加的噪音很微小，所以并不是巨大的正则化效果，你可以将Batch归一化和dropout一起使用，如果你想得到dropout更强大的正则化效果。3.7 测试时的 Batch Norm（Batch Norm at test time）在一个mini-batch中，你将mini-batch的$z^{(i)}$值求和，计算均值，所以这里你只把一个mini-batch中的样本都加起来，用m来表示这个mini-batch中的样本数量，而不是整个训练集。然后计算方差，再算$z_{\text{norm}}^{(i)}$，即用均值和标准差来调整，加上$\varepsilon$是为了数值稳定性。$\tilde{z}$是用$\gamma$和$\beta$再次调整$z_{\text{norm}}$得到的。用一个指数加权平均来估算，这个平均数涵盖了所有mini-batch：3.8 Softmax 回归（Softmax regression）3.9 训练一个 Softmax 分类器（Training a Softmax classifier）$z^{[l]} = \begin{bmatrix} 5 \\ 2 \\ - 1 \\ 3 \\ \end{bmatrix}$我们有四个分类$C=4$，$z^{[l]}$可以是4×1维向量，我们计算了临时变量$t$，$t = \begin{bmatrix} e^{5} \\ e^{2} \\ e^{- 1} \\ e^{3} \\ \end{bmatrix}$，对元素进行幂运算，最后，如果你的输出层的激活函数$g^{[L]}()$是Softmax激活函数，那么输出就会是这样的：简单来说就是用临时变量$t$将它归一化，使总和为1，于是这就变成了$a^{[L]}$，你注意到向量$z$中，最大的元素是5，而最大的概率也就是第一种概率。Softmax这个名称的来源是与所谓hardmax对比，hardmax会把向量$z$变成这个向量$\begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \\ \end{bmatrix}$，hardmax函数会观察$z$的元素，然后在$z$中最大元素的位置放上1，其它位置放上0，所这是一个hard max，也就是最大的元素的输出为1，其它的输出都为0。如果$C=2$，那么$C=2$的Softmax实际上变回了logistic回归。真实标签是$\begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \\ \end{bmatrix}$，$y = \begin{bmatrix} 0.3 \\ 0.2 \\ 0.1 \\ 0.4 \\ \end{bmatrix}$在Softmax分类中，我们一般用到的损失函数是$L(\hat y,y ) = - \sum \limits_{j = 1}^{4}{y_{j}log\hat y_{j}}$这个样本中$y_{1} =y_{3} = y_{4} = 0$，$L\left( \hat y,y \right) = - \sum \limits_{j = 1}^{4}{y_{j}\log \hat y_{j}} = - y_{2}{\ log} \hat y_{2} = - {\ log} \hat y_{2}$整个训练集的损失$J$：$J( w^{[1]},b^{[1]},\ldots\ldots) = \frac{1}{m}\sum \limits_{i = 1}^{m}{L( \hat y^{(i)},y^{(i)})}$Softmax 的梯度下降$\dfrac{\partial J}{\partial z^{[L]}}=dz^{[L]} = \hat y -y$3.10 深度学习框架（Deep Learning frameworks）作业：TensorFlow TutorialWelcome to this week’s programming assignment. Until now, you’ve always used numpy to build neural networks. Now we will step you through a deep learning framework that will allow you to build neural networks more easily. Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up your machine learning development significantly. All of these frameworks also have a lot of documentation, which you should feel free to read. In this assignment, you will learn to do the following in TensorFlow:Initialize variablesStart your own sessionTrain algorithmsImplement a Neural NetworkPrograming frameworks can not only shorten your coding time, but sometimes also perform optimizations that speed up your code.UpdatesIf you were working on the notebook before this update…The current notebook is version “v3b”.You can find your original work saved in the notebook with the previous version name (it may be either TensorFlow Tutorial version 3” or “TensorFlow Tutorial version 3a.)To view the file directory, click on the “Coursera” icon in the top left of this notebook.List of updatesforward_propagation instruction now says ‘A1’ instead of ‘a1’ in the formula for Z2;and are updated to say ‘A2’ instead of ‘Z2’ in the formula for Z3.create_placeholders instruction refer to the data type “tf.float32” instead of float.in the model function, the x axis of the plot now says “iterations (per fives)” instead of iterations(per tens)In the linear_function, comments remind students to create the variables in the order suggested by the starter code. The comments are updated to reflect this order.The test of the cost function now creates the logits without passing them through a sigmoid function (since the cost function will include the sigmoid in the built-in tensorflow function).Updated print statements and ‘expected output that are used to check functions, for easier visual comparison.1 - Exploring the Tensorflow LibraryTo start, you will import the library:12345678910import mathimport numpy as npimport h5pyimport matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow.python.framework import opsfrom tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict%matplotlib inlinenp.random.seed(1)Now that you have imported the library, we will walk you through its different applications. You will start with an example, where we compute for you the loss of one training example.loss = \mathcal{L}(\hat{y}, y) = (\hat y^{(i)} - y^{(i)})^21234567891011y_hat = tf.constant(36, name='y_hat') # Define y_hat constant. Set to 36.y = tf.constant(39, name='y') # Define y. Set to 39loss = tf.Variable((y - y_hat)**2, name='loss') # Create a variable for the lossinit = tf.global_variables_initializer() # When init is run later (session.run(init)), # the loss variable will be initialized and ready to be computedwith tf.Session() as session: # Create a session and print the output session.run(init) # Initializes the variables print(session.run(loss)) # Prints the loss# 9Writing and running programs in TensorFlow has the following steps:Create Tensors (variables) that are not yet executed/evaluated.Write operations between those Tensors.Initialize your Tensors.Create a Session.Run the Session. This will run the operations you’d written above.Therefore, when we created a variable for the loss, we simply defined the loss as a function of other quantities, but did not evaluate its value. To evaluate it, we had to run init=tf.global_variables_initializer(). That initialized the loss variable, and in the last line we were finally able to evaluate the value of loss and print its value.Now let us look at an easy example. Run the cell below:12345a = tf.constant(2)b = tf.constant(10)c = tf.multiply(a,b)print(c)# Tensor("Mul:0", shape=(), dtype=int32)As expected, you will not see 20! You got a tensor saying that the result is a tensor that does not have the shape attribute, and is of type “int32”. All you did was put in the ‘computation graph’, but you have not run this computation yet. In order to actually multiply the two numbers, you will have to create a session and run it.123sess = tf.Session()print(sess.run(c))# 20Great! To summarize, remember to initialize your variables, create a session and run the operations inside the session.Next, you’ll also have to know about placeholders. A placeholder is an object whose value you can specify only later.To specify values for a placeholder, you can pass in values by using a “feed dictionary” (feed_dict variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session.123456# Change the value of x in the feed_dictx = tf.placeholder(tf.int64, name = 'x')print(sess.run(2 * x, feed_dict = &#123;x: 3&#125;))sess.close()# 6When you first defined x you did not have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you feed data to these placeholders when running the session.Here’s what’s happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph.1.1 - Linear functionLets start this programming exercise by computing the following equation: $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector.Exercise: Compute $WX + b$ where $W, X$, and $b$ are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). As an example, here is how you would define a constant X that has shape (3,1):1X = tf.constant(np.random.randn(3,1), name = "X")You might find the following functions helpful:tf.matmul(…, …) to do a matrix multiplicationtf.add(…, …) to do an additionnp.random.randn(…) to initialize randomly12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: linear_functiondef linear_function(): """ Implements a linear function: Initializes X to be a random tensor of shape (3,1) Initializes W to be a random tensor of shape (4,3) Initializes b to be a random tensor of shape (4,1) Returns: result -- runs the session for Y = WX + b """ np.random.seed(1) """ Note, to ensure that the "random" numbers generated match the expected results, please create the variables in the order given in the starting code below. (Do not re-arrange the order). """ ### START CODE HERE ### (4 lines of code) X = tf.constant(np.random.randn(3, 1), name = "X") W = tf.constant(np.random.randn(4, 3), name = "W") b = tf.constant(np.random.randn(4, 1), name = "W") Y = tf.add(tf.matmul(W, X), b) ### END CODE HERE ### # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate ### START CODE HERE ### sess = tf.Session() result = sess.run(Y) ### END CODE HERE ### # close the session sess.close() return result123456print( "result = \n" + str(linear_function()))# result = # [[-2.15657382]# [ 2.95891446]# [-1.08926781]# [-0.84538042]]1.2 - Computing the sigmoidGreat! You just implemented a linear function. Tensorflow offers a variety of commonly used neural network functions like tf.sigmoid and tf.softmax. For this exercise lets compute the sigmoid function of an input.You will do this exercise using a placeholder variable x. When running the session, you should use the feed dictionary to pass in the input z. In this exercise, you will have to (i) create a placeholder x, (ii) define the operations needed to compute the sigmoid using tf.sigmoid, and then (iii) run the session.Exercise : Implement the sigmoid function below. You should use the following:tf.placeholder(tf.float32, name = &quot;...&quot;)tf.sigmoid(...)sess.run(..., feed_dict = {x: z})Note that there are two typical ways to create and use sessions in tensorflow:Method 1:1234sess = tf.Session()# Run the variables initialization (if needed), run the operationsresult = sess.run(..., feed_dict = &#123;...&#125;)sess.close() # Close the sessionMethod 2:1234with tf.Session() as sess: # run the variables initialization (if needed), run the operations result = sess.run(..., feed_dict = &#123;...&#125;) # This takes care of closing the session for you :)1234567891011121314151617181920212223242526272829303132# GRADED FUNCTION: sigmoiddef sigmoid(z): """ Computes the sigmoid of z Arguments: z -- input value, scalar or vector Returns: results -- the sigmoid of z """ ### START CODE HERE ### ( approx. 4 lines of code) # Create a placeholder for x. Name it 'x'. x = tf.placeholder(tf.float32, name = "x") # compute sigmoid(x) sigmoid = tf.sigmoid(x) # Create a session, and run it. Please use the method 2 explained above. # You should use a feed_dict to pass z's value to x. with tf.Session() as sess: # if need # init=tf.global_variables_initializer() # sess.run(init) # Run session and call the output "result" result = sess.run(sigmoid, feed_dict = &#123;x:z&#125;) ### END CODE HERE ### return result1234print ("sigmoid(0) = " + str(sigmoid(0)))print ("sigmoid(12) = " + str(sigmoid(12)))# sigmoid(0) = 0.5# sigmoid(12) = 0.999994To summarize, you how know how to:Create placeholdersSpecify the computation graph corresponding to operations you want to computeCreate the sessionRun the session, using a feed dictionary if necessary to specify placeholder variables’ values.1.3 - Computing the CostYou can also use a built-in function to compute the cost of your neural network. So instead of needing to write code to compute this as a function of $a^{2}$ and $y^{(i)}$ for i=1…m:J = - \frac{1}{m} \sum_{i = 1}^m \large ( \small y^{(i)} \log a^{ [2] (i)} + (1-y^{(i)})\log (1-a^{ [2] (i)} )\large )\smallyou can do it in one line of code in tensorflow!Exercise: Implement the cross entropy loss. The function you will use is:tf.nn.sigmoid_cross_entropy_with_logits(logits = ..., labels = ...)Your code should input z, compute the sigmoid (to get a) and then compute the cross entropy cost $J$. All this can be done using one call to tf.nn.sigmoid_cross_entropy_with_logits, which computes- \frac{1}{m} \sum_{i = 1}^m \large ( \small y^{(i)} \log \sigma(z^{[2](i)}) + (1-y^{(i)})\log (1-\sigma(z^{[2](i)})\large )\small1234567891011121314151617181920212223242526272829303132333435363738# GRADED FUNCTION: costdef cost(logits, labels): """ Computes the cost using the sigmoid cross entropy Arguments: logits -- vector containing z, output of the last linear unit (before the final sigmoid activation) labels -- vector of labels y (1 or 0) Note: What we've been calling "z" and "y" in this class are respectively called "logits" and "labels" in the TensorFlow documentation. So logits will feed into z, and labels into y. Returns: cost -- runs the session of the cost (formula (2)) """ ### START CODE HERE ### # Create the placeholders for "logits" (z) and "labels" (y) (approx. 2 lines) z = tf.placeholder(tf.float32, name = "z") y = tf.placeholder(tf.float32, name = "y") # Use the loss function (approx. 1 line) cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z, labels = y) # Create a session (approx. 1 line). See method 1 above. sess = tf.Session() # Run the session (approx. 1 line). cost = sess.run(cost, feed_dict=&#123;z:logits, y:labels&#125;) # Close the session (approx. 1 line). See method 1 above. sess.close() ### END CODE HERE ### return cost12345logits = np.array([0.2,0.4,0.7,0.9])cost = cost(logits, np.array([0,0,1,1]))print ("cost = " + str(cost))# cost = [ 0.79813886 0.91301525 0.40318605 0.34115386]1.4 - Using One Hot encodingsMany times in deep learning you will have a y vector with numbers ranging from 0 to C-1, where C is the number of classes. If C is for example 4, then you might have the following y vector which you will need to convert as follows:This is called a “one hot” encoding, because in the converted representation exactly one element of each column is “hot” (meaning set to 1). To do this conversion in numpy, you might have to write a few lines of code. In tensorflow, you can use one line of code:tf.one_hot(labels, depth, axis)Exercise: Implement the function below to take one vector of labels and the total number of classes $C$, and return the one hot encoding. Use tf.one_hot() to do this.123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: one_hot_matrixdef one_hot_matrix(labels, C): """ Creates a matrix where the i-th row corresponds to the ith class number and the jth column corresponds to the jth training example. So if example j had a label i. Then entry (i,j) will be 1. Arguments: labels -- vector containing the labels C -- number of classes, the depth of the one hot dimension Returns: one_hot -- one hot matrix """ ### START CODE HERE ### # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line) C = tf.constant(value = C, name = "C") # Use tf.one_hot, be careful with the axis (approx. 1 line) one_hot_matrix = tf.one_hot(labels, C, axis = 0) # Create the session (approx. 1 line) sess = tf.Session() # Run the session (approx. 1 line) one_hot = sess.run(one_hot_matrix) # Close the session (approx. 1 line). See method 1 above. sess.close() ### END CODE HERE ### return one_hot123labels = np.array([1,2,3,0,2,1])one_hot = one_hot_matrix(labels, C = 4)print ("one_hot = \n" + str(one_hot))12345one_hot = [[ 0. 0. 0. 1. 0. 0.] [ 1. 0. 0. 0. 0. 1.] [ 0. 1. 0. 0. 1. 0.] [ 0. 0. 1. 0. 0. 0.]]1.5 - Initialize with zeros and onesNow you will learn how to initialize a vector of zeros and ones. The function you will be calling is tf.ones(). To initialize with zeros you could use tf.zeros() instead. These functions take in a shape and return an array of dimension shape full of zeros and ones respectively.Exercise: Implement the function below to take in a shape and to return an array (of the shape’s dimension of ones).tf.ones(shape)1234567891011121314151617181920212223242526272829# GRADED FUNCTION: onesdef ones(shape): """ Creates an array of ones of dimension shape Arguments: shape -- shape of the array you want to create Returns: ones -- array containing only ones """ ### START CODE HERE ### # Create "ones" tensor using tf.ones(...). (approx. 1 line) ones = tf.ones(shape) # Create the session (approx. 1 line) sess = tf.Session() # Run the session to compute 'ones' (approx. 1 line) ones = sess.run(ones) # Close the session (approx. 1 line). See method 1 above. sess.close() ### END CODE HERE ### return ones12print ("ones = " + str(ones([3])))# ones = [ 1. 1. 1.]2 - Building your first neural network in tensorflowIn this part of the assignment you will build a neural network using tensorflow. Remember that there are two parts to implement a tensorflow model:Create the computation graphRun the graphLet’s delve into the problem you’d like to solve!2.0 - Problem statement: SIGNS DatasetOne afternoon, with some friends we decided to teach our computers to decipher sign language. We spent a few hours taking pictures in front of a white wall and came up with the following dataset. It’s now your job to build an algorithm that would facilitate communications from a speech-impaired person to someone who doesn’t understand sign language.Training set: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).Test set: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).Note that this is a subset of the SIGNS dataset. The complete dataset contains many more signs.Here are examples for each number, and how an explanation of how we represent the labels. These are the original pictures, before we lowered the image resolutoion to 64 by 64 pixels.Run the following code to load the dataset.12# Loading the datasetX_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()Change the index below and run the cell to visualize some examples in the dataset.1234# Example of a pictureindex = 0plt.imshow(X_train_orig[index])print ("y = " + str(np.squeeze(Y_train_orig[:, index])))As usual you flatten the image dataset, then normalize it by dividing by 255. On top of that, you will convert each label to a one-hot vector as shown in Figure 1. Run the cell below to do so.123456789101112131415161718# Flatten the training and test imagesX_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).TX_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T# Normalize image vectorsX_train = X_train_flatten/255.X_test = X_test_flatten/255.# Convert training and test labels to one hot matricesY_train = convert_to_one_hot(Y_train_orig, 6)Y_test = convert_to_one_hot(Y_test_orig, 6)print ("number of training examples = " + str(X_train.shape[1]))print ("number of test examples = " + str(X_test.shape[1]))print ("X_train shape: " + str(X_train.shape))print ("Y_train shape: " + str(Y_train.shape))print ("X_test shape: " + str(X_test.shape))print ("Y_test shape: " + str(Y_test.shape))123456number of training examples = 1080number of test examples = 120X_train shape: (12288, 1080)Y_train shape: (6, 1080)X_test shape: (12288, 120)Y_test shape: (6, 120)Note that 12288 comes from $64 \times 64 \times 3$. Each image is square, 64 by 64 pixels, and 3 is for the RGB colors. Please make sure all these shapes make sense to you before continuing.Your goal is to build an algorithm capable of recognizing a sign with high accuracy. To do so, you are going to build a tensorflow model that is almost the same as one you have previously built in numpy for cat recognition (but now using a softmax output). It is a great occasion to compare your numpy implementation to the tensorflow one.The model is LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SOFTMAX. The SIGMOID output layer has been converted to a SOFTMAX. A SOFTMAX layer generalizes SIGMOID to when there are more than two classes.2.1 - Create placeholdersYour first task is to create placeholders for X and Y. This will allow you to later pass your training data in when you run your session.Exercise: Implement the function below to create the placeholders in tensorflow.12345678910111213141516171819202122232425# GRADED FUNCTION: create_placeholdersdef create_placeholders(n_x, n_y): """ Creates the placeholders for the tensorflow session. Arguments: n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288) n_y -- scalar, number of classes (from 0 to 5, so -&gt; 6) Returns: X -- placeholder for the data input, of shape [n_x, None] and dtype "tf.float32" Y -- placeholder for the input labels, of shape [n_y, None] and dtype "tf.float32" Tips: - You will use None because it let's us be flexible on the number of examples you will for the placeholders. In fact, the number of examples during test/train is different. """ ### START CODE HERE ### (approx. 2 lines) X = tf.placeholder(tf.float32, shape = [n_x, None]) Y = tf.placeholder(tf.float32, shape = [n_y, None]) ### END CODE HERE ### return X, Y12345X, Y = create_placeholders(12288, 6)print ("X = " + str(X))print ("Y = " + str(Y))# X = Tensor("Placeholder:0", shape=(12288, ?), dtype=float32)# Y = Tensor("Placeholder_1:0", shape=(6, ?), dtype=float32)2.2 - Initializing the parametersYour second task is to initialize the parameters in tensorflow.Exercise: Implement the function below to initialize the parameters in tensorflow. You are going use Xavier Initialization for weights and Zero Initialization for biases. The shapes are given below. As an example, to help you, for W1 and b1 you could use:12W1 = tf.get_variable("W1", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))b1 = tf.get_variable("b1", [25,1], initializer = tf.zeros_initializer())Please use seed = 1 to make sure your results match ours.1234567891011121314151617181920212223242526272829303132333435# GRADED FUNCTION: initialize_parametersdef initialize_parameters(): """ Initializes parameters to build a neural network with tensorflow. The shapes are: W1 : [25, 12288] b1 : [25, 1] W2 : [12, 25] b2 : [12, 1] W3 : [6, 12] b3 : [6, 1] Returns: parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3 """ tf.set_random_seed(1) # so that your "random" numbers match ours ### START CODE HERE ### (approx. 6 lines of code) W1 = tf.get_variable("W1", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1)) b1 = tf.get_variable("b1", [25,1], initializer = tf.zeros_initializer()) W2 = tf.get_variable("W2", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1)) b2 = tf.get_variable("b2", [12,1], initializer = tf.zeros_initializer()) W3 = tf.get_variable("W3",[6,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1)) b3 = tf.get_variable("b3", [6,1], initializer = tf.zeros_initializer()) ### END CODE HERE ### parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2, "W3": W3, "b3": b3&#125; return parameters1234567tf.reset_default_graph()with tf.Session() as sess: parameters = initialize_parameters() print("W1 = " + str(parameters["W1"])) print("b1 = " + str(parameters["b1"])) print("W2 = " + str(parameters["W2"])) print("b2 = " + str(parameters["b2"]))1234W1 = &lt;tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref&gt;b1 = &lt;tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref&gt;W2 = &lt;tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref&gt;b2 = &lt;tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref&gt;As expected, the parameters haven’t been evaluated yet.2.3 - Forward propagation in tensorflowYou will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass. The functions you will be using are:tf.add(...,...) to do an additiontf.matmul(...,...) to do a matrix multiplicationtf.nn.relu(...) to apply the ReLU activationQuestion: Implement the forward pass of the neural network. We commented for you the numpy equivalents so that you can compare the tensorflow implementation to numpy. It is important to note that the forward propagation stops at z3. The reason is that in tensorflow the last linear layer output is given as input to the function computing the loss. Therefore, you don’t need a3!1234567891011121314151617181920212223242526272829303132# GRADED FUNCTION: forward_propagationdef forward_propagation(X, parameters): """ Implements the forward propagation for the model: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SOFTMAX Arguments: X -- input dataset placeholder, of shape (input size, number of examples) parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3" the shapes are given in initialize_parameters Returns: Z3 -- the output of the last LINEAR unit """ # Retrieve the parameters from the dictionary "parameters" W1 = parameters['W1'] b1 = parameters['b1'] W2 = parameters['W2'] b2 = parameters['b2'] W3 = parameters['W3'] b3 = parameters['b3'] ### START CODE HERE ### (approx. 5 lines) # Numpy Equivalents: Z1 = tf.add(tf.matmul(W1, X), b1) # Z1 = np.dot(W1, X) + b1 A1 = tf.nn.relu(Z1) # A1 = relu(Z1) Z2 = tf.add(tf.matmul(W2, A1), b2) # Z2 = np.dot(W2, A1) + b2 A2 = tf.nn.relu(Z2) # A2 = relu(Z2) Z3 = tf.add(tf.matmul(W3, A2), b3) # Z3 = np.dot(W3, A2) + b3 ### END CODE HERE ### return Z3123456789tf.reset_default_graph()with tf.Session() as sess: X, Y = create_placeholders(12288, 6) parameters = initialize_parameters() Z3 = forward_propagation(X, parameters) print("Z3 = " + str(Z3))# Z3 = Tensor("Add_2:0", shape=(6, ?), dtype=float32)You may have noticed that the forward propagation doesn’t output any cache. You will understand why below, when we get to brackpropagation.2.4 Compute costAs seen before, it is very easy to compute the cost using:1tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = ..., labels = ...))Question: Implement the cost function below.It is important to know that the “logits“ and “labels“ inputs of tf.nn.softmax_cross_entropy_with_logits are expected to be of shape (number of examples, num_classes). We have thus transposed Z3 and Y for you.Besides, tf.reduce_mean basically does the summation over the examples.1234567891011121314151617181920212223# GRADED FUNCTION: compute_cost def compute_cost(Z3, Y): """ Computes the cost Arguments: Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples) Y -- "true" labels vector placeholder, same shape as Z3 Returns: cost - Tensor of the cost function """ # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...) logits = tf.transpose(Z3) labels = tf.transpose(Y) ### START CODE HERE ### (1 line of code) cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels)) ### END CODE HERE ### return cost12345678910tf.reset_default_graph()with tf.Session() as sess: X, Y = create_placeholders(12288, 6) parameters = initialize_parameters() Z3 = forward_propagation(X, parameters) cost = compute_cost(Z3, Y) print("cost = " + str(cost)) # cost = Tensor("Mean:0", shape=(), dtype=float32)2.5 - Backward propagation &amp; parameter updatesThis is where you become grateful to programming frameworks. All the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.After you compute the cost function. You will create an “optimizer“ object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.For instance, for gradient descent the optimizer would be:1optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)To make the optimization you would do:1_ , c = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.Note When coding, we often use _ as a “throwaway” variable to store values that we won’t need to use later. Here, _ takes on the evaluated value of optimizer, which we don’t need (and c takes the value of the cost variable).2.6 - Building the model123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True): """ Implements a three-layer tensorflow neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SOFTMAX. Arguments: X_train -- training set, of shape (input size = 12288, number of training examples = 1080) Y_train -- test set, of shape (output size = 6, number of training examples = 1080) X_test -- training set, of shape (input size = 12288, number of training examples = 120) Y_test -- test set, of shape (output size = 6, number of test examples = 120) learning_rate -- learning rate of the optimization num_epochs -- number of epochs of the optimization loop minibatch_size -- size of a minibatch print_cost -- True to print the cost every 100 epochs Returns: parameters -- parameters learnt by the model. They can then be used to predict. """ ops.reset_default_graph() # to be able to rerun the model without overwriting tf variables tf.set_random_seed(1) # to keep consistent results seed = 3 # to keep consistent results (n_x, m) = X_train.shape # (n_x: input size, m : number of examples in the train set) n_y = Y_train.shape[0] # n_y : output size costs = [] # To keep track of the cost # Create Placeholders of shape (n_x, n_y) ### START CODE HERE ### (1 line) X, Y = create_placeholders(n_x, n_y) ### END CODE HERE ### # Initialize parameters ### START CODE HERE ### (1 line) parameters = initialize_parameters() ### END CODE HERE ### # Forward propagation: Build the forward propagation in the tensorflow graph ### START CODE HERE ### (1 line) Z3 = forward_propagation(X, parameters) ### END CODE HERE ### # Cost function: Add cost function to tensorflow graph ### START CODE HERE ### (1 line) cost = compute_cost(Z3, Y) ### END CODE HERE ### # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer. ### START CODE HERE ### (1 line) optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost) ### END CODE HERE ### # Initialize all the variables init = tf.global_variables_initializer() # Start the session to compute the tensorflow graph with tf.Session() as sess: # Run the initialization sess.run(init) # Do the training loop for epoch in range(num_epochs): epoch_cost = 0. # Defines a cost related to an epoch num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set seed = seed + 1 minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed) for minibatch in minibatches: # Select a minibatch (minibatch_X, minibatch_Y) = minibatch # IMPORTANT: The line that runs the graph on a minibatch. # Run the session to execute the "optimizer" and the "cost", the feedict should contain a minibatch for (X,Y). ### START CODE HERE ### (1 line) _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = &#123;X: minibatch_X, Y: minibatch_Y&#125;) ### END CODE HERE ### epoch_cost += minibatch_cost / num_minibatches # Print the cost every epoch if print_cost == True and epoch % 100 == 0: print ("Cost after epoch %i: %f" % (epoch, epoch_cost)) if print_cost == True and epoch % 5 == 0: costs.append(epoch_cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per fives)') plt.title("Learning rate =" + str(learning_rate)) plt.show() # lets save the parameters in a variable parameters = sess.run(parameters) print ("Parameters have been trained!") # Calculate the correct predictions correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y)) # Calculate accuracy on the test set accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float")) print ("Train Accuracy:", accuracy.eval(&#123;X: X_train, Y: Y_train&#125;)) print ("Test Accuracy:", accuracy.eval(&#123;X: X_test, Y: Y_test&#125;)) return parametersRun the following cell to train your model! On our machine it takes about 5 minutes. Your “Cost after epoch 100” should be 1.016458. If it’s not, don’t waste time; interrupt the training by clicking on the square (⬛) in the upper bar of the notebook, and try to correct your code. If it is the correct cost, take a break and come back in 5 minutes!1parameters = model(X_train, Y_train, X_test, Y_test)Amazing, your algorithm can recognize a sign representing a figure between 0 and 5 with 71.7% accuracy.Insights:Your model seems big enough to fit the training set well. However, given the difference between train and test accuracy, you could try to add L2 or dropout regularization to reduce overfitting.Think about the session as a block of code to train the model. Each time you run the session on a minibatch, it trains the parameters. In total you have run the session a large number of times (1500 epochs) until you obtained well trained parameters.2.7 - Test with your own image (optional / ungraded exercise)Congratulations on finishing this assignment. You can now take a picture of your hand and see the output of your model. To do that:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Write your image&#39;s name in the following code Run the code and check if the algorithm is right!1234567891011121314151617import scipyfrom PIL import Imagefrom scipy import ndimage## START CODE HERE ## (PUT YOUR IMAGE NAME) my_image = "thumbs_up.jpg"## END CODE HERE ### We preprocess your image to fit your algorithm.fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))image = image/255.my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).Tmy_image_prediction = predict(my_image, parameters)plt.imshow(image)print("Your algorithm predicts: y = " + str(np.squeeze(my_image_prediction)))You indeed deserved a “thumbs-up” although as you can see the algorithm seems to classify it incorrectly. The reason is that the training set doesn’t contain any “thumbs-up”, so the model doesn’t know how to deal with it! We call that a “mismatched data distribution” and it is one of the various of the next course on “Structuring Machine Learning Projects”.What you should remember:Tensorflow is a programming framework used in deep learningThe two main object classes in tensorflow are Tensors and Operators.When you code in tensorflow you have to take the following steps:Create a graph containing Tensors (Variables, Placeholders …) and Operations (tf.matmul, tf.add, …)Create a sessionInitialize the sessionRun the session to execute the graphYou can execute the graph multiple times as you’ve seen in model()The backpropagation and optimization is automatically done when running the session on the “optimizer” object.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/learn/deep-neural-network/home/week/2https://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning-ai笔记（2-2）]]></title>
    <url>%2F2019%2F09%2F21%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%882-2%EF%BC%89%2F</url>
    <content type="text"><![CDATA[优化算法 (Optimization algorithms)2.1 Mini-batch 梯度下降（Mini-batch gradient descent）把训练集分割为小一点的子集训练，这些子集被取名为mini-batch，假设每一个子集中只有1000个样本，那么把其中的$x^{(1)}$到$x^{(1000)}$取出来，将其称为第一个子训练集，然后你再取出接下来的1000个样本，从$x^{(1001)}$到$x^{(2000)}$，然后再取1000个样本，以此类推。把$x^{(1)}$到$x^{(1000)}$称为$X^{\{1\}}$，$x^{(1001)}$到$x^{(2000)}$称为$X^{\{2\}}$，如果你的训练样本一共有500万个，每个mini-batch都有1000个样本，也就是说，你有5000个mini-batch。对$Y$也要进行相同处理，你也要相应地拆分$Y$的训练集，所以这是$Y^{\{1\}}$，然后从$y^{(1001)}$到$y^{(2000)}$，这个叫$Y^{\{2\}}$，一直到$Y^{\{ 5000\}}$。mini-batch梯度下降法，每次同时处理的单个的mini-batch $X^{\{t\}}$和$Y^{\{ t\}}$，而不是同时处理全部的$X$和$Y$训练集。$J^{\{t\}} = \frac{1}{1000}\sum\limits_{i = 1}^{l}{L(\hat y^{(i)},y^{(i)})} +\frac{\lambda}{2 1000}\sum_{l}^{}{||w^{[l]}||}_{F}^{2}$2.2 理解mini-batch梯度下降法（Understanding mini-batch gradient descent）你需要决定的变量之一是mini-batch的大小，$m$就是训练集的大小，极端情况下，如果mini-batch的大小等于$m$，其实就是batch梯度下降法，在这种极端情况下，你就有了mini-batch $X^{\{1\}}$和$Y^{\{1\}}$，并且该mini-batch等于整个训练集，所以把mini-batch大小设为$m$可以得到batch梯度下降法。另一个极端情况，假设mini-batch大小为1，就有了新的算法，叫做随机梯度下降法，每个样本都是独立的mini-batch，当你看第一个mini-batch，也就是$X^{\{1\}}$和$Y^{\{1\}}$，如果mini-batch大小为1，它就是你的第一个训练样本，这就是你的第一个训练样本。接着再看第二个mini-batch，也就是第二个训练样本，采取梯度下降步骤，然后是第三个训练样本，以此类推，一次只处理一个。batch梯度下降：对所有m个训练样本执行一次梯度下降，每一次迭代时间较长；Cost function 总是向减小的方向下降。随机梯度下降：对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速；Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。Mini-batch梯度下降：选择一个$1&lt;size&lt;m$的合适的size进行Mini-batch梯度下降，可以实现快速学习，也应用了向量化带来的好处。Cost function的下降处于前两者之间。Mini-batch 大小的选择如果训练样本的大小比较小时，如$m⩽2000$时 —— 选择batch梯度下降法如果训练样本的大小比较大时，典型的大小为：$ 2^{6}、2^{7}、\cdots、2^{10}$Mini-batch的大小要符合CPU/GPU内存。2.3 指数加权平均数（Exponentially weighted averages）$v_{t} = \beta v_{t - 1} + (1 - \beta)\theta_{t}$大概是$\frac{1}{(1 -\beta)}$的每日温度，如果$\beta$是0.9，这是十天的平均值，也就是红线部分。将$\beta$设置为接近1的一个值，比如0.98，计算$\frac{1}{(1 - 0.98)} =50$，这就是粗略平均了一下，过去50天的温度，这时作图可以得到绿线。这个高值$\beta$要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延迟，因为当$\beta=0.98$，相当于给前一天的值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$\beta$ 较大时，指数加权平均值适应地更缓慢一些。果$\beta$是另一个极端值，比如说0.5，根据右边的公式（$\frac{1}{(1-\beta)}$），这是平均了两天的温度。作图运行后得到黄线。由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出现异常值，但是这个曲线能够更快适应温度变化。2.4 理解指数加权平均数（Understanding exponentially weighted averages）${v_t}=\beta {v_{t-1}}+(1-\beta ){\theta _{t}}$使$\beta=0.9$，写下相应的几个公式，所以在执行的时候，$t$从0到1到2到3，$t$的值在不断增加，为了更好地分析，我写的时候使得$t$的值不断减小，然后继续往下写。$v_{100} = 0.9v_{99}+0.1\theta_{100}\\v_{99} = 0.9v_{98}+0.1\theta_{99}\\v_{98} = 0.9v_{97}+0.1\theta_{98}\\ \ldots$展开:$v_{100} = 0.1\theta_{100} + 0.1 \times 0.9 \theta_{99} + 0.1 \times {(0.9)}^{2}\theta_{98} + 0.1 \times {(0.9)}^{3}\theta_{97} + 0.1 \times {(0.9)}^{4}\theta_{96} + \ldots$所有的这些系数（$0.10.1 \times 0.90.1 \times {(0.9)}^{2}0.1 \times {(0.9)}^{3}\ldots$），相加起来为1或者逼近1，我们称之为偏差修正。实际上${(0.9)}^{10}$大约为0.35，这大约是$\frac{1}{e}$，e是自然算法的基础之一。大体上说，如果有$1-\varepsilon$，在这个例子中，$\varepsilon=0.1$，所以$1-\varepsilon=0.9$，${(1-\varepsilon)}^{(\frac{1}{\varepsilon})}$约等于$\frac{1}{e}$，大约是0.34，0.35，换句话说，10天后，曲线的高度下降到$\frac{1}{3}$，相当于在峰值的$\frac{1}{e}$。因为，在计算当前时刻的平均值，只需要前一天的平均值和当前时刻的值，所以在数据量非常大的情况下，指数加权平均在节约计算成本的方面是一种非常有效的方式，可以很大程度上减少计算机资源存储和内存的占用。2.5 指数加权平均的偏差修正（Bias correction in exponentially weighted averages）计算移动平均数的时候，初始化$v_{0} = 0$，$v_{1} = 0.98v_{0} +0.02\theta_{1}$，但是$v_{0} =0$，所以这部分没有了（$0.98v_{0}$），所以$v_{1} =0.02\theta_{1}$，所以如果一天温度是40华氏度，那么$v_{1} = 0.02\theta_{1} =0.02 \times 40 = 8$，因此得到的值会小很多，所以第一天温度的估测不准。$v_{2} = 0.98v_{1} + 0.02\theta_{2}$，如果代入$v_{1}$，然后相乘，所以$v_{2}= 0.98 \times 0.02\theta_{1} + 0.02\theta_{2} = 0.0196\theta_{1} +0.02\theta_{2}$，假设$\theta_{1}$和$\theta_{2}$都是正数，计算后$v_{2}$要远小于$\theta_{1}$和$\theta_{2}$，所以$v_{2}$不能很好估测出这一年前两天的温度。有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用$v_{t}$，而是用$\frac{v_{t}}{1- \beta^{t}}$，t就是现在的天数。举个具体例子，当$t=2$时，$1 - \beta^{t} = 1 - {0.98}^{2} = 0.0396$，因此对第二天温度的估测变成了$\frac{v_{2}}{0.0396} =\frac{0.0196\theta_{1} + 0.02\theta_{2}}{0.0396}$，也就是$\theta_{1}$和$\theta_{2}$的加权平均数，并去除了偏差。你会发现随着$t$增加，$\beta^{t}$接近于0，所以当$t$很大的时候，偏差修正几乎没有作用，因此当$t$较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。2.6 动量梯度下降法（Gradient descent with Momentum）Momentum，动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，计算梯度的指数加权平均数，并利用该梯度更新你的权重。慢慢摆动到最小值，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过大，你要用一个较小的学习率。算法实现:在我们进行动量梯度下降算法的时候，由于使用了指数加权平均的方法。原来在纵轴方向上的上下波动，经过平均以后，接近于0，纵轴上的波动变得非常的小；但在横轴方向上，所有的微分都指向横轴方向，因此其平均值仍然很大。最终实现红色线所示的梯度下降曲线。在对应上面的计算公式中，将Cost function想象为一个碗状，想象从顶部往下滚球，其中：微分项$dw,db$想象为球提供的加速度动量项$v_{dw},v_{db}$相当于速度2.7 RMSproproot mean square prop算法如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向会有大幅度摆动，为了分析这个例子，假设纵轴代表参数$b$，横轴代表参数$W$，可能有$W_{1}$，$W_{2}$或者其它重要的参数，为了便于理解，被称为$b$和$W$。所以，你想减缓$b$方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，RMSprop算法可以实现这一点。在第$t$次迭代中，该算法会照常计算当下mini-batch的微分$dW$，$db$，保留这个指数加权平均数，用新符号$S_{dW}$表示，因此$S_{dW}= \beta S_{dW} + (1 -\beta) {dW}^{2}$，澄清一下，这个平方的操作是针对这一整个符号的，这样做能够保留微分平方的加权平均数，同样$S_{db}= \beta S_{db} + (1 - \beta){db}^{2}$。接着RMSprop会这样更新参数值，$W:= W -a\frac{dW}{\sqrt{S_{dW}}}$，$b:=b -\alpha\frac{db}{\sqrt{S_{db}}}$RMSprop将微分项进行平方，然后使用平方根进行梯度更新，同时为了确保算法不会除以0，平方根分母中在实际使用会加入一个很小的值如：$\varepsilon=10^{-8}$2.8 Adam 优化算法（Adam optimization algorithm）Adam优化算法基本上就是将Momentum和RMSprop结合在一起。初始化：$V_{dw} = 0，S_{dw}=0，V_{db}=0，S_{db} = 0$第$t$次迭代：用当前的mini-batch计算$dw，db$$V_{dw}=\beta_{1}V_{dw}+(1-\beta_{1})dw，V_{db}=\beta_{1}V_{db}+(1-\beta_{1})db$$S_{dw}=\beta_{2}S_{dw}+(1-\beta_{2})(dw)^{2}，S_{db}=\beta_{2}S_{db}+(1-\beta_{2})(db)^{2}$相当于Momentum更新了超参数$\beta_{1}$，RMSprop更新了超参数$\beta_{2}$。一般使用Adam算法的时候，要计算偏差修正，$v_{dW}^{\text{corrected}}$，修正也就是在偏差修正之后$V_{dw}^{corrected} = V_{dw}/(1-\beta_{1}^{t})，V_{db}^{corrected} = V_{db}/(1-\beta_{1}^{t})$$S_{dw}^{corrected} = S_{dw}/(1-\beta_{2}^{t})，S_{db}^{corrected} = S_{db}/(1-\beta_{2}^{t})$$w:=w-\alpha\dfrac{V_{dw}^{corrected}}{\sqrt{S_{dw}^{corrected}}+\varepsilon}，b:=b-\alpha\dfrac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\varepsilon}$超参数的选择$\alpha$：需要进行调试$\beta_{1}$：常用的缺省值为0.9，这是$dW$的移动平均数，也就是$dW$的加权平均数$\beta_{2}$：推荐使用0.999，这是在计算${(dW)}^{2}$以及${(db)}^{2}$的移动加权平均值$\varepsilon$：建议为$10^{-8}$Adam代表的是Adaptive Moment Estimation，$\beta_{1}$用于计算这个微分（$dW$），叫做第一矩，$\beta_{2}$用来计算平方数的指数加权平均数（${(dW)}^{2}$），叫做第二矩。2.9 学习率衰减（Learning rate decay）假设你要使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你的算法最后在附近摆动，并不会真正收敛，因为你用的$a$是固定值，不同的mini-batch中有噪音。但要慢慢减少学习率$a$的话，在初期的时候，$a$学习率还较大，你的学习还是相对较快，但随着$a$变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。所以慢慢减少$a$的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。常用：$\alpha = \dfrac{1}{1+decay_rate*epoch_num}\alpha_{0}$指数衰减：$\alpha = 0.95^{epoch_num}\alpha_{0}$其他：$\alpha = \dfrac{k}{epoch_num}\cdot\alpha_{0}$离散下降（不同阶段使用不同的学习速率）2.10 局部最优的问题（The problem of local optima）一个神经网络，通常梯度为零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。也就是在这个点，这里是$W_{1}$和$W_{2}$，高度即成本函数$J$的值。在高纬度的情况下：几乎不可能陷入局部最小值点；处于鞍点的停滞区会减缓学习过程，利用如Adam等算法进行改善。作业：Optimization MethodsUntil now, you’ve always used Gradient Descent to update the parameters and minimize the cost. In this notebook, you will learn more advanced optimization methods that can speed up learning and perhaps even get you to a better final value for the cost function. Having a good optimization algorithm can be the difference between waiting days vs. just a few hours to get a good result.Gradient descent goes “downhill” on a cost function $J$. Think of it as trying to do this:At each step of the training, you update your parameters following a certain direction to try to get to the lowest possible point.Notations: As usual, $\frac{\partial J}{\partial a } = $ da for any variable a.To get started, run the following code to import the libraries you will need.Updates to AssignmentIf you were working on a previous versionThe current notebook filename is version “Optimization_methods_v1b”.You can find your work in the file directory as version “Optimization methods’.To see the file directory, click on the Coursera logo at the top left of the notebook.List of Updatesop_utils is now opt_utils_v1a. Assertion statement in initialize_parameters is fixed.opt_utils_v1a: compute_cost function now accumulates total cost of the batch without taking the average (average is taken for entire epoch instead).In model function, the total cost per mini-batch is accumulated, and the average of the entire epoch is taken as the average cost. So the plot of the cost function over time is now a smooth downward curve instead of an oscillating curve.Print statements used to check each function are reformatted, and expected output is reformatted to match the format of the print statements (for easier visual comparisons).123456789101112131415import numpy as npimport matplotlib.pyplot as pltimport scipy.ioimport mathimport sklearnimport sklearn.datasetsfrom opt_utils_v1a import load_params_and_grads, initialize_parameters, forward_propagation, backward_propagationfrom opt_utils_v1a import compute_cost, predict, predict_dec, plot_decision_boundary, load_datasetfrom testCases import *%matplotlib inlineplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'1 - Gradient DescentA simple optimization method in machine learning is gradient descent (GD). When you take gradient steps with respect to all $m$ examples on each step, it is also called Batch Gradient Descent.Warm-up exercise: Implement the gradient descent update rule. The gradient descent rule is, for $l = 1, …, L$:W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} \tag{1}b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} \tag{2}where L is the number of layers and $\alpha$ is the learning rate. All parameters should be stored in the parameters dictionary. Note that the iterator l starts at 0 in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift l to l+1 when coding.1234567891011121314151617181920212223242526272829# GRADED FUNCTION: update_parameters_with_gddef update_parameters_with_gd(parameters, grads, learning_rate): """ Update parameters using one step of gradient descent Arguments: parameters -- python dictionary containing your parameters to be updated: parameters['W' + str(l)] = Wl parameters['b' + str(l)] = bl grads -- python dictionary containing your gradients to update each parameters: grads['dW' + str(l)] = dWl grads['db' + str(l)] = dbl learning_rate -- the learning rate, scalar. Returns: parameters -- python dictionary containing your updated parameters """ L = len(parameters) // 2 # number of layers in the neural networks # Update rule for each parameter for l in range(L): ### START CODE HERE ### (approx. 2 lines) parameters["W" + str(l+1)] = parameters["W" + str(l+1)] - learning_rate*grads["dW" + str(l+1)] parameters["b" + str(l+1)] = parameters["b" + str(l+1)] - learning_rate*grads["db" + str(l+1)] ### END CODE HERE ### return parameters1234567parameters, grads, learning_rate = update_parameters_with_gd_test_case()parameters = update_parameters_with_gd(parameters, grads, learning_rate)print("W1 =\n" + str(parameters["W1"]))print("b1 =\n" + str(parameters["b1"]))print("W2 =\n" + str(parameters["W2"]))print("b2 =\n" + str(parameters["b2"]))1234567891011121314W1 =[[ 1.63535156 -0.62320365 -0.53718766] [-1.07799357 0.85639907 -2.29470142]]b1 =[[ 1.74604067] [-0.75184921]]W2 =[[ 0.32171798 -0.25467393 1.46902454] [-2.05617317 -0.31554548 -0.3756023 ] [ 1.1404819 -1.09976462 -0.1612551 ]]b2 =[[-0.88020257] [ 0.02561572] [ 0.57539477]]A variant of this is Stochastic Gradient Descent (SGD), which is equivalent to mini-batch gradient descent where each mini-batch has just 1 example. The update rule that you have just implemented does not change. What changes is that you would be computing gradients on just one training example at a time, rather than on the whole training set. The code examples below illustrate the difference between stochastic gradient descent and (batch) gradient descent.(Batch) Gradient Descent:123456789101112X = data_inputY = labelsparameters = initialize_parameters(layers_dims)for i in range(0, num_iterations): # Forward propagation a, caches = forward_propagation(X, parameters) # Compute cost. cost += compute_cost(a, Y) # Backward propagation. grads = backward_propagation(a, caches, parameters) # Update parameters. parameters = update_parameters(parameters, grads)Stochastic Gradient Descent:12345678910111213X = data_inputY = labelsparameters = initialize_parameters(layers_dims)for i in range(0, num_iterations): for j in range(0, m): # Forward propagation a, caches = forward_propagation(X[:,j], parameters) # Compute cost cost += compute_cost(a, Y[:,j]) # Backward propagation grads = backward_propagation(a, caches, parameters) # Update parameters. parameters = update_parameters(parameters, grads)In Stochastic Gradient Descent, you use only 1 training example before updating the gradients. When the training set is large, SGD can be faster. But the parameters will “oscillate” toward the minimum rather than converge smoothly. Here is an illustration of this:Note also that implementing SGD requires 3 for-loops in total:Over the number of iterationsOver the $m$ training examplesOver the layers (to update all parameters, from $(W^{[1]},b^{[1]})$ to $(W^{[L]},b^{[L]})$)In practice, you’ll often get faster results if you do not use neither the whole training set, nor only one training example, to perform each update. Mini-batch gradient descent uses an intermediate number of examples for each step. With mini-batch gradient descent, you loop over the mini-batches instead of looping over individual training examples.What you should remember:The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.You have to tune a learning rate hyperparameter $\alpha$.With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).2 - Mini-Batch Gradient descentLet’s learn how to build mini-batches from the training set (X, Y).There are two steps:Shuffle: Create a shuffled version of the training set (X, Y) as shown below. Each column of X and Y represents a training example. Note that the random shuffling is done synchronously between X and Y. Such that after the shuffling the $i^{th}$ column of X is the example corresponding to the $i^{th}$ label in Y. The shuffling step ensures that examples will be split randomly into different mini-batches.Partition: Partition the shuffled (X, Y) into mini-batches of size mini_batch_size (here 64). Note that the number of training examples is not always divisible by mini_batch_size. The last mini batch might be smaller, but you don’t need to worry about this. When the final mini-batch is smaller than the full mini_batch_size, it will look like this:Exercise: Implement random_mini_batches. We coded the shuffling part for you. To help you with the partitioning step, we give you the following code that selects the indexes for the $1^{st}$ and $2^{nd}$ mini-batches:123first_mini_batch_X = shuffled_X[:, 0 : mini_batch_size]second_mini_batch_X = shuffled_X[:, mini_batch_size : 2 * mini_batch_size]...Note that the last mini-batch might end up smaller than mini_batch_size=64. Let $\lfloor s \rfloor$ represents $s$ rounded down to the nearest integer (this is math.floor(s) in Python). If the total number of examples is not a multiple of mini_batch_size=64 then there will be $\lfloor \frac{m}{mini_batch_size}\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini__batch__size \times \lfloor \frac{m}{mini_batch_size}\rfloor$).1234567891011121314151617181920212223242526272829303132333435363738394041424344# GRADED FUNCTION: random_mini_batchesdef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0): """ Creates a list of random minibatches from (X, Y) Arguments: X -- input data, of shape (input size, number of examples) Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples) mini_batch_size -- size of the mini-batches, integer Returns: mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y) """ np.random.seed(seed) # To make your "random" minibatches the same as ours m = X.shape[1] # number of training examples mini_batches = [] # Step 1: Shuffle (X, Y) permutation = list(np.random.permutation(m)) shuffled_X = X[:, permutation] shuffled_Y = Y[:, permutation].reshape((1,m)) # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case. num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning for k in range(0, num_complete_minibatches): ### START CODE HERE ### (approx. 2 lines) mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size : m] mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size : m] ### END CODE HERE ### mini_batch = (mini_batch_X, mini_batch_Y) mini_batches.append(mini_batch) # Handling the end case (last mini-batch &lt; mini_batch_size) if m % mini_batch_size != 0: ### START CODE HERE ### (approx. 2 lines) mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size : m] mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size : m] ### END CODE HERE ### mini_batch = (mini_batch_X, mini_batch_Y) mini_batches.append(mini_batch) return mini_batches12345678910X_assess, Y_assess, mini_batch_size = random_mini_batches_test_case()mini_batches = random_mini_batches(X_assess, Y_assess, mini_batch_size)print ("shape of the 1st mini_batch_X: " + str(mini_batches[0][0].shape))print ("shape of the 2nd mini_batch_X: " + str(mini_batches[1][0].shape))print ("shape of the 3rd mini_batch_X: " + str(mini_batches[2][0].shape))print ("shape of the 1st mini_batch_Y: " + str(mini_batches[0][1].shape))print ("shape of the 2nd mini_batch_Y: " + str(mini_batches[1][1].shape)) print ("shape of the 3rd mini_batch_Y: " + str(mini_batches[2][1].shape))print ("mini batch sanity check: " + str(mini_batches[0][0][0][0:3]))1234567shape of the 1st mini_batch_X: (12288, 20)shape of the 2nd mini_batch_X: (12288, 20)shape of the 3rd mini_batch_X: (12288, 20)shape of the 1st mini_batch_Y: (1, 20)shape of the 2nd mini_batch_Y: (1, 20)shape of the 3rd mini_batch_Y: (1, 20)mini batch sanity check: [-1.31228341 0.75041164 0.16003707]What you should remember:Shuffling and Partitioning are the two steps required to build mini-batchesPowers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.3 - MomentumBecause mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will “oscillate” toward convergence. Using momentum can reduce these oscillations.Momentum takes into account the past gradients to smooth out the update. We will store the ‘direction’ of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the “velocity” of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hillExercise: Initialize the velocity. The velocity, $v$, is a python dictionary that needs to be initialized with arrays of zeros. Its keys are the same as those in the grads dictionary, that is:for $l =1,…,L$:12v["dW" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["W" + str(l+1)])v["db" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["b" + str(l+1)])Note that the iterator l starts at 0 in the for loop while the first parameters are v[“dW1”] and v[“db1”] (that’s a “one” on the superscript). This is why we are shifting l to l+1 in the for loop.1234567891011121314151617181920212223242526272829# GRADED FUNCTION: initialize_velocitydef initialize_velocity(parameters): """ Initializes the velocity as a python dictionary with: - keys: "dW1", "db1", ..., "dWL", "dbL" - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters. Arguments: parameters -- python dictionary containing your parameters. parameters['W' + str(l)] = Wl parameters['b' + str(l)] = bl Returns: v -- python dictionary containing the current velocity. v['dW' + str(l)] = velocity of dWl v['db' + str(l)] = velocity of dbl """ L = len(parameters) // 2 # number of layers in the neural networks v = &#123;&#125; # Initialize velocity for l in range(L): ### START CODE HERE ### (approx. 2 lines) v["dW" + str(l+1)] = np.zeros(parameters["W" + str(l+1)].shape) v["db" + str(l+1)] = np.zeros(parameters["b" + str(l+1)].shape) ### END CODE HERE ### return v1234567parameters = initialize_velocity_test_case()v = initialize_velocity(parameters)print("v[\"dW1\"] =\n" + str(v["dW1"]))print("v[\"db1\"] =\n" + str(v["db1"]))print("v[\"dW2\"] =\n" + str(v["dW2"]))print("v[\"db2\"] =\n" + str(v["db2"]))1234567891011121314v["dW1"] =[[ 0. 0. 0.] [ 0. 0. 0.]]v["db1"] =[[ 0.] [ 0.]]v["dW2"] =[[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]v["db2"] =[[ 0.] [ 0.] [ 0.]]Exercise: Now, implement the parameters update with momentum. The momentum update rule is, for $l = 1, …, L$:\begin{cases} v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]} \\ W^{[l]} = W^{[l]} - \alpha v_{dW^{[l]}} \end{cases}\tag{3}\begin{cases} v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]} \\ b^{[l]} = b^{[l]} - \alpha v_{db^{[l]}} \end{cases}\tag{4}where L is the number of layers, $\beta$ is the momentum and $\alpha$ is the learning rate. All parameters should be stored in the parameters dictionary. Note that the iterator l starts at 0 in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that’s a “one” on the superscript). So you will need to shift l to l+1 when coding.123456789101112131415161718192021222324252627282930313233343536373839# GRADED FUNCTION: update_parameters_with_momentumdef update_parameters_with_momentum(parameters, grads, v, beta, learning_rate): """ Update parameters using Momentum Arguments: parameters -- python dictionary containing your parameters: parameters['W' + str(l)] = Wl parameters['b' + str(l)] = bl grads -- python dictionary containing your gradients for each parameters: grads['dW' + str(l)] = dWl grads['db' + str(l)] = dbl v -- python dictionary containing the current velocity: v['dW' + str(l)] = ... v['db' + str(l)] = ... beta -- the momentum hyperparameter, scalar learning_rate -- the learning rate, scalar Returns: parameters -- python dictionary containing your updated parameters v -- python dictionary containing your updated velocities """ L = len(parameters) // 2 # number of layers in the neural networks # Momentum update for each parameter for l in range(L): ### START CODE HERE ### (approx. 4 lines) # compute velocities v["dW" + str(l+1)] = beta*v["dW" + str(l+1)] + (1-beta)*grads["dW" + str(l+1)] v["db" + str(l+1)] = beta*v["db" + str(l+1)] + (1-beta)*grads["db" + str(l+1)] # update parameters parameters["W" + str(l+1)] = parameters["W" + str(l+1)] - learning_rate*v["dW" + str(l+1)] parameters["b" + str(l+1)] = parameters["b" + str(l+1)] - learning_rate*v["db" + str(l+1)] ### END CODE HERE ### return parameters, v1234567891011parameters, grads, v = update_parameters_with_momentum_test_case()parameters, v = update_parameters_with_momentum(parameters, grads, v, beta = 0.9, learning_rate = 0.01)print("W1 = \n" + str(parameters["W1"]))print("b1 = \n" + str(parameters["b1"]))print("W2 = \n" + str(parameters["W2"]))print("b2 = \n" + str(parameters["b2"]))print("v[\"dW1\"] = \n" + str(v["dW1"]))print("v[\"db1\"] = \n" + str(v["db1"]))print("v[\"dW2\"] = \n" + str(v["dW2"]))print("v[\"db2\"] = v" + str(v["db2"]))123456789101112131415161718192021222324252627W1 = [[ 1.62544598 -0.61290114 -0.52907334] [-1.07347112 0.86450677 -2.30085497]]b1 = [[ 1.74493465] [-0.76027113]]W2 = [[ 0.31930698 -0.24990073 1.4627996 ] [-2.05974396 -0.32173003 -0.38320915] [ 1.13444069 -1.0998786 -0.1713109 ]]b2 = [[-0.87809283] [ 0.04055394] [ 0.58207317]]v["dW1"] = [[-0.11006192 0.11447237 0.09015907] [ 0.05024943 0.09008559 -0.06837279]]v["db1"] = [[-0.01228902] [-0.09357694]]v["dW2"] = [[-0.02678881 0.05303555 -0.06916608] [-0.03967535 -0.06871727 -0.08452056] [-0.06712461 -0.00126646 -0.11173103]]v["db2"] = v[[ 0.02344157] [ 0.16598022] [ 0.07420442]]Note that:The velocity is initialized with zeros. So the algorithm will take a few iterations to “build up” velocity and start to take bigger steps.If $\beta = 0$, then this just becomes standard gradient descent without momentum.How do you choose $\beta$?The larger the momentum $\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\beta$ is too big, it could also smooth out the updates too much.Common values for $\beta$ range from 0.8 to 0.999. If you don’t feel inclined to tune this, $\beta = 0.9$ is often a reasonable default.Tuning the optimal $\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$.What you should remember:Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.You have to tune a momentum hyperparameter $\beta$ and a learning rate $\alpha$.4 - AdamAdam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum.How does Adam work?It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction).It calculates an exponentially weighted average of the squares of the past gradients, and stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction).It updates parameters in a direction based on combining information from “1” and “2”.The update rule is, for $l = 1, …, L$:\begin{cases} v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \\ v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t} \\ s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \\ s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_2)^t} \\ W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}_{dW^{[l]}}}{\sqrt{s^{corrected}_{dW^{[l]}}} + \varepsilon} \end{cases}where:t counts the number of steps taken of AdamL is the number of layers$\beta_1$ and $\beta_2$ are hyperparameters that control the two exponentially weighted averages.$\alpha$ is the learning rate$\varepsilon$ is a very small number to avoid dividing by zeroAs usual, we will store all parameters in the parameters dictionaryExercise: Initialize the Adam variables $v, s$ which keep track of the past information.Instruction: The variables $v, s$ are python dictionaries that need to be initialized with arrays of zeros. Their keys are the same as for grads, that is:for $l = 1, …, L$:1234v["dW" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["W" + str(l+1)])v["db" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["b" + str(l+1)])s["dW" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["W" + str(l+1)])s["db" + str(l+1)] = ... #(numpy array of zeros with the same shape as parameters["b" + str(l+1)])12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: initialize_adamdef initialize_adam(parameters) : """ Initializes v and s as two python dictionaries with: - keys: "dW1", "db1", ..., "dWL", "dbL" - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters. Arguments: parameters -- python dictionary containing your parameters. parameters["W" + str(l)] = Wl parameters["b" + str(l)] = bl Returns: v -- python dictionary that will contain the exponentially weighted average of the gradient. v["dW" + str(l)] = ... v["db" + str(l)] = ... s -- python dictionary that will contain the exponentially weighted average of the squared gradient. s["dW" + str(l)] = ... s["db" + str(l)] = ... """ L = len(parameters) // 2 # number of layers in the neural networks v = &#123;&#125; s = &#123;&#125; # Initialize v, s. Input: "parameters". Outputs: "v, s". for l in range(L): ### START CODE HERE ### (approx. 4 lines) v["dW" + str(l+1)] = np.zeros(parameters["W" + str(l+1)].shape) v["db" + str(l+1)] = np.zeros(parameters["b" + str(l+1)].shape) s["dW" + str(l+1)] = np.zeros(parameters["W" + str(l+1)].shape) s["db" + str(l+1)] = np.zeros(parameters["b" + str(l+1)].shape) ### END CODE HERE ### return v, s1234567891011parameters = initialize_adam_test_case()v, s = initialize_adam(parameters)print("v[\"dW1\"] = \n" + str(v["dW1"]))print("v[\"db1\"] = \n" + str(v["db1"]))print("v[\"dW2\"] = \n" + str(v["dW2"]))print("v[\"db2\"] = \n" + str(v["db2"]))print("s[\"dW1\"] = \n" + str(s["dW1"]))print("s[\"db1\"] = \n" + str(s["db1"]))print("s[\"dW2\"] = \n" + str(s["dW2"]))print("s[\"db2\"] = \n" + str(s["db2"]))12345678910111213141516171819202122232425262728v["dW1"] = [[ 0. 0. 0.] [ 0. 0. 0.]]v["db1"] = [[ 0.] [ 0.]]v["dW2"] = [[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]v["db2"] = [[ 0.] [ 0.] [ 0.]]s["dW1"] = [[ 0. 0. 0.] [ 0. 0. 0.]]s["db1"] = [[ 0.] [ 0.]]s["dW2"] = [[ 0. 0. 0.] [ 0. 0. 0.] [ 0. 0. 0.]]s["db2"] = [[ 0.] [ 0.] [ 0.]]Exercise: Now, implement the parameters update with Adam. Recall the general update rule is, for $l = 1, …, L$:\begin{cases} v_{W^{[l]}} = \beta_1 v_{W^{[l]}} + (1 - \beta_1) \frac{\partial J }{ \partial W^{[l]} } \\ v^{corrected}_{W^{[l]}} = \frac{v_{W^{[l]}}}{1 - (\beta_1)^t} \\ s_{W^{[l]}} = \beta_2 s_{W^{[l]}} + (1 - \beta_2) (\frac{\partial J }{\partial W^{[l]} })^2 \\ s^{corrected}_{W^{[l]}} = \frac{s_{W^{[l]}}}{1 - (\beta_2)^t} \\ W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}_{W^{[l]}}}{\sqrt{s^{corrected}_{W^{[l]}}}+\varepsilon} \end{cases}Note that the iterator l starts at 0 in the for loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift l to l+1 when coding.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# GRADED FUNCTION: update_parameters_with_adamdef update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8): """ Update parameters using Adam Arguments: parameters -- python dictionary containing your parameters: parameters['W' + str(l)] = Wl parameters['b' + str(l)] = bl grads -- python dictionary containing your gradients for each parameters: grads['dW' + str(l)] = dWl grads['db' + str(l)] = dbl v -- Adam variable, moving average of the first gradient, python dictionary s -- Adam variable, moving average of the squared gradient, python dictionary learning_rate -- the learning rate, scalar. beta1 -- Exponential decay hyperparameter for the first moment estimates beta2 -- Exponential decay hyperparameter for the second moment estimates epsilon -- hyperparameter preventing division by zero in Adam updates Returns: parameters -- python dictionary containing your updated parameters v -- Adam variable, moving average of the first gradient, python dictionary s -- Adam variable, moving average of the squared gradient, python dictionary """ L = len(parameters) // 2 # number of layers in the neural networks v_corrected = &#123;&#125; # Initializing first moment estimate, python dictionary s_corrected = &#123;&#125; # Initializing second moment estimate, python dictionary # Perform Adam update on all parameters for l in range(L): # Moving average of the gradients. Inputs: "v, grads, beta1". Output: "v". ### START CODE HERE ### (approx. 2 lines) v["dW" + str(l+1)] = beta1 * v["dW" + str(l+1)] + (1 - beta1) * grads['dW' + str(l+1)] v["db" + str(l+1)] = beta1 * v["db" + str(l+1)] + (1 - beta1) * grads['db' + str(l+1)] ### END CODE HERE ### # Compute bias-corrected first moment estimate. Inputs: "v, beta1, t". Output: "v_corrected". ### START CODE HERE ### (approx. 2 lines) v_corrected["dW" + str(l+1)] = v["dW" + str(l+1)] / (1 - beta1 ** t) v_corrected["db" + str(l+1)] = v["db" + str(l+1)] / (1 - beta1 ** t) ### END CODE HERE ### # Moving average of the squared gradients. Inputs: "s, grads, beta2". Output: "s". ### START CODE HERE ### (approx. 2 lines) s["dW" + str(l+1)] = beta2 * s["dW" + str(l+1)] + (1 - beta2) * (grads['dW' + str(l+1)] ** 2) s["db" + str(l+1)] = beta2 * s["db" + str(l+1)] + (1 - beta2) * (grads['db' + str(l+1)] ** 2) ### END CODE HERE ### # Compute bias-corrected second raw moment estimate. Inputs: "s, beta2, t". Output: "s_corrected". ### START CODE HERE ### (approx. 2 lines) s_corrected["dW" + str(l+1)] = s["dW" + str(l+1)] / (1 - beta2 ** t) s_corrected["db" + str(l+1)] = s["db" + str(l+1)] / (1 - beta2 ** t) ### END CODE HERE ### # Update parameters. Inputs: "parameters, learning_rate, v_corrected, s_corrected, epsilon". Output: "parameters". ### START CODE HERE ### (approx. 2 lines) parameters["W" + str(l+1)] = parameters["W" + str(l+1)] - learning_rate * ( v_corrected["dW" + str(l+1)] / (np.sqrt(s_corrected["dW" + str(l+1)]) + epsilon)) parameters["b" + str(l+1)] = parameters["b" + str(l+1)] - learning_rate * ( v_corrected["db" + str(l+1)] / (np.sqrt(s_corrected["db" + str(l+1)]) + epsilon)) ### END CODE HERE ### return parameters, v, s123456789101112131415parameters, grads, v, s = update_parameters_with_adam_test_case()parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t = 2)print("W1 = \n" + str(parameters["W1"]))print("b1 = \n" + str(parameters["b1"]))print("W2 = \n" + str(parameters["W2"]))print("b2 = \n" + str(parameters["b2"]))print("v[\"dW1\"] = \n" + str(v["dW1"]))print("v[\"db1\"] = \n" + str(v["db1"]))print("v[\"dW2\"] = \n" + str(v["dW2"]))print("v[\"db2\"] = \n" + str(v["db2"]))print("s[\"dW1\"] = \n" + str(s["dW1"]))print("s[\"db1\"] = \n" + str(s["db1"]))print("s[\"dW2\"] = \n" + str(s["dW2"]))print("s[\"db2\"] = \n" + str(s["db2"]))123456789101112131415161718192021222324252627282930313233343536373839404142W1 = [[ 1.63178673 -0.61919778 -0.53561312] [-1.08040999 0.85796626 -2.29409733]]b1 = [[ 1.75225313] [-0.75376553]]W2 = [[ 0.32648046 -0.25681174 1.46954931] [-2.05269934 -0.31497584 -0.37661299] [ 1.14121081 -1.09245036 -0.16498684]]b2 = [[-0.88529978] [ 0.03477238] [ 0.57537385]]v["dW1"] = [[-0.11006192 0.11447237 0.09015907] [ 0.05024943 0.09008559 -0.06837279]]v["db1"] = [[-0.01228902] [-0.09357694]]v["dW2"] = [[-0.02678881 0.05303555 -0.06916608] [-0.03967535 -0.06871727 -0.08452056] [-0.06712461 -0.00126646 -0.11173103]]v["db2"] = [[ 0.02344157] [ 0.16598022] [ 0.07420442]]s["dW1"] = [[ 0.00121136 0.00131039 0.00081287] [ 0.0002525 0.00081154 0.00046748]]s["db1"] = [[ 1.51020075e-05] [ 8.75664434e-04]]s["dW2"] = [[ 7.17640232e-05 2.81276921e-04 4.78394595e-04] [ 1.57413361e-04 4.72206320e-04 7.14372576e-04] [ 4.50571368e-04 1.60392066e-07 1.24838242e-03]]s["db2"] = [[ 5.49507194e-05] [ 2.75494327e-03] [ 5.50629536e-04]]You now have three working optimization algorithms (mini-batch gradient descent, Momentum, Adam). Let’s implement a model with each of these optimizers and observe the difference.5 - Model with different optimization algorithmsLets use the following “moons” dataset to test the different optimization methods. (The dataset is named “moons” because the data from each of the two classes looks a bit like a crescent-shaped moon.)1train_X, train_Y = load_dataset()We have already implemented a 3-layer neural network. You will train it with:Mini-batch Gradient Descent: it will call your function:update_parameters_with_gd()Mini-batch Momentum: it will call your functions:initialize_velocity() and update_parameters_with_momentum()Mini-batch Adam: it will call your functions:initialize_adam() and update_parameters_with_adam()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, num_epochs = 10000, print_cost = True): """ 3-layer neural network model which can be run in different optimizer modes. Arguments: X -- input data, of shape (2, number of examples) Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples) layers_dims -- python list, containing the size of each layer learning_rate -- the learning rate, scalar. mini_batch_size -- the size of a mini batch beta -- Momentum hyperparameter beta1 -- Exponential decay hyperparameter for the past gradients estimates beta2 -- Exponential decay hyperparameter for the past squared gradients estimates epsilon -- hyperparameter preventing division by zero in Adam updates num_epochs -- number of epochs print_cost -- True to print the cost every 1000 epochs Returns: parameters -- python dictionary containing your updated parameters """ L = len(layers_dims) # number of layers in the neural networks costs = [] # to keep track of the cost t = 0 # initializing the counter required for Adam update seed = 10 # For grading purposes, so that your "random" minibatches are the same as ours m = X.shape[1] # number of training examples # Initialize parameters parameters = initialize_parameters(layers_dims) # Initialize the optimizer if optimizer == "gd": pass # no initialization required for gradient descent elif optimizer == "momentum": v = initialize_velocity(parameters) elif optimizer == "adam": v, s = initialize_adam(parameters) # Optimization loop for i in range(num_epochs): # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch seed = seed + 1 minibatches = random_mini_batches(X, Y, mini_batch_size, seed) cost_total = 0 for minibatch in minibatches: # Select a minibatch (minibatch_X, minibatch_Y) = minibatch # Forward propagation a3, caches = forward_propagation(minibatch_X, parameters) # Compute cost and add to the cost total cost_total += compute_cost(a3, minibatch_Y) # Backward propagation grads = backward_propagation(minibatch_X, minibatch_Y, caches) # Update parameters if optimizer == "gd": parameters = update_parameters_with_gd(parameters, grads, learning_rate) elif optimizer == "momentum": parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate) elif optimizer == "adam": t = t + 1 # Adam counter parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2, epsilon) cost_avg = cost_total / m # Print the cost every 1000 epoch if print_cost and i % 1000 == 0: print ("Cost after epoch %i: %f" %(i, cost_avg)) if print_cost and i % 100 == 0: costs.append(cost_avg) # plot the cost plt.plot(costs) plt.ylabel('cost') plt.xlabel('epochs (per 100)') plt.title("Learning rate = " + str(learning_rate)) plt.show() return parametersYou will now run this 3 layer neural network with each of the 3 optimization methods.5.1 - Mini-batch Gradient descentRun the following code to see how the model does with mini-batch gradient descent.12345678910111213# train 3-layer modellayers_dims = [train_X.shape[0], 5, 2, 1]parameters = model(train_X, train_Y, layers_dims, optimizer = "gd")# Predictpredictions = predict(train_X, train_Y, parameters)# Plot decision boundaryplt.title("Model with Gradient Descent optimization")axes = plt.gca()axes.set_xlim([-1.5,2.5])axes.set_ylim([-1,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)12345678910Cost after epoch 0: 0.506535Cost after epoch 1000: 0.502723Cost after epoch 2000: 0.474631Cost after epoch 3000: 0.454304Cost after epoch 4000: 0.423354Cost after epoch 5000: 0.447243Cost after epoch 6000: 0.389273Cost after epoch 7000: 0.339863Cost after epoch 8000: 0.342521Cost after epoch 9000: 0.3439245.2 - Mini-batch gradient descent with momentumRun the following code to see how the model does with momentum. Because this example is relatively simple, the gains from using momemtum are small; but for more complex problems you might see bigger gains.12345678910111213# train 3-layer modellayers_dims = [train_X.shape[0], 5, 2, 1]parameters = model(train_X, train_Y, layers_dims, beta = 0.9, optimizer = "momentum")# Predictpredictions = predict(train_X, train_Y, parameters)# Plot decision boundaryplt.title("Model with Momentum optimization")axes = plt.gca()axes.set_xlim([-1.5,2.5])axes.set_ylim([-1,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)12345678910Cost after epoch 0: 0.506543Cost after epoch 1000: 0.502784Cost after epoch 2000: 0.474674Cost after epoch 3000: 0.454353Cost after epoch 4000: 0.423440Cost after epoch 5000: 0.447287Cost after epoch 6000: 0.389322Cost after epoch 7000: 0.339984Cost after epoch 8000: 0.342552Cost after epoch 9000: 0.3440745.3 - Mini-batch with Adam modeRun the following code to see how the model does with Adam.12345678910111213# train 3-layer modellayers_dims = [train_X.shape[0], 5, 2, 1]parameters = model(train_X, train_Y, layers_dims, optimizer = "adam")# Predictpredictions = predict(train_X, train_Y, parameters)# Plot decision boundaryplt.title("Model with Adam optimization")axes = plt.gca()axes.set_xlim([-1.5,2.5])axes.set_ylim([-1,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)12345678910Cost after epoch 0: 0.506277Cost after epoch 1000: 0.179246Cost after epoch 2000: 0.140424Cost after epoch 3000: 0.073110Cost after epoch 4000: 0.106034Cost after epoch 5000: 0.087949Cost after epoch 6000: 0.089428Cost after epoch 7000: 0.030555Cost after epoch 8000: 0.100690Cost after epoch 9000: 0.1585885.4 - SummaryMomentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you’ve seen that Adam converges a lot faster.Some advantages of Adam include:Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum)Usually works well even with little tuning of hyperparameters (except $\alpha$)References:Adam paper: https://arxiv.org/pdf/1412.6980.pdf参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://www.coursera.org/learn/deep-neural-network/home/week/2https://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（2-1）]]></title>
    <url>%2F2019%2F09%2F14%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%882-1%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深度学习的实践层面（Practical aspects of Deep Learning）1.1 训练，验证，测试集（Train / Dev / Test sets）在数据较少情况下，划分情况：无验证集：$0.7-0.3$有验证集：$0.6-0.2-0.2$数据较多情况下：$1,000,000$：$0.98-0.01-0.01$$&gt;1,000,000$：$0.995-0.0025-0.0025$ 或 $0.995-0.004-0.001$1.2 偏差，方差（Bias /Variance）高偏差和高方差：采用曲线函数或二次元函数会产生高方差，因为它曲线灵活性太高以致拟合了这两个错误样本和中间这些活跃数据。这看起来有些不自然，从两个维度上看都不太自然，但对于高维数据，有些数据区域偏差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强了。1.3 机器学习基础（Basic Recipe for Machine Learning）在训练机器学习模型的过程中，解决High bias 和High variance 的过程：1.是否存在High bias?增加网络结构，如增加隐藏层数目；训练更长时间；寻找合适的网络架构，使用更大的NN结构；2.是否存在High variance？获取更多的数据；正则化（ regularization）；寻找合适的网络结构；1.4 正则化（Regularization）Logistic regression加入正则化项的代价函数：$J(w,b)=\dfrac{1}{m}\sum\limits_{i=1}^{m}l(\hat y^{(i)},y^{(i)})+\dfrac{\lambda}{2m}||w||_{2}^{2}$为什么只正则化参数$w$？为什么不再加上参数 $b$ 呢？你可以这么做，只是我习惯省略不写，因为$w$通常是一个高维参数矢量，已经可以表达高偏差问题，$w$可能包含有很多参数，我们不可能拟合所有参数，而$b$只是单个数字，所以$w$几乎涵盖所有参数，而不是$b$，如果加了参数$b$，其实也没太大影响，因为$b$只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。L2正则化：$\dfrac{\lambda}{2m}||w||_{2}^{2} = \dfrac{\lambda}{2m}\sum\limits_{j=1}^{n_{x}} w_{j}^{2}=\dfrac{\lambda}{2m}w^{T}w$L1正则化：$\dfrac{\lambda}{2m}||w||_{1}=\dfrac{\lambda}{2m}\sum\limits_{j=1}^{n_{x}}|w_{j}|$其中$λ$为正则化因子。lambda在python中属于保留字，所以在编程的时候，用“lambd”代表这里的正则化因子$λ$Neural network加入正则化项的代价函数：$J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\dfrac{1}{m}\sum\limits_{i=1}^{m}l(\hat y^{(i)},y^{(i)})+\dfrac{\lambda}{2m}\sum\limits_{l=1}^{L}||w^{[l]}||_{F}^{2}$其中$||w^{[l]}||_{F}^{2}=\sum\limits_{i=1}^{n^{[l-1]}}\sum\limits_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^{2}$，因为$w$的大小为$(n^{[l-1]},n^{[l]})$，该矩阵范数被称为“Frobenius norm”（“弗罗贝尼乌斯范数”，用下标$F$标注”）使用该范数实现梯度下降：$dW^{[l]} = (form_backprop)+\dfrac{\lambda}{m}W^{[l]}$$W^{[l]}:= W^{[l]}-\alpha dW^{[l]}$$\begin{align}W^{[l]}:&amp;= W^{[l]}-\alpha [ (form_backprop)+\dfrac{\lambda}{m}W^{[l]}]\\ &amp;= W^{[l]}-\alpha\dfrac{\lambda}{m}W^{[l]} -\alpha(form_backprop)\\&amp;=(1-\dfrac{\alpha\lambda}{m})W^{[l]}-\alpha(form_backprop)\end{align}$该正则项说明，不论$W^{[l]}$是什么，我们都试图让它变得更小，实际上，相当于我们给矩阵W乘以$(1 -a\frac{\lambda}{m})$倍的权重，矩阵$W$减去$\alpha\frac{\lambda}{m}$倍的它，也就是用这个系数$(1-a\frac{\lambda}{m})$乘以矩阵$W$，该系数小于1，因此$L2$范数正则化也被称为“权重衰减”，因为它就像一般的梯度下降，$W$被更新为少了$a$乘以backprop输出的最初梯度值，同时$W$也乘以了这个系数，这个系数小于1，因此$L2$正则化也被称为“权重衰减”（Weight decay）。1.5 为什么正则化有利于预防过拟合呢？（Why regularization reduces overfitting?）左图是高偏差，右图是高方差，中间是Just Right。直观理解就是$\lambda$增加到足够大，$W$会接近于0，实际上是不会发生这种情况的，我们尝试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单，这个神经网络越来越接近逻辑回归，我们直觉上认为大量隐藏单元被完全消除了，其实不然，实际上是该神经网络的所有隐藏单元依然存在，但是它们的影响变得更小了。神经网络变得更简单了，貌似这样更不容易发生过拟合。假设我们用的是这样的双曲线激活函数：用$g(z)$表示$tanh(z)$,那么我们发现，只要$z$非常小，如果$z$只涉及少量参数，这里我们利用了双曲正切函数的线性状态，只要$z$可以扩展为这样的更大值或者更小值，激活函数开始变得非线性。如果正则化参数λ很大，激活函数的参数会相对较小，因为代价函数中的参数变大了，如果$W$很小，相对来说，$z$也会很小。特别是，如果$z$的值最终在这个范围内，都是相对较小的值，$g(z)$大致呈线性，每层几乎都是线性的，和线性回归函数一样。如果每层都是线性的，那么整个网络就是一个线性网络，即使是一个非常深的深层网络，因具有线性激活函数的特征，最终我们只能计算线性函数。1.6 dropout 正则化（Dropout Regularization）Dropout（随机失活）：为每个神经元结点设置一个随机消除的概率，对于保留下来的神经元，我们得到一个节点较少，规模较小的网络进行训练。inverted dropout（反向随机失活）1234keep_prob = 0.8 # 设置神经元保留概率d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_proba3 = np.multiply(a3, d3)a3 /= keep_prob$z^{[4]} = w^{[4]} a^{[3]} + b^{[4]}$，我们的预期是，$a^{[3]}$减少20%，也就是说$a^{[3]}$中有20%的元素被归零，为了不影响$z^{\lbrack4]}$的期望值，我们需要用$w^{[4]} a^{[3]}/0.8$，它将会修正或弥补我们所需的那20%，$a^{[3]}$的期望值不会变。在测试阶段不要用dropout，因为那样会使得预测结果变得随机。1.7 理解 dropout（Understanding Dropout）这里我们以单个神经元入手，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了Dropout以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。所以通过传播过程，dropout将产生和L2范数相同的收缩权重的效果。dropout的功能类似于$L2$正则化，与$L2$正则化不同的是，被应用的方式不同，dropout也会有所不同，甚至更适用于不同的输入范围。对于不同的层，设置的keep_prob也不同，一般来说神经元较少的层，会设keep_prob =1.0，神经元多的层，则会将keep_prob设置的较小。如果你担心某些层比其它层更容易发生过拟合，可以把某些层的keep-prob值设置得比其它层更低，缺点是为了使用交叉验证，你要搜索更多的超级参数，另一种方案是在一些层上应用dropout，而有些层不用dropout，应用dropout的层只含有一个超级参数，就是keep-prob。dropout一大缺点就是代价函数$J$不再被明确定义，每次迭代，都会随机移除一些节点，无法绘制出每次迭代$J$的图。使用Dropout：关闭dropout功能，即设置keep_prob = 1.0；运行代码，确保$J(W，b)$函数单调递减；再打开dropout函数。1.8 其他正则化方法（Other regularization methods）数据扩增（Data augmentation）通过图片的一些变换，得到更多的训练集和验证集Early stopping在交叉验证集的误差上升之前的点停止迭代，避免过拟合。这种方法的缺点是无法同时解决bias和variance之间的最优。如果不用early stopping，另一种方法就是$L2$正则化，训练神经网络的时间就可能很长。这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试很多正则化参数$\lambda$的值，这也导致搜索大量$\lambda$值的计算代价太高。Early stopping的优点是，只运行一次梯度下降，你可以找出$w$的较小值，中间值和较大值，而无需尝试$L2$正则化超级参数$\lambda$的很多值。1.9 归一化输入（Normalizing inputs）训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为2维，归一化需要两个步骤：零均值归一化方差；我们希望无论是训练集和测试集都是通过相同的$μ$和$σ^2$定义的数据转换，这两个是由训练集得出来的。计算每个特征所有样本数据的均值：$\mu = \dfrac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$减去均值得到对称的分布：$x : =x-\mu$归一化方差：$\sigma^{2} = \dfrac{1}{m}\sum\limits_{i=1}^{m}x^{(i)^{2}}$使用归一化的原因：在不使用归一化的代价函数中，如果我们设置一个较小的学习率，那么很可能我们需要很多次迭代才能到达代价函数全局最优解；如果使用了归一化，那么无论从哪个位置开始迭代，我们都能以相对很少的迭代次数找到全局最优解。1.10 梯度消失/梯度爆炸（Vanishing / Exploding gradients）假设你正在训练这样一个极深的神经网络：对于目标输出有：$\hat y = W^{[L]}W^{[L-1]}\cdots W^{[2]}W^{[1]}X$假设每个权重矩阵$W^{[l]} = \begin{bmatrix} 1.5 &amp; 0 \\0 &amp; 1.5 \\\end{bmatrix}$，从技术上来讲，最后一项有不同维度，可能它就是余下的权重矩阵，$y= W^{[1]}\begin{bmatrix} 1.5 &amp; 0 \\ 0 &amp; 1.5 \\\end{bmatrix}^{(L -1)}x$，因为我们假设所有矩阵都等于它，它是1.5倍的单位矩阵，最后的计算结果就是$\hat{y}$，$\hat{y}$也就是等于${1.5}^{(L-1)}x$。如果对于一个深度神经网络来说$L$值较大，那么$\hat{y}$的值也会非常大，实际上它呈指数级增长的，它增长的比率是${1.5}^{L}$，因此对于一个深度神经网络，$y$的值将爆炸式增长。相反的，如果权重是0.5，$W^{[l]} = \begin{bmatrix} 0.5&amp; 0 \\ 0 &amp; 0.5 \\ \end{bmatrix}$，它比1小，这项也就变成了${0.5}^{L}$，矩阵$y= W^{[1]}\begin{bmatrix} 0.5 &amp; 0 \\ 0 &amp; 0.5 \\\end{bmatrix}^{(L - 1)}x$，再次忽略$W^{[L]}$，因此每个矩阵都小于1，假设$x_{1}$和$x_{2}$都是1，激活函数将变成$\frac{1}{2}$，$\frac{1}{2}$，$\frac{1}{4}$，$\frac{1}{4}$，$\frac{1}{8}$，$\frac{1}{8}$等，直到最后一项变成$\frac{1}{2^{L}}$，所以作为自定义函数，激活函数的值将以指数级下降，它是与网络层数数量$L$相关的函数，在深度网络中，激活函数以指数级递减。上面的情况对于导数也是同样的道理，所以在计算梯度时，根据情况的不同，梯度函数会以指数级递增或者递减，导致训练导数难度上升，梯度下降算法的步长会变得非常非常小，需要训练的时间将会非常长。在梯度函数上出现的以指数级递增或者递减的情况就分别称为梯度爆炸或者梯度消失。1.11 神经网络的权重初始化（Weight Initialization for Deep NetworksVanishing / Exploding gradients）以一个单个神经元为例子：单个神经元可能有4个输入特征，从$x_{1}$到$x_{4}$，经过$a=g(z)$处理，最终得到$\hat{y}$，稍后讲深度网络时，这些输入表示为$a^{[l]}$，暂时我们用$x$表示。$z = w_{1}x_{1} + w_{2}x_{2} + \ldots +w_{n}x_{n}$，$b=0$，暂时忽略$b$，为了预防$z$值过大或过小，你可以看到$n$越大，你希望$w_{i}$越小，因为$z$是$w_{i}x_{i}$的和，如果你把很多此类项相加，希望每项值更小，最合理的方法就是设置$w_{i}=\frac{1}{n}$，$n$表示神经元的输入特征数量，实际上，你要做的就是设置某层权重矩阵$w^{[l]} = np.random.randn( \text{shape})*\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$，$n^{[l - 1]}$就是我喂给第$l$层神经单元的数量（即第$l-1$层神经元数量）。结果，如果你是用的是Relu激活函数，而不是$\frac{1}{n}$，方差设置为$\frac{2}{n}$，效果会更好。你常常发现，初始化时，尤其是使用Relu激活函数时，$g^{[l]}(z) =Relu(z)$,它取决于你对随机变量的熟悉程度，这是高斯随机变量，然后乘以它的平方根，也就是引用这个方差$\frac{2}{n}$。这里，我用的是$n^{[l - 1]}$，因为本例中，逻辑回归的特征是不变的。但一般情况下$l$层上的每个神经元都有$n^{[l - 1]}$个输入。如果激活函数的输入特征被零均值和标准方差化，方差是1，$z$也会调整到相似范围，这就没解决问题（梯度消失和爆炸问题）。但它确实降低了梯度消失和爆炸问题，因为它给权重矩阵$w$设置了合理值，你也知道，它不能比1大很多，也不能比1小很多，所以梯度没有爆炸或消失过快。对于几个其它变体函数，如tanh激活函数，有篇论文提到，常量1比常量2的效率更高，对于tanh函数来说，它是$\sqrt{\frac{1}{n^{[l-1]}}}$，这里平方根的作用与这个公式作用相同($\text{np.}\text{sqrt}(\frac{1}{n^{[l-1]}})$)，它适用于tanh激活函数，被称为Xavier初始化。Yoshua Bengio和他的同事还提出另一种方法，你可能在一些论文中看到过，它们使用的是公式$\sqrt{\frac{2}{n^{[l-1]} + n^{\left[l\right]}}}$。其它理论已对此证明，但如果你想用Relu激活函数，也就是最常用的激活函数，我会用这个公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]}})$，如果使用tanh函数，可以用公式$\sqrt{\frac{1}{n^{[l-1]}}}$，有些作者也会使用这个函数。实际上，我认为所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默认值，如果你想添加方差，方差参数则是另一个你需要调整的超级参数，可以给公式$\text{np.}\text{sqrt}(\frac{2}{n^{[l-1]}})$添加一个乘数参数，调优作为超级参数激增一份子的乘子参数。有时调优该超级参数效果一般，这并不是我想调优的首要超级参数，但我发现调优过程中产生的问题，虽然调优该参数能起到一定作用，但考虑到相比调优，其它超级参数的重要性，我通常把它的优先级放得比较低。1.12 梯度的数值逼近（Numerical approximation of gradients）使用双边误差的方法去逼近导数：这两个宽度都是ε，所以三角形的宽度是$2\varepsilon$，高宽比值为$\frac{f(\theta + \varepsilon ) - (\theta -\varepsilon)}{2\varepsilon}$，它的期望值接近$g( \theta)$，$f( \theta)=\theta^{3}$传入参数值，$\frac {f\left( \theta + \varepsilon \right) - f(\theta -\varepsilon)}{2\varepsilon} = \frac{(1.01)^{3} - {(0.99)}^{3}}{2 \times0.01}=3.0001$，当$\theta =1$时，$g( \theta)=3\theta^{2} =3$，所以这两个$g(\theta)$值非常接近，逼近误差为0.0001。单边误差，即从$\theta $到$\theta +\varepsilon$之间的误差，$g( \theta)$的值为3.0301。双边导数：$f’(\theta) = \lim\limits_{\varepsilon \to 0}=\dfrac{f(\theta+\varepsilon)-(\theta-\varepsilon)}{2\varepsilon}$ 误差：$O(\varepsilon^{2})$单边导数：$f’(\theta) = \lim\limits_{\varepsilon \to 0}=\dfrac{f(\theta+\varepsilon)-(\theta)}{\varepsilon}$ 误差：$O(\varepsilon)$1.13 梯度检验（Gradient checking）假设你的网络中含有下列参数，$W^{[1]}$和$b^{[1]}$……$W^{[l]}$和$b^{[l]}$，为了执行梯度检验，首先要做的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵$W$转换成一个向量，把所有$W$矩阵转换成向量之后，做连接运算，得到一个巨型向量$\theta$，该向量表示为参数$\theta$，代价函数$J$是所有$W$和$b$的函数，现在你得到了一个$\theta$的代价函数$J$（即$J(\theta)$）。接着，你得到与$W$和$b$顺序相同的数据，你同样可以把$dW^{[1]}$和${db}^{[1]}$……${dW}^{[l]}$和${db}^{[l]}$转换成一个新的向量，用它们来初始化大向量$d\theta$，它与$\theta$具有相同维度。同样的，把$dW^{[1]}$转换成矩阵，$db^{[1]}$已经是一个向量了，直到把${dW}^{[l]}$转换成矩阵，这样所有的$dW$都已经是矩阵，注意$dW^{[1]}$与$W^{[1]}$具有相同维度，$db^{[1]}$与$b^{[1]}$具有相同维度。经过相同的转换和连接运算操作之后，你可以把所有导数转换成一个大向量$d\theta$，它与$\theta$具有相同维度，现在的问题是$d\theta$和代价函数$J$的梯度或坡度有什么关系？这就是实施梯度检验的过程，英语里通常简称为“grad check”，首先，我们要清楚$J$是超参数$\theta$的一个函数，你也可以将J函数展开为$J(\theta_{1},\theta_{2},\theta_{3},\ldots\ldots)$，不论超级参数向量$\theta$的维度是多少，为了实施梯度检验，你要做的就是循环执行，从而对每个$i$也就是对每个$\theta$组成元素计算$d\theta_{\text{approx}}[i]$的值，我使用双边误差，也就是$d\theta_{\text{approx}}\left[i \right] = \frac{J\left( \theta_{1},\theta_{2},\ldots\theta_{i} + \varepsilon,\ldots \right) - J\left( \theta_{1},\theta_{2},\ldots\theta_{i} - \varepsilon,\ldots \right)}{2\varepsilon}$只对$\theta_{i}$增加$\varepsilon$，其它项保持不变，因为我们使用的是双边误差，对另一边做同样的操作，只不过是减去$\varepsilon$，$\theta$其它项全都保持不变。判断$d\theta_{approx}\approx d\theta$是否接近$\dfrac {||d\theta_{approx}-d\theta||_{2}}{||d\theta_{approx}||_{2}+||d\theta||_{2}}$$||\cdot ||_{2}$表示欧几里得范数，它是误差平方之和，然后求平方根，得到的欧氏距离。1.14 梯度检验应用的注意事项（Gradient Checking Implementation Notes）作业Part1:InitializationWelcome to the first assignment of “Improving Deep Neural Networks”.Training your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.If you completed the previous course of this specialization, you probably followed our instructions for weight initialization, and it has worked out so far. But how do you choose the initialization for a new neural network? In this notebook, you will see how different initializations lead to different results.A well chosen initialization can:Speed up the convergence of gradient descentIncrease the odds of gradient descent converging to a lower training (and generalization) errorTo get started, run the following cell to load the packages and the planar dataset you will try to classify.1234567891011121314import numpy as npimport matplotlib.pyplot as pltimport sklearnimport sklearn.datasetsfrom init_utils import sigmoid, relu, compute_loss, forward_propagation, backward_propagationfrom init_utils import update_parameters, predict, load_dataset, plot_decision_boundary, predict_dec%matplotlib inlineplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'# load image dataset: blue/red dots in circlestrain_X, train_Y, test_X, test_Y = load_dataset()You would like a classifier to separate the blue dots from the red dots.1 - Neural Network modelYou will use a 3-layer neural network (already implemented for you). Here are the initialization methods you will experiment with:Zeros initialization — setting initialization = &quot;zeros&quot; in the input argument.Random initialization — setting initialization = &quot;random&quot; in the input argument. This initializes the weights to large random values.He initialization — setting initialization = &quot;he&quot; in the input argument. This initializes the weights to random values scaled according to a paper by He et al., 2015.Instructions: Please quickly read over the code below, and run it. In the next part you will implement the three initialization methods that this model() calls.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758def model(X, Y, learning_rate = 0.01, num_iterations = 15000, print_cost = True, initialization = "he"): """ Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- input data, of shape (2, number of examples) Y -- true "label" vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples) learning_rate -- learning rate for gradient descent num_iterations -- number of iterations to run gradient descent print_cost -- if True, print the cost every 1000 iterations initialization -- flag to choose which initialization to use ("zeros","random" or "he") Returns: parameters -- parameters learnt by the model """ grads = &#123;&#125; costs = [] # to keep track of the loss m = X.shape[1] # number of examples layers_dims = [X.shape[0], 10, 5, 1] # Initialize parameters dictionary. if initialization == "zeros": parameters = initialize_parameters_zeros(layers_dims) elif initialization == "random": parameters = initialize_parameters_random(layers_dims) elif initialization == "he": parameters = initialize_parameters_he(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. a3, cache = forward_propagation(X, parameters) # Loss cost = compute_loss(a3, Y) # Backward propagation. grads = backward_propagation(X, Y, cache) # Update parameters. parameters = update_parameters(parameters, grads, learning_rate) # Print the loss every 1000 iterations if print_cost and i % 1000 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, cost)) costs.append(cost) # plot the loss plt.plot(costs) plt.ylabel('cost') plt.xlabel('iterations (per hundreds)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parameters2 - Zero initializationThere are two types of parameters to initialize in a neural network:the weight matrices $(W^{[1]}, W^{[2]}, W^{[3]}, …, W^{[L-1]}, W^{[L]})$the bias vectors $(b^{[1]}, b^{[2]}, b^{[3]}, …, b^{[L-1]}, b^{[L]})$Exercise: Implement the following function to initialize all parameters to zeros. You’ll see later that this does not work well since it fails to “break symmetry”, but lets try it anyway and see what happens. Use np.zeros((..,..)) with the correct shapes.12345678910111213141516171819202122232425# GRADED FUNCTION: initialize_parameters_zeros def initialize_parameters_zeros(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ parameters = &#123;&#125; L = len(layers_dims) # number of layers in the network for l in range(1, L): ### START CODE HERE ### (≈ 2 lines of code) parameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l-1])) parameters['b' + str(l)] = np.zeros((layers_dims[l],1)) ### END CODE HERE ### return parameters123456789101112parameters = initialize_parameters_zeros([3,2,1])print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))# W1 = [[ 0. 0. 0.]# [ 0. 0. 0.]]# b1 = [[ 0.]# [ 0.]]# W2 = [[ 0. 0.]]# b2 = [[ 0.]]Run the following code to train your model on 15,000 iterations using zeros initialization.12345parameters = model(train_X, train_Y, initialization = "zeros")print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)123456789101112131415Cost after iteration 0: 0.6931471805599453Cost after iteration 1000: 0.6931471805599453Cost after iteration 2000: 0.6931471805599453Cost after iteration 3000: 0.6931471805599453Cost after iteration 4000: 0.6931471805599453Cost after iteration 5000: 0.6931471805599453Cost after iteration 6000: 0.6931471805599453Cost after iteration 7000: 0.6931471805599453Cost after iteration 8000: 0.6931471805599453Cost after iteration 9000: 0.6931471805599453Cost after iteration 10000: 0.6931471805599455Cost after iteration 11000: 0.6931471805599453Cost after iteration 12000: 0.6931471805599453Cost after iteration 13000: 0.6931471805599453Cost after iteration 14000: 0.69314718055994531234On the train set:Accuracy: 0.5On the test set:Accuracy: 0.5The performance is really bad, and the cost does not really decrease, and the algorithm performs no better than random guessing. Why? Lets look at the details of the predictions and the decision boundary:12print ("predictions_train = " + str(predictions_train))print ("predictions_test = " + str(predictions_test))123456789101112predictions_train = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]predictions_test = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]12345plt.title("Model with Zeros initialization")axes = plt.gca()axes.set_xlim([-1.5,1.5])axes.set_ylim([-1.5,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)The model is predicting 0 for every example.In general, initializing all the weights to zero results in the network failing to break symmetry. This means that every neuron in each layer will learn the same thing, and you might as well be training a neural network with $n^{[l]}=1$ for every layer, and the network is no more powerful than a linear classifier such as logistic regression.What you should remember:The weights $W^{[l]}$ should be initialized randomly to break symmetry.It is however okay to initialize the biases $b^{[l]}$ to zeros. Symmetry is still broken so long as $W^{[l]}$ is initialized randomly.3 - Random initializationTo break symmetry, lets intialize the weights randomly. Following random initialization, each neuron can then proceed to learn a different function of its inputs. In this exercise, you will see what happens if the weights are intialized randomly, but to very large values.Exercise: Implement the following function to initialize your weights to large random values (scaled by *10) and your biases to zeros. Use np.random.randn(..,..) * 10 for weights and np.zeros((.., ..)) for biases. We are using a fixed np.random.seed(..) to make sure your “random” weights match ours, so don’t worry if running several times your code gives you always the same initial values for the parameters.123456789101112131415161718192021222324252627# GRADED FUNCTION: initialize_parameters_randomdef initialize_parameters_random(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ np.random.seed(3) # This seed makes sure your "random" numbers will be the as ours parameters = &#123;&#125; L = len(layers_dims) # integer representing the number of layers for l in range(1, L): ### START CODE HERE ### (≈ 2 lines of code) parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1])*10 parameters['b' + str(l)] = np.zeros((layers_dims[l],1)) ### END CODE HERE ### return parameters1234567891011parameters = initialize_parameters_random([3, 2, 1])print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))# W1 = [[ 17.88628473 4.36509851 0.96497468]# [-18.63492703 -2.77388203 -3.54758979]]# b1 = [[ 0.]# [ 0.]]# W2 = [[-0.82741481 -6.27000677]]# b2 = [[ 0.]]Run the following code to train your model on 15,000 iterations using random initialization.12345parameters = model(train_X, train_Y, initialization = "random")print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)123456789101112131415Cost after iteration 0: infCost after iteration 1000: 0.6242434241539614Cost after iteration 2000: 0.5978811277755388Cost after iteration 3000: 0.5636242569764779Cost after iteration 4000: 0.5500958254523324Cost after iteration 5000: 0.544339206192789Cost after iteration 6000: 0.5373584514307651Cost after iteration 7000: 0.469574666760224Cost after iteration 8000: 0.39766324943219844Cost after iteration 9000: 0.3934423376823982Cost after iteration 10000: 0.3920158992175907Cost after iteration 11000: 0.38913979237487845Cost after iteration 12000: 0.3861261344766218Cost after iteration 13000: 0.3849694511273874Cost after iteration 14000: 0.38274890171919171234On the train set:Accuracy: 0.83On the test set:Accuracy: 0.86If you see “inf” as the cost after the iteration 0, this is because of numerical roundoff; a more numerically sophisticated implementation would fix this. But this isn’t worth worrying about for our purposes.Anyway, it looks like you have broken symmetry, and this gives better results. than before. The model is no longer outputting all 0s.12print (predictions_train)print (predictions_test)123456789101112[[1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0]][[1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0]]12345plt.title("Model with large random initialization")axes = plt.gca()axes.set_xlim([-1.5,1.5])axes.set_ylim([-1.5,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)Observations:The cost starts very high. This is because with large random-valued weights, the last activation (sigmoid) outputs results that are very close to 0 or 1 for some examples, and when it gets that example wrong it incurs a very high loss for that example. Indeed, when $\log(a^{[3]}) = \log(0)$, the loss goes to infinity.Poor initialization can lead to vanishing/exploding gradients, which also slows down the optimization algorithm.If you train this network longer you will see better results, but initializing with overly large random numbers slows down the optimization.In summary:Initializing weights to very large random values does not work well.Hopefully intializing with small random values does better. The important question is: how small should be these random values be? Lets find out in the next part!4 - He initializationFinally, try “He Initialization”; this is named for the first author of He et al., 2015. (If you have heard of “Xavier initialization”, this is similar except Xavier initialization uses a scaling factor for the weights $W^{[l]}$ of sqrt(1./layers_dims[l-1]) where He initialization would use sqrt(2./layers_dims[l-1]).)Exercise: Implement the following function to initialize your parameters with He initialization.Hint: This function is similar to the previous initialize_parameters_random(...). The only difference is that instead of multiplying np.random.randn(..,..) by 10, you will multiply it by $\sqrt{\frac{2}{\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation.123456789101112131415161718192021222324252627# GRADED FUNCTION: initialize_parameters_hedef initialize_parameters_he(layers_dims): """ Arguments: layer_dims -- python array (list) containing the size of each layer. Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": W1 -- weight matrix of shape (layers_dims[1], layers_dims[0]) b1 -- bias vector of shape (layers_dims[1], 1) ... WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1]) bL -- bias vector of shape (layers_dims[L], 1) """ np.random.seed(3) parameters = &#123;&#125; L = len(layers_dims) - 1 # integer representing the number of layers for l in range(1, L + 1): ### START CODE HERE ### (≈ 2 lines of code) parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1])*np.sqrt(2./layers_dims[l-1]) parameters['b' + str(l)] = np.zeros((layers_dims[l],1)) ### END CODE HERE ### return parameters12345parameters = initialize_parameters_he([2, 4, 1])print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))12345678910W1 = [[ 1.78862847 0.43650985] [ 0.09649747 -1.8634927 ] [-0.2773882 -0.35475898] [-0.08274148 -0.62700068]]b1 = [[ 0.] [ 0.] [ 0.] [ 0.]]W2 = [[-0.03098412 -0.33744411 -0.92904268 0.62552248]]b2 = [[ 0.]]Run the following code to train your model on 15,000 iterations using He initialization.12345parameters = model(train_X, train_Y, initialization = "he")print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)123456789101112131415Cost after iteration 0: 0.8830537463419761Cost after iteration 1000: 0.6879825919728063Cost after iteration 2000: 0.6751286264523371Cost after iteration 3000: 0.6526117768893807Cost after iteration 4000: 0.6082958970572938Cost after iteration 5000: 0.5304944491717495Cost after iteration 6000: 0.4138645817071794Cost after iteration 7000: 0.3117803464844441Cost after iteration 8000: 0.23696215330322562Cost after iteration 9000: 0.18597287209206834Cost after iteration 10000: 0.15015556280371806Cost after iteration 11000: 0.12325079292273546Cost after iteration 12000: 0.09917746546525934Cost after iteration 13000: 0.08457055954024278Cost after iteration 14000: 0.073578959626773691234On the train set:Accuracy: 0.993333333333On the test set:Accuracy: 0.9612345plt.title("Model with He initialization")axes = plt.gca()axes.set_xlim([-1.5,1.5])axes.set_ylim([-1.5,1.5])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)Observations:The model with He initialization separates the blue and the red dots very well in a small number of iterations.5 - ConclusionsYou have seen three different types of initializations. For the same number of iterations and same hyperparameters the comparison is:ModelTrain accuracyProblem/Comment3-layer NN with zeros initialization50%fails to break symmetry3-layer NN with large random initialization83%too large weights3-layer NN with He initialization99%recommended methodWhat you should remember from this notebook:Different initializations lead to different resultsRandom initialization is used to break symmetry and make sure different hidden units can learn different thingsDon’t intialize to values that are too largeHe initialization works well for networks with ReLU activations.Part2:RegularizationWelcome to the second assignment of this week. Deep Learning models have so much flexibility and capacity that overfitting can be a serious problem, if the training dataset is not big enough. Sure it does well on the training set, but the learned network doesn’t generalize to new examples that it has never seen!You will learn to: Use regularization in your deep learning models.Let’s first import the packages you are going to use.1234567891011121314# import packagesimport numpy as npimport matplotlib.pyplot as pltfrom reg_utils import sigmoid, relu, plot_decision_boundary, initialize_parameters, load_2D_dataset, predict_decfrom reg_utils import compute_cost, predict, forward_propagation, backward_propagation, update_parametersimport sklearnimport sklearn.datasetsimport scipy.iofrom testCases import *%matplotlib inlineplt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'Problem Statement: You have just been hired as an AI expert by the French Football Corporation. They would like you to recommend positions where France’s goal keeper should kick the ball so that the French team’s players can then hit it with their head.They give you the following 2D dataset from France’s past 10 games.1train_X, train_Y, test_X, test_Y = load_2D_dataset()Each dot corresponds to a position on the football field where a football player has hit the ball with his/her head after the French goal keeper has shot the ball from the left side of the football field.If the dot is blue, it means the French player managed to hit the ball with his/her headIf the dot is red, it means the other team’s player hit the ball with their headYour goal: Use a deep learning model to find the positions on the field where the goalkeeper should kick the ball.Analysis of the dataset: This dataset is a little noisy, but it looks like a diagonal line separating the upper left half (blue) from the lower right half (red) would work well.You will first try a non-regularized model. Then you’ll learn how to regularize it and decide which model you will choose to solve the French Football Corporation’s problem.1 - Non-regularized modelYou will use the following neural network (already implemented for you below). This model can be used:in regularization mode — by setting the lambd input to a non-zero value. We use “lambd“ instead of “lambda“ because “lambda“ is a reserved keyword in Python.in dropout mode — by setting the keep_prob to a value less than oneYou will first try the model without any regularization. Then, you will implement:L2 regularization — functions: “compute_cost_with_regularization()“ and “backward_propagation_with_regularization()“Dropout — functions: “forward_propagation_with_dropout()“ and “backward_propagation_with_dropout()“In each part, you will run this model with the correct inputs so that it calls the functions you’ve implemented. Take a look at the code below to familiarize yourself with the model.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True, lambd = 0, keep_prob = 1): """ Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- input data, of shape (input size, number of examples) Y -- true "label" vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples) learning_rate -- learning rate of the optimization num_iterations -- number of iterations of the optimization loop print_cost -- If True, print the cost every 10000 iterations lambd -- regularization hyperparameter, scalar keep_prob - probability of keeping a neuron active during drop-out, scalar. Returns: parameters -- parameters learned by the model. They can then be used to predict. """ grads = &#123;&#125; costs = [] # to keep track of the cost m = X.shape[1] # number of examples layers_dims = [X.shape[0], 20, 3, 1] # Initialize parameters dictionary. parameters = initialize_parameters(layers_dims) # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. if keep_prob == 1: a3, cache = forward_propagation(X, parameters) elif keep_prob &lt; 1: a3, cache = forward_propagation_with_dropout(X, parameters, keep_prob) # Cost function if lambd == 0: cost = compute_cost(a3, Y) else: cost = compute_cost_with_regularization(a3, Y, parameters, lambd) # Backward propagation. assert(lambd==0 or keep_prob==1) # it is possible to use both L2 regularization and dropout, # but this assignment will only explore one at a time if lambd == 0 and keep_prob == 1: grads = backward_propagation(X, Y, cache) elif lambd != 0: grads = backward_propagation_with_regularization(X, Y, cache, lambd) elif keep_prob &lt; 1: grads = backward_propagation_with_dropout(X, Y, cache, keep_prob) # Update parameters. parameters = update_parameters(parameters, grads, learning_rate) # Print the loss every 10000 iterations if print_cost and i % 10000 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, cost)) if print_cost and i % 1000 == 0: costs.append(cost) # plot the cost plt.plot(costs) plt.ylabel('cost') plt.xlabel('iterations (x1,000)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parametersLet’s train the model without any regularization, and observe the accuracy on the train/test sets.12345parameters = model(train_X, train_Y)print ("On the training set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)The train accuracy is 94.8% while the test accuracy is 91.5%. This is the baseline model (you will observe the impact of regularization on this model). Run the following code to plot the decision boundary of your model.12345plt.title("Model without regularization")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)The non-regularized model is obviously overfitting the training set. It is fitting the noisy points! Lets now look at two techniques to reduce overfitting.2 - L2 RegularizationThe standard way to avoid overfitting is called L2 regularization. It consists of appropriately modifying your cost function, from:J = -\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} \tag{1}To:J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} }_\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2 regularization cost} \tag{2}Let’s modify your cost and observe the consequences.Exercise: Implement compute_cost_with_regularization() which computes the cost given by formula (2). To calculate $\sum\limits_k\sum\limits_j W_{k,j}^{[l]2}$ , use :1np.sum(np.square(Wl))Note that you have to do this for $W^{[1]}$, $W^{[2]}$ and $W^{[3]}$, then sum the three terms and multiply by $ \frac{1}{m} \frac{\lambda}{2} $.12345678910111213141516171819202122232425262728# GRADED FUNCTION: compute_cost_with_regularizationdef compute_cost_with_regularization(A3, Y, parameters, lambd): """ Implement the cost function with L2 regularization. See formula (2) above. Arguments: A3 -- post-activation, output of forward propagation, of shape (output size, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) parameters -- python dictionary containing parameters of the model Returns: cost - value of the regularized loss function (formula (2)) """ m = Y.shape[1] W1 = parameters["W1"] W2 = parameters["W2"] W3 = parameters["W3"] cross_entropy_cost = compute_cost(A3, Y) # This gives you the cross-entropy part of the cost ### START CODE HERE ### (approx. 1 line) L2_regularization_cost = ((1.*lambd)/(2.*m))*(np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) ### END CODER HERE ### cost = cross_entropy_cost + L2_regularization_cost return cost1234A3, Y_assess, parameters = compute_cost_with_regularization_test_case()print("cost = " + str(compute_cost_with_regularization(A3, Y_assess, parameters, lambd = 0.1)))# cost = 1.78648594516Of course, because you changed the cost, you have to change backward propagation as well! All the gradients have to be computed with respect to this new cost.Exercise: Implement the changes needed in backward propagation to take into account regularization. The changes only concern dW1, dW2 and dW3. For each, you have to add the regularization term’s gradient ($\frac{d}{dW} ( \frac{1}{2}\frac{\lambda}{m} W^2) = \frac{\lambda}{m} W$).123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: backward_propagation_with_regularizationdef backward_propagation_with_regularization(X, Y, cache, lambd): """ Implements the backward propagation of our baseline model to which we added an L2 regularization. Arguments: X -- input dataset, of shape (input size, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) cache -- cache output from forward_propagation() lambd -- regularization hyperparameter, scalar Returns: gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables """ m = X.shape[1] (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache dZ3 = A3 - Y ### START CODE HERE ### (approx. 1 line) dW3 = 1./m * np.dot(dZ3, A2.T) + lambd/m * W3 ### END CODE HERE ### db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True) dA2 = np.dot(W3.T, dZ3) dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0)) ### START CODE HERE ### (approx. 1 line) dW2 = 1./m * np.dot(dZ2, A1.T) + lambd/m * W2 ### END CODE HERE ### db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True) dA1 = np.dot(W2.T, dZ2) dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0)) ### START CODE HERE ### (approx. 1 line) dW1 = 1./m * np.dot(dZ1, X.T) + lambd/m * W1 ### END CODE HERE ### db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True) gradients = &#123;"dZ3": dZ3, "dW3": dW3, "db3": db3,"dA2": dA2, "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, "dZ1": dZ1, "dW1": dW1, "db1": db1&#125; return gradients123456X_assess, Y_assess, cache = backward_propagation_with_regularization_test_case()grads = backward_propagation_with_regularization(X_assess, Y_assess, cache, lambd = 0.7)print ("dW1 = "+ str(grads["dW1"]))print ("dW2 = "+ str(grads["dW2"]))print ("dW3 = "+ str(grads["dW3"]))123456dW1 = [[-0.25604646 0.12298827 -0.28297129] [-0.17706303 0.34536094 -0.4410571 ]]dW2 = [[ 0.79276486 0.85133918] [-0.0957219 -0.01720463] [-0.13100772 -0.03750433]]dW3 = [[-1.77691347 -0.11832879 -0.09397446]]Let’s now run the model with L2 regularization $(\lambda = 0.7)$. The model() function will call:compute_cost_with_regularization instead of compute_costbackward_propagation_with_regularization instead of backward_propagation12345parameters = model(train_X, train_Y, lambd = 0.7)print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)Congrats, the test set accuracy increased to 93%. You have saved the French football team!You are not overfitting the training data anymore. Let’s plot the decision boundary.12345plt.title("Model with L2-regularization")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)Observations:The value of $\lambda$ is a hyperparameter that you can tune using a dev set.L2 regularization makes your decision boundary smoother. If $\lambda$ is too large, it is also possible to “oversmooth”, resulting in a model with high bias.What is L2-regularization actually doing?:L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes.What you should remember — the implications of L2-regularization on:The cost computation:A regularization term is added to the costThe backpropagation function:There are extra terms in the gradients with respect to weight matricesWeights end up smaller (“weight decay”):Weights are pushed to smaller values.3 - DropoutFinally, dropout is a widely used regularization technique that is specific to deep learning.It randomly shuts down some neurons in each iteration. Watch these two videos to see what this means!![1568981440650](deeplearning-ai笔记（2-1）/1568981440650.png) At each iteration, you shut down (= set to zero) each neuron of a layer with probability $1 - keep\_prob$ or keep it with probability $keep\_prob$ (50% here). The dropped neurons don't contribute to the training in both the forward and backward propagations of the iteration.When you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time.3.1 -Forward propagation with dropoutExercise: Implement the forward propagation with dropout. You are using a 3 layer neural network, and will add dropout to the first and second hidden layers. We will not apply dropout to the input layer or output layer.Instructions:You would like to shut down some neurons in the first and second layers. To do that, you are going to carry out 4 Steps:In lecture, we dicussed creating a variable $d^{[1]}$ with the same shape as $a^{[1]}$ using np.random.rand() to randomly get numbers between 0 and 1. Here, you will use a vectorized implementation, so create a random matrix $D^{[1]} = [d^{1} d^{1} … d^{1}] $ of the same dimension as $A^{[1]}$.Set each entry of $D^{[1]}$ to be 0 with probability (1-keep_prob) or 1 with probability (keep_prob), by thresholding values in $D^{[1]}$ appropriately. Hint: to set all the entries of a matrix X to 0 (if entry is less than 0.5) or 1 (if entry is more than 0.5) you would do: X = (X &gt; 0.5). Note that 0 and 1 are respectively equivalent to False and True.Set $A^{[1]}$ to $A^{[1]} * D^{[1]}$. (You are shutting down some neurons). You can think of $D^{[1]}$ as a mask, so that when it is multiplied with another matrix, it shuts down some of the values.Divide $A^{[1]}$ by keep_prob. By doing this you are assuring that the result of the cost will still have the same expected value as without drop-out. (This technique is also called inverted dropout.)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# GRADED FUNCTION: forward_propagation_with_dropoutdef forward_propagation_with_dropout(X, parameters, keep_prob = 0.5): """ Implements the forward propagation: LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID. Arguments: X -- input dataset, of shape (2, number of examples) parameters -- python dictionary containing your parameters "W1", "b1", "W2", "b2", "W3", "b3": W1 -- weight matrix of shape (20, 2) b1 -- bias vector of shape (20, 1) W2 -- weight matrix of shape (3, 20) b2 -- bias vector of shape (3, 1) W3 -- weight matrix of shape (1, 3) b3 -- bias vector of shape (1, 1) keep_prob - probability of keeping a neuron active during drop-out, scalar Returns: A3 -- last activation value, output of the forward propagation, of shape (1,1) cache -- tuple, information stored for computing the backward propagation """ np.random.seed(1) # retrieve parameters W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] W3 = parameters["W3"] b3 = parameters["b3"] # LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID Z1 = np.dot(W1, X) + b1 A1 = relu(Z1) ### START CODE HERE ### (approx. 4 lines) # Steps 1-4 below correspond to the Steps 1-4 described above. D1 = np.random.rand(A1.shape[0],A1.shape[1]) # Step 1: initialize matrix D1 = np.random.rand(..., ...) D1 = D1 &lt; keep_prob # Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold) A1 = A1 * D1 # Step 3: shut down some neurons of A1 A1 = A1 / keep_prob # Step 4: scale the value of neurons that haven't been shut down ### END CODE HERE ### Z2 = np.dot(W2, A1) + b2 A2 = relu(Z2) ### START CODE HERE ### (approx. 4 lines) D2 = np.random.rand(A2.shape[0],A2.shape[1]) # Step 1: initialize matrix D2 = np.random.rand(..., ...) D2 = D2 &lt; keep_prob # Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold) A2 = A2 * D2 # Step 3: shut down some neurons of A2 A2 = A2 / keep_prob # Step 4: scale the value of neurons that haven't been shut down ### END CODE HERE ### Z3 = np.dot(W3, A2) + b3 A3 = sigmoid(Z3) cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) return A3, cache12345X_assess, parameters = forward_propagation_with_dropout_test_case()A3, cache = forward_propagation_with_dropout(X_assess, parameters, keep_prob = 0.7)print ("A3 = " + str(A3))# A3 = [[ 0.36974721 0.00305176 0.04565099 0.49683389 0.36974721]]3.2 - Backward propagation with dropoutExercise: Implement the backward propagation with dropout. As before, you are training a 3 layer network. Add dropout to the first and second hidden layers, using the masks $D^{[1]}$ and $D^{[2]}$ stored in the cache.Instruction:Backpropagation with dropout is actually quite easy. You will have to carry out 2 Steps:You had previously shut down some neurons during forward propagation, by applying a mask $D^{[1]}$ to A1. In backpropagation, you will have to shut down the same neurons, by reapplying the same mask $D^{[1]}$ to dA1.During forward propagation, you had divided A1 by keep_prob. In backpropagation, you’ll therefore have to divide dA1 by keep_prob again (the calculus interpretation is that if $A^{[1]}$ is scaled by keep_prob, then its derivative $dA^{[1]}$ is also scaled by the same keep_prob).123456789101112131415161718192021222324252627282930313233343536373839404142434445# GRADED FUNCTION: backward_propagation_with_dropoutdef backward_propagation_with_dropout(X, Y, cache, keep_prob): """ Implements the backward propagation of our baseline model to which we added dropout. Arguments: X -- input dataset, of shape (2, number of examples) Y -- "true" labels vector, of shape (output size, number of examples) cache -- cache output from forward_propagation_with_dropout() keep_prob - probability of keeping a neuron active during drop-out, scalar Returns: gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables """ m = X.shape[1] (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache dZ3 = A3 - Y dW3 = 1./m * np.dot(dZ3, A2.T) db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True) dA2 = np.dot(W3.T, dZ3) ### START CODE HERE ### (≈ 2 lines of code) dA2 = dA2 * D2 # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation dA2 = dA2 / keep_prob # Step 2: Scale the value of neurons that haven't been shut down ### END CODE HERE ### dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0)) dW2 = 1./m * np.dot(dZ2, A1.T) db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True) dA1 = np.dot(W2.T, dZ2) ### START CODE HERE ### (≈ 2 lines of code) dA1 = dA1 * D1 # Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation dA1 = dA1 / keep_prob # Step 2: Scale the value of neurons that haven't been shut down ### END CODE HERE ### dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0)) dW1 = 1./m * np.dot(dZ1, X.T) db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True) gradients = &#123;"dZ3": dZ3, "dW3": dW3, "db3": db3,"dA2": dA2, "dZ2": dZ2, "dW2": dW2, "db2": db2, "dA1": dA1, "dZ1": dZ1, "dW1": dW1, "db1": db1&#125; return gradients123456X_assess, Y_assess, cache = backward_propagation_with_dropout_test_case()gradients = backward_propagation_with_dropout(X_assess, Y_assess, cache, keep_prob = 0.8)print ("dA1 = " + str(gradients["dA1"]))print ("dA2 = " + str(gradients["dA2"]))12345dA1 = [[ 0.36544439 0. -0.00188233 0. -0.17408748] [ 0.65515713 0. -0.00337459 0. -0. ]]dA2 = [[ 0.58180856 0. -0.00299679 0. -0.27715731] [ 0. 0.53159854 -0. 0.53159854 -0.34089673] [ 0. 0. -0.00292733 0. -0. ]]Let’s now run the model with dropout (keep_prob = 0.86). It means at every iteration you shut down each neurons of layer 1 and 2 with 14% probability. The function model() will now call:forward_propagation_with_dropout instead of forward_propagation.backward_propagation_with_dropout instead of backward_propagation.123456parameters = model(train_X, train_Y, keep_prob = 0.86, learning_rate = 0.3)print ("On the train set:")predictions_train = predict(train_X, train_Y, parameters)print ("On the test set:")predictions_test = predict(test_X, test_Y, parameters)Dropout works great! The test accuracy has increased again (to 95%)! Your model is not overfitting the training set and does a great job on the test set. The French football team will be forever grateful to you!Run the code below to plot the decision boundary.12345plt.title("Model with dropout")axes = plt.gca()axes.set_xlim([-0.75,0.40])axes.set_ylim([-0.75,0.65])plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)Note:A common mistake when using dropout is to use it both in training and testing. You should use dropout (randomly eliminate nodes) only in training.Deep learning frameworks like tensorflow, PaddlePaddle, keras or caffe come with a dropout layer implementation. Don’t stress - you will soon learn some of these frameworks.What you should remember about dropout:Dropout is a regularization technique.You only use dropout during training. Don’t use dropout (randomly eliminate nodes) during test time.Apply dropout both during forward and backward propagation.During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when keep_prob is other values than 0.5.4 - ConclusionsHere are the results of our three models:modeltrain accuracytest accuracy3-layer NN without regularization95%91.5%3-layer NN with L2-regularization94%93%3-layer NN with dropout93%95%Note that regularization hurts training set performance! This is because it limits the ability of the network to overfit to the training set. But since it ultimately gives better test accuracy, it is helping your system.Congratulations for finishing this assignment! And also for revolutionizing French football. :-)What we want you to remember from this notebook:Regularization will help you reduce overfitting.Regularization will drive your weights to lower values.L2 regularization and Dropout are two very effective regularization techniques.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655https://www.coursera.org/learn/deep-neural-network/notebook/8IhFN/initialization]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四章-朴素贝叶斯法]]></title>
    <url>%2F2019%2F09%2F09%2F%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95%2F</url>
    <content type="text"><![CDATA[笔记代码1．朴素贝叶斯法是典型的生成学习方法。生成方法由训练数据学习联合概率分布$P(X,Y)$，然后求得后验概率分布$P(Y|X)$。具体来说，利用训练数据学习$P(X|Y)$和$P(Y)$的估计，得到联合概率分布：P(X,Y)＝P(Y)P(X|Y)概率估计方法可以是极大似然估计或贝叶斯估计。2．朴素贝叶斯法的基本假设是条件独立性，\begin{aligned} P(X&=x | Y=c_{k} )=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right) \\ &=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}这是一个较强的假设。由于这一假设，模型包含的条件概率的数量大为减少，朴素贝叶斯法的学习与预测大为简化。因而朴素贝叶斯法高效，且易于实现。其缺点是分类的性能不一定很高。3．朴素贝叶斯法利用贝叶斯定理与学到的联合概率模型进行分类预测。P(Y | X)=\frac{P(X, Y)}{P(X)}=\frac{P(Y) P(X | Y)}{\sum_{Y} P(Y) P(X | Y)}将输入$x$分到后验概率最大的类$y$。y=\arg \max _{c_{k}} P\left(Y=c_{k}\right) \prod_{j=1}^{n} P\left(X_{j}=x^{(j)} | Y=c_{k}\right)后验概率最大等价于0-1损失函数时的期望风险最小化。模型：高斯模型多项式模型伯努利模型12345678910import numpy as npimport pandas as pdimport matplotlib.pyplot as plt%matplotlib inlinefrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom collections import Counterimport math123456789# datadef create_data(): iris = load_iris() df = pd.DataFrame(iris.data, columns=iris.feature_names) df['label'] = iris.target df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data = np.array(df.iloc[:100, :]) # print(data) return data[:,:-1], data[:,-1]1234X, y = create_data()X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)X_train.shape, X_test.shape, y_train.shape, y_test.shape# ((70, 4), (30, 4), (70,), (30,))GaussianNB 高斯朴素贝叶斯特征的可能性被假设为高斯概率密度函数：P(x_i | y_k)=\frac{1}{\sqrt{2\pi\sigma^2_{yk}}}exp(-\frac{(x_i-\mu_{yk})^2}{2\sigma^2_{yk}})数学期望(mean)：$\mu$方差：$\sigma^2=\frac{\sum(X-\mu)^2}{N}$12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class NaiveBayes: def __init__(self): self.model = None # 数学期望 @staticmethod def mean(X): # return sum(X) / float(len(X)) return np.mean(X) # 标准差（方差） def stdev(self, X): # avg = self.mean(X) # return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X))) return np.std(X) # 概率密度函数 def gaussian_probability(self, x, mean, stdev): # exponent = math.exp(-(math.pow(x - mean, 2) / # (2 * math.pow(stdev, 2)))) # return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent exponent = np.exp(-(np.power(x - mean, 2) / (2 * np.power(stdev, 2)))) return (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent # 处理X_train def summarize(self, train_data): summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)] return summaries # 分类别求出数学期望和标准差 def fit(self, X, y): # 将数据进行分类 labels = list(set(y)) data = &#123;label: [] for label in labels&#125; for f, label in zip(X, y): data[label].append(f) # 计算每个类别下的数学期望和标准差 self.model = &#123; label: self.summarize(value) for label, value in data.items() &#125; return 'gaussianNB train done!' # 计算概率 def calculate_probabilities(self, input_data): # summaries:&#123;0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]&#125; # input_data:[1.1, 2.2] probabilities = &#123;&#125; for label, value in self.model.items(): probabilities[label] = 1 for i in range(len(value)): mean, stdev = value[i] probabilities[label] *= self.gaussian_probability( input_data[i], mean, stdev) return probabilities # 类别 def predict(self, X_test): # &#123;0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26&#125; label = sorted( self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0] return label def score(self, X_test, y_test): right = 0 for X, y in zip(X_test, y_test): label = self.predict(X) if label == y: right += 1 return right / float(len(X_test))123model = NaiveBayes()model.fit(X_train, y_train)# 'gaussianNB train done!'12model.predict([4.4, 3.2, 1.3, 0.2])# 0.012model.score(X_test, y_test)# 1.0scikit-learn1234567gaussian = GaussianNB()bernoulli = BernoulliNB()multinomial = MultinomialNB()gaussian.fit(X_train, y_train), bernoulli.fit(X_train, y_train), multinomial.fit(X_train, y_train)#(GaussianNB(priors=None, var_smoothing=1e-09),# BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),# MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))12gaussian.score(X_test, y_test), bernoulli.score(X_test, y_test), multinomial.score(X_test, y_test)# (1.0, 0.43333333333333335, 1.0)123456print(gaussian.predict([[4.4, 3.2, 1.3, 0.2]]))print(bernoulli.predict([[4.4, 3.2, 1.3, 0.2]]))print(multinomial.predict([[4.4, 3.2, 1.3, 0.2]]))# [0.]# [1.]# [0.]作业4.1 用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)。$P(Y=c_k)=\frac{\sum \limits _{i=1} ^ N I(y_i = c_k)}{N},\quad k=1,2,\cdots,K$证：$P(Y=c_k)=\theta_k,\quad k = 1,2,\cdots,K,\quad \sum \limits_{k=1} ^{K} \theta_k =1$$P(Y)=\sum\limits_{k=1}^K \theta_kI(Y=c_k)$$I_k=\sum \limits _{i=1} ^N I(y_i=c_k),\quad \sum \limits_{i=1} ^{N} I_k =N$$L(\theta_1,\theta_2,\cdots,\theta_k)=\prod \limits_{i=1}^{N}P(y_i)=\prod \limits_{k=1}^{K}\theta_k^{I_k} $$\begin{align}l(\theta)=log L(\theta) &amp;=\sum\limits_{k=1}^KI_klog\theta_k \\&amp;= \sum \limits_{k=1}^{K-1}I_klog\theta_k +(1-\sum\limits _{k=1}^{K-1}I_k)log(1-\sum \limits_{k=1}^{K-1}\theta_k)\end{align}$对其求导，令其导数为0，得：$\begin{align}\frac{\partial l(\theta)}{\partial \theta_k}&amp;=\frac{I_k}{\theta_k}-\frac{1-\sum\limits_{k=1}^{K-1}I_k}{1-\sum\limits_{k=1}^{K-1}\theta_k} \\ &amp;= \frac{I_k}{\theta_k}-\frac{I_K}{\theta_K}\\ &amp;=0\end{align}$即$\frac{I_k}{\theta_k}=\frac{I_K}{\theta_K},(k=1,2,\cdots,K-1)$4.2 用贝叶斯估计法推出朴素贝叶斯法中的慨率估计公式(4.10)及公式(4.11)。参考资料https://github.com/fengdu78/lihang-codehttps://machinelearningmastery.com/naive-bayes-classifier-scratch-python/https://blog.csdn.net/familyshizhouna/article/details/72179540https://www.zhihu.com/question/33959624/answer/93958363]]></content>
      <categories>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三章-k近邻法]]></title>
    <url>%2F2019%2F09%2F07%2F%E7%AC%AC%E4%B8%89%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95%2F</url>
    <content type="text"><![CDATA[笔记代码1．$k$近邻法是基本且简单的分类与回归方法。$k$近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的$k$个最近邻训练实例点，然后利用这$k$个训练实例点的类的多数来预测输入实例点的类。2．$k$近邻模型对应于基于训练数据集对特征空间的一个划分。$k$近邻法中，当训练集、距离度量、$k$值及分类决策规则确定后，其结果唯一确定。3．$k$近邻法三要素：距离度量、$k$值的选择和分类决策规则。常用的距离度量是欧氏距离及更一般的pL距离。$k$值小时，$k$近邻模型更复杂；$k$值大时，$k$近邻模型更简单。$k$值的选择反映了对近似误差与估计误差之间的权衡，通常由交叉验证选择最优的$k$。常用的分类决策规则是多数表决，对应于经验风险最小化。4．$k$近邻法的实现需要考虑如何快速搜索k个最近邻点。kd树是一种便于对k维空间中的数据进行快速检索的数据结构。kd树是二叉树，表示对$k$维空间的一个划分，其每个结点对应于$k$维空间划分中的一个超矩形区域。利用kd树可以省去对大部分数据点的搜索， 从而减少搜索的计算量。距离度量设特征空间$x$是$n$维实数向量空间 ，$x_{i}, x_{j} \in \mathcal{X}$,$x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}$,$x_{j}=\left(x_{j}^{(1)}, x_{j}^{(2)}, \cdots, x_{j}^{(n)}\right)^{\mathrm{T}}$，则：$x_i$,$x_j$的$L_p$距离定义为:$L_{p}\left(x_{i}, x_{j}\right)=\left(\sum_{i=1}^{n}\left|x_{i}^{(i)}-x_{j}^{(l)}\right|^{p}\right)^{\frac{1}{p}}$$p= 1$ 曼哈顿距离$p= 2$ 欧氏距离$p= inf$ 闵式距离 minkowski_distance123456789101112import mathfrom itertools import combinationsdef L(x, y, p=2): # x1 = [1, 1], x2 = [5,1] if len(x) == len(y) and len(x) &gt; 1: sum = 0 for i in range(len(x)): sum += math.pow(abs(x[i] - y[i]), p) return math.pow(sum, 1 / p) else: return 012345678910111213x1 = [1, 1]x2 = [5, 1]x3 = [4, 4]# x1, x2for i in range(1, 5): r = &#123;'1-&#123;&#125;'.format(c): L(x1, c, p=i) for c in [x2, x3]&#125; print(min(zip(r.values(), r.keys()))) # (4.0, '1-[5, 1]')# (4.0, '1-[5, 1]')# (3.7797631496846193, '1-[4, 4]')# (3.5676213450081633, '1-[4, 4]')knn12345678import numpy as npimport pandas as pdimport matplotlib.pyplot as plt%matplotlib inlinefrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom collections import Counter123456# datairis = load_iris()df = pd.DataFrame(iris.data, columns=iris.feature_names)df['label'] = iris.targetdf.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']# data = np.array(df.iloc[:100, [0, 1, -1]])12345plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend()12345data = np.array(df.iloc[:100, [0, 1, -1]])X, y = data[:,:-1], data[:,-1]X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)X_train.shape, X_test.shape, y_train.shape, y_test.shape# ((80, 2), (20, 2), (80,), (20,))123456789101112131415161718192021222324252627282930313233343536373839class KNN: def __init__(self, X_train, y_train, n_neighbors=3, p=2): """ parameter: n_neighbors 临近点个数 parameter: p 距离度量 """ self.n = n_neighbors self.p = p self.X_train = X_train self.y_train = y_train def predict(self, X): # 取出n个点 knn_list = [] for i in range(self.n): dist = np.linalg.norm(X - self.X_train[i], ord=self.p) knn_list.append((dist, self.y_train[i])) for i in range(self.n, len(self.X_train)): max_index = knn_list.index(max(knn_list, key=lambda x: x[0])) dist = np.linalg.norm(X - self.X_train[i], ord=self.p) if knn_list[max_index][0] &gt; dist: knn_list[max_index] = (dist, self.y_train[i]) # 统计 knn = [k[-1] for k in knn_list] count_pairs = Counter(knn) # max_count = sorted(count_pairs, key=lambda x: x)[-1] max_count = sorted(count_pairs.items(), key=lambda x: x[1])[-1][0] return max_count def score(self, X_test, y_test): right_count = 0 n = 10 for X, y in zip(X_test, y_test): label = self.predict(X) if label == y: right_count += 1 return right_count / len(X_test)1clf = KNN(X_train, y_train)12clf.score(X_test, y_test)# 0.95123test_point = [6.0, 3.0]print('Test Point: &#123;&#125;'.format(clf.predict(test_point)))# Test Point: 1.0123456plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')plt.plot(test_point[0], test_point[1], 'bo', label='test_point')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend()scikit-learn1from sklearn.neighbors import KNeighborsClassifier12345clf_sk = KNeighborsClassifier()clf_sk.fit(X_train, y_train)# KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',# metric_params=None, n_jobs=None, n_neighbors=5, p=2,# weights='uniform')12clf_sk.score(X_test, y_test)# 0.95kd树kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd树是二叉树，表示对$k$维空间的一个划分（partition）。构造kd树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的k维超矩形区域。kd树的每个结点对应于一个$k$维超矩形区域。构造kd树的方法如下：构造根结点，使根结点对应于$k$维空间中包含所有实例点的超矩形区域；通过下面的递归方法，不断地对$k$维空间进行切分，生成子结点。在超矩形区域（结点）上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域（子结点）；这时，实例被分到两个子区域。这个过程直到子区域内没有实例时终止（终止时的结点为叶结点）。在此过程中，将实例保存在相应的结点上。通常，依次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数（median）为切分点，这样得到的kd树是平衡的。注意，平衡的kd树搜索时的效率未必是最优的。构造平衡kd树算法输入：$k$维空间数据集$T＝\{x_1，x_2,…,x_N\}$，其中$x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(k)}\right)^{\mathrm{T}}$ ，$i＝1,2,…,N$；输出：kd树。（1）开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。选择$x^{(1)}$为坐标轴，以T中所有实例的$x^{(1)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。由根结点生成深度为1的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域， 右子结点对应于坐标$x^{(1)}$大于切分点的子区域。将落在切分超平面上的实例点保存在根结点。（2）重复：对深度为$j$的结点，选择$x^{(1)}$为切分的坐标轴，$l＝j(modk)+1$，以该结点的区域中所有实例的$x^{(1)}$坐标的中位数为切分点，将该结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。由该结点生成深度为$j+1$的左、右子结点：左子结点对应坐标$x^{(1)}$小于切分点的子区域，右子结点对应坐标$x^{(1)}$大于切分点的子区域。将落在切分超平面上的实例点保存在该结点。（3）直到两个子区域没有实例存在时停止。从而形成kd树的区域划分。1234567891011121314151617181920212223242526272829303132333435363738394041# kd-tree每个结点中主要包含的数据结构如下class KdNode(object): def __init__(self, dom_elt, split, left, right): self.dom_elt = dom_elt # k维向量节点(k维空间中的一个样本点) self.split = split # 整数（进行分割维度的序号） self.left = left # 该结点分割超平面左子空间构成的kd-tree self.right = right # 该结点分割超平面右子空间构成的kd-treeclass KdTree(object): def __init__(self, data): k = len(data[0]) # 数据维度 def CreateNode(split, data_set): # 按第split维划分数据集exset创建KdNode if not data_set: # 数据集为空 return None # key参数的值为一个函数，此函数只有一个参数且返回一个值用来进行比较 # operator模块提供的itemgetter函数用于获取对象的哪些维的数据，参数为需要获取的数据在对象中的序号 #data_set.sort(key=itemgetter(split)) # 按要进行分割的那一维数据排序 data_set.sort(key=lambda x: x[split]) split_pos = len(data_set) // 2 # //为Python中的整数除法 median = data_set[split_pos] # 中位数分割点 split_next = (split + 1) % k # cycle coordinates # 递归的创建kd树 return KdNode( median, split, CreateNode(split_next, data_set[:split_pos]), # 创建左子树 CreateNode(split_next, data_set[split_pos + 1:])) # 创建右子树 self.root = CreateNode(0, data) # 从第0维分量开始构建kd树,返回根节点# KDTree的前序遍历def preorder(root): print(root.dom_elt) if root.left: # 节点不为空 preorder(root.left) if root.right: preorder(root.right)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 对构建好的kd树进行搜索，寻找与目标点最近的样本点：from math import sqrtfrom collections import namedtuple# 定义一个namedtuple,分别存放最近坐标点、最近距离和访问过的节点数result = namedtuple("Result_tuple", "nearest_point nearest_dist nodes_visited")def find_nearest(tree, point): k = len(point) # 数据维度 def travel(kd_node, target, max_dist): if kd_node is None: return result([0] * k, float("inf"), 0) # python中用float("inf")和float("-inf")表示正负无穷 nodes_visited = 1 s = kd_node.split # 进行分割的维度 pivot = kd_node.dom_elt # 进行分割的“轴” if target[s] &lt;= pivot[s]: # 如果目标点第s维小于分割轴的对应值(目标离左子树更近) nearer_node = kd_node.left # 下一个访问节点为左子树根节点 further_node = kd_node.right # 同时记录下右子树 else: # 目标离右子树更近 nearer_node = kd_node.right # 下一个访问节点为右子树根节点 further_node = kd_node.left temp1 = travel(nearer_node, target, max_dist) # 进行遍历找到包含目标点的区域 nearest = temp1.nearest_point # 以此叶结点作为“当前最近点” dist = temp1.nearest_dist # 更新最近距离 nodes_visited += temp1.nodes_visited if dist &lt; max_dist: max_dist = dist # 最近点将在以目标点为球心，max_dist为半径的超球体内 temp_dist = abs(pivot[s] - target[s]) # 第s维上目标点与分割超平面的距离 if max_dist &lt; temp_dist: # 判断超球体是否与超平面相交 return result(nearest, dist, nodes_visited) # 不相交则可以直接返回，不用继续判断 #---------------------------------------------------------------------- # 计算目标点与分割点的欧氏距离 temp_dist = sqrt(sum((p1 - p2)**2 for p1, p2 in zip(pivot, target))) if temp_dist &lt; dist: # 如果“更近” nearest = pivot # 更新最近点 dist = temp_dist # 更新最近距离 max_dist = dist # 更新超球体半径 # 检查另一个子结点对应的区域是否有更近的点 temp2 = travel(further_node, target, max_dist) nodes_visited += temp2.nodes_visited if temp2.nearest_dist &lt; dist: # 如果另一个子结点内存在更近距离 nearest = temp2.nearest_point # 更新最近点 dist = temp2.nearest_dist # 更新最近距离 return result(nearest, dist, nodes_visited) return travel(tree.root, point, float("inf")) # 从根节点开始递归123456789data = [[2,3],[5,4],[9,6],[4,7],[8,1],[7,2]]kd = KdTree(data)preorder(kd.root)# [7, 2]# [5, 4]# [2, 3]# [4, 7]# [9, 6]# [8, 1]12345678910import timefrom random import random# 产生一个k维随机向量，每维分量值在0~1之间def random_point(k): return [random() for _ in range(k)] # 产生n个k维随机向量 def random_points(k, n): return [random_point(k) for _ in range(n)]123ret = find_nearest(kd, [3,4.5])print (ret)# Result_tuple(nearest_point=[2, 3], nearest_dist=1.8027756377319946, nodes_visited=4)123456789N = 400000t0 = time.process_time()kd2 = KdTree(random_points(3, N)) # 构建包含四十万个3维空间样本点的kd树ret2 = find_nearest(kd2, [0.1,0.5,0.8]) # 四十万个样本点中寻找离目标最近的点t1 = time.process_time()print ("time: ",t1-t0, "s")print (ret2)# time: 17.390625 s# Result_tuple(nearest_point=[0.09518737754233697, 0.5083420994683453, 0.8041131259448021], nearest_dist=0.010472333240380263, nodes_visited=81)tensorflow1import tensorflow as tf1234x = tf.placeholder(tf.float32, [None, X_train.shape[1]])y = tf.placeholder(tf.float32, [X_train.shape[1]])# 曼哈顿距离：tf.reduce_sum(tf.abs(tf.subtract(x, y)), reduction_indices=1)dist = tf.reduce_sum(tf.square(x - y), reduction_indices=1)123456789101112131415init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) pred = [] for i in range(X_train.shape[0]): result = sess.run(dist, feed_dict=&#123;x: X_train, y: X_train[i]&#125;) indexs = result.argsort()[:3] ans = np.array([y_train[i] for i in indexs], dtype='int64') prediction = np.array(np.argmax(np.bincount(ans)), dtype='float64') pred.append(prediction == y_train[i]) accuracy = tf.reduce_mean(tf.cast(pred, dtype=tf.float64)) print('accuracy:', sess.run(accuracy))# accuracy: 1.0作业3.1 参照图3.1，在二维空间中给出实例点，画出k为1和2时的k近邻法构成的空间划分，并对其进行比较，体会k值选择与模型复杂度及预测准确率的关系。3.2 利用例题 3.2 构造的$kd$树求点 $x=(3,4.5)^T$ 的最近邻点。答：$(2,3)$3.3 参照算法 3.3，写出输出为 x 的 K 近邻的算法。参考资料https://github.com/fengdu78/lihang-codehttps://blog.csdn.net/qq_35170267/article/details/84205585https://blog.csdn.net/qq_35082030/article/details/60965320]]></content>
      <categories>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二章-感知机]]></title>
    <url>%2F2019%2F09%2F07%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[笔记代码1．感知机是根据输入实例的特征向量$x$对其进行二类分类的线性分类模型：f(x)=\operatorname{sign}(w \cdot x+b)感知机模型对应于输入空间（特征空间）中的分离超平面$w \cdot x+b=0$。2．感知机学习的策略是极小化损失函数：\min _{w, b} L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)损失函数对应于误分类点到分离超平面的总距离。3．感知机学习算法是基于随机梯度下降法的对损失函数的最优化算法，有原始形式和对偶形式。算法简单且易于实现。原始形式中，首先任意选取一个超平面，然后用梯度下降法不断极小化目标函数。在这个过程中一次随机选取一个误分类点使其梯度下降。4．当训练数据集线性可分时，感知机学习算法是收敛的。感知机算法在训练数据集上的误分类次数$k$满足不等式：k \leqslant\left(\frac{R}{\gamma}\right)^{2}当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。二分类模型$f(x) = sign(w\cdot x + b)$$\operatorname{sign}(x)=\left\{\begin{array}{ll}{+1,} &amp; {x \geqslant 0} \\ {-1,} &amp; {x&lt;0}\end{array}\right.$给定训练集：$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$定义感知机的损失函数$L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)$算法随即梯度下降法 Stochastic Gradient Descent随机抽取一个误分类点使其梯度下降。$w = w + \eta y_{i}x_{i}$$b = b + \eta y_{i}$当实例点被误分类，即位于分离超平面的错误侧，则调整$w$, $b$的值，使分离超平面向该无分类点的一侧移动，直至误分类点被正确分类12345import pandas as pdimport numpy as npfrom sklearn.datasets import load_irisimport matplotlib.pyplot as plt%matplotlib inline1234# load datairis = load_iris()df = pd.DataFrame(iris.data, columns=iris.feature_names)df['label'] = iris.target1df.head()1234df.columns = [ &apos;sepal length&apos;, &apos;sepal width&apos;, &apos;petal length&apos;, &apos;petal width&apos;, &apos;label&apos;]df.label.value_counts()123456plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')# plt.scatter(df[100:150]['sepal length'], df[100:150]['sepal width'], label='2')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend()12# 选前两个特征data = np.array(df.iloc[:100, [0, 1, -1]])1X, y = data[:,:-1], data[:,-1]1y = np.array([1 if i == 1 else -1 for i in y])12X.shape, y.shape# ((100, 2), (100,))Perceptron12345678910111213141516171819202122232425262728293031# 数据线性可分，二分类数据# 此处为一元一次线性方程class Model: def __init__(self): self.w = np.ones(len(data[0]) - 1, dtype=np.float32) self.b = 0 self.l_rate = 0.1 # self.data = data def sign(self, x, w, b): y = np.dot(x, w) + b # (100, 2) x (2, ) + (100, ) return y # 随机梯度下降法 def fit(self, X_train, y_train): is_wrong = False while not is_wrong: wrong_count = 0 for d in range(len(X_train)): X = X_train[d] y = y_train[d] if y * self.sign(X, self.w, self.b) &lt;= 0: self.w = self.w + self.l_rate * np.dot(y, X) self.b = self.b + self.l_rate * y wrong_count += 1 if wrong_count == 0: is_wrong = True return 'Perceptron Model!' def score(self): pass123perceptron = Model()perceptron.fit(X, y)# 'Perceptron Model!'123456789x_points = np.linspace(4, 7, 10)y_ = -(perceptron.w[0] * x_points + perceptron.b) / perceptron.w[1]plt.plot(x_points, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend()scikit-learn1from sklearn.linear_model import Perceptron123456clf = Perceptron(fit_intercept=False, max_iter=1000, shuffle=False)clf.fit(X, y)# Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,# fit_intercept=False, max_iter=1000, n_iter=None, n_iter_no_change=5,# n_jobs=None, penalty=None, random_state=0, shuffle=False, tol=None,# validation_fraction=0.1, verbose=0, warm_start=False)12clf.coef_, clf.intercept_# (array([[ 74.6, -127.2]]), array([0.]))123456789x_ponits = np.arange(4, 8)y_ = -(clf.coef_[0][0]*x_ponits + clf.intercept_)/clf.coef_[0][1]plt.plot(x_ponits, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend()作业2.1 Minsky和Papert指出：感知机因为是线性模型，所以不能表示复杂的函数，如异或（XOR），验证感知机为什么不能表示异或。感知机的局限性就在于它只能表示由一条直线分割的空间。2.1 模仿例题 2.1，构建从训练数据求解感知机模型的例子。2.3 证明以下定理：样本集线性可分的充分必要条件是正实例点所构成的凸壳与负实例点所构成的凸壳互不相交。http://www.maoyiwei.top/2018/03/06/lhml/lh-chap-2/#more参考资料https://github.com/fengdu78/lihang-codehttps://blog.csdn.net/wizardforcel/article/details/85057670]]></content>
      <categories>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一章-统计学习及监督学习概论]]></title>
    <url>%2F2019%2F09%2F05%2F%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[笔记代码使用最小二乘法拟和曲线高斯于1823年在误差$e_1,…,e_n$独立同分布的假定下,证明了最小二乘方法的一个最优性质: 在所有无偏的线性估计类中,最小二乘方法是其中方差最小的！对于数据$(x_i, y_i) (i=1, 2, 3…,m)$拟合出函数$h(x)$有误差，即残差：$r_i=h(x_i)-y_i$此时$L2$范数(残差平方和)最小时，$h(x)$ 和 $y$ 相似度最高，更拟合一般的$H(x)$为$n$次的多项式，$H(x)=w_0+w_1x+w_2x^2+…w_nx^n$$w(w_0,w_1,w_2,…,w_n)$为参数最小二乘法就是要找到一组 $w(w_0,w_1,w_2,…,w_n)$ ，使得$\sum \limits_{i=1}^n(h(x_i)-y_i)^2$ (残差平方和) 最小即，求 $min\sum \limits_{i=1}^n(h(x_i)-y_i)^2$举例：我们用目标函数$y=sin2{\pi}x$, 加上一个正态分布的噪音干扰，用多项式去拟合【例1.1 20页】12345import numpy as npimport scipy as spfrom scipy.optimize import leastsqimport matplotlib.pyplot as plt%matplotlib inline12345678910111213# 目标函数def real_func(x): return np.sin(2*np.pi*x)# 多项式def fit_func(p, x): f = np.poly1d(p) return f(x)# 残差def residuals_func(p, x, y): ret = fit_func(p, x) - y return ret123456789101112131415161718192021222324# 十个点x = np.linspace(0, 1, 10)x_points = np.linspace(0, 1, 1000)# 加上正态分布噪音的目标函数的值y_ = real_func(x)y = [np.random.normal(0, 0.1) + y1 for y1 in y_]def fitting(M=0): """ M 为 多项式的次数 """ # 随机初始化多项式参数 p_init = np.random.rand(M + 1) # 最小二乘法 p_lsq = leastsq(residuals_func, p_init, args=(x, y)) print('Fitting Parameters:', p_lsq[0]) # 可视化 plt.plot(x_points, real_func(x_points), label='real') plt.plot(x_points, fit_func(p_lsq[0], x_points), label='fitted curve') plt.plot(x, y, 'bo', label='noise') plt.legend() return p_lsq12# M=0p_lsq_0 = fitting(M=0)12# M=1p_lsq_1 = fitting(M=1)12# M=3p_lsq_3 = fitting(M=3)12# M=9p_lsq_9 = fitting(M=9)正则化结果显示过拟合， 引入正则化项(regularizer)，降低过拟合$Q(x)=\sum \limits_{i=1}^n(h(x_i)-y_i)^2+\lambda||w||_1$。回归问题中，损失函数是平方损失，正则化可以是参数向量的L2范数,也可以是L1范数。L1：$ \lambda||w||_1^2$L2：$ \frac{\lambda}{2}||w||^2$12345678regularization = 0.0001def residuals_func_regularization(p, x, y): ret = fit_func(p, x) - y ret = np.append(ret, np.sqrt(0.5 * regularization * np.square(p))) # L2范数作为正则化项 return ret1234# 最小二乘法,加正则化项p_init = np.random.rand(9 + 1)p_lsq_regularization = leastsq( residuals_func_regularization, p_init, args=(x, y))12345678plt.plot(x_points, real_func(x_points), label='real')plt.plot(x_points, fit_func(p_lsq_9[0], x_points), label='fitted curve')plt.plot( x_points, fit_func(p_lsq_regularization[0], x_points), label='regularization')plt.plot(x, y, 'bo', label='noise')plt.legend()作业1.1说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型n次独立的数据生成结果，其中k次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。定义随机变量$A$为一次伯努利试验的结果，$A$的取值为${0,1}$，概率分布为：$P(A=1)=\theta,P(A=0)=1-\theta$似然函数为：$L(\theta)=\prod \limits_{i=1} ^{n}P(A_i)=\theta^k(1-\theta)^{n-k}$两边取对数并乘以-1得：$-log(L(\theta)) = -\sum\limits_{i=1}^{n}log(P(A_i))=-klog\theta-(n-k)log(1-\theta)$$\theta=arg\max \limits_\theta L(\theta)=arg\min\limits_\theta -logL((\theta))$对$\theta$求导得：$\frac{\partial \;-log(L(\theta))}{\partial \theta} = -\frac{k}{\theta}+\frac{n-k}{1-\theta}$令$-\frac{k}{\theta}+\frac{n-k}{1-\theta}=0$，解得：$\theta=\frac{k}{n}$使用贝叶斯估计：1.2通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。模型是条件概率分布：$P_\theta(Y|X)$损失函数是对数损失函数：$L(Y,P(Y|X))=-logP(Y|X)$经验风险为：$\begin{align} R_{emp}(f)&amp;=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i)) \\ &amp;=\frac{1}{N}\sum_{i=1}^{N}-logP(y_i|x_i) \\ &amp;=-\frac{1}{N}\sum_{i=1}^{N}logP(y_i|x_i) \end{align}$$arg\min-\frac{1}{N}\sum_{i=1}^{N}logP(y_i|x_i) \to arg\max \prod \limits_{i=1}^{N}P(y_i|x_i) $参考资料https://github.com/fengdu78/lihang-code/blob/master/%E7%AC%AC01%E7%AB%A0%20%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/1.Introduction_to_statistical_learning_methods.ipynbhttps://blog.csdn.net/familyshizhouna/article/details/70160782]]></content>
      <categories>
        <category>统计学习方法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（1-4）]]></title>
    <url>%2F2019%2F09%2F01%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[深层神经网络(Deep Neural Networks)深层神经网络（Deep L-layer neural network）深度学习的符号定义：上图是一个四层的神经网络，有三个隐藏层。我们可以看到，第一层（即左边数过去第二层，因为输入层是第0层）有5个神经元数目，第二层5个，第三层3个。我们用L表示层数，上图：$L=4$，输入层的索引为“0”，第一个隐藏层${n}^{[1]}=5$,表示有5个隐藏神经元，同理${n}^{[2]}=5$，${n}^{[3]}=3$，${n^{[4]}}$=${n^{[L]}}=1$（输出单元为1）。而输入层，${n}^{[0]}={n}_{x}=3$。对于第$l$层神经网络，单个样本其各个参数的矩阵维度为：$W^{[l]}:(n^{[l]},n^{[l]})$$b^{[l]}:(n^{[l]},1)$$Z^{[l]}:(n^{[l]},1)$前向传播和反向传播（Forward and backward propagation）前向传播的步骤可以写成： ${z}^{[l]}={W}^{[l]}\cdot{a}^{[l-1]}+{b}^{[l]}$​ ${a^{[l]}}={g^{[l]}}\left( {z^{[l]}}\right)$向量化实现过程可以写成： ${z}^{[l]}={W}^{[l]}\cdot {A}^{[l-1]}+{b}^{[l]}$​ ${A}^{[l]}={g}^{[l]}({Z}^{[l]})$前向传播需要喂入${A}^{[0]}$也就是$X$，来初始化；初始化的是第一层的输入值。${a}^{[0]}$对应于一个训练样本的输入特征，而${A^{[0]}}$对应于一整个训练样本的输入特征，所以这就是这条链的第一个前向函数的输入，重复这个步骤就可以从左到右计算前向传播。反向传播的步骤：输入为${da}^{[l]}$，输出为${da}^{[l-1]}$，${dw}^{[l]}$, ${db}^{[l]}$（1）$d{z^{[l]}}=d{a^{[l]}}*{g^{[l]}}’( {z^{[l]}})$（2）$d{w^{[l]}}=d{z^{[l]}}\cdot{a^{[l-1]}}~$（3）$d{b}^{[l]}=d{z^{[l]}}~~$（4）$d{a^{[l-1]}}={w^{\left[ l \right]T}}\cdot {dz^{[l]}}$（5）$d{z^{[l]}}={w^{[l+1]T}}d{z^{[l+1]}}\cdot \text{ }{g^{[l]}}’( {z^{[l]}})~$式子（5）由式子（4）带入式子（1）得到，前四个式子就可实现反向函数。向量化实现过程可以写成：（6）$d{Z}^{[l]}=d{A^{[l]}}*{g^{\left[ l \right]}}’\left({Z^{[l]}} \right)~~$（7）$d{W}^{[l]}=\frac{1}{m}\text{}d{Z^{[l]}}\cdot {A^{\left[ l-1 \right]T}}$（8）$d{b^{[l]}}=\frac{1}{m}\text{ }np.sum(d{z^{[l]}},axis=1,keepdims=True)$（9）$d{A^{[l-1]}}={W^{\left[ l \right]T}}.d{Z^{[l]}}$为什么使用深层表示？（Why deep representations?）人脸识别和语音识别电路逻辑运算参数VS超参数（Parameters vs Hyperparameters）什么是超参数？比如算法中的learning rate $a$（学习率）、iterations(梯度下降法循环的数量)、$L$（隐藏层数目）、${n^{[l]}}$（隐藏层单元数目）、choice of activation function（激活函数的选择）都需要你来设置，这些数字实际上控制了最后的参数$W$和$b$的值，所以它们被称作超参数。实际上深度学习有很多不同的超参数，之后我们也会介绍一些其他的超参数，如momentum、mini batch size、regularization parameters等等。作业：Building your Deep Neural Network: Step by Step1 - PackagesLet’s first import all the packages that you will need during this assignment.numpy is the main package for scientific computing with Python.matplotlib is a library to plot graphs in Python.dnn_utils provides some necessary functions for this notebook.testCases provides some test cases to assess the correctness of your functionsnp.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please don’t change the seed.123456789101112131415import numpy as npimport h5pyimport matplotlib.pyplot as pltfrom testCases_v4 import *from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward%matplotlib inlineplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'%load_ext autoreload%autoreload 2np.random.seed(1)2 - Outline of the AssignmentTo build your neural network, you will be implementing several “helper functions”. These helper functions will be used in the next assignment to build a two-layer neural network and an L-layer neural network. Each small helper function you will implement will have detailed instructions that will walk you through the necessary steps. Here is an outline of this assignment, you will:Initialize the parameters for a two-layer network and for an $L$-layer neural network.Implement the forward propagation module (shown in purple in the figure below).Complete the LINEAR part of a layer’s forward propagation step (resulting in $Z^{[l]}$).We give you the ACTIVATION function (relu/sigmoid).Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] forward function.Stack the [LINEAR-&gt;RELU] forward function L-1 time (for layers 1 through L-1) and add a [LINEAR-&gt;SIGMOID] at the end (for the final layer $L$). This gives you a new L_model_forward function.Compute the loss.Implement the backward propagation module (denoted in red in the figure below).Complete the LINEAR part of a layer’s backward propagation step.We give you the gradient of the ACTIVATE function (relu_backward/sigmoid_backward)Combine the previous two steps into a new [LINEAR-&gt;ACTIVATION] backward function.Stack [LINEAR-&gt;RELU] backward L-1 times and add [LINEAR-&gt;SIGMOID] backward in a new L_model_backward functionFinally update the parameters.Note that for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backpropagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps.3 - InitializationYou will write two helper functions that will initialize the parameters for your model. The first function will be used to initialize parameters for a two layer model. The second one will generalize this initialization process to $L$ layers.3.1 - 2-layer Neural NetworkExercise: Create and initialize the parameters of the 2-layer neural network.Instructions:The model’s structure is: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.Use random initialization for the weight matrices. Use np.random.randn(shape)*0.01 with the correct shape.Use zero initialization for the biases. Use np.zeros(shape).12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: initialize_parametersdef initialize_parameters(n_x, n_h, n_y): """ Argument: n_x -- size of the input layer n_h -- size of the hidden layer n_y -- size of the output layer Returns: parameters -- python dictionary containing your parameters: W1 -- weight matrix of shape (n_h, n_x) b1 -- bias vector of shape (n_h, 1) W2 -- weight matrix of shape (n_y, n_h) b2 -- bias vector of shape (n_y, 1) """ np.random.seed(1) ### START CODE HERE ### (≈ 4 lines of code) W1 = np.random.randn(n_h, n_x) * 0.01 b1 = np.zeros((n_h, 1)) W2 = np.random.randn(n_y, n_h) * 0.01 b2 = np.zeros((n_y, 1)) ### END CODE HERE ### assert(W1.shape == (n_h, n_x)) assert(b1.shape == (n_h, 1)) assert(W2.shape == (n_y, n_h)) assert(b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters12345parameters = initialize_parameters(3,2,1)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))123456W1 = [[ 0.01624345 -0.00611756 -0.00528172] [-0.01072969 0.00865408 -0.02301539]]b1 = [[ 0.] [ 0.]]W2 = [[ 0.01744812 -0.00761207]]b2 = [[ 0.]]3.2 - L-layer Neural NetworkThe initialization for a deeper L-layer neural network is more complicated because there are many more weight matrices and bias vectors. When completing the initialize_parameters_deep, you should make sure that your dimensions match between each layer. Recall that $n^{[l]}$ is the number of units in layer $l$. Thus for example if the size of our input $X$ is $(12288, 209)$ (with $m=209$ examples) then:Remember that when we compute $W X + b$ in python, it carries out broadcasting. For example, if:W = \begin{bmatrix} j & k & l\\ m & n & o \\ p & q & r \end{bmatrix}\;\;\; X = \begin{bmatrix} a & b & c\\ d & e & f \\ g & h & i \end{bmatrix} \;\;\; b =\begin{bmatrix} s \\ t \\ u \end{bmatrix}\tag{2}Then $WX + b$ will be:WX + b = \begin{bmatrix} (ja + kd + lg) + s & (jb + ke + lh) + s & (jc + kf + li)+ s\\ (ma + nd + og) + t & (mb + ne + oh) + t & (mc + nf + oi) + t\\ (pa + qd + rg) + u & (pb + qe + rh) + u & (pc + qf + ri)+ u \end{bmatrix}\tag{3}Exercise: Implement initialization for an L-layer Neural Network.Instructions:The model’s structure is [LINEAR -&gt; RELU] $ \times$ (L-1) -&gt; LINEAR -&gt; SIGMOID. I.e., it has $L-1$ layers using a ReLU activation function followed by an output layer with a sigmoid activation function.Use random initialization for the weight matrices. Use np.random.randn(shape) * 0.01.Use zeros initialization for the biases. Use np.zeros(shape).We will store $n^{[l]}$, the number of units in different layers, in a variable layer_dims. For example, the layer_dims for the “Planar Data classification model” from last week would have been [2,4,1]: There were two inputs, one hidden layer with 4 hidden units, and an output layer with 1 output unit. This means W1‘s shape was (4,2), b1 was (4,1), W2 was (1,4) and b2 was (1,1). Now you will generalize this to $L$ layers!Here is the implementation for $L=1$ (one layer neural network). It should inspire you to implement the general case (L-layer neural network).123if L == 1: parameters["W" + str(L)] = np.random.randn(layer_dims[1], layer_dims[0]) * 0.01 parameters["b" + str(L)] = np.zeros((layer_dims[1], 1))12345678910111213141516171819202122232425262728# GRADED FUNCTION: initialize_parameters_deepdef initialize_parameters_deep(layer_dims): """ Arguments: layer_dims -- python array (list) containing the dimensions of each layer in our network Returns: parameters -- python dictionary containing your parameters "W1", "b1", ..., "WL", "bL": Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1]) bl -- bias vector of shape (layer_dims[l], 1) """ np.random.seed(3) parameters = &#123;&#125; L = len(layer_dims) # number of layers in the network for l in range(1, L): ### START CODE HERE ### (≈ 2 lines of code) parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01 parameters['b' + str(l)] = np.zeros((layer_dims[l], 1)) ### END CODE HERE ### assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1])) assert(parameters['b' + str(l)].shape == (layer_dims[l], 1)) return parameters12345parameters = initialize_parameters_deep([5,4,3])print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))1234567891011121314W1 = [[ 0.01788628 0.0043651 0.00096497 -0.01863493 -0.00277388] [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218] [-0.01313865 0.00884622 0.00881318 0.01709573 0.00050034] [-0.00404677 -0.0054536 -0.01546477 0.00982367 -0.01101068]]b1 = [[ 0.] [ 0.] [ 0.] [ 0.]]W2 = [[-0.01185047 -0.0020565 0.01486148 0.00236716] [-0.01023785 -0.00712993 0.00625245 -0.00160513] [-0.00768836 -0.00230031 0.00745056 0.01976111]]b2 = [[ 0.] [ 0.] [ 0.]]4 - Forward propagation module4.1 - Linear ForwardNow that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order:LINEARLINEAR -&gt; ACTIVATION where ACTIVATION will be either ReLU or Sigmoid.[LINEAR -&gt; RELU] $\times$ (L-1) -&gt; LINEAR -&gt; SIGMOID (whole model)The linear forward module (vectorized over all the examples) computes the following equations:Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\tag{4}where $A^{[0]} = X$.Exercise: Build the linear part of forward propagation.Reminder:The mathematical representation of this unit is $Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$. You may also find np.dot() useful. If your dimensions don’t match, printing W.shape may help.123456789101112131415161718192021222324# GRADED FUNCTION: linear_forwarddef linear_forward(A, W, b): """ Implement the linear part of a layer's forward propagation. Arguments: A -- activations from previous layer (or input data): (size of previous layer, number of examples) W -- weights matrix: numpy array of shape (size of current layer, size of previous layer) b -- bias vector, numpy array of shape (size of the current layer, 1) Returns: Z -- the input of the activation function, also called pre-activation parameter cache -- a python tuple containing "A", "W" and "b" ; stored for computing the backward pass efficiently """ ### START CODE HERE ### (≈ 1 line of code) Z = np.dot(W, A) + b ### END CODE HERE ### assert(Z.shape == (W.shape[0], A.shape[1])) cache = (A, W, b) return Z, cache12345A, W, b = linear_forward_test_case()Z, linear_cache = linear_forward(A, W, b)print("Z = " + str(Z))# Z = [[ 3.26295337 -1.23429987]]4.2 - Linear-Activation ForwardIn this notebook, you will use two activation functions:Sigmoid: $\sigma(Z) = \sigma(W A + b) = \frac{1}{ 1 + e^{-(W A + b)}}$. We have provided you with the sigmoid function. This function returns two items: the activation value “a“ and a “cache“ that contains “Z“ (it’s what we will feed in to the corresponding backward function). To use it you could just call:A, activation_cache = sigmoid(Z)ReLU: The mathematical formula for ReLu is $A = RELU(Z) = max(0, Z)$. We have provided you with the relu function. This function returns two items: the activation value “A“ and a “cache“ that contains “Z“ (it’s what we will feed in to the corresponding backward function). To use it you could just call:A, activation_cache = relu(Z)For more convenience, you are going to group two functions (Linear and Activation) into one function (LINEAR-&gt;ACTIVATION). Hence, you will implement a function that does the LINEAR forward step followed by an ACTIVATION forward step.Exercise: Implement the forward propagation of the LINEAR-&gt;ACTIVATION layer. Mathematical relation is: $A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$ where the activation “g” can be sigmoid() or relu(). Use linear_forward() and the correct activation function.123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: linear_activation_forwarddef linear_activation_forward(A_prev, W, b, activation): """ Implement the forward propagation for the LINEAR-&gt;ACTIVATION layer Arguments: A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples) W -- weights matrix: numpy array of shape (size of current layer, size of previous layer) b -- bias vector, numpy array of shape (size of the current layer, 1) activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: A -- the output of the activation function, also called the post-activation value cache -- a python tuple containing "linear_cache" and "activation_cache"; stored for computing the backward pass efficiently """ if activation == "sigmoid": # Inputs: "A_prev, W, b". Outputs: "A, activation_cache". ### START CODE HERE ### (≈ 2 lines of code) Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = sigmoid(Z) ### END CODE HERE ### elif activation == "relu": # Inputs: "A_prev, W, b". Outputs: "A, activation_cache". ### START CODE HERE ### (≈ 2 lines of code) Z, linear_cache = linear_forward(A_prev, W, b) A, activation_cache = relu(Z) ### END CODE HERE ### assert (A.shape == (W.shape[0], A_prev.shape[1])) cache = (linear_cache, activation_cache) return A, cache12345678910A_prev, W, b = linear_activation_forward_test_case()A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = "sigmoid")print("With sigmoid: A = " + str(A))A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = "relu")print("With ReLU: A = " + str(A))# With sigmoid: A = [[ 0.96890023 0.11013289]]# With ReLU: A = [[ 3.43896131 0. ]]Note: In deep learning, the “[LINEAR-&gt;ACTIVATION]” computation is counted as a single layer in the neural network, not two layers.d) L-Layer ModelFor even more convenience when implementing the $L$-layer Neural Net, you will need a function that replicates the previous one (linear_activation_forward with RELU) $L-1$ times, then follows that with one linear_activation_forward with SIGMOID.Exercise: Implement the forward propagation of the above model.Instruction: In the code below, the variable AL will denote $A^{[L]} = \sigma(Z^{[L]}) = \sigma(W^{[L]} A^{[L-1]} + b^{[L]})$. (This is sometimes also called Yhat, i.e., this is $\hat{Y}$.)Tips:Use the functions you had previously writtenUse a for loop to replicate [LINEAR-&gt;RELU] (L-1) timesDon’t forget to keep track of the caches in the “caches” list. To add a new value c to a list, you can use list.append(c).12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: L_model_forwarddef L_model_forward(X, parameters): """ Implement forward propagation for the [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID computation Arguments: X -- data, numpy array of shape (input size, number of examples) parameters -- output of initialize_parameters_deep() Returns: AL -- last post-activation value caches -- list of caches containing: every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1) """ caches = [] A = X L = len(parameters) // 2 # number of layers in the neural network # Implement [LINEAR -&gt; RELU]*(L-1). Add "cache" to the "caches" list. for l in range(1, L): A_prev = A ### START CODE HERE ### (≈ 2 lines of code) A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], "relu") caches.append(cache) ### END CODE HERE ### # Implement LINEAR -&gt; SIGMOID. Add "cache" to the "caches" list. ### START CODE HERE ### (≈ 2 lines of code) AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], "sigmoid") caches.append(cache) ### END CODE HERE ### assert(AL.shape == (1,X.shape[1])) return AL, caches123456X, parameters = L_model_forward_test_case_2hidden()AL, caches = L_model_forward(X, parameters)print("AL = " + str(AL))print("Length of caches list = " + str(len(caches)))# AL = [[ 0.03921668 0.70498921 0.19734387 0.04728177]]# Length of caches list = 3Great! Now you have a full forward propagation that takes the input X and outputs a row vector $A^{[L]}$ containing your predictions. It also records all intermediate values in “caches”. Using $A^{[L]}$, you can compute the cost of your predictions.5 - Cost functionNow you will implement forward and backward propagation. You need to compute the cost, because you want to check if your model is actually learning.Exercise: Compute the cross-entropy cost $J$, using the following formula:-\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(a^{[L] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right)) \tag{7}12345678910111213141516171819202122232425# GRADED FUNCTION: compute_costdef compute_cost(AL, Y): """ Implement the cost function defined by equation (7). Arguments: AL -- probability vector corresponding to your label predictions, shape (1, number of examples) Y -- true "label" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples) Returns: cost -- cross-entropy cost """ m = Y.shape[1] # Compute loss from aL and y. ### START CODE HERE ### (≈ 1 lines of code) cost = -np.sum(np.multiply(np.log(AL),Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m ### END CODE HERE ### cost = np.squeeze(cost) # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17). assert(cost.shape == ()) return cost1234Y, AL = compute_cost_test_case()print("cost = " + str(compute_cost(AL, Y)))# cost = 0.4149315996156 - Backward propagation moduleJust like with forward propagation, you will implement helper functions for backpropagation. Remember that back propagation is used to calculate the gradient of the loss function with respect to the parameters.Reminder:Now, similar to forward propagation, you are going to build the backward propagation in three steps:LINEAR backwardLINEAR -&gt; ACTIVATION backward where ACTIVATION computes the derivative of either the ReLU or sigmoid activation[LINEAR -&gt; RELU] $\times$ (L-1) -&gt; LINEAR -&gt; SIGMOID backward (whole model)6.1 - Linear backwardFor layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).Suppose you have already calculated the derivative $dZ^{[l]} = \frac{\partial \mathcal{L} }{\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$.The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ are computed using the input $dZ^{[l]}$.Here are the formulas you need:dW^{[l]} = \frac{\partial \mathcal{J} }{\partial W^{[l]}} = \frac{1}{m} dZ^{[l]} A^{[l-1] T}db^{[l]} = \frac{\partial \mathcal{J} }{\partial b^{[l]}} = \frac{1}{m} \sum_{i = 1}^{m} dZ^{[l](i)}dA^{[l-1]} = \frac{\partial \mathcal{L} }{\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}Exercise: Use the 3 formulas above to implement linear_backward().1234567891011121314151617181920212223242526272829# GRADED FUNCTION: linear_backwarddef linear_backward(dZ, cache): """ Implement the linear portion of backward propagation for a single layer (layer l) Arguments: dZ -- Gradient of the cost with respect to the linear output (of current layer l) cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer Returns: dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev dW -- Gradient of the cost with respect to W (current layer l), same shape as W db -- Gradient of the cost with respect to b (current layer l), same shape as b """ A_prev, W, b = cache m = A_prev.shape[1] ### START CODE HERE ### (≈ 3 lines of code) dW = np.dot(dZ, A_prev.T) / m db = np.sum(dZ, axis=1, keepdims=True) / m dA_prev = np.dot(W.T, dZ) ### END CODE HERE ### assert (dA_prev.shape == A_prev.shape) assert (dW.shape == W.shape) assert (db.shape == b.shape) return dA_prev, dW, db1234567# Set up some test inputsdZ, linear_cache = linear_backward_test_case()dA_prev, dW, db = linear_backward(dZ, linear_cache)print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db))12345dA_prev = [[ 0.51822968 -0.19517421] [-0.40506361 0.15255393] [ 2.37496825 -0.89445391]]dW = [[-0.10076895 1.40685096 1.64992505]]db = [[ 0.50629448]]6.2 - Linear-Activation backwardNext, you will create a function that merges the two helper functions: linear_backward and the backward step for the activation linear_activation_backward.To help you implement linear_activation_backward, we provided two backward functions:sigmoid_backward: Implements the backward propagation for SIGMOID unit. You can call it as follows:1dZ = sigmoid_backward(dA, activation_cache)relu_backward: Implements the backward propagation for RELU unit. You can call it as follows:1dZ = relu_backward(dA, activation_cache)If $g(.)$ is the activation function,sigmoid_backward and relu_backward computedZ^{[l]} = dA^{[l]} * g'(Z^{[l]}).Exercise: Implement the backpropagation for the LINEAR-&gt;ACTIVATION layer.12345678910111213141516171819202122232425262728293031# GRADED FUNCTION: linear_activation_backwarddef linear_activation_backward(dA, cache, activation): """ Implement the backward propagation for the LINEAR-&gt;ACTIVATION layer. Arguments: dA -- post-activation gradient for current layer l cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently activation -- the activation to be used in this layer, stored as a text string: "sigmoid" or "relu" Returns: dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev dW -- Gradient of the cost with respect to W (current layer l), same shape as W db -- Gradient of the cost with respect to b (current layer l), same shape as b """ linear_cache, activation_cache = cache if activation == "relu": ### START CODE HERE ### (≈ 2 lines of code) dZ = relu_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) ### END CODE HERE ### elif activation == "sigmoid": ### START CODE HERE ### (≈ 2 lines of code) dZ = sigmoid_backward(dA, activation_cache) dA_prev, dW, db = linear_backward(dZ, linear_cache) ### END CODE HERE ### return dA_prev, dW, db12345678910111213dAL, linear_activation_cache = linear_activation_backward_test_case()dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = "sigmoid")print ("sigmoid:")print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db) + "\n")dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = "relu")print ("relu:")print ("dA_prev = "+ str(dA_prev))print ("dW = " + str(dW))print ("db = " + str(db))12345678910111213sigmoid:dA_prev = [[ 0.11017994 0.01105339] [ 0.09466817 0.00949723] [-0.05743092 -0.00576154]]dW = [[ 0.10266786 0.09778551 -0.01968084]]db = [[-0.05729622]]relu:dA_prev = [[ 0.44090989 -0. ] [ 0.37883606 -0. ] [-0.2298228 0. ]]dW = [[ 0.44513824 0.37371418 -0.10478989]]db = [[-0.20837892]]6.3 - L-Model BackwardNow you will implement the backward function for the whole network. Recall that when you implemented the L_model_forward function, at each iteration, you stored a cache which contains (X,W,b, and z). In the back propagation module, you will use those variables to compute the gradients. Therefore, in the L_model_backward function, you will iterate through all the hidden layers backward, starting from layer $L$. On each step, you will use the cached values for layer $l$ to backpropagate through layer $l$. Figure 5 below shows the backward pass.Initializing backpropagation:To backpropagate through this network, we know that the output is,$A^{[L]} = \sigma(Z^{[L]})$. Your code thus needs to compute dAL $= \frac{\partial \mathcal{L}}{\partial A^{[L]}}$.To do so, use this formula (derived using calculus which you don’t need in-depth knowledge of):1dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to ALYou can then use this post-activation gradient dAL to keep going backward. As seen in Figure 5, you can now feed in dAL into the LINEAR-&gt;SIGMOID backward function you implemented (which will use the cached values stored by the L_model_forward function). After that, you will have to use a for loop to iterate through all the other layers using the LINEAR-&gt;RELU backward function. You should store each dA, dW, and db in the grads dictionary. To do so, use this formula :grads[" dW" + str(l)] = dW^{[l]}For example, for $l=3$ this would store $dW^{[l]}$ in grads[&quot;dW3&quot;].Exercise: Implement backpropagation for the [LINEAR-&gt;RELU] $\times$ (L-1) -&gt; LINEAR -&gt; SIGMOID model.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# GRADED FUNCTION: L_model_backwarddef L_model_backward(AL, Y, caches): """ Implement the backward propagation for the [LINEAR-&gt;RELU] * (L-1) -&gt; LINEAR -&gt; SIGMOID group Arguments: AL -- probability vector, output of the forward propagation (L_model_forward()) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) caches -- list of caches containing: every cache of linear_activation_forward() with "relu" (it's caches[l], for l in range(L-1) i.e l = 0...L-2) the cache of linear_activation_forward() with "sigmoid" (it's caches[L-1]) Returns: grads -- A dictionary with the gradients grads["dA" + str(l)] = ... grads["dW" + str(l)] = ... grads["db" + str(l)] = ... """ grads = &#123;&#125; L = len(caches) # the number of layers m = AL.shape[1] Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL # Initializing the backpropagation ### START CODE HERE ### (1 line of code) dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) ### END CODE HERE ### # Lth layer (SIGMOID -&gt; LINEAR) gradients. Inputs: "dAL, current_cache". Outputs: "grads["dAL-1"], grads["dWL"], grads["dbL"] ### START CODE HERE ### (approx. 2 lines) current_cache = caches[L-1] grads["dA" + str(L-1)], grads["dW" + str(L)], grads["db" + str(L)] = linear_activation_backward(dAL, current_cache, "sigmoid") ### END CODE HERE ### # Loop from l=L-2 to l=0 for l in reversed(range(L-1)): # lth layer: (RELU -&gt; LINEAR) gradients. # Inputs: "grads["dA" + str(l + 1)], current_cache". Outputs: "grads["dA" + str(l)] , grads["dW" + str(l + 1)] , grads["db" + str(l + 1)] ### START CODE HERE ### (approx. 5 lines) current_cache = caches[l] dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads["dA" + str(l + 1)], current_cache, "relu") grads["dA" + str(l)] = dA_prev_temp grads["dW" + str(l + 1)] = dW_temp grads["db" + str(l + 1)] = db_temp ### END CODE HERE ### return grads123AL, Y_assess, caches = L_model_backward_test_case()grads = L_model_backward(AL, Y_assess, caches)print_grads(grads)123456789dW1 = [[ 0.41010002 0.07807203 0.13798444 0.10502167] [ 0. 0. 0. 0. ] [ 0.05283652 0.01005865 0.01777766 0.0135308 ]]db1 = [[-0.22007063] [ 0. ] [-0.02835349]]dA1 = [[ 0.12913162 -0.44014127] [-0.14175655 0.48317296] [ 0.01663708 -0.05670698]]6.4 - Update ParametersIn this section you will update the parameters of the model, using gradient descent:W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]}b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]}where $\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary.Exercise: Implement update_parameters() to update your parameters using gradient descent.Instructions:Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for $l = 1, 2, …, L$.12345678910111213141516171819202122232425# GRADED FUNCTION: update_parametersdef update_parameters(parameters, grads, learning_rate): """ Update parameters using gradient descent Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients, output of L_model_backward Returns: parameters -- python dictionary containing your updated parameters parameters["W" + str(l)] = ... parameters["b" + str(l)] = ... """ L = len(parameters) // 2 # number of layers in the neural network # Update rule for each parameter. Use a for loop. ### START CODE HERE ### (≈ 3 lines of code) for l in range(L): parameters["W" + str(l+1)] -= learning_rate * grads["dW" + str(l+1)] parameters["b" + str(l+1)] -= learning_rate * grads["db" + str(l+1)] ### END CODE HERE ### return parameters1234567parameters, grads = update_parameters_test_case()parameters = update_parameters(parameters, grads, 0.1)print ("W1 = "+ str(parameters["W1"]))print ("b1 = "+ str(parameters["b1"]))print ("W2 = "+ str(parameters["W2"]))print ("b2 = "+ str(parameters["b2"]))12345678W1 = [[-0.59562069 -0.09991781 -2.14584584 1.82662008] [-1.76569676 -0.80627147 0.51115557 -1.18258802] [-1.0535704 -0.86128581 0.68284052 2.20374577]]b1 = [[-0.04659241] [-1.28888275] [ 0.53405496]]W2 = [[-0.55569196 0.0354055 1.32964895]]b2 = [[-0.84610769]]7 - ConclusionCongrats on implementing all the functions required for building a deep neural network!We know it was a long assignment but going forward it will only get better. The next part of the assignment is easier.In the next assignment you will put all these together to build two models:A two-layer neural networkAn L-layer neural networkYou will in fact use these models to classify cat vs non-cat images!Deep Neural Network for Image Classification: Application1 - PackagesLet’s first import all the packages that you will need during this assignment.numpy is the fundamental package for scientific computing with Python.matplotlib is a library to plot graphs in Python.h5py is a common package to interact with a dataset that is stored on an H5 file.PIL and scipy are used here to test your model with your own picture at the end.dnn_app_utils provides the functions implemented in the “Building your Deep Neural Network: Step by Step” assignment to this notebook.np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.123456789101112131415161718import timeimport numpy as npimport h5pyimport matplotlib.pyplot as pltimport scipyfrom PIL import Imagefrom scipy import ndimagefrom dnn_app_utils_v3 import *%matplotlib inlineplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plotsplt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'%load_ext autoreload%autoreload 2np.random.seed(1)2 - DatasetYou will use the same “Cat vs non-Cat” dataset as in “Logistic Regression as a Neural Network” (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!Problem Statement: You are given a dataset (“data.h5”) containing:- a training set of m_train images labelled as cat (1) or non-cat (0) - a test set of m_test images labelled as cat and non-cat - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Let’s get more familiar with the dataset. Load the data by running the cell below.1train_x_orig, train_y, test_x_orig, test_y, classes = load_data()The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images.1234# Example of a pictureindex = 10plt.imshow(train_x_orig[index])print ("y = " + str(train_y[0,index]) + ". It's a " + classes[train_y[0,index]].decode("utf-8") + " picture.")123456789101112# Explore your dataset m_train = train_x_orig.shape[0]num_px = train_x_orig.shape[1]m_test = test_x_orig.shape[0]print ("Number of training examples: " + str(m_train))print ("Number of testing examples: " + str(m_test))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_x_orig shape: " + str(train_x_orig.shape))print ("train_y shape: " + str(train_y.shape))print ("test_x_orig shape: " + str(test_x_orig.shape))print ("test_y shape: " + str(test_y.shape))1234567Number of training examples: 209Number of testing examples: 50Each image is of size: (64, 64, 3)train_x_orig shape: (209, 64, 64, 3)train_y shape: (1, 209)test_x_orig shape: (50, 64, 64, 3)test_y shape: (1, 50)As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.12345678910111213# Reshape the training and test examples train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T # The "-1" makes reshape flatten the remaining dimensionstest_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T# Standardize data to have feature values between 0 and 1.train_x = train_x_flatten/255.test_x = test_x_flatten/255.print ("train_x's shape: " + str(train_x.shape))print ("test_x's shape: " + str(test_x.shape))# train_x's shape: (12288, 209)# test_x's shape: (12288, 50)$12,288$ equals $64 \times 64 \times 3$ which is the size of one reshaped image vector.3 - Architecture of your modelNow that you are familiar with the dataset, it is time to build a deep neural network to distinguish cat images from non-cat images.You will build two different models:A 2-layer neural networkAn L-layer deep neural networkYou will then compare the performance of these models, and also try out different values for $L$.Let’s look at the two architectures.3.1 - 2-layer neural networkDetailed Architecture of figure 2:The input is a (64,64,3) image which is flattened to a vector of size $(12288,1)$.The corresponding vector: $[x_0,x_1,…,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]}, 12288)$.You then add a bias term and take its relu to get the following vector: $[a_0^{[1]}, a_1^{[1]},…, a_{n^{[1]}-1}^{[1]}]^T$.You then repeat the same process.You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias).Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat.3.2 - L-layer deep neural networkIt is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation:Detailed Architecture of figure 3:The input is a (64,64,3) image which is flattened to a vector of size (12288,1).The corresponding vector: $[x_0,x_1,…,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[1]}$. The result is called the linear unit.Next, you take the relu of the linear unit. This process could be repeated several times for each $(W^{[l]}, b^{[l]})$ depending on the model architecture.Finally, you take the sigmoid of the final linear unit. If it is greater than 0.5, you classify it to be a cat.3.3 - General methodologyAs usual you will follow the Deep Learning methodology to build the model:1. Initialize parameters / Define hyperparameters 2. Loop for num_iterations: a. Forward propagation b. Compute cost function c. Backward propagation d. Update parameters (using parameters, and grads from backprop) 4. Use trained parameters to predict labels Let’s now implement those two models!4 - Two-layer neural networkQuestion: Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. The functions you may need and their inputs are:123456789101112131415def initialize_parameters(n_x, n_h, n_y): ... return parameters def linear_activation_forward(A_prev, W, b, activation): ... return A, cachedef compute_cost(AL, Y): ... return costdef linear_activation_backward(dA, cache, activation): ... return dA_prev, dW, dbdef update_parameters(parameters, grads, learning_rate): ... return parameters12345### CONSTANTS DEFINING THE MODEL ####n_x = 12288 # num_px * num_px * 3n_h = 7n_y = 1layers_dims = (n_x, n_h, n_y)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091# GRADED FUNCTION: two_layer_modeldef two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False): """ Implements a two-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- input data, of shape (n_x, number of examples) Y -- true "label" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples) layers_dims -- dimensions of the layers (n_x, n_h, n_y) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- If set to True, this will print the cost every 100 iterations Returns: parameters -- a dictionary containing W1, W2, b1, and b2 """ np.random.seed(1) grads = &#123;&#125; costs = [] # to keep track of the cost m = X.shape[1] # number of examples (n_x, n_h, n_y) = layers_dims # Initialize parameters dictionary, by calling one of the functions you'd previously implemented ### START CODE HERE ### (≈ 1 line of code) parameters = initialize_parameters(n_x, n_h, n_y) ### END CODE HERE ### # Get W1, b1, W2 and b2 from the dictionary parameters. W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID. Inputs: "X, W1, b1, W2, b2". Output: "A1, cache1, A2, cache2". ### START CODE HERE ### (≈ 2 lines of code) A1, cache1 = linear_activation_forward(X, W1, b1, activation="relu") A2, cache2 = linear_activation_forward(A1, W2, b2, activation="sigmoid") ### END CODE HERE ### # Compute cost ### START CODE HERE ### (≈ 1 line of code) cost = compute_cost(A2, Y) ### END CODE HERE ### # Initializing backward propagation dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2)) # Backward propagation. Inputs: "dA2, cache2, cache1". Outputs: "dA1, dW2, db2; also dA0 (not used), dW1, db1". ### START CODE HERE ### (≈ 2 lines of code) dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation="sigmoid") dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation="relu") ### END CODE HERE ### # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2 grads['dW1'] = dW1 grads['db1'] = db1 grads['dW2'] = dW2 grads['db2'] = db2 # Update parameters. ### START CODE HERE ### (approx. 1 line of code) parameters = update_parameters(parameters, grads, learning_rate) ### END CODE HERE ### # Retrieve W1, b1, W2, b2 from parameters W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] # Print the cost every 100 training example if print_cost and i % 100 == 0: print("Cost after iteration &#123;&#125;: &#123;&#125;".format(i, np.squeeze(cost))) if print_cost and i % 100 == 0: costs.append(cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel('cost') plt.xlabel('iterations (per hundreds)') plt.title("Learning rate =" + str(learning_rate)) plt.show() return parametersRun the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Check if the “Cost after iteration 0” matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error.1parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)12345678910111213141516171819202122232425Cost after iteration 0: 0.6930497356599888Cost after iteration 100: 0.6464320953428849Cost after iteration 200: 0.6325140647912677Cost after iteration 300: 0.6015024920354665Cost after iteration 400: 0.5601966311605747Cost after iteration 500: 0.515830477276473Cost after iteration 600: 0.4754901313943325Cost after iteration 700: 0.4339163151225749Cost after iteration 800: 0.4007977536203887Cost after iteration 900: 0.3580705011323798Cost after iteration 1000: 0.3394281538366412Cost after iteration 1100: 0.3052753636196264Cost after iteration 1200: 0.27491377282130164Cost after iteration 1300: 0.24681768210614846Cost after iteration 1400: 0.19850735037466116Cost after iteration 1500: 0.1744831811255664Cost after iteration 1600: 0.17080762978096148Cost after iteration 1700: 0.11306524562164734Cost after iteration 1800: 0.09629426845937152Cost after iteration 1900: 0.08342617959726863Cost after iteration 2000: 0.07439078704319081Cost after iteration 2100: 0.0663074813226793Cost after iteration 2200: 0.0591932950103817Cost after iteration 2300: 0.053361403485605585Cost after iteration 2400: 0.04855478562877016Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this.Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below.12predictions_train = predict(train_x, train_y, parameters)# Accuracy: 1.012predictions_test = predict(test_x, test_y, parameters)# Accuracy: 0.72Note: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called “early stopping” and we will talk about it in the next course. Early stopping is a way to prevent overfitting.Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Let’s see if you can do even better with an $L$-layer model.5 - L-layer Neural NetworkQuestion: Use the helper functions you have implemented previously to build an $L$-layer neural network with the following structure: [LINEAR -&gt; RELU]$\times$(L-1) -&gt; LINEAR -&gt; SIGMOID. The functions you may need and their inputs are:123456789101112131415def initialize_parameters_deep(layers_dims): ... return parameters def L_model_forward(X, parameters): ... return AL, cachesdef compute_cost(AL, Y): ... return costdef L_model_backward(AL, Y, caches): ... return gradsdef update_parameters(parameters, grads, learning_rate): ... return parameters12### CONSTANTS ###layers_dims = [12288, 20, 7, 5, 1] # 4-layer model123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# GRADED FUNCTION: L_layer_modeldef L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009 &quot;&quot;&quot; Implements a L-layer neural network: [LINEAR-&gt;RELU]*(L-1)-&gt;LINEAR-&gt;SIGMOID. Arguments: X -- data, numpy array of shape (num_px * num_px * 3, number of examples) Y -- true &quot;label&quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) layers_dims -- list containing the input size and each layer size, of length (number of layers + 1). learning_rate -- learning rate of the gradient descent update rule num_iterations -- number of iterations of the optimization loop print_cost -- if True, it prints the cost every 100 steps Returns: parameters -- parameters learnt by the model. They can then be used to predict. &quot;&quot;&quot; np.random.seed(1) costs = [] # keep track of cost # Parameters initialization. (≈ 1 line of code) ### START CODE HERE ### parameters = initialize_parameters_deep(layers_dims) ### END CODE HERE ### # Loop (gradient descent) for i in range(0, num_iterations): # Forward propagation: [LINEAR -&gt; RELU]*(L-1) -&gt; LINEAR -&gt; SIGMOID. ### START CODE HERE ### (≈ 1 line of code) AL, caches = L_model_forward(X, parameters) ### END CODE HERE ### # Compute cost. ### START CODE HERE ### (≈ 1 line of code) cost = compute_cost(AL, Y) ### END CODE HERE ### # Backward propagation. ### START CODE HERE ### (≈ 1 line of code) grads = L_model_backward(AL, Y, caches) ### END CODE HERE ### # Update parameters. ### START CODE HERE ### (≈ 1 line of code) parameters = update_parameters(parameters, grads, learning_rate) ### END CODE HERE ### # Print the cost every 100 training example if print_cost and i % 100 == 0: print (&quot;Cost after iteration %i: %f&quot; %(i, cost)) if print_cost and i % 100 == 0: costs.append(cost) # plot the cost plt.plot(np.squeeze(costs)) plt.ylabel(&apos;cost&apos;) plt.xlabel(&apos;iterations (per hundreds)&apos;) plt.title(&quot;Learning rate =&quot; + str(learning_rate)) plt.show() return parametersYou will now train the model as a 4-layer neural network.Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the “Cost after iteration 0” matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error.1parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)12345678910111213141516171819202122232425Cost after iteration 0: 0.771749Cost after iteration 100: 0.672053Cost after iteration 200: 0.648263Cost after iteration 300: 0.611507Cost after iteration 400: 0.567047Cost after iteration 500: 0.540138Cost after iteration 600: 0.527930Cost after iteration 700: 0.465477Cost after iteration 800: 0.369126Cost after iteration 900: 0.391747Cost after iteration 1000: 0.315187Cost after iteration 1100: 0.272700Cost after iteration 1200: 0.237419Cost after iteration 1300: 0.199601Cost after iteration 1400: 0.189263Cost after iteration 1500: 0.161189Cost after iteration 1600: 0.148214Cost after iteration 1700: 0.137775Cost after iteration 1800: 0.129740Cost after iteration 1900: 0.121225Cost after iteration 2000: 0.113821Cost after iteration 2100: 0.107839Cost after iteration 2200: 0.102855Cost after iteration 2300: 0.100897Cost after iteration 2400: 0.09287812pred_train = predict(train_x, train_y, parameters)# Accuracy: 0.98564593301412pred_test = predict(test_x, test_y, parameters)# Accuracy: 0.8Congrats! It seems that your 4-layer neural network has better performance (80%) than your 2-layer neural network (72%) on the same test set.This is good performance for this task. Nice job!Though in the next course on “Improving deep neural networks” you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others you’ll also learn in the next course).6) Results AnalysisFirst, let’s take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images.1print_mislabeled_images(classes, test_x, test_y, pred_test)A few types of images the model tends to do poorly on include:Cat body in an unusual positionCat appears against a background of a similar colorUnusual cat color and speciesCamera AngleBrightness of the pictureScale variation (cat is very large or small in image)7) Test with your own image (optional/ungraded exercise)Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Change your image&#39;s name in the following code Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!12345678910111213## START CODE HERE ##my_image = "my_image.jpg" # change this to the name of your image file my_label_y = [1] # the true class of your image (1 -&gt; cat, 0 -&gt; non-cat)## END CODE HERE ##fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))my_image = my_image/255.my_predicted_image = predict(my_image, my_label_y, parameters)plt.imshow(image)print ("y = " + str(np.squeeze(my_predicted_image)) + ", your L-layer model predicts a \"" + classes[int(np.squeeze(my_predicted_image)),].decode("utf-8") + "\" picture.")12Accuracy: 1.0y = 1.0, your L-layer model predicts a &quot;cat&quot; picture.参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（1-3）]]></title>
    <url>%2F2019%2F08%2F15%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[浅层神经网络(Shallow neural networks)神经网络概述 （Neural Network Overview）\left. \begin{array}{l} x\\ w\\ b \end{array} \right\} \implies{z={w}^Tx+b}如上所示，首先你需要输入特征$x$，参数$w$和$b$，通过这些你就可以计算出$z$：\left. \begin{array}{l} x\\ w\\ b \end{array} \right\} \implies{z={w}^Tx+b} \implies{\alpha = \sigma(z)}\\ \implies{L}(a,y)接下来使用$z$就可以计算出$a$。我们将的符号换为表示输出$\hat{y}\implies{a = \sigma(z)}$,然后可以计算出loss function $L(a,y)$在这个神经网络对应的3个节点，首先计算第一层网络中的各个节点相关的数$z^{[1]}$，接着计算$\alpha^{[1]}$，在计算下一层网络同理；符号$^{[m]}$表示第$m$层网络中节点相关的数，这些节点的集合被称为第$m$层网络。\left. \begin{array}{r} {x }\\ {W^{[1]}}\\ {b^{[1]}} \end{array} \right\} \implies{z^{[1]}=W^{[1]}x+b^{[1]}} \implies{a^{[1]} = \sigma(z^{[1]})}\left. \begin{array}{r} \text{$a^{[1]} = \sigma(z^{[1]})$}\\ \text{$W^{[2]}$}\\ \text{$b^{[2]}$}\\ \end{array} \right\} \implies{z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}} \implies{a^{[2]} = \sigma(z^{[2]})}\\ \implies{L\left(a^{[2]},y \right)}类似逻辑回归，在计算后需要使用计算，接下来你需要使用另外一个线性方程对应的参数计算$z^{[2]}$，计算$a^{[2]}$，此时$a^{[2]}$就是整个神经网络最终的输出，用 $\hat{y}$表示网络的输出。\left. \begin{array}{r} {x }\\ {dW^{[1]}}\\ {db^{[1]}} \end{array} \right\} \impliedby{dz^{[1]}={d}(W^{[1]}x+b^{[1]})} \impliedby{d\alpha^{[1]} = { d}\sigma(z^{[1]})}\left. \begin{array}{r} {da^{[1]} = {d}\sigma(z^{[1]})}\\ {dW^{[2]}}\\ {db^{[2]}}\\ \end{array} \right\} \impliedby{dz^{[2]}={d}(W^{[2]}\alpha^{[1]}+b^{[2]}}) \impliedby{da^{[2]} = {d}\sigma(z^{[2]})}\\ \impliedby{dL\left(a^{[2]},y \right)}神经网络的表示（Neural Network Representation）只有一个隐藏层的简单两层神经网络结构：输入层和隐藏层之间$w^{[1]}-&gt;(4,3)$：前面的4是隐层神经元的个数，后面的3是输入层神经元的个数；$b^{[1]}-&gt;(4,1)$：和隐藏层的神经元个数相同；隐藏层和输出层之间$w^{[2]}-&gt;(1,4)$：前面的1是输出层神经元的个数，后面的4是隐层神经元的个数；$b^{[2]}-&gt;(1,1)$：和输出层的神经元个数相同；两层之间的$w$参数矩阵大小为$(n_{out}, n_{in})$，$b$参数矩阵大小为$(n_{out},1)$，这里是作为$z = wX+b$的线性关系来说明的，在神经网络中，$w^{[i]}=w^T$。在logistic regression中，一般我们都会用$(n_{in}, n_{out})$来表示参数大小，计算使用的公式为：$z = w^{T}X+b$神经网络的输出（Computing a Neural Network’s output）$z^{[1]}_1 = w^{[1]T}_1x + b^{[1]}_1, a^{[1]}_1 = \sigma(z^{[1]}_1)$$z^{[1]}_2 = w^{[1]T}_2x + b^{[1]}_2, a^{[1]}_2 = \sigma(z^{[1]}_2)$$z^{[1]}_3 = w^{[1]T}_3x + b^{[1]}_3, a^{[1]}_3 = \sigma(z^{[1]}_3)$$z^{[1]}_4 = w^{[1]T}_4x + b^{[1]}_4, a^{[1]}_4 = \sigma(z^{[1]}_4)$向量化计算$z^{[n]} = w^{[n]}x + b^{[n]}$$a^{[n]}=\sigma(z^{[n]})$a^{[1]} = \left[ \begin{array}{c} a^{[1]}_{1}\\ a^{[1]}_{2}\\ a^{[1]}_{3}\\ a^{[1]}_{4} \end{array} \right] = \sigma(z^{[1]})\left[ \begin{array}{c} z^{[1]}_{1}\\ z^{[1]}_{2}\\ z^{[1]}_{3}\\ z^{[1]}_{4}\\ \end{array} \right] = \overbrace{ \left[ \begin{array}{c} ...W^{[1]T}_{1}...\\ ...W^{[1]T}_{2}...\\ ...W^{[1]T}_{3}...\\ ...W^{[1]T}_{4}... \end{array} \right] }^{W^{[1]}} * \overbrace{ \left[ \begin{array}{c} x_1\\ x_2\\ x_3\\ \end{array} \right] }^{input} + \overbrace{ \left[ \begin{array}{c} b^{[1]}_1\\ b^{[1]}_2\\ b^{[1]}_3\\ b^{[1]}_4\\ \end{array} \right] }^{b^{[1]}}对于神经网络的第一层，给予一个输入$x$，得到$a^{[1]}$，$x$可以表示为$a^{[0]}$。后一层的表示同样可以写成类似的形式，得到$a^{[2]}$，$\hat{y} = a^{[2]}$。多样本向量化如果有一个非向量化形式的实现，而且要计算出它的预测值，对于所有训练样本，需要让$i$从1到$m$实现这四个等式：$z^{1}=W^{1}x^{(i)}+b^{1}$$a^{1}=\sigma(z^{1})$$z^{2}=W^{2}a^{1}+b^{2}$$a^{2}=\sigma(z^{2})$对于上面的这个方程中的$^{(i)}$，是所有依赖于训练样本的变量，即将$(i)$添加到$x$，$z$和$a$。如果想计算$m$个训练样本上的所有输出，就应该向量化整个计算，以简化这列。x = \left[ \begin{array}{c} \vdots & \vdots & \vdots & \vdots\\ x^{(1)} & x^{(2)} & \cdots & x^{(m)}\\ \vdots & \vdots & \vdots & \vdots\\ \end{array} \right]Z^{[1]} = \left[ \begin{array}{c} \vdots & \vdots & \vdots & \vdots\\ z^{[1](1)} & z^{[1](2)} & \cdots & z^{[1](m)}\\ \vdots & \vdots & \vdots & \vdots\\ \end{array} \right]A^{[1]} = \left[ \begin{array}{c} \vdots & \vdots & \vdots & \vdots\\ \alpha^{[1](1)} & \alpha^{[1](2)} & \cdots & \alpha^{[1](m)}\\ \vdots & \vdots & \vdots & \vdots\\ \end{array} \right]\left. \begin{array}{r} \text{$z^{[1](i)} = W^{[1](i)}x^{(i)} + b^{[1]}$}\\ \text{$\alpha^{[1](i)} = \sigma(z^{[1](i)})$}\\ \text{$z^{[2](i)} = W^{[2](i)}\alpha^{[1](i)} + b^{[2]}$}\\ \text{$\alpha^{[2](i)} = \sigma(z^{[2](i)})$}\\ \end{array} \right\} \implies \begin{cases} \text{$A^{[1]} = \sigma(z^{[1]})$}\\ \text{$z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$}\\ \text{$A^{[2]} = \sigma(z^{[2]})$}\\ \end{cases}在$m$个训练样本中，每次计算都是在重复相同的过程，均得到同样大小和结构的输出，所以利用向量化的思想将单个样本合并到一个矩阵中，其大小为$(x_n,m)$，其中$x_n$表示每个样本输入网络的神经元个数，也可以认为是单个样本的特征数，$m$表示训练样本的个数。激活函数（Activation functions）sigmoid函数：$a = \sigma(z) = \frac{1}{1 + e^{- z}}$，$a’=a(1-a)$tanh函数：$a= tanh(z) = \frac{e^{z} - e^{- z}}{e^{z} + e^{- z}}$，$a’=1-a^{2}$ReLu函数：$ a =max( 0,z) $Leaky ReLU：$a = max( 0.01z,z)$sigmoid激活函数：函数计算量大反向传播时，很容易就会出现梯度消失的情况只有正数输出sigmoid和tanh函数的导数在正负饱和区的梯度都会接近于0，这会造成梯度弥散，而Relu和Leaky ReLu函数大于0部分都为常熟，不会产生梯度弥散现象。(同时应该注意到的是，Relu进入负半区的时候，梯度为0，神经元此时不会训练，产生所谓的稀疏性，而Leaky ReLu不会有这问题)神经网络的梯度下降（Gradient descent for neural networks）你的单隐层神经网络会有$W^{[1]}$，$b^{[1]}$，$W^{[2]}$，$b^{[2]}$这些参数，还有个$n_x$表示输入特征的个数，$n^{[1]}$表示隐藏单元个数，$n^{[2]}$表示输出单元个数。在我们的例子中，我们只介绍过的这种情况，那么参数:矩阵$W^{[1]}$的维度就是($n^{[1]}, n^{[0]}$)，$b^{[1]}$就是$n^{[1]}$维向量，可以写成$(n^{[1]}, 1)$，就是一个的列向量。矩阵$W^{[2]}$的维度就是($n^{[2]}, n^{[1]}$)，$b^{[2]}$的维度就是$(n^{[2]},1)$维度。你还有一个神经网络的成本函数，假设你在做二分类任务，那么你的成本函数等于：Cost function:公式：$J(W^{[1]},b^{[1]},W^{[2]},b^{[2]}) = {\frac{1}{m}}\sum_{i=1}^mL(\hat{y}, y)$loss function和之前做logistic回归完全一样。训练参数需要做梯度下降，在训练神经网络的时候，随机初始化参数很重要，而不是初始化成全零。当你参数初始化成某些值后，每次梯度下降都会循环计算以下预测值：$\hat{y}^{(i)},(i=1,2,…,m)$$dW^{[1]} = \frac{dJ}{dW^{[1]}},db^{[1]} = \frac{dJ}{db^{[1]}}$${d}W^{[2]} = \frac{dJ}{dW^{[2]}},{d}b^{[2]} = \frac{dJ}{db^{[2]}}$其中$W^{[1]}\implies{W^{[1]} - adW^{[1]}},b^{[1]}\implies{b^{[1]} -adb^{[1]}}$$W^{[2]}\implies{W^{[2]} - \alpha{\rm d}W^{[2]}},b^{[2]}\implies{b^{[2]} - \alpha{\rm d}b^{[2]}}$正向传播方程如下（之前讲过）：forward propagation：$z^{[1]} = W^{[1]}x + b^{[1]}$$a^{[1]} = \sigma(z^{[1]})$$z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}$$a^{[2]} = g^{[2]}(z^{[z]}) = \sigma(z^{[2]})$反向传播方程如下:back propagation：$ dz^{[2]} = A^{[2]} - Y , Y = \begin{bmatrix}y^{[1]} &amp; y^{[2]} &amp; \cdots &amp; y^{[m]}\\ \end{bmatrix} $$ dW^{[2]} = {\frac{1}{m}}dz^{[2]}A^{[1]T} $$ {\rm d}b^{[2]} = {\frac{1}{m}}np.sum({d}z^{[2]},axis=1,keepdims=True)$$\underbrace{dZ^{[1]}}_{(n^{[1]}, m)} = \underbrace{W^{[2]T}dZ^{[2]}}_{(n^{[1]}, m)}*\underbrace{g[1]^{‘}(Z^{[1]})}_{(n^{[1]}, m)}$$dW^{[1]} = {\frac{1}{m}}dz^{[1]}x^{T}$${\underbrace{db^{[1]}}_{(n^{[1]},1)}} = {\frac{1}{m}}np.sum(dz^{[1]},axis=1,keepdims=True)$上述是反向传播的步骤，注：这些都是针对所有样本进行过向量化，$Y$是$1×m$的矩阵；这里np.sum是python的numpy命令，axis=1表示水平相加求和，keepdims是防止python输出那些古怪的秩数$(n,)$，加上这个确保阵矩阵$db^{[2]}$这个向量输出的维度为$(n,1)$这样标准的形式。目前为止，我们计算的都和Logistic回归十分相似，但当你开始计算反向传播时，你需要计算，是隐藏层函数的导数，输出在使用sigmoid函数进行二元分类。这里是进行逐个元素乘积，因为$W^{[2]T}dz^{[2]}$和$(z^{[1]})$这两个都为$(n^{[1]},m)$矩阵；还有一种防止python输出奇怪的秩数，需要显式地调用reshape把np.sum输出结果写成矩阵形式。直观理解反向传播（Backpropagation intuition）下图是逻辑回归的推导：\left. \begin{array}{l} {x }\\ {w }\\ {b } \end{array} \right\} \implies{z={w}^Tx+b} \implies{\alpha = \sigma(z)} \implies{L\left(a,y \right)}所以回想当时我们讨论逻辑回归的时候，我们有这个正向传播步骤，其中我们计算$z$，然后$a$，然后损失函数$L$。\underbrace{ \left. \begin{array}{l} {x }\\ {w }\\ {b } \end{array} \right\} }_{dw={dz}\cdot x, db =dz} \impliedby\underbrace{z={w}^Tx+b}_{d z=da\cdot g^{'}(z), g(z)=\sigma(z), {\frac{dL}{dz}}={\frac{dL}{da}}\cdot{\frac{da}{dz}}, {\frac{d}{ dz}}g(z)=g^{'}(z)} \impliedby\underbrace{a = \sigma(z)} \impliedby{L(a,y)}_{da={\frac{d}{da}}{L}\left(a,y \right)=(-y\log{a} - (1 - y)\log(1 - a))^{'}={-\frac{y}{a}} + {\frac{1 - y}{1 - a}{}} }神经网络的计算中，与逻辑回归十分类似，但中间会有多层的计算。下图是一个双层神经网络，有一个输入层，一个隐藏层和一个输出层。前向传播：计算$z^{[1]}$，$a^{[1]}$，再计算$z^{[2]}$，$a^{[2]}$，最后得到loss function。反向传播：向后推算出$da^{[2]}$，然后推算出$dz^{[2]}$，接着推算出$da^{[1]}$，然后推算出$dz^{[1]}$。我们不需要对$x$求导，因为$x$是固定的，我们也不是想优化$x$。向后推算出$da^{[2]}$，然后推算出$dz^{[2]}$的步骤可以合为一步：公式3.40：$dz^{[2]}=a^{[2]}-y\;，\;dW^{[2]}=dz^{[2]}{a^{[1]}}^{T}$(注意：逻辑回归中；为什么$a^{[1]T}$多了个转置：$dw$中的$W$(视频里是$W^{[2]}_i$)是一个列向量，而$W^{[2]}$是个行向量，故需要加个转置);$db^{[2]}=dz^{[2]}$$dz^{[1]} = W^{[2]T}dz^{[2]}* g[1]^{‘}(z^{[1]})$注意：这里的矩阵：$W^{[2]}$的维度是：$(n^{[2]},n^{[1]})$。$z^{[2]}$ ， $dz^{[2]}$的维度都是：$(n^{[2]},1)$，如果是二分类，那维度就是$(1,1)$。$z^{[1]}$，$dz^{[1]}$的维度都是：$(n^{[1]},1)$。证明过程：其中$W^{[2]T}dz^{[2]}$维度为：$(n^{[1]},n^{[2]})$、$(n^{[2]},1)$相乘得到$(n^{[1]},1)$，和$z^{[1]}$维度相同，$g[1]^{‘}(z^{[1]})$的维度为$(n^{[1]},1)$，这就变成了两个都是$(n^{[1]},1)$向量逐元素乘积。实现后向传播有个技巧，就是要保证矩阵的维度相互匹配。最后得到$dW^{[1]}$和$db^{[1]}$$dW^{[1]} =dz^{[1]}x^{T},db^{[1]} = dz^{[1]}$可以看出$dW^{[1]}$ 和$dW^{[2]}$ 非常相似，其中$x$扮演了$a^{[0]}$的角色，$x^{T}$ 等同于$a^{[0]T}$。由：$Z^{[1]} = W^{[1]}x + b^{[1]}\;,\;a^{[1]}=g^{[1]}(Z^{[1]})$得到：$Z^{[1]} = W^{[1]}x + b^{[1]}, A^{[1]} = g^{[1]}(Z^{[1]})$Z^{[1]} = \left[ \begin{array}{c} \vdots &\vdots & \vdots & \vdots \\ z^{[1](1)} & z^{[1](2)} & \vdots & z^{[1](m)} \\ \vdots &\vdots & \vdots & \vdots \\ \end{array} \right]注意：大写的$Z^{[1]}$表示$z^{1},z^{1},z^{1}…z^{1}$的列向量堆叠成的矩阵，以下类同。下图写了主要的推导过程：$dZ^{[2]}=A^{[2]}-Y\;，\;dW^{[2]}={\frac{1}{m}}dZ^{[2]}{A^{[1]}}^{T}$$L = {\frac{1}{m}}\sum_i^n{L(\hat{y},y)}$$db^{[2]} = {\frac{1}{m}}np.sum(dZ^{[2]},axis=1,keepdims=True)$$\underbrace{dZ^{[1]}}_{(n^{[1]}, m)} = \underbrace{W^{[2]T}dZ^{[2]}}_{(n^{[1]}, m)}*\underbrace{g[1]^{‘}(Z^{[1]})}_{(n^{[1]}, m)}$$dW^{[1]} = {\frac{1}{m}}dZ^{[1]}x^{T}$$db^{[1]} = {\frac{1}{m}}np.sum(dZ^{[1]},axis=1,keepdims=True) $随机初始化（Random+Initialization）在初始化的时候，$W$参数要进行随机初始化，$b$则不存在对称性的问题它可以设置为0。12W = np.random.rand((2,2))* 0.01b = np.zero((2,1))这里我们将$W$的值乘以0.01是为了尽可能使得权重W初始化为较小的值，这是因为如果使用sigmoid函数或者tanh函数作为激活函数时，$W$比较小，则$Z=WX+b$所得的值也比较小，处在0的附近，0点区域的附近梯度较大，能够大大提高算法的更新速度。而如果$W$设置的太大的话，得到的梯度较小，训练过程因此会变得很慢。ReLU和Leaky ReLU作为激活函数时，不存在这种问题，因为在大于0的时候，梯度均为1。作业：Planar data classification with one hidden layer1 - PackagesLet’s first import all the packages that you will need during this assignment.numpy is the fundamental package for scientific computing with Python.sklearn provides simple and efficient tools for data mining and data analysis.matplotlib is a library for plotting graphs in Python.testCases provides some test examples to assess the correctness of your functionsplanar_utils provide various useful functions used in this assignment123456789101112# Package importsimport numpy as npimport matplotlib.pyplot as pltfrom testCases_v2 import *import sklearnimport sklearn.datasetsimport sklearn.linear_modelfrom planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets%matplotlib inlinenp.random.seed(1) # set a seed so that the results are consistent2 - DatasetFirst, let’s get the dataset you will work on. The following code will load a “flower” 2-class dataset into variables X and Y.1X, Y = load_planar_dataset()Visualize the dataset using matplotlib. The data looks like a “flower” with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. In other words, we want the classifier to define regions as either red or blue.12# Visualize the data:plt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral);You have:- a numpy-array (matrix) X that contains your features (x1, x2) - a numpy-array (vector) Y that contains your labels (red:0, blue:1). Lets first get a better sense of what our data is like.Exercise: How many training examples do you have? In addition, what is the shape of the variables X and Y?Hint: How do you get the shape of a numpy array? (help)123456789### START CODE HERE ### (≈ 3 lines of code)shape_X = X.shapeshape_Y = Y.shapem = X.shape[1] # training set size### END CODE HERE ###print ('The shape of X is: ' + str(shape_X))print ('The shape of Y is: ' + str(shape_Y))print ('I have m = %d training examples!' % (m))123The shape of X is: (2, 400)The shape of Y is: (1, 400)I have m = 400 training examples!3 - Simple Logistic RegressionBefore building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearn’s built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset.123# Train the logistic regression classifierclf = sklearn.linear_model.LogisticRegressionCV()clf.fit(X.T, Y.T) # (400,2) (400,1)You can now plot the decision boundary of these models. Run the code below.12345678# Plot the decision boundary for logistic regressionplot_decision_boundary(lambda x: clf.predict(x), X, Y)plt.title("Logistic Regression")# Print accuracyLR_predictions = clf.predict(X.T)print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) + '% ' + "(percentage of correctly labelled datapoints)")Interpretation: The dataset is not linearly separable, so logistic regression doesn’t perform well. Hopefully a neural network will do better. Let’s try this now!4 - Neural Network modelLogistic regression did not work well on the “flower dataset”. You are going to train a Neural Network with a single hidden layer.Here is our model:Mathematically:For one example $x^{(i)}$: $$z^{[1] (i)} = W^{[1]} x^{(i)} + b^{[1]}$$ $$a^{[1] (i)} = \tanh(z^{[1] (i)})$$ $$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}$$ ​\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})​y^{(i)}_{prediction} = \begin{cases} 1 & \mbox{if } a^{[2](i)} > 0.5 \\ 0 & \mbox{otherwise } \end{cases}Given the predictions on all the examples, you can also compute the cost $J$ as follows: $$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large \right) \small $$ Reminder: The general methodology to build a Neural Network is to:1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model&#39;s parameters 3. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent) You often build helper functions to compute steps 1-3 and then merge them into one function we call nn_model(). Once you’ve built nn_model() and learnt the right parameters, you can make predictions on new data.4.1 - Defining the neural network structureExercise: Define three variables:- n_x: the size of the input layer - n_h: the size of the hidden layer (set this to 4) - n_y: the size of the output layer Hint: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4.12345678910111213141516171819# GRADED FUNCTION: layer_sizesdef layer_sizes(X, Y): """ Arguments: X -- input dataset of shape (input size, number of examples) Y -- labels of shape (output size, number of examples) Returns: n_x -- the size of the input layer n_h -- the size of the hidden layer n_y -- the size of the output layer """ ### START CODE HERE ### (≈ 3 lines of code) n_x = X.shape[0] # size of input layer n_h = 4 n_y = Y.shape[0] # size of output layer ### END CODE HERE ### return (n_x, n_h, n_y)12345678X_assess, Y_assess = layer_sizes_test_case()(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)print("The size of the input layer is: n_x = " + str(n_x))print("The size of the hidden layer is: n_h = " + str(n_h))print("The size of the output layer is: n_y = " + str(n_y))# The size of the input layer is: n_x = 5# The size of the hidden layer is: n_h = 4# The size of the output layer is: n_y = 24.2 - Initialize the model’s parametersExercise: Implement the function initialize_parameters().Instructions:Make sure your parameters’ sizes are right. Refer to the neural network figure above if needed.You will initialize the weights matrices with random values.Use: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b).You will initialize the bias vectors as zeros.Use: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros.1234567891011121314151617181920212223242526272829303132333435363738# GRADED FUNCTION: initialize_parametersdef initialize_parameters(n_x, n_h, n_y): """ Argument: n_x -- size of the input layer n_h -- size of the hidden layer n_y -- size of the output layer Returns: params -- python dictionary containing your parameters: W1 -- weight matrix of shape (n_h, n_x) b1 -- bias vector of shape (n_h, 1) W2 -- weight matrix of shape (n_y, n_h) b2 -- bias vector of shape (n_y, 1) """ np.random.seed(2) # we set up a seed so that your output matches ours although the initialization is random. ### START CODE HERE ### (≈ 4 lines of code) W1 = np.random.randn(n_h, n_x) b1 = np.zeros((n_h, 1)) W2 = np.random.randn(n_y, n_h) b2 = np.zeros((n_y, 1)) ### END CODE HERE ### assert (W1.shape == (n_h, n_x)) assert (b1.shape == (n_h, 1)) assert (W2.shape == (n_y, n_h)) assert (b2.shape == (n_y, 1)) parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters1234567n_x, n_h, n_y = initialize_parameters_test_case()parameters = initialize_parameters(n_x, n_h, n_y)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))4.3 - The LoopQuestion: Implement forward_propagation().Instructions:Look above at the mathematical representation of your classifier.You can use the function sigmoid(). It is built-in (imported) in the notebook.You can use the function np.tanh(). It is part of the numpy library.The steps you have to implement are:Retrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using parameters[&quot;..&quot;].Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set).Values needed in the backpropagation are stored in “cache“. The cache will be given as an input to the backpropagation function.123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: forward_propagationdef forward_propagation(X, parameters): """ Argument: X -- input data of size (n_x, m) parameters -- python dictionary containing your parameters (output of initialization function) Returns: A2 -- The sigmoid output of the second activation cache -- a dictionary containing "Z1", "A1", "Z2" and "A2" """ # Retrieve each parameter from the dictionary "parameters" ### START CODE HERE ### (≈ 4 lines of code) W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] ### END CODE HERE ### # Implement Forward Propagation to calculate A2 (probabilities) ### START CODE HERE ### (≈ 4 lines of code) Z1 = np.dot(W1, X) + b1 # (n_h, n_x)*(n_x, m) + (n_h, 1) A1 = np.tanh(Z1) # (n_h, m) Z2 = np.dot(W2, A1) + b2 # (n_y, n_h)*(n_h, m) + (n_y, 1) A2 = sigmoid(Z2) # (n_y, m) ### END CODE HERE ### assert(A2.shape == (1, X.shape[1])) cache = &#123;"Z1": Z1, "A1": A1, "Z2": Z2, "A2": A2&#125; return A2, cache123456X_assess, parameters = forward_propagation_test_case()A2, cache = forward_propagation(X_assess, parameters)# Note: we use the mean here just to make sure that your output matches ours. print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))# 0.262818640198 0.091999045227 -1.30766601287 0.212877681719Now that you have computed $A^{[2]}$ (in the Python variable “A2“), which contains $a^{2}$ for every example, you can compute the cost function as follows:J = - \frac{1}{m} \sum\limits_{i = 1}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \smallExercise: Implement compute_cost() to compute the value of the cost $J$.Instructions:There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented$- \sum\limits_{i=0}^{m} y^{(i)}\log(a^{2})$:12logprobs = np.multiply(np.log(A2),Y)cost = - np.sum(logprobs) # no need to use a for loop!(you can use either np.multiply() and then np.sum() or directly np.dot()).Note that if you use np.multiply followed by np.sum the end result will be a type float, whereas if you use np.dot, the result will be a 2D numpy array. We can use np.squeeze() to remove redundant dimensions (in the case of single float, this will be reduced to a zero-dimension array). We can cast the array as a type float using float().123456789101112131415161718192021222324252627282930313233343536# GRADED FUNCTION: compute_costdef compute_cost(A2, Y, parameters): """ Computes the cross-entropy cost given in equation (13) Arguments: A2 -- The sigmoid output of the second activation, of shape (1, number of examples) Y -- "true" labels vector of shape (1, number of examples) parameters -- python dictionary containing your parameters W1, b1, W2 and b2 [Note that the parameters argument is not used in this function, but the auto-grader currently expects this parameter. Future version of this notebook will fix both the notebook and the auto-grader so that `parameters` is not needed. For now, please include `parameters` in the function signature, and also when invoking this function.] Returns: cost -- cross-entropy cost given equation (13) """ m = Y.shape[1] # number of example # Compute the cross-entropy cost ### START CODE HERE ### (≈ 2 lines of code) # 这时候用点乘 logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1-A2), (1-Y)) cost = (-1.0 / m) * np.sum(logprobs) ### END CODE HERE ### cost = float(np.squeeze(cost)) # makes sure cost is the dimension we expect. # E.g., turns [[17]] into 17 assert(isinstance(cost, float)) return cost1234A2, Y_assess, parameters = compute_cost_test_case()print("cost = " + str(compute_cost(A2, Y_assess, parameters)))# cost = 0.6930587610394646Using the cache computed during forward propagation, you can now implement backward propagation.Question: Implement the function backward_propagation().Instructions:Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You’ll want to use the six equations on the right of this slide, since you are building a vectorized implementation.Tips:To compute dZ1 you’ll need to compute $g^{[1]’}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]’}(z) = 1-a^2$. So you can compute $g^{[1]’}(Z^{[1]})$ using (1 - np.power(A1, 2)).123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# GRADED FUNCTION: backward_propagationdef backward_propagation(parameters, cache, X, Y): """ Implement the backward propagation using the instructions above. Arguments: parameters -- python dictionary containing our parameters cache -- a dictionary containing "Z1", "A1", "Z2" and "A2". X -- input data of shape (2, number of examples) Y -- "true" labels vector of shape (1, number of examples) Returns: grads -- python dictionary containing your gradients with respect to different parameters """ m = X.shape[1] # First, retrieve W1 and W2 from the dictionary "parameters". ### START CODE HERE ### (≈ 2 lines of code) W1 = parameters["W1"] W2 = parameters["W2"] ### END CODE HERE ### # Retrieve also A1 and A2 from dictionary "cache". ### START CODE HERE ### (≈ 2 lines of code) A1 = cache["A1"] A2 = cache["A2"] ### END CODE HERE ### # Backward propagation: calculate dW1, db1, dW2, db2. ### START CODE HERE ### (≈ 6 lines of code, corresponding to 6 equations on slide above) dZ2 = A2 - Y # (n_y, m) dW2 = 1.0 / m * np.dot(dZ2, A1.T) #(n_y, m) * (m, n_h) db2 = 1.0 / m * np.sum(dZ2, axis=1, keepdims=True) dZ1 = np.dot(W2.T, dZ2)*(1-np.power(A1, 2)) # (n_h, n_y)*(n_y, m)*(n_h, m) dW1 = 1.0 / m * np.dot(dZ1, X.T) # (n_h, m)*(m, n_x) db1 = 1.0 / m * np.sum(dZ1, axis=1, keepdims=True) ### END CODE HERE ### grads = &#123;"dW1": dW1, "db1": db1, "dW2": dW2, "db2": db2&#125; return grads# print(n_h, n_x, n_y)# 4 2 11234567parameters, cache, X_assess, Y_assess = backward_propagation_test_case()grads = backward_propagation(parameters, cache, X_assess, Y_assess)print ("dW1 = "+ str(grads["dW1"]))print ("db1 = "+ str(grads["db1"]))print ("dW2 = "+ str(grads["dW2"]))print ("db2 = "+ str(grads["db2"]))Question: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).General gradient descent rule: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter.Illustration: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.12345678910111213141516171819202122232425262728293031323334353637383940414243# GRADED FUNCTION: update_parametersdef update_parameters(parameters, grads, learning_rate = 1.2): """ Updates parameters using the gradient descent update rule given above Arguments: parameters -- python dictionary containing your parameters grads -- python dictionary containing your gradients Returns: parameters -- python dictionary containing your updated parameters """ # Retrieve each parameter from the dictionary "parameters" ### START CODE HERE ### (≈ 4 lines of code) W1 = parameters["W1"] b1 = parameters["b1"] W2 = parameters["W2"] b2 = parameters["b2"] ### END CODE HERE ### # Retrieve each gradient from the dictionary "grads" ### START CODE HERE ### (≈ 4 lines of code) dW1 = grads["dW1"] db1 = grads["db1"] dW2 = grads["dW2"] db2 = grads["db2"] ## END CODE HERE ### # Update rule for each parameter ### START CODE HERE ### (≈ 4 lines of code) W1 = W1 - learning_rate * dW1 b1 = b1 - learning_rate * db1 W2 = W2 - learning_rate * dW2 b2 = b2 - learning_rate * db2 ### END CODE HERE ### parameters = &#123;"W1": W1, "b1": b1, "W2": W2, "b2": b2&#125; return parameters1234567parameters, grads = update_parameters_test_case()parameters = update_parameters(parameters, grads)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# GRADED FUNCTION: nn_modeldef nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False): """ Arguments: X -- dataset of shape (2, number of examples) Y -- labels of shape (1, number of examples) n_h -- size of the hidden layer num_iterations -- Number of iterations in gradient descent loop print_cost -- if True, print the cost every 1000 iterations Returns: parameters -- parameters learnt by the model. They can then be used to predict. """ np.random.seed(3) n_x = layer_sizes(X, Y)[0] n_y = layer_sizes(X, Y)[2] # Initialize parameters ### START CODE HERE ### (≈ 1 line of code) parameters = initialize_parameters(n_x, n_h, n_y) ### END CODE HERE ### # Loop (gradient descent) for i in range(0, num_iterations): ### START CODE HERE ### (≈ 4 lines of code) # Forward propagation. Inputs: "X, parameters". Outputs: "A2, cache". A2, cache = forward_propagation(X, parameters) # Cost function. Inputs: "A2, Y, parameters". Outputs: "cost". cost = compute_cost(A2, Y, parameters) # Backpropagation. Inputs: "parameters, cache, X, Y". Outputs: "grads". grads = backward_propagation(parameters, cache, X, Y) # Gradient descent parameter update. Inputs: "parameters, grads". Outputs: "parameters". parameters = update_parameters(parameters, grads, learning_rate = 1.2) ### END CODE HERE ### # Print the cost every 1000 iterations if print_cost and i % 1000 == 0: print ("Cost after iteration %i: %f" %(i, cost)) return parameters123456X_assess, Y_assess = nn_model_test_case()parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)print("W1 = " + str(parameters["W1"]))print("b1 = " + str(parameters["b1"]))print("W2 = " + str(parameters["W2"]))print("b2 = " + str(parameters["b2"]))1234567891011121314151617181920Cost after iteration 0: 0.041960Cost after iteration 1000: 0.000266Cost after iteration 2000: 0.000134Cost after iteration 3000: 0.000090Cost after iteration 4000: 0.000068Cost after iteration 5000: 0.000054Cost after iteration 6000: 0.000045Cost after iteration 7000: 0.000039Cost after iteration 8000: 0.000034Cost after iteration 9000: 0.000030W1 = [[-0.89587042 1.18044635] [-2.14783312 1.70666862] [-1.50260821 -1.21347886] [ 0.80826745 -1.65434514]]b1 = [[ 0.19050922] [ 0.01614166] [-0.34103273] [-0.25208981]]W2 = [[-2.90757381 -3.18177289 0.36186225 4.50758023]]b2 = [[ 0.24451252]]4.5 PredictionsQuestion: Use your model to predict by building predict().Use forward propagation to predict results.Reminder: predictions = $y_{prediction} = \mathbb 1 \text{activation &gt; 0.5} = \begin{cases}1 &amp; \text{if}\ activation &gt; 0.5 \\0 &amp; \text{otherwise}\end{cases}$As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do:1234567891011121314151617181920212223```python# GRADED FUNCTION: predictdef predict(parameters, X): &quot;&quot;&quot; Using the learned parameters, predicts a class for each example in X Arguments: parameters -- python dictionary containing your parameters X -- input data of size (n_x, m) Returns predictions -- vector of predictions of our model (red: 0 / blue: 1) &quot;&quot;&quot; # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold. ### START CODE HERE ### (≈ 2 lines of code) A2, cache = forward_propagation(X, parameters) predictions = (A2 &gt; 0.5) ### END CODE HERE ### return predictions12345parameters, X_assess = predict_test_case()predictions = predict(parameters, X_assess)print("predictions mean = " + str(np.mean(predictions)))# predictions mean = 0.666666666667It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of $n_h$ hidden units.123456# Build a model with a n_h-dimensional hidden layerparameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)# Plot the decision boundaryplot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)plt.title("Decision Boundary for hidden layer size " + str(4))12345678910Cost after iteration 0: 1.127380Cost after iteration 1000: 0.288553Cost after iteration 2000: 0.276386Cost after iteration 3000: 0.268077Cost after iteration 4000: 0.263069Cost after iteration 5000: 0.259617Cost after iteration 6000: 0.257070Cost after iteration 7000: 0.255105Cost after iteration 8000: 0.253534Cost after iteration 9000: 0.2522451234# Print accuracypredictions = predict(parameters, X)print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')# Accuracy: 91%Accuracy is really high compared to Logistic Regression. The model has learnt the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression.Now, let’s try out several hidden layer sizes.4.6 - Tuning hidden layer size (optional/ungraded exercise)Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes.123456789101112# This may take about 2 minutes to runplt.figure(figsize=(16, 32))hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]for i, n_h in enumerate(hidden_layer_sizes): plt.subplot(5, 2, i+1) plt.title('Hidden Layer of size %d' % n_h) parameters = nn_model(X, Y, n_h, num_iterations = 5000) plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y) predictions = predict(parameters, X) accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) print ("Accuracy for &#123;&#125; hidden units: &#123;&#125; %".format(n_h, accuracy))1234567Accuracy for 1 hidden units: 67.5 %Accuracy for 2 hidden units: 67.25 %Accuracy for 3 hidden units: 90.75 %Accuracy for 4 hidden units: 90.5 %Accuracy for 5 hidden units: 91.25 %Accuracy for 20 hidden units: 90.0 %Accuracy for 50 hidden units: 90.25 %Interpretation:The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data.The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to fits the data well without also incurring noticeable overfitting.You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting.Optional questions:Note: Remember to submit the assignment by clicking the blue “Submit Assignment” button at the upper-right.Some optional/ungraded questions that you can explore if you wish:What happens when you change the tanh activation for a sigmoid activation or a ReLU activation?Play with the learning_rate. What happens?What if we change the dataset? (See part 5 below!)You’ve learnt to:Build a complete neural network with a hidden layerMake a good use of a non-linear unitImplemented forward propagation and backpropagation, and trained a neural networkSee the impact of varying the hidden layer size, including overfitting.5) Performance on other datasetsIf you want, you can rerun the whole notebook (minus the dataset part) for each of the following datasets.123456789101112131415161718192021# Datasetsnoisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure = load_extra_datasets()datasets = &#123;"noisy_circles": noisy_circles, "noisy_moons": noisy_moons, "blobs": blobs, "gaussian_quantiles": gaussian_quantiles&#125;### START CODE HERE ### (choose your dataset)dataset = "noisy_moons"### END CODE HERE ###X, Y = datasets[dataset]X, Y = X.T, Y.reshape(1, Y.shape[0])# make blobs binaryif dataset == "blobs": Y = Y%2# Visualize the dataplt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral);noisy_circlesblobsgaussian_quantiles参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655https://www.coursera.org/learn/neural-networks-deep-learning/notebook/NI888/planar-data-classification-with-a-hidden-layer]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deeplearning.ai笔记（1-2）]]></title>
    <url>%2F2019%2F08%2F14%2Fdeeplearning-ai%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[神经网络和深度学习—神经网络基础（Basics of Neural Network programming）二分类（Binary Classification）符号定义 ：$x$：表示一个$n_x$维数据，为输入数据，维度为$(n_x,1)$；$y$：表示输出结果，取值为$(0,1)$；$(x^{(i)},y^{(i)})$：表示第$i$组数据，可能是训练数据，也可能是测试数据，此处默认为训练数据；$X=[x^{(1)},x^{(2)},…,x^{(m)}]$：表示所有的训练数据集的输入值，放在一个 $n_x×m$的矩阵中，其中$m$表示样本数目;$Y=[y^{(1)},y^{(2)},…,y^{(m)}]$：对应表示所有训练数据集的输出值，维度为$1×m$。逻辑回归（Logistic Regression）逻辑回归中：$\hat{y}={w}^{T}x+b$引入$sigmoid$函数：$\begin{align}\sigma \left( z \right)&amp;=\frac{1}{1+{e^{-z}}} \\ \sigma’(z)&amp;=\frac{1}{(1+{e^{-z}})^2}\times e^{-z}\\ &amp;=\sigma(z)\frac{e^{-z}}{1+{e^{-z}}}\\ &amp;=\sigma(z)(1-\sigma(z))\end{align}$定义$\hat{y}=\sigma \left( {\theta ^{T}}x \right)$的sigmoid函数。有一组参数向量${\theta _{0}},{\theta _{1}},{\theta_{2}},…,{\theta _{n_{x}}}$，此时${\theta_{0}}$就充当了$b$，而剩下的${\theta_{1}}$ 直到${\theta_{n_{x}}}$充当了$w$$\theta.shape=(w.shape+1,1)$逻辑回归的代价函数（Logistic Regression Cost Function）逻辑回归中用到的损失函数是：$L\left( \hat{y},y \right)=-y\log(\hat{y})-(1-y)\log (1-\hat{y})$，不使用平方错误是因为平方错误损失函数一般是非凸函数（non-convex），其在使用低度下降算法的时候，容易得到局部最优解，而不是全局最优解。当$y=1$时，$L=-\log (\hat{y})$，如果$\hat{y}$越接近1，$L\left( \hat{y},y \right)\approx 0$，表示预测效果越好。当$y=0$时，$L=-\log (1-\hat{y})$，如果$\hat{y}$越接近0，$L\left( \hat{y},y \right)\approx 0$，表示预测效果越好。算法的代价函数是对$m$个样本的损失函数求和然后除以$m$:$J\left( w,b \right)=\frac{1}{m}\sum\limits_{i=1}^{m}{L\left( {\hat{y}^{(i)}},{y^{(i)}} \right)}=\frac{1}{m}\sum\limits_{i=1}^{m}{\left( -{y^{(i)}}\log {\hat{y}^{(i)}}-(1-{y^{(i)}})\log (1-{\hat{y}^{(i)}}) \right)}$梯度下降法（Gradient Descent）用梯度下降法（Gradient Descent）算法来最小化Cost function，以计算出合适的w和b的值。每次迭代更新的修正表达式：$ w:=w-\alpha\dfrac{\partial J(w,b)}{\partial w}$$b:=b-\alpha\dfrac{\partial J(w,b)}{\partial b}$$\partial $ 表示求偏导符号，可以读作round，$\frac{\partial J(w,b)}{\partial w}$ 就是函数$J(w,b)$ 对$w$ 求偏导，在代码中我们会使用$dw$ 表示这个结果，$\frac{\partial J(w,b)}{\partial b}$ 就是函数$J(w,b)$对$b$ 求偏导，在代码中我们会使用$db$ 表示这个结果，小写字母$d$ 用在求导数（derivative），即函数只有一个参数，偏导数符号$\partial $ 用在求偏导（partial derivative），即函数含有两个以上的参数。逻辑回归中的梯度下降（Logistic Regression Gradient Descent）假设样本只有两个特征${x_{1}}$和${x_{2}}$，为了计算$z$，我们需要输入参数${w_1}$、${w_2}$ 和$b$，除此之外还有特征值${x_1}$和${x_2}$。因此$z$的计算公式为：$z={w_1}{x_1}+{w_2}{x_2}+b$回想一下逻辑回归的公式定义如下：$\hat{y}=a=\sigma (z)$其中$z={w^T}x+b$$\sigma \left( z \right)=\frac{1}{1+e^{-z}}$损失函数：$L( {\hat{y}^{(i)}},{y^{(i)}})=-{y^{(i)}}\log {\hat{y}^{(i)}}-(1-{y^{(i)}})\log (1-{\hat{y}^{(i)}})$代价函数：$J\left( w,b \right)=\frac{1}{m}\sum \nolimits_{i}^{m}{L( {\hat{y}^{(i)}},{y^{(i)}})}$假设现在只考虑单个样本的情况，单个样本的代价函数定义如下：$L(a,y)=-(y\log (a)+(1-y)\log (1-a))$反向传播过程：前面过程的da、dz求导：$da = \dfrac{\partial L}{\partial a}=-\dfrac{y}{a}+\dfrac{1-y}{1-a}\\dz = \dfrac{\partial L}{\partial z}=\dfrac{\partial L}{\partial a}\cdot\dfrac{\partial a}{\partial z}=(-\dfrac{y}{a}+\dfrac{1-y}{1-a})\cdot a(1-a)=a-y$再对w1、w2和b进行求导：$dw_{1} = \dfrac{\partial L}{\partial w_{1}}=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial w_{1}}=x_{1}\cdot dz=x_{1}(a-y)$$db = \dfrac{\partial L}{\partial b }=\dfrac{\partial L}{\partial z}\cdot\dfrac{\partial z}{\partial b }=1\cdot dz=a-y$梯度下降法：$w_{1}:=w_{1}-\alpha dw_{1}$$w_{2}:=w_{2}-\alpha dw_{2}$$b:=b-\alpha db$推导过程导数：一阶泰勒展开式这里需要一点数学基础，对泰勒展开式有些了解。简单地来说，一阶泰勒展开式利用的就是函数的局部线性近似这个概念。我们以一阶泰勒展开式为例：A和B均为向量，α为两个向量之间的夹角。A和B的乘积为：m 个样本的梯度下降（Gradient Descent on m Examples）对m个样本来说，其Cost function表达式如下：$z^{(i)}= w^{T}x^{(i)}+b\\\hat y^{(i)}=a^{(i)}=\sigma(z^{(i)})\\J(w,b)=\dfrac{1}{m}\sum \limits_{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum \limits_{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]$Cost function 关于w和b的偏导数可以写成所有样本点偏导数和的平均形式：$dw_{1} =\dfrac{1}{m}\sum \limits_{i=1}^{m}x_{1}^{(i)}(a^{(i)}-y^{(i)})$$db = \dfrac{1}{m}\sum \limits_{i=1}^{m}(a^{(i)}-y^{(i)})$向量化（Vectorization）在逻辑回归中你需要去计算$z=w^Tx+b$，$w$、$x$都是列向量。如果你有很多的特征那么就会有一个非常大的向量，所以$w\in {\mathbb{R}^{n_{x}}}$ , $x\in{\mathbb{R}^{n_{x}}}$，所以如果你想使用非向量化方法去计算${w^T}x$，你需要用如下方式（python）123456z = 0for i in range(n_x): z += w[i]*x[i] z += b这是一个非向量化的实现，你会发现这真的很慢，作为一个对比，向量化实现将会非常直接计算$w^Tx$，代码如下：z=np.dot(w,x)+ba=sigmoid(z)逻辑回归向量化输入矩阵$X$：$(n_x,m)$权重矩阵$w$：$(n_x,1)$偏置$b$：为一个常数输出矩阵$Y$：$(1,m)$所有m个样本的线性输出Z可以用矩阵表示：$Z=w^TX+b$$dZ$对于m个样本，维度为$(1,m)$，表示为： $dZ = A - Y$$db$表示为： $db = \dfrac{1}{m}\sum \limits _{i=1}^{m}dz^{(i)}$$dw表示为： $$dw = \dfrac{1}{m}X\cdot dZ^{T}$单次迭代梯度下降算法流程12345678Z = np.dot(w.T,X) + bA = sigmoid(Z)dZ = A-Ydw = 1/m*np.dot(X,dZ.T)db = 1/m*np.sum(dZ)w = w - alpha*dwb = b - alpha*db关于Python的numpy点乘：np.multiply(a,b)矩阵乘法：np.dot(a,b) 或 np.matmul(a,b) 或 a.dot(b)*在 np.array 为点乘，在 np.matrix 为矩阵乘法np.outer 表示的是两个向量相乘，拿第一个向量的元素分别与第二个向量所有元素相乘得到结果的一行理解好秩、轴和纬度logistic 损失函数的解释（Explanation of logistic regression cost function）Cost function的由来：预测输出$\hat{y}$的表达式：$\hat y =\sigma(w^{T}x+b)$其中，$\sigma(z)=\dfrac{1}{1+e^{-z}}$$\hat{y}$可以看作预测输出为正类（+1）的概率：$\hat y = P(y=1|x)$当$y=1$时，$P(y|x)=\hat y$；$y=0$时，$P(y|x)=1-\hat y$$P(y|x)=\hat y^{y}(1-\hat y )^{(1-y)}$,两边取$log$$\log P(y|x)=\log\left[\hat y^{y}(1-\hat y )^{(1-y)}\right]=y\log\hat y+(1-y)\log(1-\hat y)$Loss function，我们期望其值越小越好：$L(\hat y, y)=-(y\log\hat y+(1-y)\log(1-\hat y))$对于m个训练样本来说，假设样本之间是独立同分布的，我们总是希望训练样本判断正确的概率越大越好，则有：$\max \prod\limits_{i=1}^{m} {P(y^{(i)}|x^{(i)})}$同样引入$log$函数，加负号，则可以得到Cost function：$J(w,b)=\dfrac{1}{m}\sum \limits _{i=1}^{m}L(\hat y^{(i)}, y^{(i)})=-\dfrac{1}{m}\sum \limits _{i=1}^{m}\left[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})\right]$作业Python Basics with Numpy (optional assignment)Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.Instructions:Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.You will learn to:Build the general architecture of a learning algorithm, including:Initializing parametersCalculating the cost function and its gradientUsing an optimization algorithm (gradient descent)Gather all three functions above into a main model function, in the right order.1 - Building basic functions with numpyNumpy is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org). In this exercise you will learn several key numpy functions such as np.exp, np.log, and np.reshape. You will need to know how to use these functions for future assignments.1.1 - sigmoid function, np.exp()Before using np.exp(), you will use math.exp() to implement the sigmoid function. You will then see why np.exp() is preferable to math.exp().Exercise: Build a function that returns the sigmoid of a real number x. Use math.exp(x) for the exponential function.Reminder:$sigmoid(x) = \frac{1}{1+e^{-x}}$ is sometimes also known as the logistic function. It is a non-linear function used not only in Machine Learning (Logistic Regression), but also in Deep Learning.To refer to a function belonging to a specific package you could call it using package_name.function(). Run the code below to see an example with math.exp().1234567891011121314151617181920# GRADED FUNCTION: basic_sigmoidimport mathdef basic_sigmoid(x): """ Compute sigmoid of x. Arguments: x -- A scalar Return: s -- sigmoid(x) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0 / (1 + math.exp(-1.0 * x)) ### END CODE HERE ### return s12basic_sigmoid(3)# 0.9525741268224334Actually, we rarely use the “math” library in deep learning because the inputs of the functions are real numbers. In deep learning we mostly use matrices and vectors. This is why numpy is more useful.123### One reason why we use "numpy" instead of "math" in Deep Learning ###x = [1, 2, 3]basic_sigmoid(x) # you will see this give an error when you run it, because x is a vector.In fact, if $ x = (x_1, x_2, …, x_n)$ is a row vector then $np.exp(x)$ will apply the exponential function to every element of x. The output will thus be: $np.exp(x) = (e^{x_1}, e^{x_2}, …, e^{x_n})$12345import numpy as np# example of np.expx = np.array([1, 2, 3])print(np.exp(x)) # result is (exp(1), exp(2), exp(3))Furthermore, if x is a vector, then a Python operation such as $s = x + 3$ or $s = \frac{1}{x}$ will output s as a vector of the same size as x.123# example of vector operationx = np.array([1, 2, 3])print (x + 3)Any time you need more info on a numpy function, we encourage you to look at the official documentation.You can also create a new cell in the notebook and write np.exp? (for example) to get quick access to the documentation.Exercise: Implement the sigmoid function using numpy.Instructions: x could now be either a real number, a vector, or a matrix. The data structures we use in numpy to represent these shapes (vectors, matrices…) are called numpy arrays. You don’t need to know more for now.\text{For } x \in \mathbb{R}^n \text{, } sigmoid(x) = sigmoid\begin{pmatrix} x_1 \\ x_2 \\ ... \\ x_n \\ \end{pmatrix} = \begin{pmatrix} \frac{1}{1+e^{-x_1}} \\ \frac{1}{1+e^{-x_2}} \\ ... \\ \frac{1}{1+e^{-x_n}} \\ \end{pmatrix}1234567891011121314151617181920# GRADED FUNCTION: sigmoidimport numpy as np # this means you can access numpy functions by writing np.function() instead of numpy.function()def sigmoid(x): """ Compute the sigmoid of x Arguments: x -- A scalar or numpy array of any size Return: s -- sigmoid(x) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0 / (1 + np.exp(-1.0 * x)) ### END CODE HERE ### return s123x = np.array([1, 2, 3])sigmoid(x)# array([ 0.73105858, 0.88079708, 0.95257413])1.2 - Sigmoid gradientAs you’ve seen in lecture, you will need to compute gradients to optimize loss functions using backpropagation. Let’s code your first gradient function.Exercise: Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is:sigmoid\_derivative(x) = \sigma'(x) = \sigma(x) (1 - \sigma(x))You often code this function in two steps:Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.Compute $\sigma’(x) = s(1-s)$1234567891011121314151617181920# GRADED FUNCTION: sigmoid_derivativedef sigmoid_derivative(x): """ Compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x. You can store the output of the sigmoid function into variables and then use it to calculate the gradient. Arguments: x -- A scalar or numpy array Return: ds -- Your computed gradient. """ ### START CODE HERE ### (≈ 2 lines of code) s = 1.0 / (1 + np.exp(-1.0 * x)) ds = s * (1 - s) ### END CODE HERE ### return ds123x = np.array([1, 2, 3])print ("sigmoid_derivative(x) = " + str(sigmoid_derivative(x)))# sigmoid_derivative(x) = [ 0.19661193 0.10499359 0.04517666]1.3 - Reshaping arraysTwo common numpy functions used in deep learning are np.shape and np.reshape().X.shape is used to get the shape (dimension) of a matrix/vector X.X.reshape(…) is used to reshape X into some other dimension.For example, in computer science, an image is represented by a 3D array of shape $(length, height, depth = 3)$. However, when you read an image as the input of an algorithm you convert it to a vector of shape $(lengthheight3, 1)$. In other words, you “unroll”, or reshape, the 3D array into a 1D vector.Exercise: Implement image2vector() that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:1v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = cPlease don’t hardcode the dimensions of image as a constant. Instead look up the quantities you need with image.shape[0], etc.123456789101112131415# GRADED FUNCTION: image2vectordef image2vector(image): """ Argument: image -- a numpy array of shape (length, height, depth) Returns: v -- a vector of shape (length*height*depth, 1) """ ### START CODE HERE ### (≈ 1 line of code) v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1)) ### END CODE HERE ### return v1234567891011121314# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB valuesimage = np.array([[[ 0.67826139, 0.29380381], [ 0.90714982, 0.52835647], [ 0.4215251 , 0.45017551]], [[ 0.92814219, 0.96677647], [ 0.85304703, 0.52351845], [ 0.19981397, 0.27417313]], [[ 0.60659855, 0.00533165], [ 0.10820313, 0.49978937], [ 0.34144279, 0.94630077]]])print ("image2vector(image) = " + str(image2vector(image)))123456789101112131415161718image2vector(image) = [[ 0.67826139] [ 0.29380381] [ 0.90714982] [ 0.52835647] [ 0.4215251 ] [ 0.45017551] [ 0.92814219] [ 0.96677647] [ 0.85304703] [ 0.52351845] [ 0.19981397] [ 0.27417313] [ 0.60659855] [ 0.00533165] [ 0.10820313] [ 0.49978937] [ 0.34144279] [ 0.94630077]]1.4 - Normalizing rowsAnother common technique we use in Machine Learning and Deep Learning is to normalize our data. It often leads to a better performance because gradient descent converges faster after normalization. Here, by normalization we mean changing x to $ \frac{x}{| x|} $ (dividing each row vector of x by its norm).For example, ifx = \begin{bmatrix} 0 & 3 & 4 \\ 2 & 6 & 4 \\ \end{bmatrix}then\| x\| = np.linalg.norm(x, axis = 1, keepdims = True) = \begin{bmatrix} 5 \\ \sqrt{56} \\ \end{bmatrix}andx\_normalized = \frac{x}{\| x\|} = \begin{bmatrix} 0 & \frac{3}{5} & \frac{4}{5} \\ \frac{2}{\sqrt{56}} & \frac{6}{\sqrt{56}} & \frac{4}{\sqrt{56}} \\ \end{bmatrix}Note that you can divide matrices of different sizes and it works fine: this is called broadcasting and you’re going to learn about it in part 5.Exercise: Implement normalizeRows() to normalize the rows of a matrix. After applying this function to an input matrix x, each row of x should be a vector of unit length (meaning length 1).12345678910111213141516171819202122# GRADED FUNCTION: normalizeRowsdef normalizeRows(x): """ Implement a function that normalizes each row of the matrix x (to have unit length). Argument: x -- A numpy matrix of shape (n, m) Returns: x -- The normalized (by row) numpy matrix. You are allowed to modify x. """ ### START CODE HERE ### (≈ 2 lines of code) # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True) x_norm = np.linalg.norm(x, axis=1, keepdims = True) # Divide x by its norm. x = x / x_norm ### END CODE HERE ### return x123456x = np.array([ [0, 3, 4], [1, 6, 4]])print("normalizeRows(x) = " + str(normalizeRows(x)))# normalizeRows(x) = [[ 0. 0.6 0.8 ]# [ 0.13736056 0.82416338 0.54944226]]Note:In normalizeRows(), you can try to print the shapes of x_norm and x, and then rerun the assessment. You’ll find out that they have different shapes. This is normal given that x_norm takes the norm of each row of x. So x_norm has the same number of rows but only 1 column. So how did it work when you divided x by x_norm? This is called broadcasting and we’ll talk about it now!1.5 - Broadcasting and the softmax functionA very important concept to understand in numpy is “broadcasting”. It is very useful for performing mathematical operations between arrays of different shapes. For the full details on broadcasting, you can read the official broadcasting documentation.Exercise: Implement a softmax function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about softmax in the second course of this specialization.Instructions:$\begin{align} \text{for } x \in \mathbb{R}^{1\times n} \text{, } softmax(x) &amp;= softmax(\begin{bmatrix}x_1 &amp;&amp;x_2 &amp;&amp;… &amp;&amp;x_n\end{bmatrix}) \\&amp;= \begin{bmatrix}\frac{e^{x_1}}{\sum_{j}e^{x_j}} &amp;&amp;\frac{e^{x_2}}{\sum_{j}e^{x_j}} &amp;&amp;… &amp;&amp;\frac{e^{x_n}}{\sum_{j}e^{x_j}}\end{bmatrix} \end{align}$\text{for a matrix } x \in \mathbb{R}^{m \times n} \text{, $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }\begin{align}softmax(x) &= softmax\begin{bmatrix} x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\ x_{21} & x_{22} & x_{23} & \dots & x_{2n} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ x_{m1} & x_{m2} & x_{m3} & \dots & x_{mn} \end{bmatrix} \\&= \begin{bmatrix} \frac{e^{x_{11}}}{\sum_{j}e^{x_{1j}}} & \frac{e^{x_{12}}}{\sum_{j}e^{x_{1j}}} & \frac{e^{x_{13}}}{\sum_{j}e^{x_{1j}}} & \dots & \frac{e^{x_{1n}}}{\sum_{j}e^{x_{1j}}} \\ \frac{e^{x_{21}}}{\sum_{j}e^{x_{2j}}} & \frac{e^{x_{22}}}{\sum_{j}e^{x_{2j}}} & \frac{e^{x_{23}}}{\sum_{j}e^{x_{2j}}} & \dots & \frac{e^{x_{2n}}}{\sum_{j}e^{x_{2j}}} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ \frac{e^{x_{m1}}}{\sum_{j}e^{x_{mj}}} & \frac{e^{x_{m2}}}{\sum_{j}e^{x_{mj}}} & \frac{e^{x_{m3}}}{\sum_{j}e^{x_{mj}}} & \dots & \frac{e^{x_{mn}}}{\sum_{j}e^{x_{mj}}} \end{bmatrix} \\ &= \begin{pmatrix} softmax\text{(first row of x)} \\ softmax\text{(second row of x)} \\ ... \\ softmax\text{(last row of x)} \\ \end{pmatrix} \end{align}123456789101112131415161718192021222324252627# GRADED FUNCTION: softmaxdef softmax(x): """Calculates the softmax for each row of the input x. Your code should work for a row vector and also for matrices of shape (n, m). Argument: x -- A numpy matrix of shape (n,m) Returns: s -- A numpy matrix equal to the softmax of x, of shape (n,m) """ ### START CODE HERE ### (≈ 3 lines of code) # Apply exp() element-wise to x. Use np.exp(...). x_exp = np.exp(x) # n x m # Create a vector x_sum that sums each row of x_exp. Use np.sum(..., axis = 1, keepdims = True). x_sum = np.sum(x_exp, axis = 1, keepdims = True) # n x 1 # Compute softmax(x) by dividing x_exp by x_sum. It should automatically use numpy broadcasting. s = x_exp / x_sum ### END CODE HERE ### return s12345678x = np.array([ [9, 2, 5, 0, 0], [7, 5, 0, 0 ,0]])print("softmax(x) = " + str(softmax(x)))# softmax(x) = [[ 9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04# 1.21052389e-04]# [ 8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04 # 8.01252314e-04]]Note:If you print the shapes of x_exp, x_sum and s above and rerun the assessment cell, you will see that x_sum is of shape (2,1) while x_exp and s are of shape (2,5). x_exp/x_sum works due to python broadcasting.Congratulations! You now have a pretty good understanding of python numpy and have implemented a few useful functions that you will be using in deep learning.What you need to remember:np.exp(x) works for any np.array x and applies the exponential function to every coordinatethe sigmoid function and its gradientimage2vector is commonly used in deep learningnp.reshape is widely used. In the future, you’ll see that keeping your matrix/vector dimensions straight will go toward eliminating a lot of bugs.numpy has efficient built-in functionsbroadcasting is extremely useful2) VectorizationIn deep learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is computationally efficient, you will use vectorization. For example, try to tell the difference between the following implementations of the dot/outer/elementwise product.123456789101112131415161718192021222324252627282930313233343536373839import timex1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###tic = time.process_time()dot = 0for i in range(len(x1)): dot+= x1[i]*x2[i]toc = time.process_time()print ("dot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC OUTER PRODUCT IMPLEMENTATION ###tic = time.process_time()outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zerosfor i in range(len(x1)): for j in range(len(x2)): outer[i,j] = x1[i]*x2[j]toc = time.process_time()print ("outer = " + str(outer) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC ELEMENTWISE IMPLEMENTATION ###tic = time.process_time()mul = np.zeros(len(x1))for i in range(len(x1)): mul[i] = x1[i]*x2[i]toc = time.process_time()print ("elementwise multiplication = " + str(mul) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy arraytic = time.process_time()gdot = np.zeros(W.shape[0])for i in range(W.shape[0]): for j in range(len(x1)): gdot[i] += W[i,j]*x1[j]toc = time.process_time()print ("gdot = " + str(gdot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")12345678910111213141516171819202122232425262728293031323334353637dot = 278 ----- Computation time = 0.0818910000000006msouter = [[ 81. 18. 18. 81. 0. 81. 18. 45. 0. 0. 81. 18. 45. 0. 0.] [ 18. 4. 4. 18. 0. 18. 4. 10. 0. 0. 18. 4. 10. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 63. 14. 14. 63. 0. 63. 14. 35. 0. 0. 63. 14. 35. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 81. 18. 18. 81. 0. 81. 18. 45. 0. 0. 81. 18. 45. 0. 0.] [ 18. 4. 4. 18. 0. 18. 4. 10. 0. 0. 18. 4. 10. 0. 0.] [ 45. 10. 10. 45. 0. 45. 10. 25. 0. 0. 45. 10. 25. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] ----- Computation time = 0.36966300000007557mselementwise multiplication = [ 81. 4. 10. 0. 0. 63. 10. 0. 0. 0. 81. 4. 25. 0. 0.] ----- Computation time = 0.10338200000004072msgdot = [ 24.54816166 26.72329382 24.6612841 ] ----- Computation time = 0.24241599999985652ms1234567891011121314151617181920212223242526x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]### VECTORIZED DOT PRODUCT OF VECTORS ###tic = time.process_time()dot = np.dot(x1,x2)toc = time.process_time()print ("dot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED OUTER PRODUCT ###tic = time.process_time()outer = np.outer(x1,x2)toc = time.process_time()print ("outer = " + str(outer) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED ELEMENTWISE MULTIPLICATION ###tic = time.process_time()mul = np.multiply(x1,x2)toc = time.process_time()print ("elementwise multiplication = " + str(mul) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")### VECTORIZED GENERAL DOT PRODUCT ###tic = time.process_time()dot = np.dot(W,x1)toc = time.process_time()print ("gdot = " + str(dot) + "\n ----- Computation time = " + str(1000*(toc - tic)) + "ms")12345678910111213141516171819202122dot = 278 ----- Computation time = 0.08295099999999778msouter = [[81 18 18 81 0 81 18 45 0 0 81 18 45 0 0] [18 4 4 18 0 18 4 10 0 0 18 4 10 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [63 14 14 63 0 63 14 35 0 0 63 14 35 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [81 18 18 81 0 81 18 45 0 0 81 18 45 0 0] [18 4 4 18 0 18 4 10 0 0 18 4 10 0 0] [45 10 10 45 0 45 10 25 0 0 45 10 25 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] ----- Computation time = 0.1127830000000607mselementwise multiplication = [81 4 10 0 0 63 10 0 0 0 81 4 25 0 0] ----- Computation time = 0.11321799999985949msgdot = [ 24.54816166 26.72329382 24.6612841 ] ----- Computation time = 0.06825100000007467msAs you may have noticed, the vectorized implementation is much cleaner and more efficient. For bigger vectors/matrices, the differences in running time become even bigger.Note that np.dot() performs a matrix-matrix or matrix-vector multiplication. This is different from np.multiply() and the * operator (which is equivalent to .* in Matlab/Octave), which performs an element-wise multiplication.2.1 Implement the L1 and L2 loss functionsExercise: Implement the numpy vectorized version of the L1 loss. You may find the function abs(x) (absolute value of x) useful.Reminder:The loss is used to evaluate the performance of your model. The bigger your loss is, the more different your predictions ($ \hat{y} $) are from the true values ($y$). In deep learning, you use optimization algorithms like Gradient Descent to train your model and to minimize the cost.L1 loss is defined as:\begin{align} & L_1(\hat{y}, y) = \sum_{i=0}^m|y^{(i)} - \hat{y}^{(i)}| \end{align}1234567891011121314151617# GRADED FUNCTION: L1def L1(yhat, y): """ Arguments: yhat -- vector of size m (predicted labels) y -- vector of size m (true labels) Returns: loss -- the value of the L1 loss function defined above """ ### START CODE HERE ### (≈ 1 line of code) loss = np.sum(np.abs(y - yhat)) ### END CODE HERE ### return loss1234yhat = np.array([.9, 0.2, 0.1, .4, .9])y = np.array([1, 0, 0, 1, 1])print("L1 = " + str(L1(yhat,y)))# L1 = 1.1Exercise: Implement the numpy vectorized version of the L2 loss. There are several way of implementing the L2 loss but you may find the function np.dot() useful. As a reminder, if $x = [x_1, x_2, …, x_n]$, then np.dot(x,x) = $\sum_{j=0}^n x_j^{2}$.L2 loss is defined as\begin{align} & L_2(\hat{y},y) = \sum_{i=0}^m(y^{(i)} - \hat{y}^{(i)})^2 \end{align}1234567891011121314151617# GRADED FUNCTION: L2def L2(yhat, y): """ Arguments: yhat -- vector of size m (predicted labels) y -- vector of size m (true labels) Returns: loss -- the value of the L2 loss function defined above """ ### START CODE HERE ### (≈ 1 line of code) loss = np.sum(np.power(y - yhat, 2)) ### END CODE HERE ### return loss1234yhat = np.array([.9, 0.2, 0.1, .4, .9])y = np.array([1, 0, 0, 1, 1])print("L2 = " + str(L2(yhat,y)))# L2 = 0.43Congratulations on completing this assignment. We hope that this little warm-up exercise helps you in the future assignments, which will be more exciting and interesting!What to remember:Vectorization is very important in deep learning. It provides computational efficiency and clarity.You have reviewed the L1 and L2 loss.You are familiar with many numpy functions such as np.sum, np.dot, np.multiply, np.maximum, etc…Logistic Regression with a Neural Network mindsetWelcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.Instructions:Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.You will learn to:Build the general architecture of a learning algorithm, including:Initializing parametersCalculating the cost function and its gradientUsing an optimization algorithm (gradient descent)Gather all three functions above into a main model function, in the right order.1 - PackagesFirst, let’s run the cell below to import all the packages that you will need during this assignment.numpy is the fundamental package for scientific computing with Python.h5py is a common package to interact with a dataset that is stored on an H5 file.matplotlib is a famous library to plot graphs in Python.PIL and scipy are used here to test your model with your own picture at the end.123456789import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset%matplotlib inline2 - Overview of the Problem setProblem Statement: You are given a dataset (“data.h5”) containing:- a training set of m_train images labeled as cat (y=1) or non-cat (y=0) - a test set of m_test images labeled as cat or non-cat - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px). You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat.Let’s get more familiar with the dataset. Load the data by running the following code.12# Loading the data (cat/non-cat)train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()We added “_orig” at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don’t need any preprocessing).Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the index value and re-run to see other images.1234# Example of a pictureindex = 25plt.imshow(train_set_x_orig[index])print ("y = " + str(train_set_y[:, index]) + ", it's a '" + classes[np.squeeze(train_set_y[:, index])].decode("utf-8") + "' picture.")Many software bugs in deep learning come from having matrix/vector dimensions that don’t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs.Exercise: Find the values for:123- m_train (number of training examples)- m_test (number of test examples)- num_px (= height = width of a training image)Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0].1234567891011121314### START CODE HERE ### (≈ 3 lines of code)m_train = train_set_x_orig.shape[0]m_test = test_set_x_orig.shape[0]num_px = train_set_x_orig.shape[1]### END CODE HERE ###print ("Number of training examples: m_train = " + str(m_train))print ("Number of testing examples: m_test = " + str(m_test))print ("Height/Width of each image: num_px = " + str(num_px))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_set_x shape: " + str(train_set_x_orig.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x shape: " + str(test_set_x_orig.shape))print ("test_set_y shape: " + str(test_set_y.shape))12345678Number of training examples: m_train = 209Number of testing examples: m_test = 50Height/Width of each image: num_px = 64Each image is of size: (64, 64, 3)train_set_x shape: (209, 64, 64, 3)train_set_y shape: (1, 209)test_set_x shape: (50, 64, 64, 3)test_set_y shape: (1, 50)For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $$ num_px $$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.Exercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $$ num_px $$ 3, 1).A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$$c$$d, a) is to use:X_flatten = X.reshape(X.shape[0], -1).T # X.T is the transpose of X123456789101112# Reshape the training and test examples### START CODE HERE ### (≈ 2 lines of code)train_set_x_flatten = train_set_x_orig.reshape(m_train, -1).Ttest_set_x_flatten = test_set_x_orig.reshape(m_test, -1).T### END CODE HERE ###print ("train_set_x_flatten shape: " + str(train_set_x_flatten.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))print ("test_set_y shape: " + str(test_set_y.shape))print ("sanity check after reshaping: " + str(train_set_x_flatten[0:5,0]))12345train_set_x_flatten shape: (12288, 209)train_set_y shape: (1, 209)test_set_x_flatten shape: (12288, 50)test_set_y shape: (1, 50)sanity check after reshaping: [17 31 56 22 33]To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).Let’s standardize our dataset.12train_set_x = train_set_x_flatten/255.test_set_x = test_set_x_flatten/255.What you need to remember:Common steps for pre-processing a new dataset are:Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, …)Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)“Standardize” the data3 - General Architecture of the learning algorithmIt’s time to design a simple algorithm to distinguish cat images from non-cat images.You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why Logistic Regression is actually a very simple Neural Network!Mathematical expression of the algorithm:For one example $x^{(i)}$:$z^{(i)} = w^T x^{(i)} + b$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$ \mathcal{L}(a^{(i)}, y^{(i)}) = - y^{(i)} \log(a^{(i)}) - (1-y^{(i)} ) \log(1-a^{(i)})$The cost is then computed by summing over all training examples:J = \frac{1}{m} \sum \limits_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})Key steps:In this exercise, you will carry out the following steps:1234- Initialize the parameters of the model- Learn the parameters for the model by minimizing the cost - Use the learned parameters to make predictions (on the test set)- Analyse the results and conclude4 - Building the parts of our algorithmThe main steps for building a Neural Network are:Define the model structure (such as number of input features)Initialize the model’s parametersLoop:Calculate current loss (forward propagation)Calculate current gradient (backward propagation)Update parameters (gradient descent)You often build 1-3 separately and integrate them into one function we call model().4.1 - Helper functionsExercise: Using your code from “Python Basics”, implement sigmoid(). As you’ve seen in the figure above, you need to compute $sigmoid( w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. Use np.exp().123456789101112131415161718# GRADED FUNCTION: sigmoiddef sigmoid(z): """ Compute the sigmoid of z Arguments: z -- A scalar or numpy array of any size. Return: s -- sigmoid(z) """ ### START CODE HERE ### (≈ 1 line of code) s = 1.0/(1+np.exp(-z)) ### END CODE HERE ### return s12print ("sigmoid([0, 2]) = " + str(sigmoid(np.array([0,2]))))# sigmoid([0, 2]) = [ 0.5 0.88079708]4.2 - Initializing parametersExercise: Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don’t know what numpy function to use, look up np.zeros() in the Numpy library’s documentation.1234567891011121314151617181920212223# GRADED FUNCTION: initialize_with_zerosdef initialize_with_zeros(dim): """ This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0. Argument: dim -- size of the w vector we want (or number of parameters in this case) Returns: w -- initialized vector of shape (dim, 1) b -- initialized scalar (corresponds to the bias) """ ### START CODE HERE ### (≈ 1 line of code) w = np.zeros((dim, 1)) b = 0 ### END CODE HERE ### assert(w.shape == (dim, 1)) assert(isinstance(b, float) or isinstance(b, int)) return w, b1234567dim = 2w, b = initialize_with_zeros(dim)print ("w = " + str(w))print ("b = " + str(b))# w = [[ 0.]# [ 0.]]# b = 0For image inputs, w will be of shape (num_px $\times$ num_px $\times$ 3, 1).4.3 - Forward and Backward propagationNow that your parameters are initialized, you can do the “forward” and “backward” propagation steps for learning the parameters.Exercise: Implement a function propagate() that computes the cost function and its gradient.Hints:Forward Propagation:You get XYou compute $A = \sigma(w^T X + b) = (a^{(1)}, a^{(2)}, …, a^{(m-1)}, a^{(m)})$You calculate the cost function: $J = -\frac{1}{m}\sum \limits_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$Here are the two formulas you will be using:$\frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T$$\frac{\partial J}{\partial b} = \frac{1}{m} \sum \limits_{i=1}^m (a^{(i)}-y^{(i)}) $1234567891011121314151617181920212223242526272829303132333435363738394041424344# GRADED FUNCTION: propagatedef propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(np.dot(w.T, X)+b) # compute activation cost = (-1.0 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = (1.0 / m) * np.dot(X,(A-Y).T) db = (1.0 / m) * np.sum(A-Y) ### END CODE HERE ### assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) assert(cost.shape == ()) grads = &#123;"dw": dw, "db": db&#125; return grads, cost123456789w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])grads, cost = propagate(w, b, X, Y)print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"]))print ("cost = " + str(cost))# dw = [[ 0.99845601]# [ 2.39507239]]# db = 0.00145557813678# cost = 5.801545319394.4 - OptimizationYou have initialized your parameters.You are also able to compute a cost function and its gradient.Now, you want to update the parameters using gradient descent.Exercise: Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\theta$, the update rule is $ \theta = \theta - \alpha \text{ } d\theta$, where $\alpha$ is the learning rate.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# GRADED FUNCTION: optimizedef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): """ This function optimizes w and b by running a gradient descent algorithm Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of shape (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- True to print the loss every 100 steps Returns: params -- dictionary containing the weights w and bias b grads -- dictionary containing the gradients of the weights and bias with respect to the cost function costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve. Tips: You basically need to write down two steps and iterate through them: 1) Calculate the cost and the gradient for the current parameters. Use propagate(). 2) Update the parameters using gradient descent rule for w and b. """ costs = [] for i in range(num_iterations): # Cost and gradient calculation (≈ 1-4 lines of code) ### START CODE HERE ### grads, cost = propagate(w, b, X, Y) ### END CODE HERE ### # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # update rule (≈ 2 lines of code) ### START CODE HERE ### w = w - learning_rate * dw b = b - learning_rate * db ### END CODE HERE ### # Record the costs if i % 100 == 0: costs.append(cost) # Print the cost every 100 training iterations if print_cost and i % 100 == 0: print ("Cost after iteration %i: %f" %(i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs123456params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print ("w = " + str(params["w"]))print ("b = " + str(params["b"]))print ("dw = " + str(grads["dw"]))print ("db = " + str(grads["db"]))123456w = [[ 0.19033591] [ 0.12259159]]b = 1.92535983008dw = [[ 0.67752042] [ 1.41625495]]db = 0.219194504541Exercise: The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function. There are two steps to computing predictions:Calculate $\hat{Y} = A = \sigma(w^T X + b)$Convert the entries of a into 0 (if activation &lt;= 0.5) or 1 (if activation &gt; 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this).12345678910111213141516171819202122232425262728293031323334353637# GRADED FUNCTION: predictdef predict(w, b, X): ''' Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b) Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Returns: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X ''' m = X.shape[1] Y_prediction = np.zeros((1,m)) w = w.reshape(X.shape[0], 1) # Compute vector "A" predicting the probabilities of a cat being present in the picture ### START CODE HERE ### (≈ 1 line of code) A = sigmoid(np.dot(w.T, X) + b) ### END CODE HERE ### for i in range(A.shape[1]): # Convert probabilities A[0,i] to actual predictions p[0,i] ### START CODE HERE ### (≈ 4 lines of code) if A[0,i] &gt; 0.5: Y_prediction[0,i] = 1 else: Y_prediction[0,i] = 0 ### END CODE HERE ### assert(Y_prediction.shape == (1, m)) return Y_prediction12345w = np.array([[0.1124579],[0.23106775]])b = -0.3X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])print ("predictions = " + str(predict(w, b, X)))# predictions = [[ 1. 1. 0.]]What to remember:You’ve implemented several functions that:Initialize (w,b)Optimize the loss iteratively to learn parameters (w,b):computing the cost and its gradientupdating the parameters using gradient descentUse the learned (w,b) to predict the labels for a given set of examples5 - Merge all functions into a modelYou will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.Exercise: Implement the model function. Use the following notation:123- Y_prediction_test for your predictions on the test set- Y_prediction_train for your predictions on the train set- w, costs, grads for the outputs of optimize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# GRADED FUNCTION: modeldef model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False): """ Builds the logistic regression model by calling the function you've implemented previously Arguments: X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train) Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train) X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test) Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test) num_iterations -- hyperparameter representing the number of iterations to optimize the parameters learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize() print_cost -- Set to true to print the cost every 100 iterations Returns: d -- dictionary containing information about the model. """ ### START CODE HERE ### # initialize parameters with zeros (≈ 1 line of code) w, b = initialize_with_zeros(X_train.shape[0]) # Gradient descent (≈ 1 line of code) parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost) # Retrieve parameters w and b from dictionary "parameters" w = parameters["w"] b = parameters["b"] # Predict test/train set examples (≈ 2 lines of code) Y_prediction_test = predict(w, b, X_test) Y_prediction_train = predict(w, b, X_train) ### END CODE HERE ### # Print train/test Errors print("train accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100)) print("test accuracy: &#123;&#125; %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100)) d = &#123;"costs": costs, "Y_prediction_test": Y_prediction_test, "Y_prediction_train" : Y_prediction_train, "w" : w, "b" : b, "learning_rate" : learning_rate, "num_iterations": num_iterations&#125; return d1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)12345678910111213141516171819202122Cost after iteration 0: 0.693147Cost after iteration 100: 0.584508Cost after iteration 200: 0.466949Cost after iteration 300: 0.376007Cost after iteration 400: 0.331463Cost after iteration 500: 0.303273Cost after iteration 600: 0.279880Cost after iteration 700: 0.260042Cost after iteration 800: 0.242941Cost after iteration 900: 0.228004Cost after iteration 1000: 0.214820Cost after iteration 1100: 0.203078Cost after iteration 1200: 0.192544Cost after iteration 1300: 0.183033Cost after iteration 1400: 0.174399Cost after iteration 1500: 0.166521Cost after iteration 1600: 0.159305Cost after iteration 1700: 0.152667Cost after iteration 1800: 0.146542Cost after iteration 1900: 0.140872train accuracy: 99.04306220095694 %test accuracy: 70.0 %Comment: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test accuracy is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you’ll build an even better classifier next week!Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the index variable) you can look at predictions on pictures of the test set.1234# Example of a picture that was wrongly classified.index = 1plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))print ("y = " + str(test_set_y[0,index]) + ", you predicted that it is a \"" + classes[d["Y_prediction_test"][0,index]].decode("utf-8") + "\" picture.")Let’s also plot the cost function and the gradients.1234567# Plot learning curve (with costs)costs = np.squeeze(d['costs'])plt.plot(costs)plt.ylabel('cost')plt.xlabel('iterations (per hundreds)')plt.title("Learning rate =" + str(d["learning_rate"]))plt.show()Interpretation:You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting.6 - Further analysis (optional/ungraded exercise)Congratulations on building your first image classification model. Let’s analyze it further, and examine possible choices for the learning rate $\alpha$.Choice of learning rateReminder:In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\alpha$ determines how rapidly we update the parameters. If the learning rate is too large we may “overshoot” the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That’s why it is crucial to use a well-tuned learning rate.Let’s compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the learning_rates variable to contain, and see what happens.1234567891011121314151617learning_rates = [0.01, 0.001, 0.0001]models = &#123;&#125;for i in learning_rates: print ("learning rate is: " + str(i)) models[str(i)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = i, print_cost = False) print ('\n' + "-------------------------------------------------------" + '\n')for i in learning_rates: plt.plot(np.squeeze(models[str(i)]["costs"]), label= str(models[str(i)]["learning_rate"]))plt.ylabel('cost')plt.xlabel('iterations (hundreds)')legend = plt.legend(loc='upper center', shadow=True)frame = legend.get_frame()frame.set_facecolor('0.90')plt.show()Interpretation:Different learning rates give different costs and thus different predictions results.If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost).A lower cost doesn’t mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.In deep learning, we usually recommend that you:Choose the learning rate that better minimizes the cost function.If your model overfits, use other techniques to reduce overfitting. (We’ll talk about this in later videos.)7 - Test with your own image (optional/ungraded exercise)Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub. 2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder 3. Change your image&#39;s name in the following code 4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)! 12345678910111213## START CODE HERE ## (PUT YOUR IMAGE NAME) my_image = "my_image.jpg" # change this to the name of your image file ## END CODE HERE ### We preprocess the image to fit your algorithm.fname = "images/" + my_imageimage = np.array(ndimage.imread(fname, flatten=False))image = image/255.my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((1, num_px*num_px*3)).Tmy_predicted_image = predict(d["w"], d["b"], my_image)plt.imshow(image)print("y = " + str(np.squeeze(my_predicted_image)) + ", your algorithm predicts a \"" + classes[int(np.squeeze(my_predicted_image)),].decode("utf-8") + "\" picture.")What to remember from this assignment:Preprocessing the dataset is important.You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().Tuning the learning rate (which is an example of a “hyperparameter”) can make a big difference to the algorithm. You will see more examples of this later in this course!Finally, if you’d like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:- Play with the learning rate and the number of iterations - Try different initialization methods and compare the results Test other preprocessings (center the data, or divide each row by its standard deviation)参考资料https://mooc.study.163.com/university/deeplearning_ai#/chttps://github.com/fengdu78/Coursera-ML-AndrewNg-Noteshttps://blog.csdn.net/Koala_Tree/article/details/79913655https://blog.csdn.net/pengchengliu/article/details/80932232https://www.coursera.org/learn/neural-networks-deep-learning/notebook/zAgPl/logistic-regression-with-a-neural-network-mindset]]></content>
      <categories>
        <category>deeplearning.ai笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深度学习入门-基于Python的理论实现》笔记]]></title>
    <url>%2F2019%2F08%2F13%2F%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8-%E5%9F%BA%E4%BA%8EPython%E7%9A%84%E7%90%86%E8%AE%BA%E5%AE%9E%E7%8E%B0%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[第一章：Python入门略。第二章：感知机简单例子$x_1,x_2$是输入信号，$y$是输出信号，$w_1,w_2$是权重。图中的圈称为”神经元”，或者“节点”。只有传送过来的信号总和超过某个阈值$\theta$，才会输出1。数学公式表示：$y=\left\{\begin{aligned}0 \quad (w_1x_1+w_2x_2\le\theta) \\1 \quad(w_1x_1+w_2x_2\gt \theta) \end{aligned} \right.$导入权重和偏置$y=\left\{\begin{aligned}0 \quad (b+w_1x_1+w_2x_2\le0) \\1 \quad(b+w_1x_1+w_2x_2\gt 0) \end{aligned} \right.$$\theta=-b$简单实现与门12345678910111213141516171819202122import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = AND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 0# (1, 0) -&gt; 0# (0, 1) -&gt; 0# (1, 1) -&gt; 1非门1234567891011121314151617181920212223# coding: utf-8import numpy as npdef NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = NAND(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y)) # (0, 0) -&gt; 1# (1, 0) -&gt; 1# (0, 1) -&gt; 1# (1, 1) -&gt; 0或门123456789101112131415161718# coding: utf-8import numpy as npdef OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0: return 0 else: return 1if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = OR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))感知机的可视化图：灰色区域是感知机输出0的区域，这个区域与或门的性质一致异或门感知机的局限性就在于它只能表示由一条直线分割的空间。通过组合与门、与非门、或门实现异或门1234567891011121314151617# coding: utf-8from and_gate import ANDfrom or_gate import ORfrom nand_gate import NANDdef XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y# 多层感知机if __name__ == '__main__': for xs in [(0, 0), (1, 0), (0, 1), (1, 1)]: y = XOR(xs[0], xs[1]) print(str(xs) + " -&gt; " + str(y))第三章：神经网络简单例子感知机公式可改写成$y=h(b+w_1x_1+w_2x_2)$$h(x)=\left\{\begin{aligned}0 \quad (x\le0) \\1 \quad(x\gt 0) \end{aligned} \right.$激活函数$加权总和a=h(b+w_1x_1+w_2x_2)$$激活函数转换这总和y=h(a)$sigmoid$h(x)=\frac{1} {(1+e^{-x)} }$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef sigmoid(x): return 1 / (1 + np.exp(-x)) X = np.arange(-5.0, 5.0, 0.1)Y = sigmoid(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1)plt.show()阶跃函数$h(x)=\left\{\begin{aligned}1 \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef step_function(x): return np.array(x &gt; 0, dtype=np.int)X = np.arange(-5.0, 5.0, 0.1)Y = step_function(X)plt.plot(X, Y)plt.ylim(-0.1, 1.1) plt.show()ReLU函数$h(x)=\left\{\begin{aligned}x \quad (x\gt0) \\ 0 \quad(x\le 0) \end{aligned} \right.$12345678910111213# coding: utf-8import numpy as npimport matplotlib.pylab as pltdef relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-1.0, 5.5)plt.show()3层神经网络的实现$a_1^{(1)}=w_{11}^{(1)}x_1+w_{12}^{(1)}x_2+b_1^{(1)}$矩阵乘法表示：$\bf{A}^{(1)}=XW^{(1)}+B^{(1)}$ 1x2 2x3 = 1x3输出层的设计恒等函数softmax函数$y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}$实现softmax函数的注意事项：超大值无法表示的问题，即溢出，在进行计算机的运算时必须注意，为了防止溢出，一般会加上或减去输入信号的最大值，如下公式中的$C’$：$\begin{align}y_k=\frac{e^{(a_k)}}{\sum \limits _{i=1} ^{n} e^{(a_i)}}&amp;=\frac{Ce^{(a_k)}}{C\sum \limits _{i=1} ^{n} e^{(a_i)}}\\&amp;=\frac{e^{(a_k+logC)}}{\sum \limits _{i=1} ^{n} e^{(a_i+logC)}}\\&amp;=\frac{e^{(a_k+C’)}}{\sum \limits _{i=1} ^{n} e^{(a_i+C’)}}\end{align}$手写数字识别1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8import sys, ossys.path.append(os.pardir) # 親ディレクトリのファイルをインポートするための設定import numpy as npimport picklefrom dataset.mnist import load_mnistfrom common.functions import sigmoid, softmaxdef get_data(): (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False) return x_test, t_testdef init_network(): with open(&quot;sample_weight.pkl&quot;, &apos;rb&apos;) as f: network = pickle.load(f) return networkdef predict(network, x): w1, w2, w3 = network[&apos;W1&apos;], network[&apos;W2&apos;], network[&apos;W3&apos;] b1, b2, b3 = network[&apos;b1&apos;], network[&apos;b2&apos;], network[&apos;b3&apos;] a1 = np.dot(x, w1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, w2) + b2 z2 = sigmoid(a2) a3 = np.dot(z2, w3) + b3 y = softmax(a3) return yx, t = get_data()network = init_network()batch_size = 100 # バッチの数accuracy_cnt = 0for i in range(0, len(x), batch_size): x_batch = x[i:i+batch_size] y_batch = predict(network, x_batch) p = np.argmax(y_batch, axis=1) accuracy_cnt += np.sum(p == t[i:i+batch_size])print(&quot;Accuracy:&quot; + str(float(accuracy_cnt) / len(x)))——————————————-有空再做笔记——————————————-参考资料《深度学习入门-基于Python的理论实现》https://github.com/oreilly-japan/deep-learning-from-scratch]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法小结]]></title>
    <url>%2F2019%2F08%2F02%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[排序汇总插入排序算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：从第一个元素开始，该元素可以认为已经被排序；取出下一个元素，在已经排序的元素序列中从后向前扫描；如果该元素（已排序）大于新元素，将该元素移到下一位置；重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；将新元素插入到该位置后；重复步骤2~5。动图演示代码描述123456789101112int insert_sort(int *arr, int n)&#123; int i, j; for (i = 1; i &lt; n; i++)&#123; if (arr[i] &lt; arr[i - 1])&#123; int temp = arr[i]; for (j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--) arr[j + 1] = arr[j]; arr[j + 1] = temp; &#125; &#125; return 0;&#125;优化折半插入排序123456789101112131415161718192021void binary_insert_sort(int* arr, int n) &#123; int i, j, mid, low, high, temp; for (i = 1; i &lt; n; i++)&#123; temp = arr[i]; low = 0; high = i; while (low &lt;= high)&#123; mid = (low + high) / 2; if (temp &gt; arr[mid])&#123; low = mid + 1; &#125; else &#123; high = mid - 1; &#125; &#125; for (j = i - 1; j &gt;= low; j--)&#123; arr[j + 1] = arr[j]; &#125; arr[low] = temp; &#125;&#125;希尔排序1959年Shell发明，第一个突破$O(n^2)$的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：选择一个增量序列$t_1,t_2,…,t_k，$其中$t_i&gt;t_j$，$t_k=1$；按增量序列个数k，对序列进行k 趟排序；每趟排序，根据对应的增量$t_i$，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。动图演示算法描述通常写法通常写法12345678910111213for (gap = n / 2; gap &gt; 0; gap /= 2)&#123; for (j = gap; j &lt; n; j++)&#123;//从数组第gap个元素开始 if (a[j] &lt; a[j - gap])&#123;//每个元素与自己组内的数据进行直接插入排序 int temp = a[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; a[k] &gt; temp)&#123; a[k + gap] = a[k]; k -= gap; &#125; a[k + gap] = temp; &#125; &#125;&#125;另一种写法1234for (gap = n / 2; gap &gt; 0; gap /= 2) for (i = gap; i &lt; n; i++) for (j = i - gap; j &gt;= 0 &amp;&amp; a[j] &gt; a[j + gap]; j -= gap) swap(a[j], a[j + gap]);增量序列$Shell：1，…，N/8，N/4，N/2 \quad 最坏O(n^2)$$Hibbard：{1, 3, …, 2^k-1} \quad 最坏O(n^3/2) \quad 猜想T(avg) = O(n^5/4)$$Sedgewick：{1, 5, 19, 41, 109…}该序列中的项或者是94^i - 92^i + 1或者是4^i - 3*2^i + 1$$猜想T(avg) = O(n^7/6) \quad T(worst)O(n^4/3)$选择排序算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：初始状态：无序区为$R[1..n]$，有序区为空；第$i$趟排序($i=1,2,3…n-1)$开始时，当前有序区和无序区分别为$R[1..i-1]$和$R(i..n）$。该趟排序从当前无序区中-选出关键字最小的记录 $R[k]$，将它与无序区的第1个记录$R$交换，使$R[1..i]$和$R[i+1..n)$分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；$n-1$趟结束，数组有序化了。动图演示代码描述1234567891011121314151617void select_sort(int number[])&#123; int i, j, min; for(i = 1; i &lt; MAX; i++) &#123; min = i; for(j = i+1; j &lt;= MAX; j++) &#123; if(number[min] &gt; number[j]) min = j; &#125; if(min != i)&#123; array[min] = array[min] + array[i]; array[i] = array[min] - array[i]; array[min] = array[min] - array[i]; &#125; &#125;&#125;优化每次查找时不仅找出最小值，还找出最大值，分别插到前面和后面，可以减少一半的查询时间。ps:也有人说是负优化12345678910111213141516171819202122232425void select_sort_plus(int array[], int size)&#123; int left = 0;//查找的左边界 int right = size - 1;//查找的右边界 while(left &lt; right) &#123; int min = left; int max = right; for (int i = left; i &lt;= right; i++)&#123; if (array[min]&gt;array[i])min = i; if (array[max] &lt; array[i])max = i; if (array[min] &lt; array[left]) &#123; array[min] = array[min] + array[left]; array[left] = array[min] - array[left]; array[min] = array[min] - array[left]; &#125; if (array[max] &gt; array[right]) &#123; array[max] = array[max] + array[right]; array[right] = array[max] - array[right]; array[max] = array[max] - array[right]; &#125; &#125; right--; left++; &#125;&#125;堆排序算法描述将初始待排序关键字序列$(R1,R2….Rn)$构建成大顶堆，此堆为初始的无序区；将堆顶元素$R[1]$与最后一个元素$R[n]$交换，此时得到新的无序区$(R1,R2,……Rn-1)$和新的有序区$(Rn)$,且满足$R[1,2…n-1]$&lt;=$R[n]$；由于交换后新的堆顶$R[1]$可能违反堆的性质，因此需要对当前无序区$(R1,R2,……Rn-1)$调整为新堆，然后再次将$R[1]$与无序区最后一个元素交换，得到新的无序区$(R1,R2….Rn-2)$和新的有序区$(Rn-1,Rn)$。不断重复此过程直到有序区的元素个数为$n-1$，则整个排序过程完成。动图演示代码描述1234567891011121314151617181920212223242526272829int build_heap(int arr[], int left, int right)&#123; int child,tmp; for (tmp = arr[left]; 2 * left + 1 &lt; right; left = child) &#123; //注意数组下标是从0开始的，所以左孩子的求发不是2*i child = 2 * left + 1; if (child != right - 1 &amp;&amp; arr[child + 1] &gt; arr[child]) ++child; //找到最大的儿子节点 if (tmp &lt; arr[child]) arr[left] = arr[child]; else break; &#125; arr[left] = tmp; return 0;&#125;//堆排序int heap_sort(int arr[], int left, int right)&#123; int i; for (i = left + (right - left) / 2; i &gt;= 0; --i) //构造堆 build_heap(arr, i, right); for (i = right; i&gt;0; --i)&#123; //将最大元素（根）与数组末尾元素交换，从而删除最大元素，重新构造堆 swap(arr,0, i); build_heap(arr, 0, i); &#125; return 0;&#125;冒泡排序算法描述比较相邻的元素。如果第一个比第二个大，就交换它们两个；对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；针对所有的元素重复以上的步骤，除了最后一个；重复步骤1~3，直到排序完成。动图演示代码描述12345678910111213void bubble_sort(int a[], int n)&#123; int i, j, temp; for (j = 0; j &lt; n - 1; j++)&#123; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; &#125; &#125; &#125;&#125;算法分析稳定最好情况 顺序 $T=O(n)$最坏情况 逆序 $T=O(n^2)$优化1.定义一个flag，用来判断有没有进行交换，如果在某次内层循环中没有交换操作，就说明此时数组已经是有序了的，不用再进行判断，这样可以节省时间。12345678910111213141516171819void bubble_sort(int a[], int n)&#123; int i, j, temp; // C语言没有bool int isSorted = 0; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; n - 1 - j; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; &#125; &#125; if(isSorted == 0) break; &#125;&#125;2.每一次交换记录最后一次交换的位置，为零的时候就停止。12345678910111213141516171819202122void bubble_sort(int a[], int n)&#123; int i, j, temp; int isSorted = 0; int last = 0; int border = n - 1; for (j = 0; j &lt; n - 1; j++)&#123; isSorted = 0; for (i = 0; i &lt; border; i++)&#123; if(a[i] &gt; a[i + 1])&#123; temp = a[i]; a[i] = a[i + 1]; a[i + 1] = temp; isSorted = 1; last = i; &#125; &#125; border = last; if(isSorted = 0) break; &#125;&#125;3.鸡尾酒排序左右交替比较，交换例子第一次第二次第三次last没有变，结束原本排序8次，现在只需要3次记下两个边界值，分离出有序区。1234567891011121314151617181920212223242526272829303132333435363738def CockTailSort(array): """ :param array: 无序数组 :return: 有序数组 """ # 左右侧最后一次交换位置和左右边界 last_left = last_right = left_sort_border = 0 right_sort_border = len(array) - 1 i = j = 0 while i &lt; len(array) / 2: # 有序标记，每一轮的初始是true is_sorted = True j = left_sort_border while j &lt; right_sort_border: if array[j] &gt; array[j + 1]: array[j], array[j + 1] = array[j + 1], array[j] # 有元素交换，不是有序 is_sorted = False last_right = j j += 1 right_sort_border = last_right if is_sorted: break # 偶数轮之前，重新标记为true is_sorted = True j = right_sort_border while j &gt; left_sort_border: if array[j] &lt; array[j - 1]: array[j], array[j - 1] = array[j - 1], array[j] # 有元素交换，不是有序 is_sorted = False last_left = j j -= 1 left_sort_border = last_left if is_sorted: break i += 1 return array快速排序算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：从数列中挑出一个元素，称为 “基准”（pivot）；重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。动图演示代码描述左右指针法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴。设置两个变量$left = 0;right = N - 1$;从$left$一直向后走，直到找到一个大于$key$的值，$right$从后至前，直至找到一个小于$key$的值，然后交换这两个数。重复第三步，一直往后找，直到$left$和$right$相遇，这时将$key$放置$left$的位置即可。1234567891011121314int PartSort(int* array,int left,int right) &#123; int&amp; key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; swap(array[left],array[right]); &#125; swap(array[left],key); return left; &#125;挖坑法选取一个关键字($key$)作为枢轴，一般取整组记录的第一个数/最后一个，这里采用选取序列最后一个数为枢轴，也是初始的坑位。设置两个变量$left = 0;right = N - 1;$从$left$一直向后走，直到找到一个大于$key$的值，然后将该数放入坑中，坑位变成了$array[left]$。$right$一直向前走，直到找到一个小于$key$的值，然后将该数放入坑中，坑位变成了$array[right]$。重复3和4的步骤，直到$left$和$right$相遇，然后将$key$放入最后一个坑位。123456789101112131415int PartSort(int* array,int left,int right) &#123; int key = array[right]; while(left &lt; right) &#123; while(left &lt; right &amp;&amp; array[left] &lt;= key) &#123; ++left; &#125; array[right] = array[left]; while(left &lt; right &amp;&amp; array[right] &gt;= key) &#123; --right; &#125; array[left] = array[right]; &#125; array[right] = key; return right;&#125;前后指针法定义变量$cur$指向序列的开头，定义变量$pre$指向$cur$的前一个位置。当$array[cur] &lt; key$时，$cur$和$pre$同时往后走，如果$array[cur]&gt;key$，$cur$往后走，$pre$留在大于$key$的数值前一个位置。当$array[cur]$再次 &lt; $key$时，交换$array[cur]$和$array[pre]$。123456789101112131415161718int PartSort(int* array,int left,int right) &#123; if(left &lt; right)&#123; int key = array[right]; int cur = left; int pre = cur - 1; while(cur &lt; right) &#123; while(array[cur] &lt; key &amp;&amp; ++pre != cur)&#123; //如果找到小于key的值，并且cur和pre之间有距离时则进行交换。 //注意两个条件的先后位置不能更换 swap(array[cur],array[pre]); &#125; ++cur; &#125; swap(array[++pre],array[right]); return pre; &#125; return -1; &#125;非递归实现递归的算法主要是在划分子区间，如果要非递归实现快排，只要使用一个栈来保存区间就可以了。一般将递归程序改成非递归首先想到的就是使用栈，因为递归本身就是一个压栈的过程。1234567891011121314151617181920212223242526void QuickSortNotR(int* array,int left,int right)&#123; assert(array); stack&lt;int&gt; s; s.push(left); s.push(right);//后入的right，所以要先拿right while(!s.empty)//栈不为空 &#123; int right = s.top(); s.pop(); int left = s.top(); s.pop(); int index = PartSort(array,left,right); if((index - 1) &gt; left)//左子序列 &#123; s.push(left); s.push(index - 1); &#125; if((index + 1) &lt; right)//右子序列 &#123; s.push(index + 1); s.push(right); &#125; &#125;&#125;优化优化一：当待排序序列的长度分割到一定大小后，使用插入排序原因：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排。截止范围：待排序序列长度N = 10，虽然在5~20之间任一截止范围都有可能产生类似的结果，这种做法也避免了一些有害的退化情形。优化二：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割举例：待排序序列 1 4 6 7 6 6 7 6 8 6三数取中选取基准：下标为4的数6转换后，待分割序列：6 4 6 7 1 6 7 6 8 6​ 基准key：6本次划分后，未对与key元素相等处理的结果：1 4 6 6 7 6 7 6 8 6下次的两个子序列为：1 4 6 和 7 6 7 6 8 6本次划分后，对与key元素相等处理的结果：1 4 6 6 6 6 6 7 8 7下次的两个子序列为：1 4 和 7 8 7经过对比，我们可以看出，在一次划分后，把与key相等的元素聚在一起，能减少迭代次数，效率会提高不少具体过程：在处理过程中，会有两个步骤第一步，在划分过程中，把与key相等元素放入数组的两端第二步，划分结束后，把与key相等的元素移到枢轴周围归并排序算法描述把长度为n的输入序列分成两个长度为n/2的子序列；对这两个子序列分别采用归并排序；将两个排序好的子序列合并成一个最终的排序序列。动图演示代码描述递归实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/将数组b[]中的数复制到数组a[]中 template&lt;class Type&gt; void Copy(Type a[],Type b[],int left,int right) &#123; for(int i=left;i&lt;=right;i++) a[i]=b[i]; &#125; //将已排好序的数组合并到数组b[]中 template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) //i的取值范围为 [left,mid], j的取值范围为 [mid+1,right] &#123; if(a[i]&lt;a[j]) //取左右两边数组中较小的元素放入数组b中，最后得到的数组b即为有序 b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) //说明右边的数组的元素个数多 for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;i&lt;=mid;i++) b[k++]=a[z]; &#125; //将待排序集合一分为二，直至待排序集合只剩下一个元素为止， //然后不断合并两个排好序的数组段 template&lt;class Type&gt; void MergeSort(Type a[],int left,int right) &#123; Type *b=new Type [maxn]; if(left&lt;right) //控制待排序数组中至少有两个元素，一个元素时为有序 &#123; int i=(left+right)/2; //取数组中点，将数组尽量均等划分 MergeSort(a,left,i); //将左半段进行递归排序 MergeSort(a,i+1,right); //将右半段进行递归排序 Merge(a,b,left,i,right); //合并到数组b Copy(a,b,left,right); //复制到数组a &#125; delete[] b; &#125;非递归实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556template&lt;class Type&gt; void Merge(Type a[],Type b[],int left,int mid,int right) &#123; int i=left; int j=mid+1; int k=left; while(i&lt;=mid &amp;&amp; j&lt;=right) &#123; if(a[i]&lt;a[j]) b[k++]=a[i++]; else b[k++]=a[j++]; &#125; if(i&gt;mid) for(int z=j;z&lt;=right;z++) b[k++]=a[z]; else for(int z=i;z&lt;=mid;z++) b[k++]=a[z]; &#125; //合并大小为s的相邻子数组 template&lt;class Type&gt; void MergePass(Type x[],Type y[],int s,int n) &#123; int i=0; while(i+2*s-1&lt;n) &#123; Merge(x,y,i,i+s-1,i+2*s-1); //合并大小为s的相邻2段子数组 i+=2*s; &#125; if(i+s&lt;n) //剩下的元素个数m满足：s&lt;= m &lt;2*s Merge(x,y,i,i+s-1,n-1); else //剩下的元素个数m满足：m&lt;s for(int j=i;j&lt;=n-1;j++) y[j]=x[j]; &#125; template&lt;class Type&gt; void MergeSort(Type c[],int n) &#123; Type *d=new Type [n]; int s=1; while(s&lt;n) &#123; MergePass(c,d,s,n); //合并到数组d s+=s; MergePass(d,c,s,n); //合并到数组c s+=s; &#125; delete[] b; &#125;计数排序计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。算法描述找出待排序的数组中最大和最小的元素；统计数组中每个值为i的元素出现的次数，存入数组C的第i项；对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。动图演示代码描述12345678910111213141516171819202122232425262728void CountSort(int* array, int size) &#123; assert(array); int max = array[0];//序列中的最大值 int min = array[0];//序列中的最小值 for(int i = 0;i &lt; size;++i) &#123; if(array[i] &gt;= max) &#123; max = array[i]; &#125; else &#123; min = array[i]; &#125; &#125; int range = max - min + 1;//需要开辟的空间大小 int* count = new int[range]; memset(count,0,sizeof(int)*range);//辅助空间初始化为0,0代表没有那个数 for(int i = 0;i &lt; size;++i) &#123; count[array[i] - min]++;//array[i]-min是将该数对应到辅助空间的下标 &#125; int index = 0; //遍历辅助空间 for(int i = 0;i &lt; range;++i) &#123; //下标处的数值是几，说明该数出现了几次 while(count[i]--) &#123; array[index++] = i + min;//将下标处的数对应回原数组 &#125; &#125; delete[] count;&#125;桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。算法描述设置一个定量的数组当作空桶；遍历输入数据，并且把数据一个一个放到对应的桶里去；对每个不是空的桶进行排序；从不是空的桶里把排好序的数据拼接起来。动图演示代码描述12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#pragma once//每一个节点的结构struct node&#123; int key; //关键字，在桶中统计桶中数据量，在数据节点中就是节点的数据 struct node *next;&#125;;//声明：void PrintBucketSort(node** bucket, int bucket_size);int f(int x);void BucketSort(int* a, int size,int bucket_size)&#123; assert(a); //给桶申请空间 node** bucket = new node*[bucket_size*sizeof(node)]; //初始化 for (int i = 0; i &lt; bucket_size; ++i) &#123; bucket[i] = new node[sizeof(node)]; //每一个桶 bucket[i]-&gt;key = 0; bucket[i]-&gt;next = nullptr; &#125; for (int j = 0; j &lt; size; ++j) &#123; node* sub_node = new node[sizeof(node)]; //桶下的每一个节点 sub_node-&gt;key = a[j]; sub_node-&gt;next = nullptr; //计算这数据在哪个桶中 int num = f(a[j]); //让一个指针指向这个桶号的头 node* sub_head = bucket[num]; //开始插入 if (sub_head-&gt;next == nullptr) &#123; bucket[num]-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; //该桶号不为空，那么插入排序 else &#123; while (sub_head-&gt;next != nullptr &amp;&amp; sub_node-&gt;key &gt;= sub_head-&gt;next-&gt;key) &#123; sub_head = sub_head-&gt;next; &#125; sub_node-&gt;next = sub_head-&gt;next; sub_head-&gt;next = sub_node; bucket[num]-&gt;key++; &#125; &#125; //打印 PrintBucketSort(bucket, bucket_size);&#125;//映射函数int f(int x)&#123; return (x / 10);&#125;//打印void PrintBucketSort(node** bucket, int bucket_size)&#123; //多少桶链(桶号) for (int i = 0; i &lt; bucket_size; ++i) &#123; node* cur = bucket[i]-&gt;next; while (cur) &#123; cout &lt;&lt; cur-&gt;key &lt;&lt; " "; cur = cur-&gt;next; &#125; &#125; cout &lt;&lt; endl;&#125;void Test7()&#123; int a[10] = &#123; 49, 38, 35, 97, 76, 73, 27, 49, 34, 78 &#125;; cout &lt;&lt; "桶排序" &lt;&lt; endl; BucketSort(a, 10, 10); //桶数据最大才97，所以需要10个桶&#125;归并排序算法描述取得数组中的最大数，并取得位数；arr为原始数组，从最低位开始取每个位组成radix数组；对radix进行计数排序（利用计数排序适用于小范围数的特点）动图演示代码描述LSD+MSD1234//伪代码如下RADIXSORT(A,d) for i = 1 to d use a stable sort to sort array A on digit i表排序算法描述又称间接排序，排序时不调整元素的实际位置，而是定义一个额外的数组作为“表”（table）。根据元素的关键字大小来调整元素对应下标在表中的位置。动图演示物理排序经过表排序后，得到了排好序的table数组，但是如果需要调整元素的实际位置，那就需要物理排序。分别对每个环里面的元素按照物理排序，取出环中一个元素，保存在临时变量中，由于空出了一个位置，就可以将该位置上本来应该放置的元素移动过来，又空出一个位置，继续移动，直到环中元素访问完成，将保存在临时变量中的元素放在最后一个空位。这就完成了一个环的物理排序。如何判断一个环的结束：每访问一个空位i后，就令table[i]=i。当发现table[i]==i时，环就结束了。代码描述12345678910111213141516171819202122struct Element &#123; ElementType Data; // data可以是任意类型 ElementType key; // 关键字只要可比即可&#125;// 物理排序过程 Elements = 元素数组， table = 表数组，假设表数组已经排好了void Sort(Element[] Elements, int[] table, int N) &#123; for (i = 0; i &lt; N; i++) &#123; Temp = Elements[i]; int j = i; while (table[j] != j) &#123; Elements[j] = Elements[table[j]]; // 把实际该置于j位置的元素置于J NextIndex = table[j]; // 记录下一个元素的位置 table[j] = j; j = NextIndex; // 让j跳到下一个元素 &#125; if (Elements[j] != Temp) &#123; // 说明该环不止一个元素，需要进行temp的赋值 Elements[j] = Temp; &#125; &#125;&#125;复杂度分析​ * 最好情况：初始即有序​ * 最坏情况：​ * 有$⌊N/2⌋$个环，每个环包含2个元素需要$⌊3N/2⌋$次元素移动 $T=O(mN)$，$m$是每个元素复制的时间其他排序算法睡眠排序Stooge排序Bogo 排序参考资料https://mooc.study.163.com/course/1000033001?tid=2402970002https://www.cnblogs.com/chengxiao/category/880910.htmlhttps://blog.csdn.net/qq_36528114/article/details/78667034《漫画算法：小灰的算法之旅》]]></content>
      <tags>
        <tag>算法学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 3 - Image Sentiment Classification]]></title>
    <url>%2F2019%2F04%2F11%2FHomework-3-Image-Sentiment-Classification%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，情感图片分类情感图片分类导入相关库123import pandas as pdimport numpy as npfrom matplotlib import pyplot as plt数据处理123df_train = pd.read_csv("train.csv")df_test = pd.read_csv("test.csv")df_train.info()1sentiment = ['angry','disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']123456789plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure(figsize=(6,4))ax = fig.add_subplot(111)# plt.hist(train_df['label'], 7)df_train['label'].value_counts().plot(kind='bar')plt.ylabel("人数")plt.show()df_train['label'].value_counts()12123456# 传入来的每张图片feature都是字符串X = df_train.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X = np.array(X.map(lambda x: x.reshape(48,48,1)).values.tolist()) X = (X/255.0*0.99) + 0.001X.shape# (28709, 48, 48, 1)12345X_test = df_test.feature.apply(lambda x : np.array(x.split()).astype(np.float32))X_test = np.array(X_test.map(lambda x: x.reshape(48,48,1)).values.tolist()) X_test = (X_test/255.0*0.99) + 0.001X_test.shape# (7178, 48, 48, 1)123y = df_train.label.values.reshape(-1, 1)y.shape# (28709, 1)123456# 查看一张图片fig = plt.figure(figsize=(3, 3))ax = fig.subplots(1)ax.imshow(X[0].reshape(48, 48), cmap = 'gray')plt.xlabel(sentiment[int(y[0])])plt.show()开始训练123456789import tensorflow as tffrom tensorflow import kerasfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, \ Flatten, BatchNormalization, InputLayer, Input, Activationfrom tensorflow.keras.optimizers import RMSpropfrom tensorflow.keras.models import Modelfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard1234# one-hoty = keras.utils.to_categorical(y, 7)y.shape# (28709, 7)1234from sklearn.model_selection import train_test_splitX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3)X_train.shape, X_valid.shape, y_train.shape, y_valid.shape# ((20096, 48, 48, 1), (8613, 48, 48, 1), (20096, 7), (8613, 7))12CNN1234567891011121314151617181920212223242526272829303132cnn_model = Sequential()# 48*48*1 -&gt; 48*48*64cnn_model.add(Conv2D(filters= 64, kernel_size=(5, 5), strides=1, padding='Same', activation='relu',input_shape=(48,48,1)))# -&gt;24*24*64 cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25)) # -&gt; 24*24*128cnn_model.add(Conv2D(filters= 128, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;12*12*128cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.25))# -&gt; 12*12*256cnn_model.add(Conv2D(filters= 256, kernel_size=(5,5), strides=1, padding='Same', activation='relu'))# -&gt;6*6*256cnn_model.add(MaxPooling2D(pool_size=(2,2), strides=2))cnn_model.add(BatchNormalization())cnn_model.add(Dropout(0.5))# -&gt;9216cnn_model.add(Flatten())cnn_model.add(BatchNormalization())# -&gt;128cnn_model.add(Dense(128, activation='relu')) # -&gt;7cnn_model.add(BatchNormalization())cnn_model.add(Dense(7, activation='softmax'))12batch_size = 64epochs = 100 # 1012# optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234cnn_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])123456789101112131415161718# class_weight = 'auto', 用于处理skewed classes# 也可以model.compile(.... metrics=[Precision, Recall])# 或者# from sklearn.utils.class_weight import compute_class_weight# class_weight = compute_class_weight(class_weight='balanced',# classes=np.unique(train_data.label),# y=train_data.label)# model.fit(... class_weight=class_weight)# import os# os.environ["CUDA_VISIBLE_DEVICES"] = "0"cnn_result = cnn_model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto') # callbacks=[tensorboard]12345678910# 查看accfig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(cnn_result.history['loss'], label='Train Loss')ax[0].plot(cnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(cnn_result.history['acc'], label='Train acc')ax[1].plot(cnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()DNN123456789101112131415161718192021222324#DNN modelinputs = Input(shape=(48,48,1))dnn = Flatten()(inputs)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.25)(dnn)dnn = Dense(1024)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(512)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('relu')(dnn)dnn = Dropout(0.5)(dnn)dnn = Dense(7)(dnn)dnn = BatchNormalization(axis = -1)(dnn)dnn = Activation('softmax')(dnn)1234567outputs = dnndnn_model = Model(inputs=inputs, outputs=outputs)# tensorboard = TensorBoard(log_dir="logs/&#123;&#125;".format(time()))dnn_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])123456dnn_result = model.fit(x = X_train, y = y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid), verbose =2, class_weight = 'auto')123456789fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(dnn_result.history['loss'], label='Train Loss')ax[0].plot(dnn_result.history['val_loss'], label='Validation Loss')ax[1].plot(dnn_result.history['acc'], label='Train acc')ax[1].plot(dnn_result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()保存h5文件12cnn_model.save('cnn.h5')dnn_model.save('dnn.h5')模型分析混淆矩阵绘制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from sklearn.metrics import confusion_matrixdef plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues): """ This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. """ if not title: if normalize: title = 'Normalized confusion matrix' else: title = 'Confusion matrix, without normalization' # Compute confusion matrix cm = confusion_matrix(y_true, y_pred) # Only use the labels that appear in the data #classes = classes[unique_labels(y_true, y_pred)] if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] print("Normalized confusion matrix") else: print('Confusion matrix, without normalization') print(cm) fig, ax = plt.subplots() im = ax.imshow(cm, interpolation='nearest', cmap=cmap) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=title, ylabel='True label', xlabel='Predicted label') # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor") # Loop over data dimensions and create text annotations. fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha="center", va="center", color="white" if cm[i, j] &gt; thresh else "black") fig.tight_layout() return ax1234567cnn_predict = cnn_model.predict(X_valid)cnn_cls = np.argmax(cnn_predict, axis=1)dnn_predict = dnn_model.predict(X_valid)dnn_cls = np.argmax(dnn_predict, axis=1)y_label = data = [np.argmax(one_hot)for one_hot in y_valid]1plot_confusion_matrix(y_label, cnn_cls, sentiment)1plot_confusion_matrix(y_label, dnn_cls, sentiment)错误图片查看1234true_cls = pd.Series(y_label, name='true_cls')[y_label!=cnn_cls]wrong_cls = pd.Series(cnn_cls, name='wrong_cls')[y_label!=cnn_cls]wrong = pd.concat([true_cls, wrong_cls], axis = 1)特征图查看卷积核的可视化参考资料http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HWhttps://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Titanic: Machine Learning from Disaster]]></title>
    <url>%2F2019%2F04%2F06%2FTitanic-Machine-Learning-from-Disaster%2F</url>
    <content type="text"><![CDATA[Kaggle入坑题目数据处理导入基础库1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns读取并处理数据1234train_data = pd.read_csv('train.csv')test_data = pd.read_csv('test.csv')# train_data.columns.valuestrain_data.head()#查看前五行1train_data.info()#查看数据信息123456# 查看空值数目print('train_data:')print(train_data.isnull().sum())print("-"*20)print('test_data:')print(test_data.isnull().sum())train_data中891位乘客信息，其中属性Age，Cabin和Embarked有数据丢失。test_data中，属性Age，Fare和Cabin有数据丢失。对于缺少数据，使用年龄的中位数填补年龄空值，去除丢失Embarked，Fare属性的数据。对于Cabin属性，种类很多，观察其是否丢失与是否存活之间的关系，将Cabin属性分为是否丢失两类。1234567891011121314plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.figure() fig.set(alpha=0.2) # 设定图表颜色alpha参数 not_null_cabin = train_data.Survived[train_data.Cabin.isnull()].value_counts() null_cabin = train_data.Survived[train_data.Cabin.notnull()].value_counts() df = pd.DataFrame(&#123;'Cabin丢失':not_null_cabin , 'Cabin未丢失':null_cabin&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("是否存活") plt.ylabel("人数") plt.show()# train_data.Cabin.value_counts()12345678910111213141516171819202122 # 使用年龄的中位数填补年龄空值train_data['Age'].fillna(train_data['Age'].median(), inplace = True)test_data['Age'].fillna(test_data['Age'].median(), inplace = True)# Cabin根据是否缺失分为两类train_data.loc[ (train_data.Cabin.notnull()), 'Cabin' ] = "Yes"train_data.loc[ (train_data.Cabin.isnull()), 'Cabin' ] = "No"test_data.loc[ (test_data.Cabin.notnull()), 'Cabin' ] = "Yes"test_data.loc[ (test_data.Cabin.isnull()), 'Cabin' ] = "No" # 去除丢失Embarked，Fare的数据train_data = train_data.dropna()# test_data补充test_data.loc[ (test_data.Fare.isnull()), 'Fare' ] = test_data['Fare'].median()# 去除无关数据PassengerId和Tickettrain_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)test_id = test_data.PassengerIdtest_data.drop(['PassengerId', 'Ticket'], axis=1, inplace = True)train_data.info()# test_data.info()进一步处理数据12345678910111213141516171819202122232425262728293031323334def clean_data(dataset): # 新建家庭大小属性：堂兄弟/妹个数 + 父母与小孩个数 dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 # 是否仅有自身一人，1：是，0：否 dataset['IsAlone'] = 1 dataset['IsAlone'].loc[dataset['FamilySize'] &gt; 1] = 0 # 分离出称谓 Mr/Mrs/Miss/Master... dataset['Title'] = dataset['Name'].str.split(", ", expand=True)[1].str.split(".", expand=True)[0] # 比起把Fare和Age当作特征列，将这些列的值进行二进制转换更为合理。 # Scikit-Learn 开发了新的估计器 KBinsDiscretizer 来执行这一操作。 # 它不仅将这些值转换为二进制码，还会对其进行编码。 # 也可以通过 Pandas 的 cut 和 qcut 函数手动完成这个过程。 # qcut据这些值的频率来选择箱子的均匀间隔，即每个箱子中含有的数的数量是相同的 dataset['FareBin'] = pd.qcut(dataset['Fare'], 4) # cut将根据值本身来选择箱子均匀间隔，即每个箱子的间距都是相同的 dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)clean_data(train_data)clean_data(test_data) # print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (train_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctrain_data['Title'] = train_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(train_data['Title'].value_counts())12345678# print(train_data['Title'].value_counts())stat_min = 10 # 判断某一称谓人数是否大于10title_names = (test_data['Title'].value_counts() &lt; stat_min) # 判称谓人数小于10的转换为Misctest_data['Title'] = test_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)print(test_data['Title'].value_counts())123456789101112# from sklearn.preprocessing import OneHotEncoder, LabelEncoder# LabelEncoder()对不连续的数字或文本编号# 这里使用one-hotdummy = ['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Title', 'Embarked', 'FamilySize', 'IsAlone','FareBin', 'AgeBin'] Target = ['Survived']train_dummy = pd.get_dummies(train_data[dummy])test_dummy = pd.get_dummies(test_data[dummy])train_dummy.columns.values1train_dummy = train_dummy.drop(['Age', 'Fare'], axis=1)123456from sklearn import model_selectiontrain_x_dummy, valid_x_dummy, train_y, valid_y = model_selection.train_test_split \ (train_dummy, train_data[Target], random_state = 0)train_x_dummy.shape, valid_x_dummy.shape, train_y.shape, valid_y.shape# ((666, 26), (223, 26), (666, 1), (223, 1))进行数据分析12345678for x in ['Pclass', 'Sex','SibSp', 'Parch', 'Cabin', 'Embarked', \ 'FamilySize', 'IsAlone', 'Title']: # 打印和Survived相关的属性，'Age'和'Fare' 除外 print('Survival Correlation by:', x) print(train_data[[x, "Survived"]].groupby(x, as_index=False).mean()) print('-'*10, '\n')# print(pd.crosstab(train_x_dummy.Pclass, train_y.Survived))12345678910111213141516171819202122232425262728293031323334# plt.figure(figsize=[18,10])# plt.subplot(231)# plt.boxplot(x=train_data['Fare'], showmeans = True, meanline = True)# plt.subplot(232)# plt.boxplot(train_data['Age'], showmeans = True, meanline = True)# plt.subplot(233)# plt.boxplot(train_data['FamilySize'], showmeans = True, meanline = True)# plt.subplot(234)# plt.hist(x = [train_data[train_data['Survived']==1]['Fare'], \# train_data[train_data['Survived']==0]['Fare']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(235)# plt.hist(x = [train_data[train_data['Survived']==1]['Age'], \# train_data[train_data['Survived']==0]['Age']], # stacked=True, label = ['Survived','Dead'])# plt.subplot(236)# plt.hist(x = [train_data[train_data['Survived']==1]['FamilySize'], \# train_data[train_data['Survived']==0]['FamilySize']], # stacked=True, label = ['Survived','Dead'])fig, saxis = plt.subplots(2,3,figsize=(18,10))sns.boxplot(y = 'Fare', hue = 'Survived', data = train_data, ax = saxis[0,0])sns.boxplot(y = 'Age', hue = 'Survived', data = train_data, ax = saxis[0,1])sns.boxplot(y = 'FamilySize', hue = 'Survived', data = train_data, ax = saxis[0,2])sns.barplot(x = 'FareBin', y = 'Survived', data = train_data, ax = saxis[1,0])sns.barplot(x = 'AgeBin', y = 'Survived', data = train_data, ax = saxis[1,1])sns.barplot(x = 'FamilySize', y = 'Survived', data = train_data, ax = saxis[1,2])123456789fig, saxis = plt.subplots(2, 3,figsize=(18,10))sns.barplot(x = 'Embarked', y = 'Survived', data=train_data, ax = saxis[0,0])sns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=train_data, ax = saxis[0,1])sns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=train_data, ax = saxis[0,2])sns.pointplot(x = 'FareBin', y = 'Survived', data=train_data, ax = saxis[1,0])sns.pointplot(x = 'AgeBin', y = 'Survived', data=train_data, ax = saxis[1,1])sns.pointplot(x = 'FamilySize', y = 'Survived', data=train_data, ax = saxis[1,2])12345fig, saxis = plt.subplots(1,3,figsize=(18,5))sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=train_data, ax = saxis[0])sns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=train_data, ax = saxis[1])sns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=train_data, ax = saxis[2])12345678910fig, saxis = plt.subplots(1, 2,figsize=(12,5))sns.pointplot(x="FamilySize", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[0])sns.pointplot(x="Pclass", y="Survived", hue="Sex", data=train_data, palette=&#123;"male": "blue", "female": "pink"&#125;, markers=["*", "o"], linestyles=["-", "--"], ax = saxis[1])123e = sns.FacetGrid(train_data, col = 'Embarked')e.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')e.add_legend()1234e = sns.FacetGrid(train_data, hue = 'Survived', aspect=4 )e.map(sns.kdeplot, 'Age', shade= True )e.set(xlim=(0 , train_data['Age'].max()))e.add_legend()123e = sns.FacetGrid(train_data, row = 'Sex', col = 'Pclass', hue = 'Survived')e.map(plt.hist, 'Age', alpha = .75)e.add_legend()12e = sns.pairplot(train_data, hue = 'Survived', palette = 'deep', height=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )e.set(xticklabels=[])12345678910111213141516171819# 热力图def correlation_heatmap(df): _ , ax = plt.subplots(figsize =(14, 12)) colormap = sns.diverging_palette(220, 10, as_cmap = True) # 创建分散颜色 _ = sns.heatmap( df.corr(), cmap = colormap, square=True, # 设置热力图矩阵小块形状，默认值是False cbar_kws=&#123;'shrink':.9 &#125;, # 热力图侧边绘制颜色刻度条时，相关字体设置，默认值是None ax=ax, annot=True, # 在热力图每个方格写入数据；如果是矩阵，在热力图每个方格写入该矩阵对应位置数据，默认值是False linewidths=0.1,vmax=1.0, linecolor='white', # vmax热力图的颜色取值最大范围 annot_kws=&#123;'fontsize':12 &#125; ) plt.title('Pearson Correlation of Features', y=1.05, size=15)correlation_heatmap(train_data)选择MLA进行训练1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from sklearn import ensemble, gaussian_process, linear_model, naive_bayes, \ neighbors, svm, tree, discriminant_analysisfrom xgboost import XGBClassifierfrom sklearn.linear_model import stochastic_gradientMLA = [ # 集成方法 ensemble.AdaBoostClassifier(), ensemble.BaggingClassifier(), ensemble.ExtraTreesClassifier(), ensemble.GradientBoostingClassifier(), ensemble.RandomForestClassifier(), # 高斯过程 gaussian_process.GaussianProcessClassifier(), # 广义线性模型 linear_model.LogisticRegressionCV(), linear_model.PassiveAggressiveClassifier(max_iter=5), linear_model.RidgeClassifierCV(), stochastic_gradient.SGDClassifier(max_iter=5), linear_model.Perceptron(max_iter=5), # 朴素贝叶斯 naive_bayes.BernoulliNB(), naive_bayes.GaussianNB(), #邻近算法 neighbors.KNeighborsClassifier(), # 支持向量机 svm.SVC(probability=True), svm.NuSVC(probability=True), svm.LinearSVC(), # 树 tree.DecisionTreeClassifier(), tree.ExtraTreeClassifier(), # 判别分析 discriminant_analysis.LinearDiscriminantAnalysis(), discriminant_analysis.QuadraticDiscriminantAnalysis(), # xgboost XGBClassifier() ]123456789101112131415161718192021222324252627282930313233343536from sklearn.preprocessing import StandardScaler# X = pd.concat([train_x_dummy,valid_x_dummy])# y = pd.concat([train_y,valid_y])# 防止线性相关X = train_dummy.drop(['Sex_male', 'Cabin_No'], axis=1)y = train_data[Target]# 标准化scaler = StandardScaler()scaler.fit(X) X = scaler.fit_transform(X)MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', \ 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']MLA_compare = pd.DataFrame(columns = MLA_columns)cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )row_index = 0for alg in MLA: MLA_name = alg.__class__.__name__ MLA_compare.loc[row_index, 'MLA Name'] = MLA_name MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params()) cv_results = model_selection.cross_validate(alg, X, y.values.ravel(), cv = cv_split, return_train_score=True) MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean() MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean() MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3 row_index+=1MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)MLA_compare123456sns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare)plt.title('Machine Learning Algorithm Accuracy Score \n')plt.xlabel('Accuracy Score (%)')plt.ylabel('Algorithm')plt.show()12345678910111213141516171819202122232425262728vote_est = [ # Ensemble Methods ('ada', ensemble.AdaBoostClassifier()), ('bc', ensemble.BaggingClassifier()), ('etc',ensemble.ExtraTreesClassifier()), ('gbc', ensemble.GradientBoostingClassifier()), ('rfc', ensemble.RandomForestClassifier()), # Gaussian Processes ('gpc', gaussian_process.GaussianProcessClassifier()), # GLM ('lr', linear_model.LogisticRegressionCV()), # Navies Bayes ('bnb', naive_bayes.BernoulliNB()), ('gnb', naive_bayes.GaussianNB()), # Nearest Neighbor ('knn', neighbors.KNeighborsClassifier()), # SVM ('svc', svm.SVC(probability=True)), # xgboost ('xgb', XGBClassifier())]1234567891011121314151617181920212223import warningswarnings.filterwarnings("ignore")# Hard Votevote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')vote_hard_cv = model_selection.cross_validate(vote_hard, X, y.values.ravel(), cv = cv_split)vote_hard.fit(X, y.values.ravel())print("Hard Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['train_score'].mean()*100)) print("Hard Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_hard_cv['test_score'].mean()*100))print("Hard Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilitiesvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')vote_soft_cv = model_selection.cross_validate(vote_soft, X, y.values.ravel(), cv = cv_split)vote_soft.fit(X, y.values.ravel())print("Soft Voting Training w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['train_score'].mean()*100)) print("Soft Voting Test w/bin score mean: &#123;:.2f&#125;". format(vote_soft_cv['test_score'].mean()*100))print("Soft Voting Test w/bin score 3*std: +/- &#123;:.2f&#125;". format(vote_soft_cv['test_score'].std()*100*3))print('-'*10)进行网格调参123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136import timegrid_n_estimator = [10, 50, 100, 300]grid_ratio = [.1, .25, .5, .75, 1.0]grid_learn = [.01, .03, .05, .1, .25]grid_max_depth = [2, 4, 6, 8, 10, None]grid_min_samples = [5, 10, .03, .05, .10]grid_criterion = ['gini', 'entropy']grid_bool = [True, False]grid_seed = [0]grid_param = [ [&#123; #AdaBoostClassifier 'n_estimators': grid_n_estimator, #default=50 'learning_rate': grid_learn, #default=1 #'algorithm': ['SAMME', 'SAMME.R'], #default=’SAMME.R 'random_state': grid_seed &#125;], [&#123; #BaggingClassifier 'n_estimators': grid_n_estimator, #default=10 'max_samples': grid_ratio, #default=1.0 'random_state': grid_seed &#125;], [&#123; #ExtraTreesClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'random_state': grid_seed &#125;], [&#123; #GradientBoostingClassifier #'loss': ['deviance', 'exponential'], #default=’deviance’ 'learning_rate': [.05], 'n_estimators': [300], #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse” 'max_depth': grid_max_depth, #default=3 'random_state': grid_seed &#125;], [&#123; #RandomForestClassifier 'n_estimators': grid_n_estimator, #default=10 'criterion': grid_criterion, #default=”gini” 'max_depth': grid_max_depth, #default=None 'oob_score': [True], #default=False 'random_state': grid_seed &#125;], [&#123; #GaussianProcessClassifier 'max_iter_predict': grid_n_estimator, #default: 100 'random_state': grid_seed &#125;], [&#123; #LogisticRegressionCV 'fit_intercept': grid_bool, #default: True #'penalty': ['l1','l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs 'random_state': grid_seed &#125;], [&#123; #BernoulliNB 'alpha': grid_ratio, #default: 1.0 &#125;], #GaussianNB [&#123;&#125;], [&#123; #KNeighborsClassifier 'n_neighbors': [1,2,3,4,5,6,7], #default: 5 'weights': ['uniform', 'distance'], #default = ‘uniform’ 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'] &#125;], [&#123; #SVC #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1,2,3,4,5], #default=1.0 'gamma': grid_ratio, #edfault: auto 'decision_function_shape': ['ovo', 'ovr'], #default:ovr 'probability': [True], 'random_state': grid_seed &#125;], [&#123; #XGBClassifier 'learning_rate': grid_learn, #default: .3 'max_depth': [1,2,4,6,8,10], #default 2 'n_estimators': grid_n_estimator, 'seed': grid_seed &#125;] ]start_total = time.perf_counter() for clf, param in zip (vote_est, grid_param): #print(clf[1]) #vote_est is a list of tuples, index 0 is the name and index 1 is the algorithm #print(param) start = time.perf_counter() best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'roc_auc') best_search.fit(X, y.values.ravel()) run = time.perf_counter() - start best_param = best_search.best_params_ print('The best parameter for &#123;&#125; is &#123;&#125; with a runtime of &#123;:.2f&#125; seconds.'\ .format(clf[1].__class__.__name__, best_param, run)) clf[1].set_params(**best_param) run_total = time.perf_counter() - start_totalprint('Total optimization time was &#123;:.2f&#125; minutes.'.format(run_total/60))print('-'*10)1234567891011121314151617181920212223242526# Hard Vote or majority rules w/Tuned Hyperparametersgrid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')grid_hard_cv = model_selection.cross_validate(grid_hard, X, y.values.ravel(), cv = cv_split)grid_hard.fit(X, y.values.ravel())print("Hard Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['train_score'].mean()*100)) print("Hard Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].mean()*100))print("Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_hard_cv['test_score'].std()*100*3))print('-'*10)#Soft Vote or weighted probabilities w/Tuned Hyperparametersgrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')grid_soft_cv = model_selection.cross_validate(grid_soft, X, y.values.ravel(), cv = cv_split)grid_soft.fit(X, y.values.ravel())print("Soft Voting w/Tuned Hyperparameters Training w/bin score mean: &#123;:.2f&#125;"\ .format(grid_soft_cv['train_score'].mean()*100)) print("Soft Voting w/Tuned Hyperparameters Test w/bin score mean: &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].mean()*100))print("Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- &#123;:.2f&#125;"\ . format(grid_soft_cv['test_score'].std()*100*3))print('-'*10)保存预测结果1234X_test = test_dummy.drop(['Sex_male', 'Cabin_No'], axis=1).valuesy_test = grid_hard.predict(X_test)f = pd.DataFrame(&#123;'PassengerId':test_id.values, 'Survived':y_test&#125;)f.to_csv("C:/Users/DHX17/Jupyter/Kaggle/titanic/ans.csv", index=False)参考资料https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MNIST 手写数字识别]]></title>
    <url>%2F2019%2F03%2F31%2FMNIST-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[摘要使用神经网络进行MNIST手写数字识别《Python神经网络编程》代码导入相关库123import numpy as npfrom scipy.special import expitimport matplotlib.pyplot as plt搭建神经网络12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class neuralNetwork: def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes self.lr = learningrate #随机初始化权重，当然权重在0到1之间（不含）。这里通过高斯函数产生权重 #其中均值是零，方差是1/sqrt(连接数)，当然连接数等于节点数。后一个是矩阵hnodes行， # numpy.random.normal(loc=0.0, scale=1.0, size=None) self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes)) self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes)) self.activation_function = lambda x: expit(x) pass def train(self,inputs_list, targets_list): inputs = np.array(inputs_list, ndmin=2).T targets = np.array(targets_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who,hidden_outputs) final_outputs = self.activation_function(final_inputs) #误差 output_errors = targets - final_outputs hidden_errors = np.dot(self.who.T, output_errors) #权重更新 self.who += self.lr*np.dot((output_errors*final_outputs*(1.0 - final_outputs)), np.transpose(hidden_outputs)) self.wih += self.lr*np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), np.transpose(inputs)) pass def query(self, inputs_list): inputs = np.array(inputs_list, ndmin=2).T hidden_inputs = np.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = np.dot(self.who, hidden_outputs) final_outputs = self.activation_function(final_inputs) return final_outputs数据处理1234567input_nodes = 784 hidden_nodes = 100 output_nodes = 10 learning_rate = 0.3n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)1234#导入训练数据 training_data_file = open('./mnist_train_100.csv','r') training_data_list = training_data_file.readlines() training_data_file.close()1training_data_list[0]123all_values = training_data_list[0].split(',')image_array = np.asfarray(all_values[1:]).reshape((28, 28))plt.imshow(image_array, cmap='Greys', interpolation='None')进行数据训练123456789for record in training_data_list: all_values = record.split(',') #输入数据数学处理，使其在0.01到1之间.颜色的范围是[0,255] inputs = (np.asfarray(all_values[1:])/255.0*0.99)+0.01 #初始化目标值，使其在0.01到0.99之间 targets = np.zeros(output_nodes) + 0.01 targets[int(record[0])] = 0.99 n.train(inputs,targets) pass123test_data_file = open('./mnist_test_10.csv','r') test_data_list = test_data_file.readlines() test_data_file.close()12345678all_values = test_data_list[0].split(',')correct_label = int(all_values[0])image_array = np.asfarray(all_values[1:]).reshape((28,28))plt.imshow(image_array,cmap='Greys')inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01outputs = n.query(inputs)label = np.argmax(outputs) #argmax返回最大值的索引值print("correct:&#123;0&#125;, predict:&#123;1&#125;".format(correct_label, label))1234567891011121314151617181920scorecard = []#多个数据检测for record in test_data_list: all_values = record.split(',') correct_label = int(all_values[0]) print(correct_label, "correct label") inputs = (np.asfarray(all_values[1:])/255.0*0.99) + 0.01 outputs = n.query(inputs) label = np.argmax(outputs) print(label, "network's answer") if(label == correct_label): scorecard.append(1) else: scorecard.append(0) print(scorecard) # [1, 0, 1, 1, 1, 1, 1, 0, 0, 0]123scorecard_array = np.asarray(scorecard)print("performance = ", scorecard_array.sum() / scorecard_array.size)# performance = 0.6一些改进调整学习率多次运行改变网络形状基于Keras导入相关库12345678910111213141516import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sn# sklearn的mnist数据集是8x8# from sklearn.datasets import load_digits# from sklearn.preprocessing import LabelBinarizer# from sklearn.model_selection import train_test_split# from sklearn.metrics import confusion_matriximport kerasfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flattenfrom keras.optimizers import RMSpropfrom keras.preprocessing.image import ImageDataGeneratorfrom keras.callbacks import ModelCheckpoint处理数据1234567891011121314151617181920212223242526# 导入数据# digits = load_digits()# X = digits.data# y = digits.target# X /= 8# y = LabelBinarizer().fit_transform(y)# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)# X_train.shape, X_test.shape, y_train.shape, y_test.shape# (X_train, y_train), (X_test, y_test) = mnist.load_data()path = 'datasets/mnist.npz' f = np.load(path)X_train, y_train = f['x_train'], f['y_train']X_test, y_test = f['x_test'], f['y_test']f.close()X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)X_test = X_test.reshape(X_test.shape[0], 28, 28, 1) X_train = X_train.astype('float32')X_test = X_test.astype('float32') X_train /= 255 X_test /= 255X_train.shape, X_test.shape# ((60000, 28, 28, 1), (10000, 28, 28, 1))1234y_train = keras.utils.to_categorical(y_train, 10)y_test = keras.utils.to_categorical(y_test, 10)y_train.shape, y_test.shape# ((60000, 10), (10000, 10))12plt.imshow(X_train[0].reshape(28, 28), cmap='Greys', interpolation='None')y_train[0]搭建神经网络12345678910111213141516171819model = Sequential() # 使用3x3的卷积核，激活函数为ReLU# 池化核大小2x2model.add(Conv2D(filters=28, kernel_size=(3, 3), padding='Same', activation='relu',input_shape=(28,28,1)))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25)) model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))model.add(MaxPooling2D(pool_size=(2,2), strides=1))model.add(Dropout(0.25))# Fully connected layer.model.add(Flatten())model.add(Dense(256, activation='relu')) model.add(Dropout(0.25)) #10 outputsmodel.add(Dense(10, activation='softmax'))12batch_size = 250epochs = 1012optimizer = RMSprop(lr = 0.001, decay=0.0)# optimizer = keras.optimizers.Adam()1234model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])12345678910111213141516171819# reduce_lr = LearningRateScheduler(function)reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, #每次减少学习率的因子，学习率将以lr = lr*factor的形式被减少 patience=10, # 当patience个epoch过去而模型性能不提升时，学习率减少的动作会被触发 verbose=0, mode='auto', # 在min模式下，如果检测值触发学习率减少。在max模式下，当检测值不再上升则触发学习率减少。 min_delta=0.0001, # 用来确定是否进入检测值的“平原区” cooldown=0, # 学习率减少后，会经过cooldown个epoch才重新进行正常操作 min_lr=0.00001)gen = ImageDataGenerator(# featurewise_center=True,对输入的图片每个通道减去每个通道对应均值 # featurewise_std_normalization=True,每张图片减去样本均值, 使得每个样本均值为0 rotation_range=20, # 旋转范围 zoom_range= 0.2, # 缩放范围 width_shift_range=0.2, # 水平平移范围 height_shift_range=0.2, # 垂直平移范围 horizontal_flip=True) #水平反转train_generator = gen.flow(X_train, y_train, batch_size=batch_size)123456result = model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs= epochs, validation_data=(X_test, y_test), verbose =2, callbacks=[reduce_lr])12345678910fig,ax = plt.subplots(2,1,figsize=(10,10))ax[0].plot(result.history['loss'], label='Train Loss')ax[0].plot(result.history['val_loss'], label='Validation Loss')ax[1].plot(result.history['acc'], label='Train acc')ax[1].plot(result.history['val_acc'], label='Validation Acc')plt.legend()plt.show()参考资料《Python神经网络编程》代码https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork/]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 2 - Income Prediction]]></title>
    <url>%2F2019%2F03%2F29%2FHomework-2-Income-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业二，收入预测收入预测导入相关库123456import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom random import shufflefrom math import floor, logfrom numpy.linalg import inv数据处理12train_data = pd.read_csv("train.csv")train_data.info()1train_data.head()对数据进行可视化观察12345678910111213141516171819202122232425262728293031323334353637383940plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False #用来正常显示负号fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231)train_data.income.value_counts().plot(kind='bar')plt.xlabel("收入情况")plt.ylabel("人数") ax2 = plt.subplot(232)train_data.education.value_counts().plot(kind='bar')plt.ylabel("人数")# #plt.xticks([1, 2, 3])plt.xlabel("教育情况")ax3 = plt.subplot(233)plt.hist(train_data.age,20)# #plt.yticks([0, 1])plt.ylabel('人数')plt.xlabel('年龄')ax4 = plt.subplot(234)train_data.sex.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel('性别')ax5 = plt.subplot(235)train_data.workclass.value_counts().plot(kind='bar')plt.ylabel("人数") plt.xlabel("所属企业类型")ax6 = plt.subplot(236)train_data.race.value_counts().plot(kind='bar')plt.ylabel("人数")plt.xlabel("种族")# 调整每隔子图之间的距离 plt.tight_layout()plt.show()1234567# 将&gt;50K转为1，&lt;=50K转为0， 方便数据可视化操作# 使用train_data.income[train_data.income == " &gt;50K"] = 1# 会弹出A value is trying to be set on a copy of a slice from a DataFrame.# 修改数据最好不要使用链式操作train_data.loc[train_data.income == " &gt;50K", 'income'] = 1train_data.loc[train_data.income ==" &lt;=50K", 'income'] = 0train_data.head()12345678910fig = plt.figure() fig.set(alpha=0.2) male = train_data.income[train_data.sex == ' Male'].value_counts() female = train_data.income[train_data.sex == ' Female'].value_counts() df=pd.DataFrame(&#123;'male':male, 'female':female&#125;) df.plot(kind='bar', stacked=True) plt.xlabel("收入情况") plt.ylabel("人数") plt.show()train_data[["sex", "income"]].groupby(['sex'], as_index=False).mean().sort_values(by='income', ascending=False)查看学历对应的收入情况12345678910111213141516171819202122232425262728293031323334fig = plt.subplots(figsize=(16,8),dpi=80)plt.figure(1)ax1 = plt.subplot(231) train_data.income[train_data.education == ' HS-grad'].value_counts().plot(kind='bar', label=" HS-grad", color='red') ax1.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax1.legend(["HS研究生学位"], loc='best') ax2 = plt.subplot(232) train_data.income[train_data.education == ' Doctorate'].value_counts().plot(kind='bar', label=" Doctorate", color='lightblue') ax2.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax2.legend(["博士学位"], loc='best') ax3 = plt.subplot(233) train_data.income[train_data.education == ' Masters'].value_counts().plot(kind='bar', label=" Masters", color='blue') ax3.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax3.legend(["硕士学位"], loc='best') ax4 = plt.subplot(234) train_data.income[train_data.education == ' Bachelors'].value_counts().plot(kind='bar', label=" Bachelors", color='pink') ax4.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax4.legend(["学士学位"], loc='best') ax5 = plt.subplot(235) train_data.income[train_data.education == ' Assoc-voc'].value_counts().plot(kind='bar', label=" Assoc-voc", color='steelblue') ax5.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax5.legend(["副学士学位"], loc='best') ax6 = plt.subplot(236) train_data.income[train_data.education == ' Some-college'].value_counts().plot(kind='bar', label=" Some-college", color='#FA2479') ax6.set_xticklabels(["&gt;50K", "&lt;=50K"], rotation=0) ax6.legend(["本科生学位"], loc='best') plt.show()12# 各国家人数train_data.native_country.value_counts()将所有含有缺失值的行都去掉，可以使用RandomForestRegressor填补缺失12345678910111213141516171819202122232425262728# from sklearn.ensemble import RandomForestRegressor# 使用RandomForestRegressor填补缺失的年龄属性# def set_missing_workclass(df):# # 把已有的数值型特征取出来丢进RandomForestRegressor中# workclass_df = df[['workclass','age', 'education', 'race', 'income']]## # 提取未知值和已知值# known_workclass = workclass_df[workclass_df.workclass.notnull()].values# unknown_workclass = workclass_df[workclass_df.workclass.isnull()].values # # y即目标workclass# y = known_workclass[:, 0] # # X即特征属性值# X = known_workclass[:, 1:] # # fit到RandomForestRegressor之中# rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)# rfr.fit(X, y) # # 用得到的模型进行未知年龄结果预测# predictedAges = rfr.predict(unknown_workclass[:, 1::]) # # 用得到的预测结果填补原缺失数据# df.loc[ (df.workclass.isnull()), 'workclass' ] = predictedAges # return df, rfr# train_data, rfr = set_missing_ages(train_data)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def dataProcess_X(raw_data): if "income" in raw_data.columns: # data = raw_data.drop(["sex", 'income'], axis=1) data = raw_data.drop(["income"], axis=1) else: # data = raw_data.drop(["sex"], axis=1) pass # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'], value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() # 剔除没有用的数据特征fnlwgt # fnlwgt: 连续性数值变量；人口普查员认为观察值的人数 data.drop(['fnlwgt'], axis=1) # 处理sex data.loc[data.sex == " Male", 'sex'] = 1 data.loc[data.sex ==" Female", 'sex'] = 0 listObjectColumn = [col for col in data.columns if data[col].dtypes == "object"] #读取非数字的column listNonObjedtColumn = [x for x in list(data) if x not in listObjectColumn] ObjectData = data[listObjectColumn] NonObjectData = data[listNonObjedtColumn] # NonObjectData.insert(0 ,"sex", (raw_data["sex"] == " Female").astype(np.int)) # 使用pd.get_dummies()特征因子化 # 也可以使用one-hot # from sklearn.feature_extraction import DictVectorizer # dict_vect=DictVectorizer(sparse=False) # X_train=dict_vect.fit_transform(X_train.to_dict(orient='record')) # X_test=dict_vect.transform(X_test.to_dict(orient='record')) # dict_vect.feature_names_ ObjectData = pd.get_dummies(ObjectData) data = pd.concat([NonObjectData, ObjectData], axis=1) X = data.astype("int64") # 标准化 X = (X - X.mean()) / X.std() return np.array(X)def dataProcess_y(raw_data): data = raw_data.copy() # 处理数据无效字符 data_clean = data.replace(regex=[r'\?|\.|\$'],value=np.nan) data = data_clean.dropna(how='any') # data_clean.isnull().any() try: # y = data['income'] # y = pd.DataFrame((y ==' &gt;50K').astype("int64"), columns=["income"]) data.loc[data.income == " &gt;50K", 'income'] = 1 data.loc[data.income == " &lt;=50K", 'income'] = 0 except: pass y = np.array(data['income']) y = y.reshape(y.shape[0], 1) return yX_train = dataProcess_X(train_data)y_train = dataProcess_y(train_data)X_train.shape, y_train.shape# ((30162, 103), (30162, 1))导入测试集12345test_data = pd.read_csv("test.csv")X_test = dataProcess_X(train_data)y_test = dataProcess_y(train_data)X_test.shape, y_test.shape# ((30162, 103), (30162, 1))12345678910111213141516171819202122def _shuffle(X, y): #X and Y are np.array randomize = np.arange(X.shape[0]) np.random.shuffle(randomize) return (X[randomize], y[randomize])def split_valid_set(X, y, percentage): all_size = X.shape[0] valid_size = int(floor(all_size * percentage)) X, y = _shuffle(X, y) X_valid, y_valid = X[ : valid_size], y[ : valid_size] X_train, y_train = X[valid_size:], y[valid_size:] return X_train, y_train, X_valid, y_valid# 也可用sklearn函数打散数据# from sklearn.model_selection import train_test_split# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=1)X_train, y_train, X_valid, y_valid = split_valid_set(X_train, y_train, 0.1)X_train.shape, y_train.shape, X_valid.shape, y_valid.shape# ((27146, 103), (27146, 1), (3016, 103), (3016, 1))Generative方法123456789101112131415161718192021222324252627282930313233343536373839404142def train(X_train, y_train): # vaild_set_percetange = 0.1 # X_train, Y_train, X_valid, Y_valid = split_valid_set(X, Y, vaild_set_percetange) #Gussian distribution parameters train_data_size = X_train.shape[0] cnt1 = 0 cnt2 = 0 mu1 = np.zeros((1, X_train.shape[1])) mu2 = np.zeros((1, X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: # &gt;50k mu1 += X_train[i] cnt1 += 1 else: mu2 += X_train[i] cnt2 += 1 mu1 /= cnt1 mu2 /= cnt2 sigma1 = np.zeros((X_train.shape[1], X_train.shape[1])) sigma2 = np.zeros((X_train.shape[1], X_train.shape[1])) for i in range(train_data_size): if y_train[i] == 1: sigma1 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu1), X_train[i] - mu1) else: sigma2 += np.dot(np.transpose(X_train[i].reshape(1,103) - mu2), X_train[i] - mu2) sigma1 /= cnt1 sigma2 /= cnt2 shared_sigma = (float(cnt1) / train_data_size) * sigma1 + (float(cnt2) / train_data_size) * sigma2 N1 = cnt1 N2 = cnt2 return mu1, mu2, shared_sigma, N1, N2mu1, mu2, shared_sigma, N1, N2 = train(X_train, y_train)mu1.shape, mu2.shape, shared_sigma.shape, N1, N212345def sigmoid(z): res = 1 / (1.0 + np.exp(-z)) return np.clip(res, 1e-8, (1-(1e-8)))# from scipy.special import expit1234567891011121314151617def valid(funname, X, Y, mu1, mu2, shared_sigma, N1, N2): sigma_inv = inv(shared_sigma) w = np.dot((mu1-mu2), sigma_inv) X_t = X.T b = (-0.5) * np.dot(np.dot(mu1, sigma_inv), mu1.T) + (0.5) * np.dot(np.dot(mu2, sigma_inv), mu2.T) + np.log(float(N1)/N2) a = np.dot(w,X_t) + b y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))valid("train", X_train, y_train, mu1, mu2, shared_sigma, N1, N2)valid("valid", X_valid, y_valid, mu1, mu2, shared_sigma, N1, N2)valid("test", X_test, y_test, mu1, mu2, shared_sigma, N1, N2)# train acc = 0.837140# valid acc = 0.851459# test acc = 0.838572Discriminative方法mini_batch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# mini_batch def train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) l_rate = 0.0001 batch_size = 32 train_dataz_size = len(X_train) step_num = int(floor(train_dataz_size / batch_size)) epoch_num = 300 list_cost = [] total_loss = 0.0 for epoch in range(1, epoch_num): total_loss = 0.0 X_train, y_train = _shuffle(X_train, y_train) for idx in range(1, step_num): X = X_train[idx*batch_size:(idx+1)*batch_size] #32*104 Y = y_train[idx*batch_size:(idx+1)*batch_size] #32*1 s_grad = np.zeros((1,len(X[0]))) z = np.dot(X, w.T) # 32*104*104*1 y = sigmoid(z) # squeeze 函数：从数组的形状中删除单维度条目，即把shape中为1的维度去掉 # loss = y - np.squeeze(Y) loss = y - Y cross_entropy = -1 * (np.dot(Y.T, np.log(y)) + np.dot((1 - Y.T),\ np.log(1 - y)))/ len(Y) total_loss += cross_entropy[0][0] #grad = np.sum(-1 * X * (np.squeeze(Y) - y).reshape((batch_size, 1)), axis=0) grad = np.sum(np.dot((y - Y).T, X), axis=0) #1*32*32*104 # grad = np.dot(X.T, loss) w = w - l_rate * grad # s_grad += grad ** 2 # ada = np.sqrt(s_grad) # w = w - l_rate * grad / ada list_cost.append(total_loss) # valid(X_valid, Y_valid, w) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wdef valid(funname, X, Y, w): a = np.dot(w, X.T) y = sigmoid(a) y_ = np.around(y) result = (np.squeeze(Y) == y_) print(f'&#123;funname&#125; acc = %f' % (float(result.sum()) / X.shape[0]))X_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)Ada12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Adadef train(X_train, y_train): w = np.zeros((1, len(X_train[0]))) s_grad = np.zeros((1, len(X_train[0]))) l_rate = 0.1 epoch_num = 10000 list_cost = [] total_loss = 0.0 X = X_train y = y_train for epoch in range(epoch_num): z = np.dot(X, w.T) # n*104*104*1 Y = sigmoid(z) loss = Y - y cross_entropy = -1 * (np.dot(y.T, np.log(Y)) + np.dot((1 - y.T),\ np.log(1 - Y)))/ len(y) if abs(total_loss - cross_entropy[0][0]) &lt; 10**-9: break else: total_loss = cross_entropy[0][0] list_cost.append(total_loss) grad = np.sum(np.dot((Y - y).T, X), axis=0) #1*104 s_grad += grad**2 ada = np.sqrt(s_grad) w = w - l_rate * grad / ada print("times:", len(list_cost)) plt.plot(np.arange(len(list_cost)), list_cost) plt.title("Train Process") plt.xlabel("epoch_num") plt.ylabel("Cost Function (Cross Entropy)") plt.show() return wX_train_logi = np.concatenate((np.ones((X_train.shape[0], 1)), X_train), axis=1)X_valid_logi = np.concatenate((np.ones((X_valid.shape[0], 1)), X_valid), axis=1)X_test_logi = np.concatenate((np.ones((X_test.shape[0], 1)), X_test), axis=1)w_train = train(X_train_logi, y_train)valid("train", X_train_logi, y_train, w_train)valid("valid", X_valid_logi, y_valid, w_train)valid("test", X_test_logi, y_test, w_train)使用Kreas12from keras.models import Sequentialfrom keras.layers import Dense, Activation1234567891011121314151617model = Sequential()model.add(Dense(units=600, activation='sigmoid', input_dim=103))model.add(Dense(units=600, activation='sigmoid'))model.add(Dense(units=1, activation='sigmoid'))model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])model.fit(X_train, y_train, batch_size=32, epochs=50)score = model.evaluate(X_test, y_test)result = np.squeeze(model.predict(X_test))# print('Total loss on Testing set: ', score[0])# print('Accuracy of Testing set: ', score[1])# Total loss on Testing set: 0.2154487861520091# Accuracy of Testing set: 0.90295736357400741234y_ = np.around(result).astype(np.int)result = (np.squeeze(y_test) == y_)print('Test acc = %f' % (float(result.sum()) / X_test.shape[0]))# Test acc = 0.902957使用Tensorflow搭建3层神经网络1import tensorflow as tf12345678910111213141516171819xs = tf.placeholder(tf.float32, [None, 103])ys = tf.placeholder(tf.float32, [None, 1])w1 = tf.Variable(tf.random_normal([103, 600], stddev=1, seed=1))w2 = tf.Variable(tf.random_normal([600, 600], stddev=1, seed=1))w3 = tf.Variable(tf.random_normal([600, 1], stddev=1, seed=1))a = tf.nn.relu(tf.matmul(xs, w1))b = tf.sigmoid(tf.matmul(a, w2))y = tf.sigmoid(tf.matmul(b, w3))# a = tf.matmul(xs, w1)# y = tf.matmul(a, w2)y_ = tf.round(y)cross_entropy = -tf.reduce_mean(ys*tf.log(tf.clip_by_value(y,1e-10,1.0)))train_step = tf.train.GradientDescentOptimizer(0.001).minimize(cross_entropy)correct_prediction = tf.equal(y_, ys)accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))1234567891011result = Nonewith tf.Session() as sess: init = tf.global_variables_initializer() sess.run(init) for step in range(101): # training sess.run(train_step, feed_dict=&#123;xs: X_train, ys: y_train&#125;) result = sess.run(y, feed_dict=&#123;xs: X_train, ys: y_train&#125;) if step % 100 == 0: print("accuracy:",sess.run(accuracy, feed_dict=&#123;xs: X_train, ys: y_train&#125;))# accuracy: 0.7285788随机森林和XGBoost1234# 随机森林from sklearn import metricsfrom sklearn.ensemble import RandomForestClassifierrfc=RandomForestClassifier()123# XGBoostfrom xgboost import XGBClassifierxgbc=XGBClassifier()123456# 选取k-1折的数据进行模型训练import warningswarnings.filterwarnings("ignore")from sklearn.model_selection import cross_val_score cross_val_score(rfc,X_train, y_train.ravel(),cv=5).mean(), cross_val_score(xgbc,X_train, y_train.ravel(),cv=5).mean()# (0.8434758405223647, 0.8613788898712886)12345#默认随机森林预测rfc.fit(X_train, y_train)rfc_y_predict = rfc.predict(X_valid)rfc.score(X_valid, y_valid)# 0.839854111405835512345# XGBoost预测xgbc.fit(X_train, y_train)xgbc_y_predict = xgbc.predict(X_valid)xgbc.score(X_valid, y_valid)# 0.862068965517241312345from sklearn.metrics import classification_reportprint('随机森林的预测准确率:')print(classification_report(y_valid, rfc_y_predict, target_names=['result'])) print('XGBoost的预测准确率:') print(classification_report(y_valid, xgbc_y_predict, target_names=['result']))保存数据1234# df = pd.DataFrame(&#123;"id": np.arange(1, 16282), "label": y_&#125;)# if not os.path.exists(output_dir):# os.mkdir(output_dir)# df.to_csv(os.path.join(output_dir + 'nn_output.csv'), sep='\t', index=False)参考资料http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homework 1 - PM2.5 Prediction]]></title>
    <url>%2F2019%2F03%2F25%2FHomework-1-PM2-5-Prediction%2F</url>
    <content type="text"><![CDATA[摘要李宏毅机器学习作业一，PM2.5预测PM2.5预测1. 导入相关库123import numpy as npimport pandas as pdimport matplotlib.pyplot as plt2. 数据处理1234train_data = pd.read_csv("train.csv")# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data.info() # 240条数据，每条数据18个feature12345# 将RAINFALL值为NR的数据置0train_data[train_data[train_data['Obvservations']=='RAINFALL'].iloc[:,3:] == 'NR'] = 0# pm2_5 = train_data[train_data['Obvservations']=='PM2.5'].iloc[:,3:]# pm2_5.info()train_data[train_data['Obvservations']=='RAINFALL'].head()123456789101112tempxlist = [] tempylist = [] # 一天内总共有24-10+1 =15条记录for j in range(0, 240): for i in range(15): tempx = np.array(train_data.iloc[j*18:(j+1)*18,3:].iloc[:, i:i+9], float).reshape(1, 18*9) tempy = np.array(train_data.iloc[j*18+9:j*18+10,3:].iloc[:, i+9], float) # tempx = pm2_5.iloc[:,i:i+9] #使用前9小时数据作为feature # tempy = pm2_5.iloc[:,i+9] #使用第10个小数数据作为lable tempxlist.append(tempx) tempylist.append(tempy)12345678# X = np.array(pd.concat(tempxlist), float)X = np.concatenate(tempxlist, axis=0)# 插入列向量[1;1;...;1;]X = np.insert(X, 0, values=np.ones((1, X.shape[0])), axis=1)# y = np.array(pd.concat(tempylist), float)y = np.concatenate(tempylist, axis=0)y = y.reshape(y.shape[0], 1)X, y12X.shape, y.shape# ((3600, 163), (3600, 1))12# 特征归一化(Feature Scaling)X = (X - X.mean()) / X.std()12345# 代价函数def cost(y, w): temp = np.dot(X,w) loss = np.square(y - temp) return np.sum(loss)/len(y)3. 开始训练adagrad123456789101112131415161718192021# adagraddef ada(X, y, w, lr, iteration, lambdaL2): list_cost = [] s_grad = np.zeros([len(X[0]), 1]) for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2*w s_grad += grad**2 ada = np.sqrt(s_grad) w = w - lr*grad/ada return w, list_costlr_ada = 10w_ada = np.zeros([X.shape[1], 1])w_ada, list_cost_ada = ada(X, y, w_ada, lr_ada, 10000, 0.)cost(y, w_ada)# 38.190334888655144SGD1234567891011121314151617181920# SGDdef SGD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X,w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) rand = np.random.randint(0, len(X)) grad = X[rand].reshape(X.shape[1], 1)*loss[rand].reshape(loss.shape[1], 1)/len(X) + lambdaL2*w w = w - lr*grad return w, list_costw_sgd = np.zeros([X.shape[1], 1])lr_sgd = 0.1w_sgd, list_cost_sgd = SGD(X, y, w_sgd, lr_sgd, 10000, 0.)cost(y, w_sgd)# 209.00938349734912GD1234567891011121314151617def GD(X, y, w, lr, iteration, lambdaL2): list_cost = [] for i in range(iteration): hypo = np.dot(X, w) loss = hypo - y cost = np.sum(loss**2)/len(X) list_cost.append(cost) grad = np.dot(X.T, loss)/len(X) + lambdaL2 * w w = w - lr*grad return w, list_costw_gd = np.zeros([X.shape[1], 1])lr_gd = 0.01w_gd, list_cost_gd = GD(X, y, w_gd, lr_gd, 10000, 0.)cost(y, w_gd)# 44.80863160107732正规方程1234#close formw_cf = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)cost_wcf = np.sum((X.dot(w_cf)-y)**2) / len(X)hori = [cost_wcf for i in range(10000-3)]12345678910fig = plt.figure(figsize=(12,8))plt.plot(np.arange(len(list_cost_ada[3:])), list_cost_ada[3:], 'b', label="ada")plt.plot(np.arange(len(list_cost_sgd[3:])), list_cost_sgd[3:], 'g', label='sgd')plt.plot(np.arange(len(list_cost_gd[3:])), list_cost_gd[3:], 'r', label='gd')plt.plot(np.arange(len(list_cost_ada[3:])), hori, 'y--', label='close-form')plt.title('Train Process')plt.xlabel('Iteration')plt.ylabel('Loss Function(Quadratic)')plt.legend()plt.show()4. 使用Sklearn1234from sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import cross_val_predictfrom sklearn import metrics1234567X_train, X_test, y_train, y_test = train_test_split(X[:, 1:], y, random_state=1)linreg = LinearRegression()linreg.fit(X_train, y_train)predicted = cross_val_predict(linreg, X, y, cv=10)# linreg.intercept_, linreg.coef_metrics.mean_squared_error(y, predicted)# 42.576599287222915. 使用Tensorflow1import tensorflow as tf1234567891011121314151617181920212223242526272829303132333435363738def linear_regression(X_data, y_data, alpha, epoch, optimizer=tf.train.GradientDescentOptimizer): tf.reset_default_graph() xs = tf.placeholder(tf.float32, [None, X_data.shape[1]]) ys = tf.placeholder(tf.float32, [None, 1]) W = tf.Variable(tf.random_uniform([X_data.shape[1], 1], -10.0, 10.0)) y_pred = tf.matmul(xs, W) loss = tf.reduce_mean(tf.square(ys - y_pred)) if optimizer == tf.train.GradientDescentOptimizer: alpha = 0.01 elif optimizer == tf.train.AdagradOptimizer: alpha = 10 elif optimizer == tf.train.AdamOptimizer: alpha = 0.1 elif optimizer == tf.train.FtrlOptimizer: alpha = 10 elif optimizer == tf.train.RMSPropOptimizer: alpha = 10 opt = optimizer(learning_rate=alpha) opt_operation = opt.minimize(loss) # run the session with tf.Session() as sess: sess.run(tf.global_variables_initializer()) loss_data = [] for i in range(epoch): _, loss_val, W_val = sess.run([opt_operation, loss, W], feed_dict=&#123;xs: X_data, ys: y_data&#125;) loss_data.append(loss_val) if len(loss_data) &gt; 1 and np.abs(loss_data[-1] - loss_data[-2]) &lt; 10 ** -9: break tf.reset_default_graph() return &#123;'loss': loss_data, 'parameters': W_val&#125; # just want to return in row vector format123456789101112131415161718epoch = 10000alpha = 0.0001# 各种优化函数optimizer_dict=&#123;'GD': tf.train.GradientDescentOptimizer, 'Adagrad': tf.train.AdagradOptimizer, #'Adam': tf.train.AdamOptimizer, #'Ftrl': tf.train.FtrlOptimizer, #'RMS': tf.train.RMSPropOptimizer #'Momentum': tf.train.MomentumOptimizer两个参数 &#125;results = []t_loss = dict()for name in optimizer_dict: # 这里X应该是X[:, 1:] res = linear_regression(X, y, alpha, epoch, optimizer=optimizer_dict[name]) res['name'] = name t_loss[name] = res results.append(res)1234567891011121314fig, ax = plt.subplots(figsize=(16, 9))for res in results: loss_data = res['loss'] ax.plot(np.arange(len(loss_data[10:])), loss_data[10:], label=res['name'])ax.plot(np.arange(len(list_cost_ada[10:])), hori[0: 9990], label='close-form') ax.set_xlabel('epoch', fontsize=18)ax.set_ylabel('cost', fontsize=18)ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)ax.set_title('different optimizer', fontsize=18)plt.show()12t_loss["Adagrad"]["loss"][-1], t_loss["GD"]["loss"][-1]# (39.07505, 168.04092)6. 保存数据123test_data = pd.read_csv("test.csv")# pm2_5_test = test_data[test_data['AMB_TEMP'] == 'PM2.5'].iloc[:,2:]# pm2_5_test.info()1234# 对X_test进行一系列数据处理即可# X_test = np.array(pm2_5_test, float)# X_test = np.insert(X_test, 0, values=np.ones((1, X_test.shape[0])), axis=1)X_test12345#预测y_star = np.dot(X_test, w)y_pre = pd.read_csv("sampleSubmission.csv")y_pre.value = y_stary_pre.to_csv('predict.csv', index=False)参考资料http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.htmlhttps://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW]]></content>
      <categories>
        <category>李宏毅机器学习作业</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好]]></title>
    <url>%2F2019%2F02%2F28%2F%E4%BD%A0%E5%A5%BD%2F</url>
    <content type="text"><![CDATA[你好呀~]]></content>
  </entry>
</search>
